{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"faq/","title":"Frequently Asked Questions","text":"What is deployKF? Is commercial support available for deployKF? Which ML and AI tools are in deployKF? Who maintains deployKF? Who has adopted deployKF? How are Kubeflow and deployKF related? How can I get involved with deployKF? How is deployKF licensed?"},{"location":"faq/#what-is-deploykf","title":"What is deployKF?","text":"<p>deployKF builds world-class Data and Machine Learning Platforms on any Kubernetes cluster, in any cloud or environment. Our vision is that anyone with Kubernetes experience can effortlessly build, maintain, and support a custom Data and ML Platform for their organization, without requiring specialized MLOps knowledge.</p> <p>Key features of deployKF include:</p> <ul> <li>Support for leading tools from Kubeflow and more</li> <li>Intuitive and centralized configs to manage all aspects of the platform</li> <li>Seamless in-place upgrades and config rollouts</li> <li>Connect with existing cluster dependencies like Istio and cert-manager</li> <li>Native support for GitOps via ArgoCD</li> </ul>"},{"location":"faq/#is-commercial-support-available-for-deploykf","title":"Is commercial support available for deployKF?","text":"<p>Yes! The founder of deployKF (Mathew Wicks), operates a US-based company named Aranui Solutions to provide commercial support and advisory services for organizations building ML &amp; Data Platforms on Kubernetes.</p> <p>Email <code>sales@aranui.solutions</code> to learn more!</p>"},{"location":"faq/#which-ml-and-ai-tools-are-in-deploykf","title":"Which ML and AI tools are in deployKF?","text":"<p>deployKF supports all tools from the Kubeflow Ecosystem including Kubeflow Pipelines and Kubeflow Notebooks. We are actively adding support for other popular tools such as MLflow, Airflow, and Feast.  For more information, please see our current and future tools!</p>"},{"location":"faq/#who-maintains-deploykf","title":"Who maintains deployKF?","text":"<p>deployKF was originally created by Mathew Wicks (GitHub: @thesuperzapper), a Kubeflow lead and maintainer of the popular Apache Airflow Helm Chart. deployKF is a community-led project that welcomes contributions from anyone who wants to help.</p>"},{"location":"faq/#who-has-adopted-deploykf","title":"Who has adopted deployKF?","text":"<p>deployKF is a new project, and we are still building our community, consider adding your organization to our list of adopters.</p>"},{"location":"faq/#how-are-kubeflow-and-deploykf-related","title":"How are Kubeflow and deployKF related?","text":"<p>Kubeflow and deployKF are two different but related projects. For more details, please see our deployKF vs Kubeflow comparison.</p>"},{"location":"faq/#how-can-i-get-involved-with-deploykf","title":"How can I get involved with deployKF?","text":"<p>The deployKF project is a welcoming community of contributors and users.  We encourage participation from anyone who shares our mission of making it easy to build open ML Platforms on Kubernetes. For more details, see our community page.</p>"},{"location":"faq/#how-is-deploykf-licensed","title":"How is deployKF licensed?","text":"<p>deployKF is licensed under the Apache License 2.0. However, some of the tools that deployKF can help deploy are licensed differently. Please ensure you are aware of how the tools you deploy are licenced.</p>"},{"location":"about/architecture/","title":"Architecture of deployKF","text":"<p>This document takes a detailed look at the architecture of deployKF and its components.</p>"},{"location":"about/architecture/#overview","title":"Overview","text":"<p>deployKF has two user-facing components:</p> <ul> <li>deployKF CLI: a command line program who's primary purpose is to generate a set of folders containing GitOps-ready Kubernetes manifests, from configs provided in one or more values files</li> <li>deployKF Generator: a versioned <code>.zip</code> package which contains all the templates and helpers needed to generate the output folders</li> </ul>"},{"location":"about/architecture/#deploykf-cli","title":"deployKF CLI","text":"<p>The deployKF CLI is a command line program written in Go, it is developed in the <code>deployKF/cli</code> GitHub repo.</p>"},{"location":"about/architecture/#steps-of-the-deploykf-generate-command","title":"Steps of the <code>deploykf generate</code> command","text":"<ol> <li>Locate the deployKF Generator to use, depending on which arguments were provided:<ul> <li><code>--source-version</code>: download a generator ZIP from the releases of <code>deploykf/deploykf</code> GitHub repo</li> <li><code>--source-path</code>: use a local generator ZIP or folder with unzipped generator files</li> </ul> </li> <li>Unzip or copy the generator into a temporary folder:<ul> <li>The folder is automatically deleted after the command is run, or if the command fails</li> </ul> </li> <li>Read the <code>.deploykf_generator</code> marker file from the root of the generator:<ul> <li>The <code>.deploykf_generator</code> file contains JSON data with information like the <code>generator_schema</code> version</li> <li>If the CLI does not support the encountered <code>generator_schema</code> version, the CLI will exit with an error</li> </ul> </li> <li>Clean the folder currently at the <code>--outut-dir</code> target:<ul> <li>The CLI will only remove the contents of a non-empty target if there is a <code>.deploykf_output</code> marker file at its root</li> </ul> </li> <li>Render the manifests into <code>--outut-dir</code> in two phases, using the provided <code>--values</code> files:<ol> <li>PHASE 1: render the <code>.gomplateignore_template</code> files into <code>.gomplateignore</code> files (still in the temporary folder)<ul> <li>Note, these files behave like <code>.gitignore</code> files, and are used to exclude files from the output in the second phase</li> </ul> </li> <li>PHASE 2: render the templates from the <code>templates</code> folder into the <code>--output-dir</code><ul> <li>Note, the resulting output folder will be structured identically to the <code>templates</code> folder (subject to the <code>.gomplateignore</code> files)</li> </ul> </li> </ol> </li> </ol>"},{"location":"about/architecture/#notes-about-the-deploykf-generate-command","title":"Notes about the <code>deploykf generate</code> command","text":"<ul> <li>The generator templates are rendered using a version of gomplate that is embedded in the deployKF CLI:<ul> <li>The template delimiters are set to <code>{{&lt;</code> and <code>&gt;}}</code> as to avoid conflicts with Helm and other Go-like templates</li> </ul> </li> <li>The output folder will contain a <code>.deploykf_output</code> marker file which contains the following information in JSON format:<ul> <li><code>generated_at</code>: the time the generator was run</li> <li><code>source_version</code>: the source version that was used (if <code>--source-version</code> was provided)</li> <li><code>source_path</code>: the path of the source artifact that was used </li> <li><code>source_hash</code>: the SHA256 hash of the source artifact that was used</li> <li><code>cli_version</code>: the version of the deployKF CLI that was used</li> </ul> </li> </ul>"},{"location":"about/architecture/#deploykf-generator","title":"deployKF Generator","text":"<p>The deployKF Generator is a versioned ZIP package which contains all the templates and helpers needed to generate the output folders, it is developed in the <code>deployKF/deployKF</code> GitHub repo.</p>"},{"location":"about/architecture/#structure-of-generator-zip","title":"Structure of generator ZIP","text":"<pre><code>.\n\u251c\u2500\u2500 .deploykf_generator\n\u251c\u2500\u2500 default_values.yaml\n\u251c\u2500\u2500 helpers/\n\u2514\u2500\u2500 templates/\n    \u251c\u2500\u2500 .gomplateignore_template\n    \u251c\u2500\u2500 app-of-apps.yaml\n    \u251c\u2500\u2500 argocd/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 kustomization.yaml\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-core/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-dependencies/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-opt/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-tools/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 kubeflow-dependencies/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 kubeflow-tools/\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 namespaces/\n    \u2514\u2500\u2500 manifests/\n        \u251c\u2500\u2500 deploykf-core/\n        \u251c\u2500\u2500 deploykf-dependencies/\n        \u251c\u2500\u2500 deploykf-opt/\n        \u251c\u2500\u2500 deploykf-tools/\n        \u251c\u2500\u2500 kubeflow-dependencies/\n        \u2514\u2500\u2500 kubeflow-tools/\n</code></pre>"},{"location":"about/architecture/#purpose-of-each-item-under","title":"Purpose of each item under <code>.</code>","text":"<ul> <li><code>.deploykf_generator</code> a file with metadata about the generator, in JSON format, including the <code>generator_schema</code> version</li> <li><code>default_values.yaml</code> a file with the default values for this generator version</li> <li><code>helpers/</code> a folder with helpers that are used in the <code>templates/</code></li> <li><code>templates/</code> a folder with templates that are used to generate the output</li> </ul>"},{"location":"about/architecture/#purpose-of-each-item-under-templates","title":"Purpose of each item under <code>templates/</code>","text":"<ul> <li><code>.gomplateignore_template</code> is used to generate the <code>.gomplateignore</code> files in the first phase of the <code>deploykf generate</code> command</li> <li><code>app-of-apps.yaml</code> a template for an Argo CD app of apps, which points to <code>./argocd/kustomization.yaml</code> (this is the only manifest which is manually applied by the user)</li> <li><code>argocd/</code> a folder with templates of Argo CD applications</li> <li><code>manifests/</code> a folder with templates of Kubernetes manifests</li> </ul>"},{"location":"about/architecture/#purpose-of-each-item-under-templatesargocd","title":"Purpose of each item under <code>templates/argocd/</code>","text":"<ul> <li><code>kustomization.yaml</code> a Kustomize file pointing to the other Argo CD applications and namespaces (this is the target of the <code>app-of-apps.yaml</code>)</li> <li><code>deploykf-core/</code> a folder with templates of Argo CD applications for \"core components of deployKF\"</li> <li><code>deploykf-dependencies/</code> a folder with templates of Argo CD applications for \"dependencies of deployKF\"</li> <li><code>deploykf-opt/</code> a folder with templates of Argo CD applications for \"optional embedded applications that are used when external alternatives are not configured\"</li> <li><code>deploykf-tools/</code> a folder with templates of Argo CD applications for \"MLOps tools from the deployKF ecosystem\"</li> <li><code>kubeflow-dependencies/</code> a folder with templates of Argo CD applications for \"dependencies of Kubeflow's MLOps tools\"</li> <li><code>kubeflow-tools/</code> a folder with templates of Argo CD applications for \"MLOps tools from the Kubeflow ecosystem\"</li> <li><code>namespaces/</code> a folder with the templates for Kubernetes Namespaces</li> </ul>"},{"location":"about/architecture/#purpose-of-each-item-under-templatesmanifests","title":"Purpose of each item under <code>templates/manifests/</code>","text":"<ul> <li><code>deploykf-core/</code> a folder with templates of Kubernetes manifests for \"core components of deployKF\"</li> <li><code>deploykf-dependencies/</code> a folder with templates of Kubernetes manifests for \"dependencies of deployKF\"</li> <li><code>deploykf-opt/</code> a folder with templates of Kubernetes manifests for \"optional embedded applications that are used when external alternatives are not configured\"</li> <li><code>deploykf-tools/</code> a folder with templates of Kubernetes manifests for \"MLOps tools from the deployKF ecosystem\"</li> <li><code>kubeflow-dependencies/</code> a folder with templates of Kubernetes manifests for \"dependencies of Kubeflow's MLOps tools\"</li> <li><code>kubeflow-tools/</code> a folder with templates of Kubernetes manifests for \"MLOps tools from the Kubeflow ecosystem\"</li> </ul>"},{"location":"about/community/","title":"Community","text":"<p>The deployKF project is a welcoming community of contributors and users. We encourage participation from anyone who shares our mission of making it easy to build open ML Platforms on Kubernetes.</p>"},{"location":"about/community/#vendor-partnerships","title":"Vendor Partnerships","text":"<p>Are you a vendor who wants to support deployKF or use it in your product?</p> <p>Email <code>team@deploykf.org</code> to discuss!</p>"},{"location":"about/community/#slack","title":"Slack","text":"<p>The deployKF community uses the Kubeflow Slack for informal discussions among users and contributors. After you join, connect with us on the <code>#deploykf</code> channel!</p> <p> Join the Kubeflow / deployKF Slack</p>"},{"location":"about/community/#mailing-lists","title":"Mailing Lists","text":"<p>The deployKF community has two mailing lists which are hosted on Google Groups.</p>"},{"location":"about/community/#users-mailing-list","title":"Users Mailing List","text":"<p>The deploykf-users mailing list is for users of deployKF to ask questions and share ideas.</p> <p> Join the User Mailing List</p>"},{"location":"about/community/#dev-mailing-list","title":"Dev Mailing List","text":"<p>The deploykf-dev mailing list is for contributors to deployKF to discuss development and design.</p> <p> Join the Contributor Mailing List</p>"},{"location":"about/kubeflow-vs-deploykf/","title":"Kubeflow vs deployKF","text":"<p>This page aims to unpack the differences between deployKF and Kubeflow.</p> <p>Packaged distributions of Kubeflow</p> <p>The other distributions of Kubeflow, are using mostly unmodified versions of the Kubeflow Manifests, so the following comparison is still relevant for them.</p>"},{"location":"about/kubeflow-vs-deploykf/#overview","title":"Overview","text":"<p>Kubeflow and deployKF are two different but related projects:</p> <ul> <li>deployKF is a tool for deploying Kubeflow and other MLOps tools on Kubernetes as a cohesive platform.</li> <li>Kubeflow is a project that develops MLOps tools, including Kubeflow Pipelines, Kubeflow Notebooks, Katib, and more.</li> </ul>"},{"location":"about/kubeflow-vs-deploykf/#kubeflow-vs-kubeflow-manifests","title":"Kubeflow vs Kubeflow Manifests","text":"<p>Before a more detailed comparison can be made, it is important to understand the distinction between Kubeflow and Kubeflow Manifests.</p>        Kubeflow             A project that develops many MLOps tools, including Kubeflow Pipelines, Kubeflow Notebooks, Katib, and more.             Kubeflow Manifests             A set of Kubernetes manifests that can be used to deploy Kubeflow's MLOps tools on Kubernetes, found in the <code>kubeflow/manifests</code> repo."},{"location":"about/kubeflow-vs-deploykf/#deploykf-vs-kubeflow-manifests","title":"deployKF vs Kubeflow Manifests","text":"<p>Hopefully, it is now clear the most useful comparison is between deployKF and Kubeflow Manifests (not the Kubeflow project as a whole).</p> <p>The following table compares the two projects across a number of different aspects:</p> Aspect deployKF Kubeflow Manifests Ease of Use <ul><li>Has a Helm-like interface, with values for configuring all aspects of the deployment (no need to edit Kubernetes YAML)</li><li>Upgrades are easy because config values only have minimal changes between versions.</li></ul> <ul><li>Manual patching of YAML manifests required for any changes.</li><li>Upgrades are difficult because new versions require starting from scratch with the new manifests.</li></ul> Capabilities <ul><li>Supports leading MLOps &amp; Data tools from both Kubeflow, and other projects.</li><li>When a config or secret is changed, any affected components are automatically restarted.</li><li>Includes Argo Server UI with integrated single sign-on where access is aligned to profile membership.</li><li>Optionally includes MinIO Console UI with integrated single sign-on where access is aligned to profile membership.</li></ul> <ul><li>Limited to Kubeflow's tools.</li></ul> Customization <ul><li>Allows selective deployment of MLOps tools through simple config values.</li><li>Allows brining custom versions of dependencies like Istio, cert-manager, MySQL, S3, and more.</li><li>Simplifies multi-cluster configurations with support for shared common values and environment-specific overlays.</li></ul> <ul><li>Less customizable, and requires difficult patching of YAML manifests.</li></ul> GitOps <ul><li>GitOps-native application with built-in support for Argo CD.</li></ul> <ul><li>Lacks native support for Argo CD or other GitOps tools.</li></ul> Security <ul><li>All secrets are randomly generated at install time, rather than being hardcoded in manifests.</li><li>Reduced attack vectors compared to Kubeflow Manifests, particularly in Istio configurations.</li><li>Utilizes standard auth tools (<code>oauth2-proxy</code>) over unknown tools (<code>arrikto/oidc-authservice</code>).</li><li>Automatically refreshes session cookies for active users in most cases.</li><li>Uses Istio with distroless images by default.</li><li>MinIO (or S3) access keys are isolated to each profile, not shared, and scoped to the minimum required permissions.</li><li>Supports using AWS IRSA instead of S3 access keys.</li></ul> <ul><li>Potentially more security vulnerabilities than deployKF.</li><li>Lacks session cookie refresh for active users in most cases.</li></ul>"},{"location":"about/kubeflow-vs-deploykf/#next-steps","title":"Next Steps","text":"<ul> <li>If you're ready to start migrating from Kubeflow to deployKF, check out the Migrate from Kubeflow Manifests guide.</li> </ul>"},{"location":"about/support/","title":"Get Support","text":"<p>While we aim to make deployKF as self-service as possible, sometimes things go wrong, or your use-case is a little different to the norm.  In these cases, you have a few options.</p>"},{"location":"about/support/#commercial-support","title":"Commercial Support","text":"<p>The founder of deployKF (Mathew Wicks), operates a US-based company named Aranui Solutions to provide commercial support and advisory services for organizations building ML &amp; Data Platforms on Kubernetes.</p> <p>Email <code>sales@aranui.solutions</code> to learn more!</p>"},{"location":"about/support/#open-source-support","title":"Open-Source Support","text":""},{"location":"about/support/#join-the-community","title":"Join the Community","text":"<p>If you have a question, or just want to chat, you can:</p> <ol> <li>Post a message on the Slack</li> <li>Start a thread on the Users Mailing List</li> </ol>"},{"location":"about/support/#raise-an-issue","title":"Raise an Issue","text":"<p>If you have found a bug, or have a feature request, you can raise an issue on the relevant GitHub repository:</p> Component Repository deployKF Generator <code>deployKF/deployKF</code> deployKF CLI <code>deployKF/cli</code> deployKF Website <code>deployKF/website</code>"},{"location":"guides/deploykf-cli/","title":"Install deployKF CLI","text":"<p>This guide explains how to install the deployKF command line interface.</p>"},{"location":"guides/deploykf-cli/#about-the-cli","title":"About the CLI","text":"<p>The deployKF CLI is used to generate GitOps-ready Kubernetes manifests from one or more values files. This example generates manifests under the <code>./GENERATOR_OUTPUT</code> directory from the <code>0.1.3</code> source version with the values specified in the <code>./custom-values.yaml</code> file.</p> <pre><code>deploykf \\\n  --source-version \"0.1.3\" \\\n  --values ./custom-values.yaml \\\n  --output-dir ./GENERATOR_OUTPUT\n</code></pre> <p>Source Version</p> <p>The <code>--source-version</code> is a tagged release of the deployKF generator, without the \"v\" prefix.</p> <p>The version of the CLI does NOT need to match the <code>--source-version</code>.  If a breaking change is ever needed, the CLI will fail to generate with newer source versions, and will print message telling you to upgrade the CLI.</p> <p>deployKF ArgoCD Plugin</p> <p>If you are using the deployKF ArgoCD Plugin, it is NOT necessary to install the deployKF CLI, this is because the manifests generation will happen inside the ArgoCD plugin, rather than on your local machine.</p>"},{"location":"guides/deploykf-cli/#install-the-cli","title":"Install the CLI","text":"<p>You can install the CLI on your local machine by following the instructions below that are appropriate for your operating system.</p> <p>Latest Version</p> <p>You can find the latest version of the CLI on the GitHub releases page, which is currently <code>v0.1.2</code>.</p> macOSLinuxWindows <p>macOS Security</p> <p>macOS has security features that will prevent you running the CLI if you downloaded it via a web browser. However, if you download it from the command line (for example, using <code>curl</code> or <code>wget</code>) it should be allowed to run.</p> <p>Either way, if you encounter a \"this app is from an unidentified developer\" error you can go to <code>System Preferences &gt; Privacy &amp; Security</code> and click <code>Open Anyway</code> to allow the CLI to run.</p> <p>The following commands will download the CLI for macOS and place it in <code>/usr/local/bin</code>:</p> <pre><code>DKF_CLI_VERSION=\"0.1.2\"\nDKF_CLI_ARCH=$(uname -m | sed -e 's/x86_64/amd64/')\nDFK_CLI_DEST=/usr/local/bin/deploykf\n\n# download the binary\nsudo curl -fL \"https://github.com/deploykf/cli/releases/download/v${DKF_CLI_VERSION}/deploykf-darwin-${DKF_CLI_ARCH}\" -o \"${DFK_CLI_DEST}\"\n\n# make the binary executable\nsudo chmod +x \"${DFK_CLI_DEST}\"\n\n# test the binary\ndeploykf version\n</code></pre> <p>Alternatively, you can manually download the latest <code>deploykf-darwin-{ARCH}</code> binary from the <code>v0.1.2</code> GitHub Release and place it in a directory on your <code>PATH</code> environment variable.</p> <p>Apple Silicon</p> <p>If you have a Mac with an Apple Silicon processor (M1, M2, etc), you will need to download the <code>deploykf-darwin-arm64</code> binary. If you have a Mac with an Intel processor, you will need to download the <code>deploykf-darwin-amd64</code> binary.</p> <p>The following commands will download the CLI for Linux and place it in <code>/usr/local/bin</code>:</p> <pre><code>DKF_CLI_VERSION=\"0.1.2\"\nDKF_CLI_ARCH=$(uname -m | sed -e 's/x86_64/amd64/' -e 's/aarch64/arm64/')\nDFK_CLI_DEST=/usr/local/bin/deploykf\n\n# download the binary\nsudo curl -fL \"https://github.com/deploykf/cli/releases/download/v${DKF_CLI_VERSION}/deploykf-linux-${DKF_CLI_ARCH}\" -o \"${DFK_CLI_DEST}\"\n\n# make the binary executable\nsudo chmod +x \"${DFK_CLI_DEST}\"\n\n# test the binary\ndeploykf version\n</code></pre> <p>Alternatively, you can manually download the latest <code>deploykf-linux-{ARCH}</code> binary from the <code>v0.1.2</code> GitHub Release and place it in a directory on your <code>PATH</code> environment variable.</p> <p>Processor Architecture</p> <p>If you are using a Linux machine with an ARM64 processor, you will need to download the <code>deploykf-linux-arm64</code> binary. If you are using a Linux machine with an X86/AMD64 processor, you will need to download the <code>deploykf-linux-amd64</code> binary.</p> <p>Elevated PowerShell Prompt</p> <p>You will need to run the following commands in an elevated PowerShell prompt (right-click and select <code>Run as administrator</code>).</p> <p>Windows Security</p> <p>Windows has security features that may prevent you from running the CLI. If you encounter a \"Windows protected your PC\" error you can click <code>More info</code> and then <code>Run anyway</code> to allow the CLI to run.</p> <p>The following PowerShell commands will download the CLI for Windows and place it in <code>C:\\Windows\\System32</code>:</p> <pre><code>$DKF_CLI_VERSION=\"0.1.2\"\n$DFK_CLI_DEST=\"C:\\Windows\\System32\\deploykf.exe\"\n\n# download the binary\nInvoke-WebRequest -Uri \"https://github.com/deploykf/cli/releases/download/v${DKF_CLI_VERSION}/deploykf-windows-amd64.exe\" -OutFile \"${DFK_CLI_DEST}\"\n\n# test the binary\ndeploykf version\n</code></pre> <p>Alternatively, you can manually download the latest <code>deploykf-windows-amd64.exe</code> binary from the <code>v0.1.2</code> GitHub Release and place it in a directory on your <code>PATH</code> environment variable.</p>"},{"location":"guides/getting-started/","title":"Getting Started","text":"<p>This guide will help you build your production ready deployKF ML Platform on any Kubernetes cluster.</p> <p>Related Guides</p> <ul> <li>Local Quickstart - quickly try deployKF on your local machine</li> <li>Migrate from Kubeflow Manifests - migrate from an existing Kubeflow deployment</li> </ul>"},{"location":"guides/getting-started/#about-deploykf","title":"About deployKF","text":"<p>Before starting, let's briefly introduce the deployKF project.</p> <p>What is deployKF?</p> <p>deployKF builds world-class Data and Machine Learning Platforms on any Kubernetes cluster, in any cloud or environment. Our vision is that anyone with Kubernetes experience can effortlessly build, maintain, and support a custom Data and ML Platform for their organization, without requiring specialized MLOps knowledge.</p> <p>Key features of deployKF include:</p> <ul> <li>Support for leading tools from Kubeflow and more</li> <li>Intuitive and centralized configs to manage all aspects of the platform</li> <li>Seamless in-place upgrades and config rollouts</li> <li>Connect with existing cluster dependencies like Istio and cert-manager</li> <li>Native support for GitOps via ArgoCD</li> </ul> <p>Do you offer commercial support?</p> <p>Yes! The founder of deployKF (Mathew Wicks), operates a US-based company named Aranui Solutions to provide commercial support and advisory services for organizations building ML &amp; Data Platforms on Kubernetes.</p> <p>Email <code>sales@aranui.solutions</code> to learn more!</p>"},{"location":"guides/getting-started/#common-questions","title":"Common Questions","text":"Which ML and AI tools are in deployKF? <p>deployKF supports all tools from the Kubeflow Ecosystem including Kubeflow Pipelines and Kubeflow Notebooks. We are actively adding support for other popular tools such as MLflow, Airflow, and Feast. </p> <p>For more information, please see our current and future tools!</p> Who maintains deployKF? <p>deployKF was originally created by Mathew Wicks (GitHub: @thesuperzapper), a Kubeflow lead and maintainer of the popular Apache Airflow Helm Chart. deployKF is a community-led project that welcomes contributions from anyone who wants to help.</p> Do you have a Slack or Mailing List? <p>Slack:</p> <ul> <li>The deployKF community uses the Kubeflow Slack for informal discussions among users and contributors.</li> <li>Find us on the <code>#deploykf</code> channel!</li> </ul> <p> Join the Kubeflow Slack</p> <p>Mailing Lists:</p> <ul> <li>The deploykf-users mailing list is for users of deployKF to ask questions and share ideas.</li> <li>The deploykf-dev mailing list is for contributors to deployKF to discuss development and design.</li> </ul> <p> Join the User Mailing List</p> <p> Join the Contributor Mailing List</p>"},{"location":"guides/getting-started/#media","title":"Media","text":"Intro / Demo - Kubeflow Community Call - July 2023"},{"location":"guides/getting-started/#0-modes-of-operation","title":"0. Modes of Operation","text":"<p>There are currently two \"modes of operation\" for deployKF, the modes differ by how manifests are generated and applied to your Kubernetes cluster.</p> Mode Description ArgoCD Plugin Mode (Recommended) The <code>deployKF ArgoCD Plugin</code> is used to generate and apply manifests from within ArgoCD. Manifests Repo Mode The <code>deployKF CLI</code> is used to generate manifests, the manifests are then committed to a git repo which ArgoCD can read from."},{"location":"guides/getting-started/#1-requirements","title":"1. Requirements","text":"<p>First, you need a Kubernetes cluster with a version that is supported by deployKF.</p> Which distributions of Kubernetes are supported? <p>deployKF is designed to work on any Kubernetes cluster, within any cloud or local environment.</p> <p>Here are some popular Kubernetes distributions that users have reported success with:</p> Platform Kubernetes Distribution Amazon Web Services Amazon Elastic Kubernetes Service (EKS) Microsoft Azure Azure Kubernetes Service (AKS) Google Cloud Google Kubernetes Engine (GKE) IBM Cloud IBM Cloud Kubernetes Service (IKS) N/A Rancher Kubernetes Engine (RKE) N/A Canonical Kubernetes (MicroK8s) Local Machine k3d, kind, minikube <p>Other requirements vary depending on the \"mode of operation\" you have chosen:</p> Requirement \u2192 required //  \u2192 optional ArgoCD Plugin Mode Manifests Repo Mode a Kubernetes cluster (version compatibility) ArgoCD is installed on your Kubernetes ArgoCD has the deployKF Plugin - deployKF's CLI is installed locally - a private git repo (for generated manifests) - external MySQL database (connecting guide) external S3-like object store (connecting guide) <p>Dedicated Kubernetes Cluster</p> <p>Only one deployKF platform can be deployed on a Kubernetes cluster at a time.</p> <p>Additionally, deployKF is not well suited to multi-tenant clusters. It uses cluster-wide components (e.g. Istio) and namespaces for user/team profiles. Therefore, we strongly recommend using a dedicated Kubernetes cluster for deployKF.</p> <p>If you are unable to create a new Kubernetes cluster, you may consider using vCluster to create a virtual Kubernetes cluster within an existing one.</p> <p>Cluster Domain</p> <p>deployKF currently requires the Kubernetes kubelet <code>clusterDomain</code> be left as the default of <code>cluster.local</code>. This is caused by a small number of Kubeflow components hard-coding this value, with no way to change it.</p> <p>ARM Processors</p> <p>deployKF does NOT currently support ARM clusters.  A small number of Kubeflow components do not support ARM just yet, we expect this to change after the release of Kubeflow 1.8 in October 2023.</p> <p>Default StorageClass</p> <p>The default values assume your Kubernetes cluster has a default StorageClass which has support for the <code>ReadWriteOnce</code> access mode.</p> What if I don't have a compatible default StorageClass? <p>If you do NOT have a compatible default StorageClass, you have a few options:</p> <ol> <li>Configure a default StorageClass that has <code>ReadWriteOnce</code> support</li> <li>Explicitly set the <code>storageClass</code> value for the following components:<ul> <li><code>deploykf_opt.deploykf_minio.persistence.storageClass</code></li> <li><code>deploykf_opt.deploykf_mysql.persistence.storageClass</code></li> </ul> </li> <li>Disable components which require the StorageClass, and use external alternatives:<ul> <li><code>deploykf_opt.deploykf_minio.enabled</code></li> <li><code>deploykf_opt.deploykf_mysql.enabled</code></li> </ul> </li> </ol>"},{"location":"guides/getting-started/#2-platform-configuration","title":"2. Platform Configuration","text":""},{"location":"guides/getting-started/#about-values","title":"About Values","text":"<p>All aspects of your deployKF platform are configured with YAML-based configs named \"values\". There are a very large number of values (more than 1500), but as deployKF supports in-place upgrades you can start with a few important ones, and then grow your values file over time.</p>"},{"location":"guides/getting-started/#create-values-files","title":"Create Values Files","text":"<p>We recommend using the <code>sample-values.yaml</code> file as a starting point for your values. These sample values (which are different for each deployKF version) have all ML &amp; Data tools enabled, along with some sensible security defaults.</p> <p>You may copy and make changes to the sample values, or directly use it as a base, and override specific values in a separate file. We provide the <code>sample-values-overrides.yaml</code> file as an example of this approach.</p> <p>For your reference, ALL values and their defaults are listed on the values reference page, which is generated from the full <code>default_values.yaml</code> file.</p> <p>YAML Syntax</p> <p>For a refresher on YAML syntax, we recommend the following resources:</p> <ul> <li>Learn YAML in Y minutes</li> <li>YAML Multiline Strings</li> </ul>"},{"location":"guides/getting-started/#configuration-guides","title":"Configuration Guides","text":"<p>deployKF is incredibly configurable, so we provide a number of guides to help you get started with common configuration tasks.</p>"},{"location":"guides/getting-started/#platform-configuration","title":"Platform Configuration","text":"Guide Description User Authentication Integrate with your existing user authentication system (GitHub, Google, Okta, etc.) and define static user accounts. User Authorization and Profile Management Manage user permissions by defining profiles and assigning users to them. Expose Gateway and configure HTTPS Make deployKF available publicly and configure valid HTTPS certificates. Customize the Dashboard Customize the deployKF dashboard with your own branding and links."},{"location":"guides/getting-started/#tool-configuration","title":"Tool Configuration","text":"Guide Description Connect an external MySQL Database Replace the embedded MySQL instance with a production-ready external database service. Connect an external Object Store Replace the embedded MinIO instance with an external S3-compatible object store. Configure Kubeflow Notebooks Configure Kubeflow Notebooks with custom server images and compute resources, including GPUs."},{"location":"guides/getting-started/#3-platform-deployment","title":"3. Platform Deployment","text":""},{"location":"guides/getting-started/#about-argocd","title":"About ArgoCD","text":"<p>ArgoCD is an extremely widely-used tool that helps you programmatically manage the applications deployed on your cluster.</p> Why does deployKF use Argo CD? <p>ML Platforms are made up of many interconnected dependencies, and it can be difficult to manage the state of all these components manually. This is where GitOps comes in, it allows us to define the desired state of all the components in a single place, and then use a tool to reconcile the actual state of our cluster to match the defined state.</p> <p>Argo CD is a great tool for this job given its widespread adoption, and well designed interface for visualizing and managing the current state of your cluster. In the future, we plan to support other Kubernetes GitOps tools (like Flux CD), but we have initially chosen to use Argo CD due to its overwhelming popularity.</p> Argo CD vs Argo Workflows <p>It's important to note that Argo CD is NOT the same as Argo Workflows, they just have similar names:</p> <ul> <li>Argo CD is a GitOps Tool, it manages the state of Kubernetes resources</li> <li>Argo Workflows is a Workflow Engine, it defines and runs DAG workflows in Pods on Kubernetes</li> </ul>"},{"location":"guides/getting-started/#about-argocd-applications","title":"About ArgoCD Applications","text":"<p>The main config for ArgoCD is the <code>Application</code>, a Kubernetes custom resource that specifies Kubernetes manifests that ArgoCD should deploy and manage (typically from a git repository).</p> <p>An \"app of apps\" is a pattern where a single ArgoCD <code>Application</code> contains other <code>Application</code> definitions, this is typically done to make bootstrapping large applications easier.</p>"},{"location":"guides/getting-started/#deploykf-versions","title":"deployKF Versions","text":"<p>The \"source version\" chooses which version of the deployKF generator will be used. Each version may include different tools, and may support different versions of external dependencies (like Kubernetes, Istio and cert-manager).</p> <p>The version matrix lists which tools and dependency versions are supported by each deployKF release. Specific information about each release (including important upgrade notes), can be found in the deployKF generator changelog.</p>"},{"location":"guides/getting-started/#generate-apply-manifests","title":"Generate &amp; Apply Manifests","text":"<p>How you generate and apply the deployKF manifests to your Kubernetes cluster will depend on the \"mode of operation\" you have chosen.</p> Generate &amp; Apply Manifests - ArgoCD Plugin Mode <p>To generate and apply the manifests when using \"ArgoCD Plugin Mode\", you will need to:</p> <ol> <li>install the deployKF ArgoCD plugin on your ArgoCD instance</li> <li>create an app-of-apps which uses the plugin</li> <li>apply your app-of-apps manifest</li> </ol> <p>Step 1: Install the ArgoCD Plugin</p> <p>We provide two options for installing the deployKF ArgoCD plugin:</p> Install Plugin - New ArgoCD <p>This method installs our pre-patched ArgoCD manifests with the plugin pre-installed. Use this method if you are installing ArgoCD for the first time.</p> <p>For specific information, see the Install Plugin - New ArgoCD guide.</p> Install Plugin - Patch Existing ArgoCD <p>This method explains how to patch an existing ArgoCD installation to include the plugin. Use this method if you already have an ArgoCD installation.</p> <p>For more information, see the Install Plugin - Existing ArgoCD guide.</p> <p>Step 2: Create an App-of-Apps Manifest</p> <p>The \"deploykf\" plugin has the following parameters:</p> Parameter Type Description <code>source_version</code> String the version of deployKF to use (see changelog for available versions) <code>values_files</code> Array a list of paths to values files in your ArgoCD Application's <code>source</code> repo (relative to the <code>source.path</code>) <code>values</code> String a string containing the contents of a values file (these take precedence when being merged with values from <code>values_files</code>) <p>For example, the following \"app of apps\" specification will use deployKF <code>0.1.3</code> and read the <code>sample-values.yaml</code> (from the <code>v0.1.3</code> tag of the <code>deploykf/deploykf</code> repo) while also showing how to set values with the <code>values</code> parameter:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: deploykf-app-of-apps\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: deploykf-app-of-apps\n    app.kubernetes.io/part-of: deploykf\nspec:\n  project: \"default\"\n  source:\n    ## source git repo configuration\n    ##  - we use the 'deploykf/deploykf' repo so we can read its 'sample-values.yaml'\n    ##    file, but you may use any repo (even one with no files)\n    ##\n    repoURL: \"https://github.com/deployKF/deployKF.git\"\n    targetRevision: \"v0.1.3\"\n    path: \".\"\n\n    ## plugin configuration\n    ##\n    plugin:\n      name: \"deploykf\"\n      parameters:\n\n        ## the deployKF generator version\n        ##  - available versions: https://github.com/deployKF/deployKF/releases\n        ##\n        - name: \"source_version\"\n          string: \"0.1.3\"\n\n        ## paths to values files within the `repoURL` repository\n        ##  - the values in these files are merged, with later files taking precedence\n        ##  - we strongly recommend using 'sample-values.yaml' as the base of your values\n        ##    so you can easily upgrade to newer versions of deployKF\n        ##\n        - name: \"values_files\"\n          array:\n            - \"./sample-values.yaml\"\n\n        ## a string containing the contents of a values file\n        ##  - this parameter allows defining values without needing to create a file in the repo\n        ##  - these values are merged with higher precedence than those defined in `values_files`\n        ##\n        - name: \"values\"\n          string: |\n            ##\n            ## This demonstrates how you might structure overrides for the 'sample-values.yaml' file.\n            ## For a more comprehensive example, see the 'sample-values-overrides.yaml' in the main repo.\n            ##\n            ## Notes:\n            ##  - YAML maps are RECURSIVELY merged across values files\n            ##  - YAML lists are REPLACED in their entirety across values files\n            ##  - Do NOT include empty/null sections, as this will remove ALL values from that section.\n            ##    To include a section without overriding any values, set it to an empty map: `{}`\n            ##\n\n            ## --------------------------------------------------------------------------------\n            ##                              deploykf-dependencies\n            ## --------------------------------------------------------------------------------\n            deploykf_dependencies:\n\n              ## --------------------------------------\n              ##             cert-manager\n              ## --------------------------------------\n              cert_manager:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##                 istio\n              ## --------------------------------------\n              istio:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##                kyverno\n              ## --------------------------------------\n              kyverno:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                  deploykf-core\n            ## --------------------------------------------------------------------------------\n            deploykf_core:\n\n              ## --------------------------------------\n              ##             deploykf-auth\n              ## --------------------------------------\n              deploykf_auth:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##        deploykf-istio-gateway\n              ## --------------------------------------\n              deploykf_istio_gateway:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##      deploykf-profiles-generator\n              ## --------------------------------------\n              deploykf_profiles_generator:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                   deploykf-opt\n            ## --------------------------------------------------------------------------------\n            deploykf_opt:\n\n              ## --------------------------------------\n              ##            deploykf-minio\n              ## --------------------------------------\n              deploykf_minio:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##            deploykf-mysql\n              ## --------------------------------------\n              deploykf_mysql:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                  kubeflow-tools\n            ## --------------------------------------------------------------------------------\n            kubeflow_tools:\n\n              ## --------------------------------------\n              ##                 katib\n              ## --------------------------------------\n              katib:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##               notebooks\n              ## --------------------------------------\n              notebooks:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##               pipelines\n              ## --------------------------------------\n              pipelines:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  destination:\n    server: \"https://kubernetes.default.svc\"\n    namespace: \"argocd\"\n</code></pre> <p>Step 3: Apply App-of-Apps Manifest</p> <p>After writing your app-of-apps manifest to a local file named <code>app-of-apps.yaml</code>, you may apply it with:</p> <pre><code>kubectl apply --filename ./app-of-apps.yaml --namespace \"argocd\"\n</code></pre> Generate &amp; Apply Manifests - Manifests Repo Mode <p>To generate and apply the manifests when using \"Manifests Repo Mode\", you will need to:</p> <ol> <li>generate the manifests</li> <li>commit the generated manifests to a git repo</li> <li>apply the generated app-of-apps manifest</li> </ol> <p>Step 1: Generate Manifests</p> <p>The <code>deploykf generate</code> command writes generated manifests into a folder, using one or more values files.</p> <p>The required arguments of the <code>deploykf generate</code> command are:</p> Argument Description <code>--source-version</code> the version of deployKF to use (see changelog for available versions) <code>--values</code> one or more values files to use for generating the manifests <code>--output-dir</code> the directory where the generated manifests will be written <p>For example, this command will use deployKF <code>0.1.3</code> to generate manifests under <code>GENERATOR_OUTPUT/</code>, from a values file named <code>custom-values.yaml</code>:</p> <pre><code>deploykf generate \\\n    --source-version \"0.1.3\" \\\n    --values ./custom-values.yaml \\\n    --output-dir ./GENERATOR_OUTPUT\n</code></pre> <p>Avoid Manual Changes</p> <p>Manual changes in the <code>--output-dir</code> will be overwritten each time the <code>deploykf generate</code> command runs. If you find yourself needing to make manual changes, please raise an issue so we may consider adding a new value to support your use-case.</p> <p>Multiple Values Files</p> <p>If you specify <code>--values</code> multiple times, they will be merged with later ones taking precedence. Note, values which are YAML lists are NOT merged, they are replaced in full.</p> <p>Step 2: Commit Generated Manifests</p> <p>After running <code>deploykf generate</code>, you will likely want to commit the changes to your repo:</p> <pre><code># for example, to directly commit changes to the 'main' branch of your repo\ngit add GENERATOR_OUTPUT\ngit commit -m \"my commit message\"\ngit push origin main\n</code></pre> <p>Private Git Repositories</p> <p>If your app-of-apps source repo is private, you will need to configure ArgoCD with git credentials.</p> <p>Step 3: Apply App-of-Apps Manifest</p> <p>The only manifest you need to manually apply is the ArgoCD app-of-apps, which creates all the other ArgoCD applications.</p> <p>The <code>app-of-apps.yaml</code> manifest is generated at the root of your <code>--output-dir</code> folder, so you can apply it with:</p> <pre><code>kubectl apply --filename GENERATOR_OUTPUT/app-of-apps.yaml\n</code></pre> Required Values (Only for Manifests Repo Mode) <p>When using \"manifests repo mode\", the following values MUST be defined in your values file(s).</p> <p> Value Description Example <code>argocd.source.repo.url</code> the URL of the git repo where your generated manifests are stored if you are using a GitHub repo named <code>deployKF/examples</code>, you might set this value to <code>\"https://github.com/deployKF/examples\"</code> or <code>\"git@github.com:deployKF/examples.git\"</code> <code>argocd.source.repo.revision</code> is the git branch/tag/commit that ArgoCD should sync the manifests from if you are using the <code>main</code> branch of your repo, you might set this value to <code>\"main\"</code> <code>argocd.source.repo.path</code> is the folder path under the git repo where your generated manifests are stored if you are using a folder named <code>GENERATOR_OUTPUT</code> at the root of your repo, you might set this value to <code>\"./GENERATOR_OUTPUT/\"</code> </p>"},{"location":"guides/getting-started/#sync-argocd-applications","title":"Sync ArgoCD Applications","text":"<p>Now that your deployKF app-of-apps has been applied, you must sync the ArgoCD applications to deploy your platform. Syncing an application will cause ArgoCD to reconcile the actual state in the cluster, to match the state defined by the application resource.</p> <p>ArgoCD supports syncing applications both graphically (Web UI) and programmatically (CLI). If you are new to ArgoCD, we recommend taking a look at the Web UI, as it provides a visual overview of each application and its sync status.</p> <p>Sync Order</p> <p>It is important to note that deployKF applications depend on each other, so you MUST sync them in the correct order.</p> <p>There are a few ways to sync the applications, but you only need to use one of them:</p> Sync Applications - ArgoCD Web UI <p>To sync the deployKF applications with the ArgoCD Web UI, you will need to:</p> <ol> <li>access the ArgoCD Web UI</li> <li>sync the applications</li> </ol> <p>Step 1: Access the ArgoCD Web UI</p> How do I access the ArgoCD Web UI? <p>If this is the first time you are using ArgoCD, you will need to retrieve the initial password for the <code>admin</code> user:</p> <pre><code>echo $(kubectl -n argocd get secret/argocd-initial-admin-secret \\\n  -o jsonpath=\"{.data.password}\" | base64 -d)\n</code></pre> <p>If you don't want to expose ArgoCD with a <code>LoadBalancer</code> or <code>Ingress</code>, you may use <code>kubectl</code> port-forwarding to access the ArgoCD Web UI:</p> <pre><code>kubectl port-forward --namespace \"argocd\" svc/argocd-server 8090:https\n</code></pre> <p>You will now be able to access ArgoCD at https://localhost:8090 in your browser.</p> <p>Log in with the <code>admin</code> user, and the password you retrieved above.</p> <p>The ArgoCD Web UI will look like this:</p> <p> </p> <p>Step 2: Sync the Applications</p> <p>The deployKF applications are grouped into the following \"groups\", which must be synced in the order described.</p> <p>Group 0: \"app-of-apps\"</p> <p>First, you must sync the app-of-apps application:</p> <ol> <li><code>deploykf-app-of-apps</code></li> <li><code>deploykf-namespaces</code> (will only appear if using a remote destination)</li> </ol> <p>Group 1: \"deploykf-dependencies\"</p> <p>Second, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-dependencies</code>:</p> <ol> <li><code>dkf-dep--cert-manager</code> (may fail on first attempt)</li> <li><code>dkf-dep--istio</code></li> <li><code>dkf-dep--kyverno</code></li> </ol> <p>Group 2: \"deploykf-core\"</p> <p>Third, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-core</code>:</p> <ol> <li><code>dkf-core--deploykf-istio-gateway</code></li> <li><code>dkf-core--deploykf-auth</code></li> <li><code>dkf-core--deploykf-dashboard</code></li> <li><code>dkf-core--deploykf-profiles-generator</code> (may fail on first attempt)</li> </ol> <p>Group 3: \"deploykf-opt\"</p> <p>Fourth, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-opt</code>:</p> <ul> <li><code>dkf-opt--deploykf-minio</code></li> <li><code>dkf-opt--deploykf-mysql</code></li> </ul> <p>Group 4: \"deploykf-tools\"</p> <p>Fifth, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-tools</code>:</p> <ul> <li>(none yet)</li> </ul> <p>Group 5: \"kubeflow-dependencies\"</p> <p>Sixth, you must sync the applications with the label <code>app.kubernetes.io/component=kubeflow-dependencies</code>:</p> <ul> <li><code>kf-dep--argo-workflows</code></li> </ul> <p>Group 6: \"kubeflow-tools\"</p> <p>Seventh, you must sync the applications with the label <code>app.kubernetes.io/component=kubeflow-tools</code>:</p> <ul> <li><code>kf-tools--katib</code></li> <li><code>kf-tools--notebooks--jupyter-web-app</code></li> <li><code>kf-tools--notebooks--notebook-controller</code></li> <li><code>kf-tools--pipelines</code></li> <li><code>kf-tools--poddefaults-webhook</code></li> <li><code>kf-tools--tensorboards--tensorboard-controller</code></li> <li><code>kf-tools--tensorboards--tensorboards-web-app</code></li> <li><code>kf-tools--training-operator</code></li> <li><code>kf-tools--volumes--volumes-web-app</code></li> </ul> Sync Applications - ArgoCD CLI (Automated) <p>We provide the <code>sync_argocd_apps.sh</code> script to automatically sync the applications that make up deployKF.</p> <p>Learn more about the automated sync script from the <code>scripts</code> folder README in the deployKF repo.</p> Sync Applications - ArgoCD CLI (Manual) <p>To sync the deployKF applications with the ArgoCD CLI, you will need to:</p> <ol> <li>install the ArgoCD CLI</li> <li>expose the ArgoCD API server</li> <li>log in to ArgoCD</li> <li>sync the applications</li> </ol> <p>Step 1: Install the ArgoCD CLI</p> <p>You can install by following the ArgoCD CLI Installation instructions.</p> <p>Step 2: Expose the ArgoCD API Server</p> <p>You can expose the ArgoCD API server by port-forwarding the <code>argocd-server</code> Service to your local machine.</p> <p>You can do this with the following <code>kubectl</code> command:</p> <pre><code>kubectl port-forward svc/argocd-server --namespace \"argocd\" 8090:https\n</code></pre> <p>Step 3: Log in to ArgoCD</p> <p>If this is the first time you are using ArgoCD, you will need to retrieve the initial password for the <code>admin</code> user.</p> <p>You can do this with the following <code>kubectl</code> command:</p> <pre><code>echo $(kubectl -n argocd get secret/argocd-initial-admin-secret \\\n  -o jsonpath=\"{.data.password}\" | base64 -d)\n</code></pre> <p>You can now log in to ArgoCD with the <code>admin</code> user and the password you retrieved above.</p> <pre><code>ARGOCD_PASSWORD=\"&lt;YOUR_PASSWORD_HERE&gt;\"\nargocd login localhost:8090 --username \"admin\" --password \"$ARGOCD_PASSWORD\" --insecure\n</code></pre> <p>Step 4: Sync the Applications</p> <p>The deployKF applications are grouped into the following \"groups\", which must be synced in the order described.</p> <p>Sync Waves and Race Conditions</p> <p>Within each group, there is an additional order defined by the <code>argocd.argoproj.io/sync-wave</code> annotation, this order is NOT respected by the following commands, but is respected by the automated script.</p> <pre><code># sync the \"deploykf-app-of-apps\" application\nargocd app sync -l \"app.kubernetes.io/name=deploykf-app-of-apps\"\n\n# sync the \"deploykf-namespaces\" application\n# NOTE: This will only be present if you are using a remote destination\nargocd app sync -l \"app.kubernetes.io/name=deploykf-namespaces\"\n\n# sync all applications in the \"deploykf-dependencies\" group\nargocd app sync -l \"app.kubernetes.io/component=deploykf-dependencies\"\n\n# sync all applications in the \"deploykf-core\" group\nargocd app sync -l \"app.kubernetes.io/component=deploykf-core\"\n\n# sync all applications in the \"deploykf-opt\" group\nargocd app sync -l \"app.kubernetes.io/component=deploykf-opt\"\n\n# sync all applications in the \"deploykf-tools\" group\nargocd app sync -l \"app.kubernetes.io/component=deploykf-tools\"\n\n# sync all applications in the \"kubeflow-dependencies\" group\nargocd app sync -l \"app.kubernetes.io/component=kubeflow-dependencies\"\n\n# sync all applications in the \"kubeflow-tools\" group\nargocd app sync -l \"app.kubernetes.io/component=kubeflow-tools\"\n</code></pre>"},{"location":"guides/getting-started/#4-use-the-platform","title":"4. Use the Platform","text":"<p>Now that you have a working deployKF ML Platform, here are some things to try out!</p>"},{"location":"guides/getting-started/#the-dashboard","title":"The Dashboard","text":"<p>The deployKF dashboard is the web-based interface for deployKF, it gives users authenticated access to tools like Kubeflow Pipelines, Kubeflow Notebooks, and Katib.</p> <p> </p> <p>Customize the Dashboard</p> <p>If you would like to make changes to the deployKF dashboard, such as adding custom links to the sidebar or homepage, see the dashboard customization guide.</p>"},{"location":"guides/getting-started/#expose-the-gateway","title":"Expose the Gateway","text":"<p>All public deployKF services (including the dashboard) are accessed via your deployKF Istio Gateway, to use the gateway, you will need to expose its Kubernetes Service.</p> Expose Gateway - Production Usage <p>To make effective use of your deployKF platform in the real-world, you should expose the deployKF Istio Gateway using a method that is appropriate for your environment.</p> <p>We provide a comprehensive guide named \"Expose Gateway and configure HTTPS\" for your reference.</p> Expose Gateway - Local Testing <p>If you are just testing deployKF, and don't want to expose the gateway more widely, you may use local <code>kubectl</code> port-forwarding with the following steps:</p> <ol> <li>modify your local machine's <code>/etc/hosts</code> file</li> <li>port-forward the <code>deploykf-gateway</code> Service with <code>kubectl</code></li> </ol> <p>Step 1: Modify Hosts File</p> <p>You will need to add some lines to your local <code>/etc/hosts</code> file of your local machine.</p> <p>If the <code>deploykf_core.deploykf_istio_gateway.gateway.hostname</code> value has been left as the default of <code>\"deploykf.example.com\"</code>, you should add the following lines to <code>/etc/hosts</code>:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> <p>Why do I need these entries in my hosts file?</p> <p>The deployKF Istio Gateway uses the HTTP <code>Host</code> header to route requests to the correct internal service, meaning that using <code>localhost</code> or <code>127.0.0.1</code> will NOT work.</p> <p>Step 2: Port-Forward the Gateway Service</p> <p>You may now port-forward the <code>deploykf-gateway</code> Service with the following <code>kubectl</code> command:</p> <pre><code>kubectl port-forward \\\n  --namespace \"deploykf-istio-gateway\" \\\n  svc/deploykf-gateway 8080:http 8443:https\n</code></pre> <p>The deployKF dashboard should now be available on your local machine at:</p> <p> https://deploykf.example.com:8443/</p>"},{"location":"guides/getting-started/#default-login-credentials","title":"Default Login Credentials","text":"<p>The default values include static user/password combinations defined by the <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> value, which can be used for testing.</p> <p>This table lists the default login credentials:</p> Username Password Notes <code>admin@example.com</code> <code>admin</code> The default \"owner\" of all profiles, but a \"member\" of none, meaning it does NOT have access to \"MinIO Console\" or \"Argo Workflows Server\".In production, we recommend leaving this account as the default \"owner\" but excluding its <code>staticPasswords</code> entry, so it can't be used to log in. <code>user1@example.com</code> <code>user1</code> Has write access to <code>team-1</code> profile, and read access to <code>team-1-prod</code>. <code>user2@example.com</code> <code>user2</code> Has write access to <code>team-1</code> profile, and read access to <code>team-1-prod</code>."},{"location":"guides/getting-started/#ml-data-tools","title":"ML &amp; Data Tools","text":"<p>deployKF includes many tools that address different stages of the ML &amp; Data lifecycle. The following links give more specific information about some of our most popular tools:</p> <ul> <li>Kubeflow Pipelines</li> <li>Kubeflow Notebooks</li> </ul>"},{"location":"guides/getting-started/#user-reference-guides","title":"User Reference Guides","text":"<p>We also provide a number of user-focused reference guides to help them deliver value with the platform faster. You should share these guides with your users to help them get started.</p> User Guide Description Access Kubeflow Pipelines API Learn how to access the Kubeflow Pipelines API from both inside and outside the cluster with the Kubeflow Pipelines SDK. GitOps for Kubeflow Pipelines Schedules Learn how to use GitOps to manage Kubeflow Pipelines schedules (rather than manually creating them with the UI or Python SDK)."},{"location":"guides/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li> Join the deployKF community!</li> <li> Support us with a star on GitHub!</li> <li> Get support from our experts!</li> </ul>"},{"location":"guides/local-quickstart/","title":"Local Quickstart","text":"<p>This guide will show you how to quickly try deployKF on a local Kubernetes cluster.</p> <p>Related Guides</p> <ul> <li>Getting Started - start building your production-ready ML Platform on any Kubernetes cluster</li> </ul>"},{"location":"guides/local-quickstart/#introduction","title":"Introduction","text":"<p>Before starting, let's answer some common questions about deployKF.</p> <p>What is deployKF?</p> <p>deployKF builds world-class Data and Machine Learning Platforms on any Kubernetes cluster, in any cloud or environment. Our vision is that anyone with Kubernetes experience can effortlessly build, maintain, and support a custom Data and ML Platform for their organization, without requiring specialized MLOps knowledge.</p> <p>For more details, see the introduction of the Getting Started guide.</p> <p>Do you offer commercial support?</p> <p>Yes! The founder of deployKF (Mathew Wicks), operates a US-based company named Aranui Solutions to provide commercial support and advisory services for organizations building ML &amp; Data Platforms on Kubernetes.</p> <p>Email <code>sales@aranui.solutions</code> to learn more!</p>"},{"location":"guides/local-quickstart/#1-requirements","title":"1. Requirements","text":"<p>The requirements for this quickstart depend on your operating system.</p> macOSLinuxWindows Requirement Notes Homebrew Install Guide Docker Desktop Install Guide Bash 4.2+ RUN: <code>brew install bash</code>(macOS has bash <code>3.2</code> by default) CLI: <code>argocd</code> RUN: <code>brew install argocd</code> CLI: <code>jq</code> RUN: <code>brew install jq</code> CLI: <code>k3d</code> RUN: <code>brew install k3d</code> CLI: <code>kubectl</code> RUN: <code>brew install kubectl</code> <p>Apple Silicon</p> <p>deployKF does NOT currently support ARM clusters.  A small number of Kubeflow components do not support ARM just yet, we expect this to change after the release of Kubeflow 1.8 in October 2023.</p> <p>Resource Allocation</p> <p>In Docker Desktop, you may need to increase the resource allocation, we recommend allocating at least:</p> <ul> <li>4 CPU Cores</li> <li>10 GB RAM</li> </ul> Can I use Podman instead of Docker Desktop? <p>Yes. While we recommend using Docker Desktop, you may use Podman instead.</p> <p>Follow these steps to configure <code>k3d</code> to use Podman:</p> <ol> <li>Install Podman</li> <li>Enable Podman socket: <code>sudo systemctl enable --now podman.socket</code></li> <li>Link Docker socket to Podman: <code>sudo ln -s /run/podman/podman.sock /var/run/docker.sock</code></li> </ol> Requirement Notes Docker Engine Install Guide CLI: <code>argocd</code> Install Guide <sup>(also on Homebrew for Linux)</sup> CLI: <code>jq</code> Install Guide <sup>(also on Homebrew for Linux)</sup> CLI: <code>k3d</code> Install Guide <sup>(also on Homebrew for Linux)</sup> CLI: <code>kubectl</code> Install Guide <sup>(also on Homebrew for Linux)</sup> <p>Inotify Limits</p> <p>On Linux, you may need to increase your system's open/watched file limits.</p> <ol> <li>Modify <code>/etc/sysctl.conf</code> to include the following lines:<ul> <li><code>fs.inotify.max_user_instances = 1280</code></li> <li><code>fs.inotify.max_user_watches = 655360</code></li> </ul> </li> <li>Reload sysctl configs by running <code>sudo sysctl -p</code></li> </ol> Homebrew for Linux <p>An easy way to install the requirements is with Homebrew, while traditionally a macOS tool, it supports linux as well.</p> <p>The following commands will install <code>brew</code> and add it to your PATH:</p> <pre><code># install Homebrew for Linux\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# add 'brew' to your PATH\n# NOTE: reopen your shell for this to take effect\n(echo; echo 'eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"') &gt;&gt; ~/.profile\n</code></pre> <p>After Homebrew is installed, you may use commands like:</p> <pre><code>brew install argocd\nbrew install jq\nbrew install k3s\nbrew install kubectl\n</code></pre> <p>Step 1: Install Host Dependencies</p> <p>Install these dependencies on your Windows host:</p> Requirement Notes Windows Subsystem for Linux (WSL 2) Install Guide Docker Desktop Install Guide <p>Step 2: Configure WSL</p> <p>Configure WSL to use our custom kernel that properly supports Kubernetes (specifically Istio).</p> Why do we need a custom kernel? <ul> <li>For context on why a custom kernel is needed, see <code>deployKF/deployKF#41</code>.</li> <li>To see what changes we have made to the kernel, review <code>deployKF/WSL2-Linux-Kernel</code>.</li> <li>Hopefully, once <code>microsoft/WSL#8153</code> is resolved, we will no longer need a custom kernel.</li> </ul> <p>Run these commands in PowerShell (search <code>PowerShell</code> in start menu):</p> <pre><code># create a directory for custom kernels\nNew-Item -Path \"$env:USERPROFILE\\WSL2Kernels\" -ItemType Directory -Force | Out-Null\n\n# download our custom kernel\n$KERNEL_VERSION = \"linux-deploykf-wsl-5.15.133.1\"\n$KERNEL_URL = \"https://github.com/deployKF/WSL2-Linux-Kernel/releases/download/${KERNEL_VERSION}/linux-deploykf-wsl\"\n$KERNEL_PATH = \"$env:USERPROFILE\\WSL2Kernels\\linux-deploykf-wsl\"\nInvoke-WebRequest -Uri \"${KERNEL_URL}\" -OutFile \"${KERNEL_PATH}\"\n\n# set the custom kernel as the default\n# NOTE: this will overwrite any existing .wslconfig file\n$KERNEL_PATH_ESCAPED = (\"$env:USERPROFILE\\WSL2Kernels\\linux-deploykf-wsl\" -replace '\\\\', '\\\\')\n$WSLCONFIG_CONTENT = @\"\n[wsl2]\nkernel=\"${KERNEL_PATH_ESCAPED}\"\n\"@\nSet-Content -Path \"$env:USERPROFILE\\.wslconfig\" -Value \"${WSLCONFIG_CONTENT}\"\n\n# restart WSL\nwsl --shutdown\n</code></pre> <p>Restart Docker Desktop</p> <p>Now you must restart Docker Desktop to ensure it is using the new kernel.</p> <p>Right-click the Docker Desktop icon in the system tray, then select <code>Restart</code>.</p> <p>Step 3: Install Homebrew</p> <p>Install Homebrew for Linux within your WSL environment.</p> <p>Run these commands in an Ubuntu shell (search <code>Ubuntu</code> in start menu):</p> <pre><code># install Homebrew for Linux\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# add 'brew' to your PATH\n# NOTE: reopen your shell for this to take effect\n(echo; echo 'eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"') &gt;&gt; ~/.profile\n</code></pre> <p>Step 4: Install WSL Dependencies</p> <p>Install these dependencies within your Ubuntu shell (search <code>Ubuntu</code> in start menu):</p> Requirement Notes CLI: <code>argocd</code> RUN: <code>brew install argocd</code> CLI: <code>jq</code> RUN: <code>brew install jq</code> CLI: <code>k3d</code> RUN: <code>brew install k3d</code> CLI: <code>kubectl</code> RUN: <code>brew install kubectl</code> <p>For the rest of the guide, unless otherwise instructed, run all commands in an Ubuntu shell.</p>"},{"location":"guides/local-quickstart/#2-kubernetes","title":"2. Kubernetes","text":""},{"location":"guides/local-quickstart/#about-k3d","title":"About k3d","text":"<p>K3d is a helpful command line tool which helps you spin up k3s Kubernetes clusters running inside Docker containers.</p> <p>K3s itself is an extremely lightweight Kubernetes distribution, which is fully compliant with the Kubernetes API, while being very similar to how cloud-based clusters are configured.</p>"},{"location":"guides/local-quickstart/#create-kubernetes-cluster","title":"Create Kubernetes Cluster","text":"<p>Run this command to create a local k3s cluster using <code>k3d</code>, named <code>deploykf</code>:</p> <pre><code># NOTE: this will change your kubectl context to the new cluster\nk3d cluster create \"deploykf\" \\\n  --image \"rancher/k3s:v1.26.9-k3s1\"\n</code></pre> Can I use a different version of Kubernetes? <p>Yes. The <code>--image</code> flag allows you to specify the version of Kubernetes. You may use any version of the <code>rancher/k3s</code> image which corresponds to a version of Kubernetes that is supported by deployKF.</p>"},{"location":"guides/local-quickstart/#wait-for-cluster-to-be-ready","title":"Wait for Cluster to be Ready","text":"<p>Wait until the cluster is ready (all pods are in a <code>Running</code> or <code>Completed</code> state) before continuing.</p> Get the state of Pods - <code>k9s</code> <p>We highly recommend <code>k9s</code>, it makes interacting with Kubernetes much easier by providing a text-based management interface for any Kubernetes cluster.</p> <p>You may install <code>k9s</code> with <code>brew install k9s</code> on macOS and Linux.</p> <p>Get the status of all pods:</p> <ol> <li>Run <code>k9s</code> in your terminal</li> <li>Presh <code>shift</code> + <code>:</code> to open the command prompt - (tip: press <code>escape</code> to close any prompt)</li> <li>Type <code>pods</code> and press <code>enter</code> - (tip: press <code>tab</code> to autocomplete resource names)</li> <li>Press <code>0</code> to show all namespaces</li> <li>Scroll through the list of pods and check the <code>STATUS</code> column</li> </ol> <p>The resulting list of pods will look similar to this:</p> <pre><code> Context: k3d-deploykf                             &lt;0&gt; all           &lt;a&gt;      Attach     &lt;l&gt;       Logs               &lt;y&gt; YAML                    ____  __.________        \n Cluster: k3d-deploykf                             &lt;1&gt; default       &lt;ctrl-d&gt; Delete     &lt;p&gt;       Logs Previous                                 |    |/ _/   __   \\______ \n User:    admin@k3d-deploykf                                         &lt;d&gt;      Describe   &lt;shift-f&gt; Port-Forward                                  |      &lt; \\____    /  ___/ \n K9s Rev: v0.27.4                                                    &lt;e&gt;      Edit       &lt;s&gt;       Shell                                         |    |  \\   /    /\\___ \\  \n K8s Rev: v1.26.4+k3s1                                               &lt;?&gt;      Help       &lt;n&gt;       Show Node                                     |____|__ \\ /____//____  &gt; \n CPU:     0%                                                         &lt;ctrl-k&gt; Kill       &lt;f&gt;       Show PortForward                                      \\/            \\/  \n MEM:     22%                                                                                                                                                              \n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Pods(all)[7] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 NAMESPACE\u2191               NAME                                                      PF READY RESTARTS STATUS     CPU  MEM %CPU/R %CPU/L %MEM/R %MEM/L IP           NODE  \u2502\n\u2502 kube-system              coredns-59b4f5bbd5-7vp9v                                  \u25cf  1/1          0 Running      2   26      2    n/a     38     15 10.42.0.106  k3d-d \u2502\n\u2502 kube-system              helm-install-traefik-2h5mn                                \u25cf  0/1          0 Completed    0    0    n/a    n/a    n/a    n/a 10.42.0.2    k3d-d \u2502\n\u2502 kube-system              helm-install-traefik-crd-q9mjn                            \u25cf  0/1          0 Completed    0    0    n/a    n/a    n/a    n/a 10.42.0.5    k3d-d \u2502\n\u2502 kube-system              local-path-provisioner-76d776f6f9-pslbf                   \u25cf  1/1          0 Running      1   16    n/a    n/a    n/a    n/a 10.42.0.92   k3d-d \u2502\n\u2502 kube-system              metrics-server-7b67f64457-qc5nt                           \u25cf  1/1          0 Running     2\u2193  40\u2191     2\u2193    n/a    57\u2191    n/a 10.42.0.110  k3d-d \u2502\n\u2502 kube-system              svclb-traefik-1d8d8195-8j89l                              \u25cf  2/2          0 Running      0    2    n/a    n/a    n/a    n/a 10.42.0.90   k3d-d \u2502\n\u2502 kube-system              traefik-56b8c5fb5c-q4hqp                                  \u25cf  1/1          0 Running      1   69    n/a    n/a    n/a    n/a 10.42.0.133  k3d-d \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Filtering by namespace:</p> <ol> <li>Press <code>shift</code> + <code>:</code> to open the command prompt</li> <li>Type <code>ns</code> and press <code>enter</code></li> <li>Select the namespace you want to view and press <code>enter</code> (will open list of pods in that namespace)</li> <li>Press <code>shift</code> + <code>:</code> to open the command prompt</li> <li>Type the name of a resource type (e.g. <code>service</code> or <code>secret</code>) and press <code>enter</code></li> </ol> <p>Note, recently viewed namespaces are given a number (e.g. <code>1</code>, <code>2</code>, <code>3</code>), press that number to show all instances of the currently selected resource type in that namespace.</p> <p>Other features:</p> <ul> <li>When viewing a list of resources, press <code>/</code> to open the search prompt - (tip: press <code>escape</code> to close any prompt)</li> <li>When highlighting any resource, press <code>y</code> to view its YAML</li> <li>When highlighting any resource, press <code>d</code> to describe it</li> <li>When highlighting any resource, press <code>e</code> to open a <code>vim</code> editor for its YAML</li> <li>When highlighting a pod, press <code>l</code> to view its logs</li> <li>When highlighting a pod, press <code>s</code> to open an interactive shell</li> <li>When highlighting a secret, press <code>x</code> to view its base64-decoded data</li> </ul> <p>For more information about the features of <code>k9s</code>, see the k9s documentation, or press <code>?</code> to view the help menu.</p> Get the state of Pods - <code>kubectl</code> <p>You can use <code>kubectl</code> to check the status of all pods, in all namespaces:</p> <pre><code>kubectl get -A pods\n</code></pre> <p>The list of pods will look similar to this:</p> <pre><code>NAMESPACE    NAME                                      READY   STATUS      RESTARTS         AGE\nkube-system  helm-install-traefik-crd-q9mjn            0/1     Completed   0                1h\nkube-system  helm-install-traefik-2h5mn                0/1     Completed   0                1h\nkube-system  svclb-traefik-1d8d8195-8j89l              2/2     Running     0                1h\nkube-system  local-path-provisioner-76d776f6f9-pslbf   1/1     Running     0                1h\nkube-system  coredns-59b4f5bbd5-7vp9v                  1/1     Running     0                1h\nkube-system  traefik-56b8c5fb5c-q4hqp                  1/1     Running     0                1h\nkube-system  metrics-server-7b67f64457-qc5nt           1/1     Running     0                1h\n</code></pre>"},{"location":"guides/local-quickstart/#3-prepare-argocd","title":"3. Prepare ArgoCD","text":""},{"location":"guides/local-quickstart/#about-argocd","title":"About ArgoCD","text":"<p>ArgoCD is an extremely widely-used tool that helps you programmatically manage the applications deployed on your cluster.</p> Why does deployKF use Argo CD? <p>ML Platforms are made up of many interconnected dependencies, and it can be difficult to manage the state of all these components manually. This is where GitOps comes in, it allows us to define the desired state of all the components in a single place, and then use a tool to reconcile the actual state of our cluster to match the defined state.</p> <p>Argo CD is a great tool for this job given its widespread adoption, and well designed interface for visualizing and managing the current state of your cluster. In the future, we plan to support other Kubernetes GitOps tools (like Flux CD), but we have initially chosen to use Argo CD due to its overwhelming popularity.</p> Argo CD vs Argo Workflows <p>It's important to note that Argo CD is NOT the same as Argo Workflows, they just have similar names:</p> <ul> <li>Argo CD is a GitOps Tool, it manages the state of Kubernetes resources</li> <li>Argo Workflows is a Workflow Engine, it defines and runs DAG workflows in Pods on Kubernetes</li> </ul>"},{"location":"guides/local-quickstart/#about-argocd-applications","title":"About ArgoCD Applications","text":"<p>The main config for ArgoCD is the <code>Application</code>, a Kubernetes custom resource that specifies Kubernetes manifests that ArgoCD should deploy and manage (typically from a git repository).</p> <p>An \"app of apps\" is a pattern where a single ArgoCD <code>Application</code> contains other <code>Application</code> definitions, this is typically done to make bootstrapping large applications easier.</p>"},{"location":"guides/local-quickstart/#about-deploykf-plugin","title":"About deployKF Plugin","text":"<p>We will be using the deployKF ArgoCD Plugin, which adds a special kind of ArgoCD <code>Application</code> that produces deployKF manifests.</p> <p>The plugin removes the need to generate manifests, and instead allows you to define your platform using a single \"app of apps\" <code>Application</code> whose specification only needs your values, and a specified source version of deployKF.</p>"},{"location":"guides/local-quickstart/#install-argocd-and-deploykf-plugin","title":"Install ArgoCD and deployKF Plugin","text":"<p>First, ensure that your current <code>kubectl</code> context is set to the new cluster.</p> How do I check my current kubectl context? <p>Run the following command, and ensure it prints <code>k3d-deploykf</code>:</p> <pre><code># get the name of the current kubectl context\nkubectl config current-context\n</code></pre> How do I change my kubectl context? <p>We recommend using <code>kubectx</code> to manage your <code>kubectl</code> contexts, which can be installed with <code>brew install kubectx</code> on macOS and Linux.</p> <p>To change your kubectl context with <code>kubectx</code>, run these commands:</p> <pre><code># list all contexts \n# NOTE: this is interactive, if `fzf` is installed\nkubectx\n\n# set the current context to 'k3d-deploykf'\nkubectx \"k3d-deploykf\"\n</code></pre> <p>Now, run these commands to install ArgoCD and the deployKF ArgoCD Plugin into your cluster:</p> <pre><code># clone the deploykf repo\n# NOTE: we use 'main', as the latest plugin version always lives there\ngit clone -b main https://github.com/deployKF/deployKF.git ./deploykf\n\n# ensure the script is executable\nchmod +x ./deploykf/argocd-plugin/install_argocd.sh\n\n# run the install script\n# WARNING: this will install into your current kubectl context\nbash ./deploykf/argocd-plugin/install_argocd.sh\n</code></pre> <p>After the script completes, wait for all pods in the <code>argocd</code> Namespace to be in a <code>Running</code> state (using <code>k9s</code> or <code>kubectl</code> as described above).</p>"},{"location":"guides/local-quickstart/#4-create-argocd-applications","title":"4. Create ArgoCD Applications","text":""},{"location":"guides/local-quickstart/#about-values","title":"About Values","text":"<p>All aspects of your deployKF platform are configured with YAML-based configs named \"values\". There are a very large number of values (more than 1500), but as deployKF supports in-place upgrades you can start with a few important ones, and then grow your values file over time.</p> <p>For this quickstart, will be using the <code>sample-values.yaml</code> file as our base. These sample values (which are different for each deployKF version) have all ML &amp; Data tools enabled, along with some sensible security defaults.</p> <p>You may copy and make changes to the sample values, or directly use it as a base, and override specific values in a separate file. We provide the <code>sample-values-overrides.yaml</code> file as an example of this approach.</p> <p>YAML Syntax</p> <p>For a refresher on YAML syntax, we recommend the following resources:</p> <ul> <li>Learn YAML in Y minutes</li> <li>YAML Multiline Strings</li> </ul>"},{"location":"guides/local-quickstart/#deploykf-versions","title":"deployKF Versions","text":"<p>The \"source version\" chooses which version of the deployKF generator will be used. Each version may include different tools, and may support different versions of external dependencies (like Kubernetes, Istio and cert-manager).</p> <p>The version matrix lists which tools and dependency versions are supported by each deployKF release. Specific information about each release (including important upgrade notes), can be found in the deployKF generator changelog.</p>"},{"location":"guides/local-quickstart/#create-an-app-of-apps","title":"Create an App-of-Apps","text":"<p>To use deployKF, the only <code>Application</code> that you will need to manually create is the \"app of apps\".</p> <p>For example, the following \"app of apps\" specification will use deployKF <code>0.1.3</code> and read the <code>sample-values.yaml</code> (from the <code>v0.1.3</code> tag of the <code>deploykf/deploykf</code> repo) while also showing how to set values with the <code>values</code> parameter:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: deploykf-app-of-apps\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: deploykf-app-of-apps\n    app.kubernetes.io/part-of: deploykf\nspec:\n  project: \"default\"\n  source:\n    ## source git repo configuration\n    ##  - we use the 'deploykf/deploykf' repo so we can read its 'sample-values.yaml'\n    ##    file, but you may use any repo (even one with no files)\n    ##\n    repoURL: \"https://github.com/deployKF/deployKF.git\"\n    targetRevision: \"v0.1.3\"\n    path: \".\"\n\n    ## plugin configuration\n    ##\n    plugin:\n      name: \"deploykf\"\n      parameters:\n\n        ## the deployKF generator version\n        ##  - available versions: https://github.com/deployKF/deployKF/releases\n        ##\n        - name: \"source_version\"\n          string: \"0.1.3\"\n\n        ## paths to values files within the `repoURL` repository\n        ##  - the values in these files are merged, with later files taking precedence\n        ##  - we strongly recommend using 'sample-values.yaml' as the base of your values\n        ##    so you can easily upgrade to newer versions of deployKF\n        ##\n        - name: \"values_files\"\n          array:\n            - \"./sample-values.yaml\"\n\n        ## a string containing the contents of a values file\n        ##  - this parameter allows defining values without needing to create a file in the repo\n        ##  - these values are merged with higher precedence than those defined in `values_files`\n        ##\n        - name: \"values\"\n          string: |\n            ##\n            ## This demonstrates how you might structure overrides for the 'sample-values.yaml' file.\n            ## For a more comprehensive example, see the 'sample-values-overrides.yaml' in the main repo.\n            ##\n            ## Notes:\n            ##  - YAML maps are RECURSIVELY merged across values files\n            ##  - YAML lists are REPLACED in their entirety across values files\n            ##  - Do NOT include empty/null sections, as this will remove ALL values from that section.\n            ##    To include a section without overriding any values, set it to an empty map: `{}`\n            ##\n\n            ## --------------------------------------------------------------------------------\n            ##                              deploykf-dependencies\n            ## --------------------------------------------------------------------------------\n            deploykf_dependencies:\n\n              ## --------------------------------------\n              ##             cert-manager\n              ## --------------------------------------\n              cert_manager:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##                 istio\n              ## --------------------------------------\n              istio:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##                kyverno\n              ## --------------------------------------\n              kyverno:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                  deploykf-core\n            ## --------------------------------------------------------------------------------\n            deploykf_core:\n\n              ## --------------------------------------\n              ##             deploykf-auth\n              ## --------------------------------------\n              deploykf_auth:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##        deploykf-istio-gateway\n              ## --------------------------------------\n              deploykf_istio_gateway:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##      deploykf-profiles-generator\n              ## --------------------------------------\n              deploykf_profiles_generator:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                   deploykf-opt\n            ## --------------------------------------------------------------------------------\n            deploykf_opt:\n\n              ## --------------------------------------\n              ##            deploykf-minio\n              ## --------------------------------------\n              deploykf_minio:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##            deploykf-mysql\n              ## --------------------------------------\n              deploykf_mysql:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                  kubeflow-tools\n            ## --------------------------------------------------------------------------------\n            kubeflow_tools:\n\n              ## --------------------------------------\n              ##                 katib\n              ## --------------------------------------\n              katib:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##               notebooks\n              ## --------------------------------------\n              notebooks:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##               pipelines\n              ## --------------------------------------\n              pipelines:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  destination:\n    server: \"https://kubernetes.default.svc\"\n    namespace: \"argocd\"\n</code></pre> <p>You will need to apply this <code>Application</code> resource to your Kubernetes cluster.</p> Apply the application - CLI <p>First, create a file named <code>deploykf-app-of-apps.yaml</code> with the contents of the application YAML above.</p> <p>Next, ensure your <code>kubectl</code> context is set to the <code>k3d-deploykf</code> cluster.</p> <p>Finally, run this command to apply the app-of-apps:</p> <pre><code>kubectl apply -f ./deploykf-app-of-apps.yaml\n</code></pre> Apply the application - ArgoCD Web UI <p>You will need to retrieve the initial password for the <code>admin</code> user:</p> <pre><code>echo $(kubectl -n argocd get secret/argocd-initial-admin-secret \\\n  -o jsonpath=\"{.data.password}\" | base64 -d)\n</code></pre> <p>Next, use <code>kubectl</code> port-forwarding to access the ArgoCD Web UI:</p> <pre><code>kubectl port-forward --namespace \"argocd\" svc/argocd-server 8090:https\n</code></pre> <p>You will now be able to access ArgoCD at https://localhost:8090 in your browser.</p> <p>Log in with the <code>admin</code> user, and the password you retrieved above.</p> <p>The ArgoCD Web UI will look like this (but without any applications):</p> <p> </p> <p>To create the app-of-apps, follow these steps:</p> <ol> <li>Click the <code>+ New App</code> button</li> <li>Click the <code>Edit as YAML</code> button</li> <li>Paste the application YAML into the editor</li> <li>Click the <code>Save</code> button</li> <li>Click the <code>Create</code> button</li> </ol>"},{"location":"guides/local-quickstart/#5-sync-argocd-applications","title":"5. Sync ArgoCD Applications","text":"<p>Now that your deployKF app-of-apps has been applied, you must sync the ArgoCD applications to deploy your platform. Syncing an application will cause ArgoCD to reconcile the actual state in the cluster, to match the state defined by the application resource.</p> <p>ArgoCD supports syncing applications both graphically (Web UI) and programmatically (CLI). For this quickstart, we will use the CLI via our automated <code>sync_argocd_apps.sh</code> script.</p> <pre><code># clone the deploykf repo\n# NOTE: we use 'main', as the latest script always lives there\ngit clone -b main https://github.com/deployKF/deployKF.git ./deploykf\n\n# ensure the script is executable\nchmod +x ./deploykf/scripts/sync_argocd_apps.sh\n\n# run the script\nbash ./deploykf/scripts/sync_argocd_apps.sh\n</code></pre> <p>About the sync script</p> <ul> <li>The script can take around 5-10 minutes to run on first install.</li> <li>If the script fails or is interrupted, you can safely re-run it, and it will pick up where it left off.</li> <li>There are a number of configuration variables at the top of the script which change the default behavior.</li> <li>Learn more about the automated sync script from the <code>scripts</code> folder README in the deployKF repo.</li> </ul>"},{"location":"guides/local-quickstart/#6-try-the-platform","title":"6. Try the Platform","text":"<p>Now that you have a local deployKF ML Platform, here are some things to try out!</p>"},{"location":"guides/local-quickstart/#the-dashboard","title":"The Dashboard","text":"<p>The deployKF dashboard is the web-based interface for deployKF, it gives users authenticated access to tools like Kubeflow Pipelines, Kubeflow Notebooks, and Katib.</p> <p> </p>"},{"location":"guides/local-quickstart/#access-the-gateway","title":"Access the Gateway","text":"<p>All public deployKF services (including the dashboard) are accessed via your deployKF Istio Gateway, to use the gateway, you will need to expose its Kubernetes Service.</p> <p>For this quickstart, we will be using the port-forward feature of <code>kubectl</code> to expose the gateway locally on your machine.</p> macOSLinuxWindows <p>Step 1: Modify Hosts</p> <p>You will need to add the following lines to the END of your local <code>/etc/hosts</code> file:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> <p>Why do I need these entries in my hosts file?</p> <p>The deployKF Istio Gateway uses the HTTP <code>Host</code> header to route requests to the correct internal service, meaning that using <code>localhost</code> or <code>127.0.0.1</code> will NOT work.</p> <p>Step 1: Modify Hosts</p> <p>You will need to add the following lines to the END of your local <code>/etc/hosts</code> file:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> <p>Why do I need these entries in my hosts file?</p> <p>The deployKF Istio Gateway uses the HTTP <code>Host</code> header to route requests to the correct internal service, meaning that using <code>localhost</code> or <code>127.0.0.1</code> will NOT work.</p> <p>Step 1: Modify Hosts</p> <p>You will need to add the following lines to the END of your <code>C:\\Windows\\System32\\drivers\\etc\\hosts</code> file:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> <p>Edit hosts file as Administrator</p> <p>The hosts file can ONLY be edited by the Windows Administrator user.</p> <p>Run this PowerShell command to start an Administrator Notepad, which can edit the hosts file:</p> <pre><code>Start-Process notepad.exe -ArgumentList \"C:\\Windows\\System32\\drivers\\etc\\hosts\" -Verb RunAs\n</code></pre> <p>Why do I need these entries in my hosts file?</p> <p>The deployKF Istio Gateway uses the HTTP <code>Host</code> header to route requests to the correct internal service, meaning that using <code>localhost</code> or <code>127.0.0.1</code> will NOT work.</p> Step 2: Port-Forward Gateway <p>You may now port-forward the <code>deploykf-gateway</code> Service using this <code>kubectl</code> command:</p> <pre><code>kubectl port-forward \\\n  --namespace \"deploykf-istio-gateway\" \\\n  svc/deploykf-gateway 8080:http 8443:https\n</code></pre> <p>The deployKF dashboard should now be available on your local machine at:</p> <p> https://deploykf.example.com:8443/</p> Step 3: Log in to Dashboard <p>The default values include static user/password combinations defined by the <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> value, which can be used for testing.</p> <p>This table lists the default login credentials:</p> Username Password Notes <code>admin@example.com</code> <code>admin</code> The default \"owner\" of all profiles, but a \"member\" of none, meaning it does NOT have access to \"MinIO Console\" or \"Argo Workflows Server\".In production, we recommend leaving this account as the default \"owner\" but excluding its <code>staticPasswords</code> entry, so it can't be used to log in. <code>user1@example.com</code> <code>user1</code> Has write access to <code>team-1</code> profile, and read access to <code>team-1-prod</code>. <code>user2@example.com</code> <code>user2</code> Has write access to <code>team-1</code> profile, and read access to <code>team-1-prod</code>."},{"location":"guides/local-quickstart/#ml-data-tools","title":"ML &amp; Data Tools","text":"<p>deployKF includes many tools that address different stages of the ML &amp; Data lifecycle. The following links give more specific information about some of our most popular tools:</p> <ul> <li>Kubeflow Pipelines</li> <li>Kubeflow Notebooks</li> </ul>"},{"location":"guides/local-quickstart/#next-steps","title":"Next Steps","text":"<ul> <li> Build a production-ready deployKF platform!</li> <li> Join the deployKF community!</li> <li> Support us with a star on GitHub!</li> <li> Get support from our experts!</li> </ul>"},{"location":"guides/migrate-from-kubeflow-manifests/","title":"Migrate from Kubeflow Manifests","text":"<p>This guide explains how to migrate from Kubeflow to deployKF.</p>"},{"location":"guides/migrate-from-kubeflow-manifests/#1-understand-the-differences","title":"1. Understand the Differences","text":"<p>Before migrating, you may wish to review our detailed deployKF vs  Kubeflow comparison.</p>"},{"location":"guides/migrate-from-kubeflow-manifests/#2-create-a-new-deployment","title":"2. Create a New Deployment","text":"<p>The best way to migrate from Kubeflow Manifests to deployKF is to spin up deployKF in a separate Kubernetes cluster, and then migrate your data manually.</p> <p>To create a new deployment of deployKF, follow the Getting Started guide.</p> <p>Warning</p> <p>Kubeflow Manifests and deployKF can NOT be deployed concurrently in the same Kubernetes cluster, doing so will result in unexpected behavior.</p>"},{"location":"guides/migrate-from-kubeflow-manifests/#3-migrate-your-data","title":"3. Migrate your data","text":"<p>Once you have a new deployment of deployKF, you can migrate the data from specific Kubeflow tools to their deployKF equivalents.</p> <p>For example, you will likely need to migrate your existing Kubeflow Pipelines (scheduled runs, pipeline definitions) and Kubeflow Notebooks (user volume data) to the new deployment.</p>"},{"location":"guides/troubleshooting/","title":"Troubleshooting","text":"<p>The following sections contain troubleshooting steps for common issues with deployKF.</p>"},{"location":"guides/troubleshooting/#deployment-issues","title":"Deployment Issues","text":"<p>Pods fail with \"too many open files\" error</p>"},{"location":"guides/troubleshooting/#pods-fail-with-too-many-open-files-error","title":"Pods fail with \"too many open files\" error:","text":"<p>This error has been discussed in the upstream Kubeflow repo (<code>kubeflow/manifests#2087</code>), to resolve it, you will need to increase your system's open/watched file limits.</p> <p>On linux, you may need to increase the <code>fs.inotify.max_user_*</code> sysctl values:</p> <ol> <li>Modify <code>/etc/sysctl.conf</code> to include the following lines:<ul> <li><code>fs.inotify.max_user_instances = 1280</code></li> <li><code>fs.inotify.max_user_watches = 655360</code></li> </ul> </li> <li>Reload sysctl configs by running <code>sudo sysctl -p</code></li> </ol>"},{"location":"guides/platform/deploykf-authentication/","title":"User Authentication and External Identity Providers","text":"<p>This guide explains how to configure user authentication and connect with external identity providers in deployKF.</p> <p>Related Guides</p> <p>In addition to configuring how users are authenticated, you will likely want to authorize them by assigning to profiles. Note, the level of access a user has is directly determined by which profiles they are a member of.</p>"},{"location":"guides/platform/deploykf-authentication/#overview","title":"Overview","text":"<p>deployKF uses Dex and Oauth2 Proxy via our Istio <code>EnvoyFilters</code> for user authentication.</p> <p>Dex allows multiple authentication methods to be used at the same time, including:</p> <ul> <li>Connecting External Identity Providers</li> <li>Defining Static User/Password Combinations</li> </ul>"},{"location":"guides/platform/deploykf-authentication/#external-identity-providers","title":"External Identity Providers","text":"<p>Dex provides connectors for many external identity providers including LDAP (Active Directory), GitHub, Google, Microsoft and OpenID Connect (Azure, Okta, Salesforce, etc).</p> <p>The <code>deploykf_core.deploykf_auth.dex.connectors</code> value configures the list of connectors which are available for user authentication.</p> <p>For example, to connect with Google, you might use the following values:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        ## NOTE:\n        ##  - this element is formatted the same as described in: \n        ##    https://dexidp.io/docs/connectors/google/\n        ##  - in addition to `type`, `id`, `name`, and `config`, \n        ##    which are the same as upstream dex, we provide the\n        ##    `configExistingSecret` and `configExistingSecretKey`\n        ##    fields, to set the `config` from a kubernetes secret\n        - type: google\n          id: google\n          name: Google\n\n          ## NOTE: \n          ##  - the full `config` must come from a single source, \n          ##     you can NOT mix `config` and `configExistingSecret`\n          config:\n           clientID : \"kubeflow\"\n           clientSecret : \"XXXXXXXXXXXXXXXXXXXXXXXXX\"\n           redirectURI : \"https://XXXXXXXX/dex/callback\"\n\n          ## NOTE: \n          ##  - the `configExistingSecretKey` key in the secret must \n          ##    contain a string of YAML that is formatted the same \n          ##    as the CONTENTS of the `config` map key above\n          #configExistingSecret: \"my-dex-connector-secret\"\n          #configExistingSecretKey: \"google-config\"\n</code></pre> <p>SAML 2.0 Connector</p> <p>You should NOT use the SAML 2.0 connector, as it does not support refreshing tokens, so users would be forced to re-login every 60 minutes.</p>"},{"location":"guides/platform/deploykf-authentication/#static-userpassword-combinations","title":"Static User/Password Combinations","text":"<p>The <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> value defines a list of static user/password combinations.</p> <p>For example, you might use the following values to define three users:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      staticPasswords:\n        ## a user with password defined as a plaintext value\n        - email: \"plaintext@example.com\"\n          password:\n            value: \"password\"\n\n        ## a user with password defined as a bcrypt hash\n        ##  - a bcrypt hash for \"PASSWORD_STRING\" can be generated with one of the following:\n        ##     - echo \"PASSWORD_STRING\" | htpasswd -BinC 10 NULL | cut -d: -f2\n        ##     - python -c 'import bcrypt; print(bcrypt.hashpw(b\"password\", bcrypt.gensalt(10)).decode())'\n        - email: \"bcrypt@example.com\"\n          password:\n            ## the bcrypt hash of the password \"password\"\n            value: \"$2y$10$z22lKMtSyC65VhMfTROkGesiS2ofrVQQdkGu.vjhIH2HM5Epmhil2\"\n            type: \"hash\"\n\n        ## a user with password defined from a kubernetes secret\n        - email: \"kubernetes-secret@example.com\"\n          existingSecret: \"my-secret\"\n          existingSecretKey: \"password-key\"\n</code></pre> <p>Password Secret Rotation</p> <p>If a user's password is defined from a Kubernetes Secret, the password will be automatically rotated when the Secret is updated.</p> <p>Service Accounts</p> <p>The static accounts are commonly used as \"service accounts\" for things like Accessing the Kubeflow Pipelines API, but may also be used for regular users if you do not have an external identity provider.</p>"},{"location":"guides/platform/deploykf-dashboard/","title":"Customize the Dashboard","text":"<p>This guide explains how to customize the deployKF Dashboard.</p>"},{"location":"guides/platform/deploykf-dashboard/#overview","title":"Overview","text":"<p>The deployKF Dashboard is the web-based interface for deployKF, and is the primary way that users interact with the platform.</p> <p>The dashboard includes navigation menus with links to various tools and documentation which can be customized.</p>"},{"location":"guides/platform/deploykf-dashboard/#sidebar-links","title":"Sidebar Links","text":"<p>Extra links may be added to the sidebar navigation menu with the <code>deploykf_core.deploykf_dashboard.navigation.externalLinks</code> value.</p> <p>For example, you may use the following values to add a link to the deployKF website:</p> <pre><code>deploykf_core:\n  deploykf_dashboard:\n    navigation:\n      externalLinks:\n        - name: \"deployKF Website\"\n          url: \"https://deployKF.org\"\n          icon: \"launch\"\n</code></pre>"},{"location":"guides/platform/deploykf-dashboard/#documentation-links","title":"Documentation Links","text":"<p>Extra links may be added to the \"documentation\" section of the home page with the <code>deploykf_core.deploykf_dashboard.navigation.documentationItems</code> value.</p> <p>For example, you may use the following values to add a link to the deployKF website:</p> <pre><code>deploykf_core:\n  deploykf_dashboard:\n    navigation:\n      documentationItems:\n        - text: \"deployKF Website\"\n          desc: \"The tool that deployed your ML platform!\"\n          link: \"https://github.com/deployKF/deployKF\"\n</code></pre>"},{"location":"guides/platform/deploykf-gateway/","title":"Expose Gateway and configure HTTPS","text":"<p>This guide explains how to expose the deployKF Gateway and configure HTTPS.</p> <p>Help Improve this Guide</p> <p>This guide covers an incredibly broad topic with near limitless possible implementations. If you see anything incorrect or missing, please help us by raising an issue!</p>"},{"location":"guides/platform/deploykf-gateway/#overview","title":"Overview","text":"<p>The \"deployKF Gateway Service\" is the main network entry point to deployKF.  By default, it is a Kubernetes Service named <code>deploykf-gateway</code> pointing to our Istio Ingress Gateway pods.</p>"},{"location":"guides/platform/deploykf-gateway/#1-set-hostname-and-ports","title":"1. Set Hostname and Ports","text":"<p>The hostnames and ports on which the deployKF Gateway listens are configured with these values:</p> Value Purpose <code>deploykf_core.deploykf_istio_gateway.gateway.hostname</code> base domain name <code>deploykf_core.deploykf_istio_gateway.gateway.ports</code> ports for HTTP/HTTPS <p>For example, the following values will use <code>deploykf.example.com</code> on port <code>80</code> and <code>443</code>:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n    gateway:\n      ## NOTE: this domain and its subdomains must be dedicated to deployKF\n      hostname: deploykf.example.com\n\n      ## NOTE: these are the defaults, but if you are using 'sample-values.yaml' \n      ##       as a base, the defaults are 8080/8443, so you will need to \n      ##       override them to use the standard ports \n      ports:\n        http: 80\n        https: 443\n</code></pre> <p>Depending on which tools you have enabled, the gateway may serve the following hostnames:</p> Hostname Description <code>deploykf.example.com</code> the deployKF Gateway <code>argo-server.deploykf.example.com</code> the Argo Server UI <code>minio-api.deploykf.example.com</code> the MinIO API <code>minio-console.deploykf.example.com</code> the MinIO UI"},{"location":"guides/platform/deploykf-gateway/#2-expose-the-gateway-service","title":"2. Expose the Gateway Service","text":"<p>So your users can access deployKF, the deployKF Gateway Service will need to be accessible from outside the cluster. There are two main options to expose the deployKF Gateway Service:</p> <ol> <li>Use a LoadBalancer type <code>Service</code> (recommended)</li> <li>Configure an <code>Ingress</code></li> </ol> Expose Gateway Service - LoadBalancer Service <p>Most Kubernetes platforms provide a LoadBalancer Service that can expose on a public/private IP address.</p> <p>To use this option, you will generally need to do the following:</p> <ol> <li>Set the <code>deploykf_core.deploykf_istio_gateway.gatewayService.type</code> value to <code>\"LoadBalancer\"</code> (the default)</li> <li>Use the <code>deploykf_core.deploykf_istio_gateway.gatewayService.annotations</code> value to configure the Service</li> </ol> <p>How you configure a LoadBalancer Service will depend on the platform you are using, for example:</p> Amazon Web Services (EKS) <p>The AWS Load Balancer Controller is commonly used to configure LoadBalancer services on EKS.</p> <p>For example, you might set the following values to use a Network Load Balancer (NLB):</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## these values are used to configure the deployKF Gateway Service\n    ##\n    gatewayService:\n      name: \"deploykf-gateway\"\n      type: \"LoadBalancer\"\n      annotations:\n        service.beta.kubernetes.io/aws-load-balancer-type: \"external\"\n        service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: \"ip\"\n        service.beta.kubernetes.io/aws-load-balancer-scheme: \"internal\"\n\n        ## for external-dns integration (if not `--source=istio-gateway` config)\n        #external-dns.alpha.kubernetes.io/hostname: \"deploykf.example.com, *.deploykf.example.com\"\n\n        ## for static private IP addresses\n        #service.beta.kubernetes.io/aws-load-balancer-private-ipv4-addresses: \"192.168.XXX.XXX, 192.168.YYY.YYY\"\n        #service.beta.kubernetes.io/aws-load-balancer-subnets: \"subnet-XXX, subnet-YYY\"\n\n        ## for static public IP addresses\n        #service.beta.kubernetes.io/aws-load-balancer-eip-allocations: \"eipalloc-XXX, eipalloc-YYY\"\n        #service.beta.kubernetes.io/aws-load-balancer-subnets: \"subnet-XXX, subnet-YYY\"\n</code></pre> Google Cloud (GKE) <p>GKE, has a LoadBalancer Service type, which is configured with annotations like <code>networking.gke.io/load-balancer-type</code>. </p> <p>For example, you might set the following values to use an INTERNAL Passthrough Network Load Balancer:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## these values are used to configure the deployKF Gateway Service\n    ##\n    gatewayService:\n      name: \"deploykf-gateway\"\n      type: \"LoadBalancer\"\n      annotations:\n        networking.gke.io/load-balancer-type: \"Internal\"\n\n        ## for external-dns integration (if not `--source=istio-gateway` config)\n        #external-dns.alpha.kubernetes.io/hostname: \"deploykf.example.com, *.deploykf.example.com\"\n\n      ## for static IP addresses\n      #loadBalancerIP: \"192.168.XXX.XXX\"\n      #loadBalancerSourceRanges: [\"192.168.XXX.XXX/32\"]\n</code></pre> Expose Gateway Service - Ingress <p>Most Kubernetes platforms provide an Ingress class that can expose on a public/private IP address.</p> <p>To use this option, you will generally need to do the following:</p> <ol> <li>Set the <code>deploykf_core.deploykf_istio_gateway.gatewayService.type</code> value to <code>\"NodePort\"</code> or <code>\"ClusterIP\"</code></li> <li>Use the <code>deploykf_core.deploykf_istio_gateway.gatewayService.annotations</code> value to configure the Service</li> <li>Create an <code>Ingress</code> resource that points to the <code>deploykf-gateway</code> Service</li> </ol> <p>How you configure an Ingress will depend on the platform you are using, for example:</p> Amazon Web Services (EKS) <p>The AWS Load Balancer Controller is commonly used to configure Ingress resources on EKS.</p> <p>Because ALB does NOT support TLS-passthrough, you must manually create an AWS Certificate Manager (ACM) wildcard certificate for your domain. The <code>alb.ingress.kubernetes.io/certificate-arn</code> Ingress annotation will be used to select the certificate and allow the Ingress to terminate TLS before forwarding to the Gateway Service.</p> Hostname Certificate Field <code>*.deploykf.example.com</code> CN, SAN <code>deploykf.example.com</code> SAN <p>For example, you might set the following values to use an Application Load Balancer (ALB):</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## this value is used to add arbitrary manifests to the generated output\n    ##\n    extraManifests:\n      - |\n        apiVersion: extensions/v1beta1\n        kind: Ingress\n        metadata:\n          name: deploykf-gateway\n          annotations:\n            alb.ingress.kubernetes.io/scheme: internal\n            alb.ingress.kubernetes.io/target-type: ip\n            alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n            alb.ingress.kubernetes.io/ssl-redirect: '443'\n            alb.ingress.kubernetes.io/certificate-arn: \"arn:aws:acm:REGION_NAME:ACCOUNT_ID:certificate/CERTIFICATE_ID\"\n            alb.ingress.kubernetes.io/backend-protocol: HTTPS\n        spec:\n          ingressClassName: alb                  \n          rules:\n            - host: \"deploykf.example.com\"\n              http:\n                paths:\n                  - path: \"/*\"\n                    backend:\n                      service:\n                        name: \"deploykf-gateway\"\n                        port:\n                          name: https\n            - host: \"*.deploykf.example.com\"\n              http:\n                paths:\n                  - path: \"/*\"\n                    backend:\n                      service:\n                        name: \"deploykf-gateway\"\n                        port:\n                          name: https\n\n    ## these values are used to configure the deployKF Gateway Service\n    ##\n    gatewayService:\n      name: \"deploykf-gateway\"\n      type: \"NodePort\"\n      annotations: {}\n</code></pre> Google Cloud (GKE) <p>GKE, has an Ingress class that can be used to configure Ingress resources for external or internal access. </p> <p>In the following example, we are configuring the GKE Ingress to use the same TLS certificate as the deployKF Gateway Service (found in <code>Secret/deploykf-istio-gateway-cert</code>). Later in this guide you will learn how to make this certificate valid, and not self-signed.</p> <p>For example, you might set the following values to use an INTERNAL Application Load Balancer:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n      ## this value is used to add arbitrary manifests to the generated output\n      ##\n      extraManifests:\n        - |\n          apiVersion: networking.k8s.io/v1\n          kind: Ingress\n          metadata:\n            name: deploykf-gateway\n            annotations:\n              kubernetes.io/ingress.class: \"gce-internal\"\n              kubernetes.io/ingress.allow-http: \"false\"\n          spec:\n            tls:\n              ## NOTE: this secret is created as part of the deployKF installation\n              - secretName: \"deploykf-istio-gateway-cert\"\n            rules:\n              - host: \"deploykf.example.com\"\n                http:\n                  paths:\n                    - path: \"/*\"\n                      pathType: ImplementationSpecific\n                      backend:\n                        service:\n                          name: \"deploykf-gateway\"\n                          port:\n                            name: https\n              - host: \"*.deploykf.example.com\"\n                http:\n                  paths:\n                    - path: \"/*\"\n                      pathType: ImplementationSpecific\n                      backend:\n                        service:\n                          name: \"deploykf-gateway\"\n                          port:\n                            name: https\n\n      ## these values are used to configure the deployKF Gateway Service\n      ##\n      gatewayService:\n        name: \"deploykf-gateway\"\n        type: \"NodePort\"\n        annotations:\n          cloud.google.com/app-protocols: '{\"https\":\"HTTPS\",\"http\":\"HTTP\"}'\n\n          ## this annotation may be required if you are using a Shared VPC\n          ##  https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balance-ingress#shared_vpc\n          #cloud.google.com/neg: '{\"ingress\": true}'\n</code></pre> <p>Public Internet</p> <p>You should seriously consider the security implications of exposing the deployKF Gateway to the public internet. Given the nature of ML Platforms, most organizations choose to expose the gateway on their private network, and then use a VPN or other secure connection to access it.</p> <p>Ingress vs LoadBalancer</p> <p>In most cases, using a LoadBalancer Service rather than an Ingress is preferred for the following reasons:</p> <ol> <li>Faster: less hops between the client and the gateway</li> <li>Future-proof: deployKF might expose non-HTTP services in the future</li> <li>Simpler TLS: many Ingress controllers don't support TLS passthrough</li> </ol> <p>Including Arbitrary Manifests</p> <p>deployKF provides an <code>extraManifests</code> value for each component which allows arbitrary YAML manifests to be added to the generated output.</p> <p>For example, <code>deploykf_core.deploykf_istio_gateway.extraManifests</code> may be used to add a custom Ingress or Secret resource to the generated output of the <code>deploykf-istio-gateway</code> component.</p>"},{"location":"guides/platform/deploykf-gateway/#3-configure-dns","title":"3. Configure DNS","text":"<p>Now that the deployKF Gateway Service has an IP address, you must configure DNS records which point to it. There are two main options to provision DNS records:</p> <ol> <li>Automatically with External-DNS (recommended)</li> <li>Manually with your DNS provider</li> </ol> Configure DNS - External-DNS <p>External-DNS is a Kubernetes controller that automatically configures DNS records for Kubernetes resources.</p> <p>To use this option, you will generally need to do the following:</p> <ol> <li>Install External-DNS and connect it to your DNS provider</li> <li>Configure External-DNS to set DNS records for the deployKF Gateway Service</li> </ol> <p>Step 1: Install External-DNS</p> <p>The External-DNS documentation provides instructions for installing External-DNS on various platforms.</p> <p>Here are some popular platforms:</p> Cloud Platform DNS Provider Amazon Web Services Route53 Google Cloud Cloud DNS Microsoft Azure Azure DNS, Azure Private DNS Any Cloudflare, Akamai Edge DNS <p>Step 2: Configure External-DNS</p> <p>There are a few ways to configure External-DNS so that it sets DNS records for the deployKF Gateway Service.</p> Configure External-DNS - Automatically from Istio Gateway <p>You may configure External-DNS to automatically extract the domain names from Istio <code>Gateway</code> resources.</p> <p>If you do this, a separate DNS record is created for each domain selected by our Istio <code>Gateway</code>.</p> <p>To connect External-DNS with Istio, you will need to:</p> <ol> <li>Update your <code>Deployment/external-dns</code> to set the <code>--source=istio-gateway</code> start argument</li> <li>Update your <code>ClusterRole/external-dns</code> to allow access to Istio <code>Gateway</code> and <code>VirtualService</code> resources</li> </ol> Configure External-DNS - Manual Annotations <p>You can manually configure External-DNS by annotating the <code>Service</code> or <code>Ingress</code> resource with the <code>external-dns.alpha.kubernetes.io/hostname</code> annotation.</p> <p>If you do this, you need to add BOTH the base domain AND subdomains. You can avoid the need to specify each subdomain by using a wildcard DNS record, but you will still need to specify the base domain. Multiple hostnames can be specified in a single annotation using a comma-separated list.</p> <p>Depending on if you are using a Service or Ingress, you will set the <code>external-dns.alpha.kubernetes.io/hostname</code> annotation by:</p> <ul> <li>Service: setting the <code>deploykf_core.deploykf_istio_gateway.gatewayService.annotations</code> value</li> <li>Ingress: manually annotating your Ingress resource</li> </ul> <p>Deletion of DNS Records</p> <p>Be aware that External-DNS will delete the DNS records associated with resources when they are deleted:</p> <ul> <li>When using the annotation method, deleting the <code>Service</code> or <code>Ingress</code> resource will delete the associated DNS records.</li> <li>When using <code>--source=istio-gateway</code>, deleting the Istio <code>Gateway</code> or <code>VirtualService</code> will delete the associated DNS records.</li> </ul> <p>Remember that DNS records take time to propagate, so you may experience downtime if you delete resources and then recreate them.</p> Configure DNS - Manual <p>You can manually configure DNS records with your DNS provider that target your deployKF Gateway Service.</p> <p>To use this option, you will generally need to do the following:</p> <ol> <li>Ensure the deployKF Gateway has a static IP address (or hostname, in some cases)</li> <li>Configure DNS records with your DNS provider</li> </ol> <p>Step 1: Static IP Addresses</p> <p>Each type of LoadBalancer Service (or Ingress controller) has different ways to configure static IP addresses or hostnames. Please refer to the documentation for your platform.</p> <p>Step 2: Configure DNS Records</p> <p>You need to create records for BOTH the base domain AND subdomains. You can avoid the need to specify each subdomain by using a wildcard DNS record, but you will still need to specify the base domain.</p> <p>Wildcard DNS Records</p> <p>If you plan to manually create the records (either via External-DNS annotations or manual record creation), we recommend using a wildcard DNS record to account for any future subdomains that may be added to the deployKF Gateway Service.</p> <p>For example, you might set BOTH the following DNS records:</p> <ul> <li><code>*.deploykf.example.com</code></li> <li><code>deploykf.example.com</code></li> </ul>"},{"location":"guides/platform/deploykf-gateway/#4-configure-httpstls","title":"4. Configure HTTPS/TLS","text":"<p>Now that the deployKF Gateway Service has a DNS pointing to it, to prevent self-signed certificate errors, you must configure a way to make the TLS certificates valid.</p> <ul> <li>If you are exposing the Gateway with a LoadBalancer type Service, then ONLY the Istio Gateway will need to be configured with valid TLS certificates.</li> <li>If you are exposing the Gateway with an Ingress, then BOTH the Istio Gateway and the Ingress will need to be configured with valid TLS certificates (unless your Ingress supports TLS passthrough, which most do not).</li> </ul> <p>The following sections explain how to configure TLS at the Istio Gateway and Ingress levels.</p> Configure TLS - Istio Gateway <p>This section explains how to configure TLS for the Istio Gateway (which you will always need to do).</p> <p>deployKF includes cert-manager to automatically generate TLS certificates for the Istio Gateway.</p> <p>By default, the Istio Gateway uses a self-signed certificate generated by this <code>ClusterIssuer</code>, which is fine for testing (especially if you don't own the domain you are using), but not recommended for production usage.</p> <p>To have cert-manager generate valid TLS certificates for the Istio Gateway, you will need to:</p> <ol> <li>Connect cert-manager to your DNS provider</li> <li>Create a <code>ClusterIssuer</code> resource that can generate certificates for your domain</li> <li>Configure the Istio Gateway to use your <code>ClusterIssuer</code> to generate certificates</li> </ol> <p>Can I bring my own cert-manager?</p> <p>Yes. deployKF includes an embedded version of cert-manager, but if you want to bring your own, you may set the <code>deploykf_dependencies.cert_manager.enabled</code> value to <code>false</code>.</p> <p>Note, if you do this, the <code>deploykf_dependencies.cert_manager.clusterIssuer</code> values are still used to select the <code>ClusterIssuer</code> (provisioned by you), which is used to generate certificates for the Istio Gateway.</p> <p>ServiceAccount Annotations</p> <p>To use Pod-based authentication with your DNS Provider (for example, to use IRSA on EKS), you may need to annotate the cert-manager ServiceAccount.</p> <p>Custom ServiceAccount annotations may be applied to the embedded cert-manager with the <code>deploykf_dependencies.cert_manager.controller.serviceAccount.annotations</code> value.</p> <p> STEP 1: Connect cert-manager to DNS Provider</p> <p>For almost everyone, the best Certificate Authority (CA) is Let's Encrypt.</p> <p>Because deployKF uses a wildcard <code>Certificate</code>, you MUST use the <code>DNS-01</code> challenge to verify domain ownership rather than <code>HTTP-01</code>. This requires you to configure cert-manager so that it is able to create DNS records.</p> <p>The cert-manager documentation provides instructions for configuring <code>DNS-01</code> challenges for various DNS providers. The following table lists some popular DNS providers:</p> Cloud Platform DNS Provider Amazon Web Services Route53 Google Cloud Cloud DNS Microsoft Azure Azure DNS Any Cloudflare, Akamai Edge DNS <p>Issuer Kind</p> <p>Most cert-manager examples show an <code>Issuer</code> resource.  Note that any issuer may be converted to its equivalent cluster version by changing the <code>kind</code> field from <code>\"Issuer\"</code> to <code>\"ClusterIssuer\"</code> and removing the <code>metadata.namespace</code> field.</p> <p>STEP 2: Create a ClusterIssuer</p> <p>Once cert-manager is connected to your DNS provider, you must create a <code>ClusterIssuer</code> resource that can generate certificates for your domain from Let's Encrypt.</p> <p>For example, you may create a <code>ClusterIssuer</code> resource like this when using Google Cloud DNS:</p> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: my-cluster-issuer\nspec:\n  acme:\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    email: user@example.com\n    privateKeySecretRef:\n      name: letsencrypt-staging\n      key: tls.key\n    solvers:\n      - dns01:\n          cloudDNS:\n            project: my-project-id\n            serviceAccountSecretRef:\n              name: my-service-account-secret\n              key: service-account.json\n        selector:\n          dnsNames:\n            - \"*.deploykf.example.com\"\n            - \"deploykf.example.com\"\n</code></pre> <p>STEP 3: Configure the Istio Gateway</p> <p>Once you have a <code>ClusterIssuer</code> resource that can generate certificates for your domain, you must configure the deployKF Istio Gateway to use it.</p> <p>This is done by using the <code>deploykf_dependencies.cert_manager.clusterIssuer</code> values. For example, if you created a <code>ClusterIssuer</code> named <code>my-cluster-issuer</code>, you would set the following values:</p> <pre><code>deploykf_dependencies:\n  cert_manager:\n    clusterIssuer:\n      ## this tells deployKF that you have created a ClusterIssuer\n      enabled: false\n\n      ## this value should match the name of your ClusterIssuer\n      issuerName: \"my-cluster-issuer\"\n</code></pre> Configure TLS - Ingress <p>This section explains how to configure TLS for your Ingress (if you are using one).</p> <p>Both Istio Gateway and Ingress need valid TLS</p> <p>Pods which are in the Istio mesh use hairpinning (via this Istio <code>ServiceEntry</code>) to access the gateway without leaving the cluster. This means that even if your Ingress has a valid TLS certificate, if you do not Configure TLS for the Istio Gateway, you may see certificate errors when accessing services from within the cluster.</p> <p>How you configure TLS for your Ingress will depend on which Ingress controller you are using. Please refer to the documentation for your platform.</p> <p>Share Certificate with Istio Gateway</p> <p>In some cases, your Ingress can use the same TLS certificate as the Istio Gateway.</p> <p>By default, a Kubernetes <code>Secret</code> named <code>deploykf-istio-gateway-cert</code> which contains the certificate is found in the <code>deploykf-istio-gateway</code> namespace, managed by this <code>Certificate</code> resource. If your Ingress controller supports referencing a Kubernetes <code>Secret</code> for TLS certificates, you can use this <code>Secret</code> to share the certificate with your Ingress.</p>"},{"location":"guides/platform/deploykf-profiles/","title":"User Authorization and Profile Management","text":"<p>This guide explains how to manage profiles and assign users to them in deployKF.</p> <p>Related Guides</p> <p>Users are identified and selected into profiles by an email-like string which is verified by the authentication system. Before reading this guide, you may want to define static user credentials or connect with an external identity provider.</p>"},{"location":"guides/platform/deploykf-profiles/#introduction","title":"Introduction","text":"<p>A deployKF profile has a 1:1 relationship with a Kubernetes namespace. The profiles which users are members of determine their level of access to resources/tools in the cluster.</p> <p>The core entities of the profile system are:</p> Entity Description User User entities are identified by email address, and may be assigned to groups or profiles. Group Group entities are logical collections of users, and may be assigned to profiles. Profile Profiles define the access level for the users/groups assigned to them. <p>No Profile = No Access</p> <p>If a user is not a member of any profiles, they will NOT have any access, even though they may be able to log in.</p> <p>Use Profile Generator Only</p> <p>You must ONLY use the <code>deploykf_core.deploykf_profiles_generator</code> values to manage profile definitions or user assignments. Any manual changes using the UI or other manifests will result in undefined behaviour.</p>"},{"location":"guides/platform/deploykf-profiles/#user-entities","title":"User Entities","text":"<p>The <code>deploykf_core.deploykf_profiles_generator.users</code> value defines \"user\" entities.</p> <p>For example, you might use the following values to define three users:</p> <pre><code>deploykf_core:\n  deploykf_profiles_generator:\n    users:\n      - id: user-1\n        email: \"user1@example.com\"\n\n      - id: user-2\n        email: \"user2@example.com\"\n\n      - id: user-3\n        email: \"user3@example.com\"\n</code></pre> <p>User Identifiers</p> <p>Users are identified by email address, which is provided from the identity provider or static accounts, this means that each <code>email</code> must be unique.</p>"},{"location":"guides/platform/deploykf-profiles/#group-entities","title":"Group Entities","text":"<p>The <code>deploykf_core.deploykf_profiles_generator.groups</code> value defines \"group\" entities, which are logical collections of \"user\" entities.</p> <p>For example, you might use the following values to define two groups:</p> <pre><code>deploykf_core:\n  deploykf_profiles_generator:\n    groups:\n      - id: team-1--admins\n        users:\n          - user-1\n\n      - id: team-1--users\n        users:\n          - user-1\n          - user-2\n          - user-3\n</code></pre> <p>Syncing External Groups</p> <p>Currently, groups must be manually defined in the values, and can NOT be synced from an external identity provider.</p>"},{"location":"guides/platform/deploykf-profiles/#profile-definitions","title":"Profile Definitions","text":"<p>The <code>deploykf_core.deploykf_profiles_generator.profiles</code> value defines the profiles (namespaces) to create, and the groups/users to assign to them.</p> <p>For example, you might use the following values to define two profiles:</p> <pre><code>deploykf_core:\n  deploykf_profiles_generator:\n    profiles:\n      - name: team-1\n        members:\n          - group: team-1--users\n            access:\n              role: edit\n              notebooksAccess: true\n\n      - name: team-1-prod\n        members:\n          - group: team-1--admins\n            access:\n              role: edit\n              notebooksAccess: true\n\n          - group: team-1--users\n            access:\n              role: view\n              notebooksAccess: false\n</code></pre> <p>Highest Level of Access</p> <p>If a user has multiple memberships in the same profile, the highest level of access will be used.</p> <p>Default Profile Owner</p> <p>By default, <code>\"admin@example.com\"</code> is the \"owner\" of all profiles, but is not a \"member\" of any. This means that it does not have access to the \"MinIO Console\" or \"Argo Workflows Server\" interfaces.</p> <p>Because it is NOT possible to change the owner of a profile (<code>kubeflow/kubeflow#6576</code>), we recommend that you leave the default owner as <code>admin@example.com</code>, and never log into that account.</p> <p>For additional security, remove the <code>staticPasswords</code> entry for that email, so it can never be used to log in.</p>"},{"location":"guides/tools/external-mysql/","title":"Connect an external MySQL Database","text":"<p>This guide explains how to connect an external MySQL database with deployKF.</p>"},{"location":"guides/tools/external-mysql/#introduction","title":"Introduction","text":"<p>deployKF includes an embedded MySQL instance. However, you will likely want to replace this with an external MySQL database for production usage.</p> <p>Embedded MySQL is NOT for Production</p> <p>The embedded MySQL instance is only intended for development and testing purposes. It is a single-instance MySQL server, with no backups, and no high-availability. For production usage, you should always use an external MySQL database.</p> <p>MySQL 8.0.4+</p> <p>Kubeflow Pipelines ONLY supports authenticating with the <code>mysql_native_password</code> plugin and NOT the <code>caching_sha2_password</code> plugin (see <code>kubeflow/pipelines#9549</code>).</p> <p>Since MySQL version 8.0.4, the default authentication plugin is <code>caching_sha2_password</code>, so you may have to explicitly set the <code>mysql_native_password</code> plugin for the user you create. </p> <p>Alternatively, you may set your MySQL server's <code>default-authentication-plugin</code> to <code>mysql_native_password</code>.</p>"},{"location":"guides/tools/external-mysql/#1-disable-embedded-mysql","title":"1. Disable Embedded MySQL","text":"<p>The <code>deploykf_opt.deploykf_mysql.enabled</code> value controls if the embedded MySQL instance is deployed.</p> <p>For example, to disable MySQL, set the following value:</p> <pre><code>deploykf_opt:\n  deploykf_mysql:\n    enabled: false\n</code></pre>"},{"location":"guides/tools/external-mysql/#2-create-databases-and-user","title":"2. Create Databases and User","text":"<p>You must manually create the databases (schemas) for Kubeflow Pipelines and Katib, and assign the correct permissions to the users they connect as.</p> <p>For example, you might run the following SQL commands to create the databases and users:</p> <pre><code>-- create the databases\nCREATE DATABASE IF NOT EXISTS `katib`;\nCREATE DATABASE IF NOT EXISTS `kfp_cache`;\nCREATE DATABASE IF NOT EXISTS `kfp_metadata`;\nCREATE DATABASE IF NOT EXISTS `kfp_pipelines`;\n\n-- create the 'kubeflow' user (allowing access from any host)\nCREATE USER 'kubeflow'@'%' IDENTIFIED WITH mysql_native_password BY 'MY_PASSWORD';\n\n-- grant access to the databases\nGRANT ALL PRIVILEGES ON `katib`.* TO 'kubeflow'@'%';\nGRANT ALL PRIVILEGES ON `kfp_cache`.* TO 'kubeflow'@'%';\nGRANT ALL PRIVILEGES ON `kfp_metadata`.* TO 'kubeflow'@'%';\nGRANT ALL PRIVILEGES ON `kfp_pipelines`.* TO 'kubeflow'@'%';\n</code></pre> <p>Here are some MySQL database services which can be used with deployKF:</p> Platform MySQL Service Amazon Web Services Amazon Relational Database Service (RDS) Microsoft Azure Azure Database for MySQL Google Cloud Cloud SQL Alibaba Cloud ApsaraDB RDS for MySQL IBM Cloud IBM Cloud Databases for MySQL Self-Hosted MySQL Community Edition"},{"location":"guides/tools/external-mysql/#3-connect-katib","title":"3. Connect Katib","text":"<p>To connect Katib to your external MySQL database, you will need to configure the following values:</p> Value Purpose <code>kubeflow_tools.katib.mysqlDatabase</code> name of database/schema <code>kubeflow_tools.katib.mysql</code> connection details &amp; credentials <p>For example, the following values will connect Katib to an external MySQL database:</p> <pre><code>kubeflow_tools:\n  katib:\n    mysqlDatabase: \"katib\"\n\n    mysql:\n      useExternal: true\n      host: \"mysql.example.com\"\n      port: 3306\n      auth:\n        ## (OPTION 1):\n        ##  - set username/password with values (NOT RECOMMENDED)\n        #username: kubeflow\n        #password: password\n\n        ## (OPTION 2):\n        ##  - read a kubernetes secret from the 'kubeflow' namespace\n        ##  - note, `existingSecret*Key` specifies the KEY NAMES in the \n        ##    secret itself, which contain the secret values\n        existingSecret: \"my-secret-name\"\n        existingSecretUsernameKey: \"username\"\n        existingSecretPasswordKey: \"password\"\n</code></pre>"},{"location":"guides/tools/external-mysql/#4-connect-kubeflow-pipelines","title":"4. Connect Kubeflow Pipelines","text":"<p>To connect Kubeflow Pipelines to your external MySQL database, you will need to configure the following values:</p> Value Purpose <code>kubeflow_tools.pipelines.mysqlDatabases</code> names of databases/schemas <code>kubeflow_tools.pipelines.mysql</code> connection details &amp; credentials <p>For example, the following values will connect Kubeflow Pipelines to an external MySQL database:</p> <pre><code>kubectl_tools:\n  pipelines:\n    mysqlDatabases:\n      cacheDatabase: kfp_cache\n      metadataDatabase: kfp_metadata\n      pipelinesDatabase: kfp_pipelines\n\n    mysql:\n      useExternal: true\n      host: \"mysql.example.com\"\n      port: 3306\n      auth:\n        ## (OPTION 1):\n        ##  - set username/password with values (NOT RECOMMENDED)\n        #username: kubeflow\n        #password: password\n\n        ## (OPTION 2):\n        ##  - read a kubernetes secret from the 'kubeflow' namespace\n        ##  - note, `existingSecret*Key` specifies the KEY NAMES in the \n        ##    secret itself, which contain the secret values\n        existingSecret: \"my-secret-name\"\n        existingSecretUsernameKey: \"username\"\n        existingSecretPasswordKey: \"password\"\n</code></pre>"},{"location":"guides/tools/external-object-store/","title":"Connect an external Object Store","text":"<p>This guide explains how to connect an external object store that is S3-compatible with deployKF.</p>"},{"location":"guides/tools/external-object-store/#introduction","title":"Introduction","text":"<p>deployKF includes an embedded MinIO instance.  However, you will likely want to replace this with an external S3-like object store for production usage.</p> <p>Embedded MinIO is NOT for Production</p> <p>Currently, the embedded MinIO is only intended for development and testing purposes as it only supports a single replica. In future, we may add support for a multi-replica MinIO deployment, but for now you should always use an external S3-like object store for production usage.</p> <p>MinIO License</p> <p>If you choose to use the embedded MinIO, please ensure you are familiar with MinIO's licence. At the time of writing it was AGPLv3. However, rest assured that deployKF itself does NOT contain any code from MinIO, and is licensed under the Apache 2.0 License.</p>"},{"location":"guides/tools/external-object-store/#1-disable-embedded-minio","title":"1. Disable Embedded MinIO","text":"<p>The <code>deploykf_opt.deploykf_minio.enabled</code> value controls if the embedded MinIO instance is deployed.</p> <p>For example, to disable MinIO, set the following value:</p> <pre><code>deploykf_opt:\n  deploykf_minio:\n    enabled: false\n</code></pre>"},{"location":"guides/tools/external-object-store/#2-create-buckets","title":"2. Create Buckets","text":"<p>You must manually create the buckets that Kubeflow Pipelines will use. Please refer to the documentation for your object store for instructions on how to create buckets. For example, if you are using S3 you may use the AWS Console or the AWS CLI.</p> <p>Here are some object stores which can be used with Kubeflow Pipelines:</p> Platform Object Store XML API Endpoint Amazon Web Services Amazon S3 <code>s3.amazonaws.com</code> Google Cloud Google Cloud Storage <code>storage.googleapis.com</code> Microsoft Azure Azure Blob Storage No first-party S3 API, but translation layers like S3Proxy can be used. Alibaba Cloud Alibaba Cloud Object Storage Service (OSS) <code>s3.oss-{region}.aliyuncs.com</code> IBM Cloud IBM Cloud Object Storage <code>s3.{region}.cloud-object-storage.appdomain.cloud</code> Other MinIO, Ceph, Wasabi See provider documentation. <p>S3-compatible APIs Only</p> <p>Currently, Kubeflow Pipelines only supports object stores which have an S3-compatible XML API. This means that while you can use services like Google Cloud Storage, you will need to use their XML API, and features like GKE Workload Identity will NOT work.</p> <p>If you would like Kubeflow Pipelines to implement support for the native APIs of your object store, please raise this with the upstream Kubeflow Pipelines community.</p> <p>Object Prefixes</p> <p>The following table shows bucket prefixes used by Kubeflow Pipelines:</p> Object Prefix Purpose Config Value <code>/pipelines</code> pipeline definitions (can not be changed) <code>/artifacts/{profile_name}</code> pipeline run artifacts (KFP v1) <code>kubeflow_dependencies.kubeflow_argo_workflows.artifactRepository.keyFormat</code> <code>/v2/artifacts/{profile_name}</code> pipeline run artifacts (KFP v2) <code>kubeflow_tools.pipelines.kfpV2.defaultPipelineRoot</code> <p>Bucket IAM Policies</p> <p>When using the embedded MinIO, we automatically configure prefix-based IAM Policies for each profile.</p> <p>This is possible because of the \"key format\" structure we use for pipeline artifacts, which includes the name of the executing namespace/profile at the start of the key:</p> <ul> <li><code>kubeflow_dependencies.kubeflow_argo_workflows.artifactRepository.keyFormat</code></li> <li><code>kubeflow_tools.pipelines.kfpV2.defaultPipelineRoot</code></li> </ul> <p>To replicate this in your external object store, you may assign an IAM Policy for each profile that is similar to the ones generated by deployKF.</p> <p>The following IAM Policy is used by the Kubeflow Pipelines BACKEND:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetBucketLocation\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:PutObject\",\n        \"s3:DeleteObject\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;/artifacts/*\",\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;/pipelines/*\",\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;/v2/artifacts/*\"\n      ]\n    }\n  ]\n}\n</code></pre> <p>A version of the following IAM Policy is used by each PROFILE:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetBucketLocation\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:PutObject\",\n        \"s3:DeleteObject\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;/artifacts/&lt;PROFILE_NAME&gt;/*\",\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;/v2/artifacts/&lt;PROFILE_NAME&gt;/*\"\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"guides/tools/external-object-store/#3-connect-kubeflow-pipelines","title":"3. Connect Kubeflow Pipelines","text":""},{"location":"guides/tools/external-object-store/#key-based-authentication","title":"Key-based Authentication","text":"<p>Key-based authentication is the simplest way to connect Kubeflow Pipelines to an external object store. The following values are needed to configure key-based auth:</p> Value Purpose <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth</code> Default bucket authentication used in profiles that do NOT have <code>tools.kubeflowPipelines.objectStoreAuth</code> defined in their <code>deploykf_core.deploykf_profiles_generator.profiles</code> list entry. <code>kubeflow_tools.pipelines.objectStore</code> Connection details &amp; bucket authentication used by the KFP backend (not profiles). <code>kubeflow_tools.pipelines.bucket</code> Bucket name and region configs. <p>For example, these values will connect Kubeflow Pipelines to an external object store using key-based authentication:</p> <pre><code>deploykf_core:\n  deploykf_profiles_generator:\n\n    ## NOTE: you may also define `tools.kubeflowPipelines.objectStoreAuth`\n    ##       in a specific profile to override the default auth for that profile\n    profileDefaults:\n      tools:\n        kubeflowPipelines:\n          objectStoreAuth:\n            ## (OPTION 1):\n            ##  - all profiles share the same access key (NOT RECOMMENDED)\n            ##  - note, you will need to create the Kubernetes Secret\n            ##    named `existingSecret` in `existingSecretNamespace`\n            ##  - in this approach, the IAM Policy bound to this access key\n            ##    must have access to all KFP artifacts in the bucket\n            existingSecret: \"my-secret-name\"\n            existingSecretNamespace: \"my-namespace\"\n            existingSecretAccessKeyKey: \"access_key\"\n            existingSecretSecretKeyKey: \"secret_key\"\n\n            ## (OPTION 2):\n            ##  - each profile has its own access key\n            ##  - for each profile you need to create a Kubernetes Secret \n            ##    matching `existingSecret` in `existingSecretNamespace`,\n            ##  - instances of '{profile_name}' in `existingSecret` \n            ##    are replaced with the profile name\n            ##  - the default `existingSecretNamespace` is the kubeflow namespace\n            ##  - in this approach, the IAM Policy bound to each access key\n            ##    can be restricted to only access KFP artifacts of the profile\n            #existingSecret: \"kubeflow-pipelines--profile-object-store-auth--{profile_name}\"\n            #existingSecretNamespace: \"my-namespace\"\n            #existingSecretAccessKeyKey: \"access_key\"\n            #existingSecretSecretKeyKey: \"secret_key\"\n\n    ## example of a profile which overrides the default auth\n    #profiles:\n    #  - name: \"my-profile\"\n    #    members: []\n    #    tools:\n    #      kubeflowPipelines:\n    #        objectStoreAuth:\n    #          existingSecret: \"my-secret-name\"\n    #          existingSecretNamespace: \"\" # defaults to the profile's namespace\n    #          existingSecretAccessKeyKey: \"access_key\"\n    #          existingSecretSecretKeyKey: \"secret_key\"\n\nkubeflow_tools:\n  pipelines:\n    bucket:\n      ## this specifies the name of your bucket (and region, if applicable)\n      name: kubeflow-pipelines\n      region: \"\"\n\n    objectStore:\n      useExternal: true\n\n      ## this specifies the XML REST endpoint of your object store\n      host: s3.amazonaws.com\n      port: \"\"\n      useSSL: true\n\n      ## these credentials are used by the KFP backend (not profiles)\n      auth:\n        ## (OPTION 1):\n        ##  - set keys with values (NOT RECOMMENDED)\n        #accessKey: my-access-key\n        #secretKey: my-secret-key\n\n        ## (OPTION 2):\n        ##  - read a kubernetes secret from the 'kubeflow' namespace\n        ##  - note, `existingSecret*Key` specifies the KEY NAMES in the \n        ##    secret itself, which contain the secret values\n        existingSecret: \"my-secret-name\"\n        existingSecretAccessKeyKey: \"AWS_ACCESS_KEY_ID\"\n        existingSecretSecretKeyKey: \"AWS_SECRET_ACCESS_KEY\"\n\n    ## NOTE: only required if you are using 'sample-values.yaml' as a base\n    ##       as `minioFix` can only be 'true' when using the embedded MinIO\n    #kfpV2:\n    #  minioFix: false\n</code></pre>"},{"location":"guides/tools/external-object-store/#irsa-based-authentication","title":"IRSA-based Authentication","text":"<p>IRSA is only supported on EKS</p> <p>IRSA is only supported when connecting to S3 from an EKS cluster. If you are using a different platform, you will need to use key-based authentication.</p> <p>If you are using EKS and S3, you may use IAM roles for service accounts (IRSA) to authenticate with your object store. The following values are needed to configure IRSA-based auth:</p> Value Purpose <code>deploykf_core.deploykf_profiles_generator.profileDefaults.plugins</code> Default profile-plugins, used by profiles which do NOT have <code>plugins</code> defined in their <code>deploykf_core.deploykf_profiles_generator.profiles</code> list entry.Note, the <code>AwsIamForServiceAccount</code> plugin is used to configure AWS IRSA-based auth by annotating the <code>default-editor</code> and <code>default-viewer</code> ServiceAccounts in each profile. <code>kubeflow_dependencies.kubeflow_argo_workflows.controller.serviceAccount</code> Kubernetes ServiceAccount used by the Argo Workflows Controller <code>kubeflow_dependencies.kubeflow_argo_workflows.server.serviceAccount</code> Kubernetes ServiceAccount used by the Argo Server UI <code>kubeflow_tools.pipelines.serviceAccounts.apiServer</code> Kubernetes ServiceAccount used by the Kubeflow Pipelines API Server <code>kubeflow_tools.pipelines.serviceAccounts.frontend</code> Kubernetes ServiceAccount used by the Kubeflow Pipelines Frontend <code>kubeflow_tools.pipelines.objectStore.auth.fromEnv</code> If <code>true</code>, disables all other auth methods, so the AWS Credential Provider Chain will try to use IRSA-based auth. <p>For example, these values will connect Kubeflow Pipelines to an external object store using IRSA-based authentication:</p> <pre><code>deploykf_core:\n  deploykf_profiles_generator:\n\n    ## NOTE: if you want to have a different set of plugins for each profile,\n    ##       for example, to have some profiles use a different IAM role,\n    ##       you can define the `plugins` list explicitly in a profile \n    ##       to override the default plugins\n    profileDefaults:\n      plugins:\n        - kind: AwsIamForServiceAccount\n          spec:\n            awsIamRole: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n            AnnotateOnly: true\n\n    ## example of a profile which overrides the default plugins\n    #profiles:\n    #  - name: \"my-profile\"\n    #    members: []\n    #    plugins:\n    #      - kind: AwsIamForServiceAccount\n    #        spec:\n    #          awsIamRole: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n    #          AnnotateOnly: true\n\nkubeflow_dependencies:\n  kubeflow_argo_workflows:\n    controller:\n      serviceAccount:\n        annotations:\n          eks.amazonaws.com/role-arn: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n    server:\n      serviceAccount:\n        annotations:\n          eks.amazonaws.com/role-arn: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n\nkubeflow_tools:\n  pipelines:\n    serviceAccounts:\n      apiServer:\n        annotations:\n          eks.amazonaws.com/role-arn: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n      frontend:\n        annotations:\n          eks.amazonaws.com/role-arn: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n\n    bucket:\n      name: kubeflow-pipelines\n      region: \"\"\n\n    objectStore:\n      useExternal: true\n\n      ## for IRSA, this should always be 's3.amazonaws.com'\n      host: s3.amazonaws.com\n      port: \"\"\n      useSSL: true\n\n      auth:\n        ## setting `fromEnv` to `true` disables all other auth methods\n        ## so the AWS Credential Provider Chain will try to use IRSA-based auth\n        fromEnv: true\n\n    ## NOTE: only required if you are using 'sample-values.yaml' as a base\n    ##       as `minioFix` can only be 'true' when using the embedded MinIO\n    #kfpV2:\n    #  minioFix: false\n</code></pre>"},{"location":"guides/tools/kubeflow-notebooks/","title":"Configure Kubeflow Notebooks","text":"<p>This guide explains how to configure Kubeflow Notebooks in deployKF.</p>"},{"location":"guides/tools/kubeflow-notebooks/#overview","title":"Overview","text":"<p>Kubeflow Notebooks allows users to spawn Pods running instances of JupyterLab, Visual Studio Code (code-server), and RStudio in profile namespaces.</p> <p>As the cluster administrator, you may configure which options are available to users when spawning a Notebook Pod:</p> <ul> <li>Container Images</li> <li>Container Resources (CPU, Memory, GPU)</li> <li>Storage Volumes</li> <li>Advanced Pod Options (Affinity, Tolerations, PodDefaults)</li> <li>Idle Notebook Culling</li> </ul> <p>Kubeflow Notebooks Limitations</p> <p>The current version of Kubeflow Notebooks exposes many Kubernetes-specific concepts to users, which may be confusing for non-technical users. There is an upstream proposal to abstract away these concepts in a more user-friendly way, see <code>kubeflow/kubeflow#7156</code> for more information.</p> <p>When the <code>kubeflow_tools.notebooks.spawnerFormDefaults</code> values are updated, this has no effect on existing Notebook Pods, only new Pods will use the updated values.</p>"},{"location":"guides/tools/kubeflow-notebooks/#container-images","title":"Container Images","text":"<p>Container images are the \"environment\" which users will be working in when using a Notebook Pod, and can be configured to provide different tools and packages to users.</p> <p>The following values configure which container images are available to users when spawning a Notebook Pod:</p> <ul> <li>Jupyter-Like: <code>kubeflow_tools.notebooks.spawnerFormDefaults.image</code></li> <li>VSCode-like: <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupOne</code></li> <li>RStudio-like: <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupTwo</code></li> </ul>"},{"location":"guides/tools/kubeflow-notebooks/#container-resources","title":"Container Resources","text":"<p>Container resources directly correspond to Kubernetes Container Resources which are requested by the Notebook Pod.</p> <p>The following values configure the resource requests/limits for containers in Notebook Pods:</p> <ul> <li>CPU: <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu</code></li> <li>Memory: <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory</code></li> <li>GPU: <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpu</code></li> </ul> <p>Resource Requests</p> <p>Kubernetes uses resource requests when scheduling Pods, and does not strictly enforce them at runtime. User Notebooks are not well-behaved applications (from a resource perspective), so will likely impact other Pods running on the same node.</p> <p>However, setting resource limits will have unintended consequences for users, as the Notebook Pod will be terminated if it exceeds certain limits (like memory), which may result in lost work.</p> <p>A common alternative is to use a dedicated node for each Notebook Pod, see Advanced Pod Options for information on how to do this with Affinity and Tolerations.</p>"},{"location":"guides/tools/kubeflow-notebooks/#storage-volumes","title":"Storage Volumes","text":"<p>Storage volumes are used to provide persistent storage to Notebook Pods between restarts, and are implemented using Kubernetes Persistent Volumes.</p> <p>The following values configure the storage volumes for Notebook Pods:</p> <ul> <li>Home Volume: <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume</code></li> <li>Data Volume: <code>kubeflow_tools.notebooks.spawnerFormDefaults.dataVolumes</code></li> </ul> <p>StorageClass and Performance</p> <p>The <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.spec.storageClassName</code> value defines which Kubernetes StorageClass is used to provision the workspace volume. If a <code>storageClassName</code> is not specified, the cluster's default StorageClass is used.</p> <p>As ML workloads are often IO-intensive, it is recommended to use a StorageClass which provides high-performance, typically this is only possible with drives which are attached to the node, rather than network-attached storage.</p>"},{"location":"guides/tools/kubeflow-notebooks/#advanced-pod-options","title":"Advanced Pod Options","text":"<p>Advanced Pod Options are additional configurations for Notebook Pods which manage things like Pod Affinity, Node Tolerations, and Kubeflow's PodDefaults.</p> <p>The following values configure the advanced options for Notebook Pods:</p> <ul> <li>Pod Affinity: <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig</code></li> <li>Node Tolerations: <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup</code></li> <li>PodDefaults: <code>kubeflow_tools.notebooks.spawnerFormDefaults.configurations</code></li> </ul> Dedicated Node for each Notebook Pod <p>Because Notebook Pods are not well-behaved applications (from a resource perspective), it is common to want a dedicated node for each Notebook Pod. With a combination of Pod Affinity and Node Tolerations, this can be achieved.</p> <p>Note, this will require your cluster to have node-autoscaling configured (e.g. Cluster Autoscaler or Karpenter), as the cluster will need to provision a new node for each Notebook Pod.</p> <p>First, you will need to make one or more groups of nodes that are tainted to prevent other Pods from being scheduled on them. In the following example, we have four groups of nodes with different CPU/Memory configurations, that are each tainted with a different value of the <code>dedicated</code> key with effect <code>NoSchedule</code>:</p> <ul> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-c5.xlarge</code>, Effect: <code>NoSchedule</code></li> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-c5.2xlarge</code>, Effect: <code>NoSchedule</code></li> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-c5.4xlarge</code>, Effect: <code>NoSchedule</code></li> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-r5.8xlarge</code>, Effect: <code>NoSchedule</code> </li> </ul> <p>Next, you will need to configure Pod Affinity configs that do not allow two Notebook Pods to be scheduled on the same node. In the following example, we do this by:</p> <ul> <li>Using <code>nodeAffinity</code> to require a Node with label <code>lifecycle=kubeflow-notebook</code></li> <li>Using <code>podAntiAffinity</code> to require a Node WITHOUT an existing Pod having <code>notebook-name</code> label</li> </ul> <p>Finally, you may use the following values to expose these options to users:</p> <pre><code>kubeflow_tools:\n  notebooks:\n    spawnerFormDefaults:\n      ## Affinity\n      ##  - note, setting `readOnly` to `true` to ensures that this affinity is always applied\n      ##  - note, `namespaceSelector` was added in Kubernetes 1.22, \n      ##    so this will NOT work on older clusters\n      ##\n      affinityConfig:\n        readOnly: true\n        value: \"dedicated_node_per_notebook\"\n        options:\n          - configKey: \"dedicated_node_per_notebook\"\n            displayName: \"Dedicated Node Per Notebook\"\n            affinity:\n              ## Require a Node with label `lifecycle=kubeflow-notebook`\n              nodeAffinity:\n                requiredDuringSchedulingIgnoredDuringExecution:\n                  nodeSelectorTerms:\n                    - matchExpressions:\n                        - key: \"lifecycle\"\n                          operator: \"In\"\n                          values:\n                            - \"kubeflow-notebook\"\n\n              ## Require a Node WITHOUT an existing Pod having `notebook-name` label\n              podAntiAffinity:\n                requiredDuringSchedulingIgnoredDuringExecution:\n                  - labelSelector:\n                      matchExpressions:\n                        - key: \"notebook-name\"\n                          operator: \"Exists\"\n                    topologyKey: \"kubernetes.io/hostname\"\n                    namespaceSelector: {}\n\n      ## Tolerations\n      ##\n      tolerationGroup:\n        readOnly: false\n        value: \"group_1\"\n        options:\n          - groupKey: \"group_1\"\n            displayName: \"4 CPU 8Gb Mem at ~$X.XXX USD per day\"\n            tolerations:\n              - key: \"dedicated\"\n                operator: \"Equal\"\n                value: \"kubeflow-c5.xlarge\"\n                effect: \"NoSchedule\"\n\n          - groupKey: \"group_2\"\n            displayName: \"8 CPU 16Gb Mem at ~$X.XXX USD per day\"\n            tolerations:\n              - key: \"dedicated\"\n                operator: \"Equal\"\n                value: \"kubeflow-c5.2xlarge\"\n                effect: \"NoSchedule\"\n\n          - groupKey: \"group_3\"\n            displayName: \"16 CPU 32Gb Mem at ~$X.XXX USD per day\"\n            tolerations:\n              - key: \"dedicated\"\n                operator: \"Equal\"\n                value: \"kubeflow-c5.4xlarge\"\n                effect: \"NoSchedule\"\n\n          - groupKey: \"group_4\"\n            displayName: \"32 CPU 256Gb Mem at ~$X.XXX USD per day\"\n            tolerations:\n              - key: \"dedicated\"\n                operator: \"Equal\"\n                value: \"kubeflow-r5.8xlarge\"\n                effect: \"NoSchedule\"\n</code></pre> <p>Users will then be able to select which group of nodes they want to use by choosing the corresponding \"Toleration\" group when spawning their Notebook.</p> PodDefault for Kubeflow Pipelines Authentication <p>The <code>kubeflow_tools.pipelines.profileResourceGeneration.kfpApiTokenPodDefault</code> value  configures if a <code>PodDefault</code> named <code>\"kubeflow-pipelines-api-token\"</code> is automatically generated in each profile namespace.</p> <p>If the user selects this \"configuration\" when spawning their Notebook, they will be able to use the Kubeflow Pipelines Python SDK from the Notebook without needing to manually authenticate.</p> <p>To have this \"configuration\" selected by default in the spawner, you may use the following values:</p> <pre><code>kubeflow_tools:\n  notebooks:\n    spawnerFormDefaults:\n      configurations:\n        value:\n          - \"kubeflow-pipelines-api-token\"\n</code></pre> <p>For more information, see the Access Kubeflow Pipelines API user guide.</p>"},{"location":"guides/tools/kubeflow-notebooks/#idle-notebook-culling","title":"Idle Notebook Culling","text":"<p>Kubeflow Notebooks supports automatically culling idle Notebook Pods, which is configured by the <code>kubeflow_tools.notebooks.notebookCulling</code> values.</p> <p>For example, the following values will enable idle culling after 1 day of inactivity:</p> <pre><code>kubeflow_tools:\n  notebooks:\n    notebookCulling:\n      enabled: true\n      idleTime: 1440 # 1 day in minutes\n</code></pre> <p>Jupyter Notebooks Only</p> <p>Currently, only Jupyter Notebooks are supported for idle culling, see the upstream design proposal for more information.</p>"},{"location":"privacy-policy/website/","title":"Website Privacy Policy","text":""},{"location":"privacy-policy/website/#introduction","title":"Introduction","text":"<p>The deployKF project is committed to protecting the privacy of our users.  This Privacy Policy explains how we collect, use, disclose, and safeguard your information when you visit the deployKF website (the \"Website\"). Please read this Privacy Policy carefully.  If you do not agree with the terms of this Privacy Policy, please do not use our Website.</p> <p>We reserve the right to make changes to this Privacy Policy at any time and for any reason.  We will alert you about any changes by updating the \"Last Updated\" date of this Privacy Policy.  You are encouraged to periodically review this Privacy Policy to stay informed of updates.  You will be deemed to have been made aware of, will be subject to, and will be deemed to have accepted the changes in any revised Privacy Policy by your continued use of the Website after the date such revised Privacy Policy is posted.</p>"},{"location":"privacy-policy/website/#collection-of-your-information","title":"Collection of Your Information","text":"<p>We may collect information about you in a variety of ways. </p> <p>The information we may collect on the Website includes:</p>"},{"location":"privacy-policy/website/#anonymous-usage-data","title":"Anonymous Usage Data","text":"<p>When you visit the Website, we may automatically collect anonymous usage data to help improve the Website and understand how our users interact with it.  This information may include, but is not limited to, your IP address, browser type, device type, pages visited, and time spent on the Website.</p>"},{"location":"privacy-policy/website/#cookies","title":"Cookies","text":"<p>We may use cookies and similar tracking technologies on the Website to, among other things, analyze trends, administer the website, track user's movements around the website, and gather demographic information about our user base as a whole.  You can control the use of cookies at the individual browser level, but if you choose to disable cookies, it may limit your use of certain features or functions on our website.</p>"},{"location":"privacy-policy/website/#use-of-your-information","title":"Use of Your Information","text":"<p>We may use the information collected from the Website for various purposes, including:</p> <ul> <li>To monitor and analyze usage trends and preferences, and to improve the Website</li> <li>To identify areas of the Website that may need improvement, optimization, or additional features</li> <li>To diagnose and fix issues with the Website</li> </ul>"},{"location":"privacy-policy/website/#disclosure-of-your-information","title":"Disclosure of Your Information","text":"<p>We will not sell, trade, rent, or otherwise share your information for marketing purposes. </p> <p>We may, however, share your information in the following situations:</p>"},{"location":"privacy-policy/website/#third-party-service-providers","title":"Third-Party Service Providers","text":"<p>We may share your information with third-party service providers that perform services on our behalf, such as analytics providers.  These service providers are required to protect your information in a manner consistent with this Privacy Policy and may not use your information for any purpose other than to carry out the services they are performing for us.</p>"},{"location":"privacy-policy/website/#security-of-your-information","title":"Security of Your Information","text":"<p>We are committed to protecting the information we collect and maintain.  While no method of data transmission or storage is 100% secure, we implement administrative, technical, and physical security measures, such as encryption and access controls, to protect against unauthorized access, alteration, disclosure, or destruction of your information.</p>"},{"location":"privacy-policy/website/#changes-to-this-privacy-policy","title":"Changes to This Privacy Policy","text":"<p>We may update our Privacy Policy from time to time.  We will notify you of any changes by posting the new Privacy Policy on this page.  You are advised to review this Privacy Policy periodically for any changes.  Changes to this Privacy Policy are effective when they are posted on this page.</p>"},{"location":"privacy-policy/website/#contact-us","title":"Contact Us","text":"<p>If you have any questions or concerns about this Privacy Policy, please contact us at:</p> <p>privacy@deploykf.org</p> <p>Last Updated: 2023-04-03</p>"},{"location":"reference/deploykf-values/","title":"Generator Values","text":"<p>The following is a summary of the generator values (configs) available in deployKF.</p> <p>What are Generator Values?</p> <p>The generator values are how you configure all aspects of deployKF, including which tools are deployed, how they are configured, and what versions are used.</p> <p>For more information, see the getting started guide to learn how to configure the values to suit your needs.</p>"},{"location":"reference/deploykf-values/#argo-cd","title":"Argo CD","text":"<p>Values for configuring Argo CD.</p>"},{"location":"reference/deploykf-values/#argocd","title":"<code>argocd</code>","text":"Value Default <code>argocd.appNamePrefix</code> <code>\"\"</code> <code>argocd.namespace</code> <code>\"argocd\"</code> <code>argocd.project</code> <code>\"default\"</code> <code>argocd.source.plugin.enabled</code> <code>false</code> <code>argocd.source.repo.url</code> <code>\"\"</code> <code>argocd.source.repo.revision</code> <code>\"\"</code> <code>argocd.source.repo.path</code> <code>\"\"</code> <code>argocd.destination.server</code> <code>\"https://kubernetes.default.svc\"</code> <code>argocd.destination.name</code> <code>\"\"</code>"},{"location":"reference/deploykf-values/#deploykf-dependencies","title":"deployKF Dependencies","text":"<p>Values for configuring the dependencies of deployKF.</p>"},{"location":"reference/deploykf-values/#deploykf_dependenciescert_manager","title":"<code>deploykf_dependencies.cert_manager</code>","text":"Value Default <code>deploykf_dependencies.cert_manager.enabled</code> <code>true</code> <code>deploykf_dependencies.cert_manager.namespace</code> <code>\"cert-manager\"</code> <code>deploykf_dependencies.cert_manager.extraManifests</code> <code>[]</code> <code>deploykf_dependencies.cert_manager.charts.certManager.name</code> <code>\"cert-manager\"</code> <code>deploykf_dependencies.cert_manager.charts.certManager.version</code> <code>\"1.12.2\"</code> <code>deploykf_dependencies.cert_manager.charts.certManager.repository</code> <code>\"https://charts.jetstack.io\"</code> <code>deploykf_dependencies.cert_manager.charts.trustManager.name</code> <code>\"trust-manager\"</code> <code>deploykf_dependencies.cert_manager.charts.trustManager.version</code> <code>\"0.5.0-deploykf\"</code> <code>deploykf_dependencies.cert_manager.charts.trustManager.repository</code> <code>\"file://forks/trust-manager\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerController.repository</code> <code>\"quay.io/jetstack/cert-manager-controller\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerController.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerWebhook.repository</code> <code>\"quay.io/jetstack/cert-manager-webhook\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerWebhook.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerWebhook.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerCainjector.repository</code> <code>\"quay.io/jetstack/cert-manager-cainjector\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerCainjector.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerCainjector.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerAcmesolver.repository</code> <code>\"quay.io/jetstack/cert-manager-acmesolver\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerAcmesolver.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerCtl.repository</code> <code>\"quay.io/jetstack/cert-manager-ctl\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerCtl.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerCtl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.trustManager.repository</code> <code>\"quay.io/jetstack/trust-manager\"</code> <code>deploykf_dependencies.cert_manager.images.trustManager.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.trustManager.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.trustManagerDefaultPackage.repository</code> <code>\"quay.io/jetstack/cert-manager-package-debian\"</code> <code>deploykf_dependencies.cert_manager.images.trustManagerDefaultPackage.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.trustManagerDefaultPackage.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.controller.securityContext.fsGroup</code> <code>1001</code> <code>deploykf_dependencies.cert_manager.controller.serviceAccount.create</code> <code>true</code> <code>deploykf_dependencies.cert_manager.controller.serviceAccount.name</code> <code>\"cert-manager\"</code> <code>deploykf_dependencies.cert_manager.controller.extraArgs</code> <code>[\"--enable-certificate-owner-ref=true\"]</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.enabled</code> <code>true</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.issuerName</code> <code>\"deploykf-gateway-issuer\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.type</code> <code>\"SELF_SIGNED\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.selfSigned.caIssuerName</code> <code>\"selfsigned-ca-issuer\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.selfSigned.caSecretName</code> <code>\"selfsigned-ca-issuer-root-cert\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.selfSigned.injectedConfigMapName</code> <code>\"deploykf-gateway-issuer-root-ca-cert\"</code>"},{"location":"reference/deploykf-values/#deploykf_dependenciesistio","title":"<code>deploykf_dependencies.istio</code>","text":"Value Default <code>deploykf_dependencies.istio.enabled</code> <code>true</code> <code>deploykf_dependencies.istio.namespace</code> <code>\"istio-system\"</code> <code>deploykf_dependencies.istio.extraManifests</code> <code>[]</code> <code>deploykf_dependencies.istio.charts.istioBase.name</code> <code>\"base\"</code> <code>deploykf_dependencies.istio.charts.istioBase.version</code> <code>\"1.17.3\"</code> <code>deploykf_dependencies.istio.charts.istioBase.repository</code> <code>\"https://istio-release.storage.googleapis.com/charts\"</code> <code>deploykf_dependencies.istio.charts.istioDaemon.name</code> <code>\"istiod\"</code> <code>deploykf_dependencies.istio.charts.istioDaemon.version</code> <code>\"1.17.3\"</code> <code>deploykf_dependencies.istio.charts.istioDaemon.repository</code> <code>\"https://istio-release.storage.googleapis.com/charts\"</code> <code>deploykf_dependencies.istio.images.istioProxy.repository</code> <code>\"docker.io/istio/proxyv2\"</code> <code>deploykf_dependencies.istio.images.istioProxy.tag</code> <code>nil</code> <code>deploykf_dependencies.istio.images.istioPilot.repository</code> <code>\"docker.io/istio/pilot\"</code> <code>deploykf_dependencies.istio.images.istioPilot.tag</code> <code>nil</code> <code>deploykf_dependencies.istio.defaultImageVariant</code> <code>\"distroless\"</code>"},{"location":"reference/deploykf-values/#deploykf_dependencieskyverno","title":"<code>deploykf_dependencies.kyverno</code>","text":"Value Default <code>deploykf_dependencies.kyverno.enabled</code> <code>true</code> <code>deploykf_dependencies.kyverno.namespace</code> <code>\"kyverno\"</code> <code>deploykf_dependencies.kyverno.extraManifests</code> <code>[]</code> <code>deploykf_dependencies.kyverno.charts.kyverno.name</code> <code>\"kyverno\"</code> <code>deploykf_dependencies.kyverno.charts.kyverno.version</code> <code>\"3.0.1\"</code> <code>deploykf_dependencies.kyverno.charts.kyverno.repository</code> <code>\"https://kyverno.github.io/kyverno\"</code> <code>deploykf_dependencies.kyverno.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_dependencies.kyverno.images.kubectl.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyverno.repository</code> <code>\"ghcr.io/kyverno/kyverno\"</code> <code>deploykf_dependencies.kyverno.images.kyverno.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyverno.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoInit.repository</code> <code>\"ghcr.io/kyverno/kyvernopre\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoInit.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoInit.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoBackgroundController.repository</code> <code>\"ghcr.io/kyverno/background-controller\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoBackgroundController.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoBackgroundController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoCleanupController.repository</code> <code>\"ghcr.io/kyverno/cleanup-controller\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoCleanupController.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoCleanupController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoReportsController.repository</code> <code>\"ghcr.io/kyverno/reports-controller\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoReportsController.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoReportsController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.extraResourceRules</code> <code>[]</code> <code>deploykf_dependencies.kyverno.admissionController.replicas</code> <code>3</code> <code>deploykf_dependencies.kyverno.backgroundController.replicas</code> <code>1</code> <code>deploykf_dependencies.kyverno.cleanupController.replicas</code> <code>1</code> <code>deploykf_dependencies.kyverno.reportsController.replicas</code> <code>1</code> <code>deploykf_dependencies.kyverno.clusterPolicies.imagePullSecrets.enabled</code> <code>false</code> <code>deploykf_dependencies.kyverno.clusterPolicies.imagePullSecrets.excludeNamespaces</code> <code>[\"argocd\", \"kube-system\"]</code> <code>deploykf_dependencies.kyverno.clusterPolicies.imagePullSecrets.registryCredentials</code> <code>[]</code>"},{"location":"reference/deploykf-values/#deploykf-core","title":"deployKF Core","text":"<p>Values for configuring core deployKF components.</p>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_dashboard","title":"<code>deploykf_core.deploykf_dashboard</code>","text":"Value Default <code>deploykf_core.deploykf_dashboard.enabled</code> <code>true</code> <code>deploykf_core.deploykf_dashboard.namespace</code> <code>\"deploykf-dashboard\"</code> <code>deploykf_core.deploykf_dashboard.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_dashboard.images.dashboard.repository</code> <code>\"ghcr.io/deploykf/dashboard\"</code> <code>deploykf_core.deploykf_dashboard.images.dashboard.tag</code> <code>\"0.1.0\"</code> <code>deploykf_core.deploykf_dashboard.images.dashboard.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_dashboard.images.profileController.repository</code> <code>\"kubeflownotebookswg/profile-controller\"</code> <code>deploykf_core.deploykf_dashboard.images.profileController.tag</code> <code>\"v1.7.0\"</code> <code>deploykf_core.deploykf_dashboard.images.profileController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_dashboard.images.kfamApi.repository</code> <code>\"kubeflownotebookswg/kfam\"</code> <code>deploykf_core.deploykf_dashboard.images.kfamApi.tag</code> <code>\"v1.7.0\"</code> <code>deploykf_core.deploykf_dashboard.images.kfamApi.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_dashboard.navigation.externalLinks</code> <code>[]</code> <code>deploykf_core.deploykf_dashboard.navigation.documentationItems</code> <code>[{\"text\": \"deployKF Website\", \"desc\": \"The tool that deployed your ML platform!\", \"link\": \"https://github.com/deployKF/deployKF\"}]</code>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_profiles_generator","title":"<code>deploykf_core.deploykf_profiles_generator</code>","text":"Value Default <code>deploykf_core.deploykf_profiles_generator.enabled</code> <code>true</code> <code>deploykf_core.deploykf_profiles_generator.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.profileNamePrefix</code> <code>\"\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.ownerEmail</code> <code>\"admin@example.com\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.memberAccess.role</code> <code>\"view\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.memberAccess.notebooksAccess</code> <code>false</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.plugins</code> <code>[]</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecret</code> <code>\"kubeflow-pipelines--profile-object-store-auth--{profile_name}\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecretNamespace</code> <code>\"\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecretAccessKeyKey</code> <code>\"access_key\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecretSecretKeyKey</code> <code>\"secret_key\"</code> <code>deploykf_core.deploykf_profiles_generator.users</code> <code>[{\"id\": \"user-1\", \"email\": \"user1@example.com\"}, {\"id\": \"user-2\", \"email\": \"user2@example.com\"}]</code> <code>deploykf_core.deploykf_profiles_generator.groups</code> <code>[{\"id\": \"team-1\", \"users\": [\"user-1\", \"user-2\"]}]</code> <code>deploykf_core.deploykf_profiles_generator.profiles</code> <code>[{\"name\": \"team-1\", \"members\": [{\"group\": \"team-1\", \"access\": {\"role\": \"edit\", \"notebooksAccess\": true}}]}, {\"name\": \"team-1-prod\", \"members\": [{\"group\": \"team-1\", \"access\": {\"role\": \"view\", \"notebooksAccess\": false}}]}]</code>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_auth","title":"<code>deploykf_core.deploykf_auth</code>","text":"Value Default <code>deploykf_core.deploykf_auth.enabled</code> <code>true</code> <code>deploykf_core.deploykf_auth.namespace</code> <code>\"deploykf-auth\"</code> <code>deploykf_core.deploykf_auth.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_auth.images.dex.repository</code> <code>\"ghcr.io/dexidp/dex\"</code> <code>deploykf_core.deploykf_auth.images.dex.tag</code> <code>\"v2.37.0\"</code> <code>deploykf_core.deploykf_auth.images.dex.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_auth.images.oauth2Proxy.repository</code> <code>\"quay.io/oauth2-proxy/oauth2-proxy\"</code> <code>deploykf_core.deploykf_auth.images.oauth2Proxy.tag</code> <code>\"v7.5.1\"</code> <code>deploykf_core.deploykf_auth.images.oauth2Proxy.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_auth.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_core.deploykf_auth.images.kubectl.tag</code> <code>\"1.26.6-debian-11-r8\"</code> <code>deploykf_core.deploykf_auth.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> <code>[{\"email\": \"admin@example.com\", \"password\": {\"value\": \"admin\"}}, {\"email\": \"user1@example.com\", \"password\": {\"value\": \"user1\"}}, {\"email\": \"user2@example.com\", \"password\": {\"value\": \"user2\"}}]</code> <code>deploykf_core.deploykf_auth.dex.connectors</code> <code>[]</code> <code>deploykf_core.deploykf_auth.dex.expiry.idToken</code> <code>\"60m\"</code> <code>deploykf_core.deploykf_auth.dex.expiry.refreshToken.idle</code> <code>\"168h\"</code> <code>deploykf_core.deploykf_auth.dex.expiry.refreshToken.total</code> <code>\"2160h\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientId</code> <code>\"oauth2-proxy\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.value</code> <code>\"bbbbbbbbbbbbbbbb\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.existingSecretKey</code> <code>\"client_secret\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.generateSecret</code> <code>false</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientId</code> <code>\"minio-console\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.value</code> <code>\"bbbbbbbbbbbbbbbb\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.existingSecretKey</code> <code>\"client_secret\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.generateSecret</code> <code>false</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientId</code> <code>\"argo-server\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.value</code> <code>\"bbbbbbbbbbbbbbbb\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.existingSecretKey</code> <code>\"client_secret\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.generateSecret</code> <code>false</code> <code>deploykf_core.deploykf_auth.dex.clients.kubeflowPipelinesSDK.enabled</code> <code>true</code> <code>deploykf_core.deploykf_auth.dex.clients.kubeflowPipelinesSDK.clientId</code> <code>\"kubeflow-pipelines-sdk\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.name</code> <code>\"_deploykf_token\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.expire</code> <code>\"168h\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.refresh</code> <code>\"60m\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.value</code> <code>\"cccccccccccccccc\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.existingSecretKey</code> <code>\"cookie_secret\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.generateSecret</code> <code>false</code>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_istio_gateway","title":"<code>deploykf_core.deploykf_istio_gateway</code>","text":"Value Default <code>deploykf_core.deploykf_istio_gateway.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.namespace</code> <code>\"deploykf-istio-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.name</code> <code>\"gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.version</code> <code>\"1.17.3\"</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.repository</code> <code>\"https://istio-release.storage.googleapis.com/charts\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.name</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.hostname</code> <code>\"deploykf.example.com\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.ports.http</code> <code>80</code> <code>deploykf_core.deploykf_istio_gateway.gateway.ports.https</code> <code>443</code> <code>deploykf_core.deploykf_istio_gateway.gateway.tls.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.gateway.selectorLabels.app</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.selectorLabels.istio</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.enableProxyProtocol</code> <code>false</code> <code>deploykf_core.deploykf_istio_gateway.gateway.xffNumTrustedHops</code> <code>0</code> <code>deploykf_core.deploykf_istio_gateway.gateway.emailToLowercase</code> <code>false</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.replicaCount</code> <code>1</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.serviceAccount.name</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.minReplicas</code> <code>1</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.maxReplicas</code> <code>5</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.targetCPUUtilizationPercentage</code> <code>80</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.name</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.type</code> <code>\"LoadBalancer\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.loadBalancerIP</code> <code>\"\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.loadBalancerSourceRanges</code> <code>[]</code>"},{"location":"reference/deploykf-values/#deploykf-opt","title":"deployKF Opt","text":"<p>Values for configuring optional embedded applications that are used when external alternatives are not configured.</p>"},{"location":"reference/deploykf-values/#deploykf_optdeploykf_mysql","title":"<code>deploykf_opt.deploykf_mysql</code>","text":"Value Default <code>deploykf_opt.deploykf_mysql.enabled</code> <code>false</code> <code>deploykf_opt.deploykf_mysql.namespace</code> <code>\"deploykf-mysql\"</code> <code>deploykf_opt.deploykf_mysql.extraManifests</code> <code>[]</code> <code>deploykf_opt.deploykf_mysql.images.mysql.repository</code> <code>\"docker.io/mysql\"</code> <code>deploykf_opt.deploykf_mysql.images.mysql.tag</code> <code>\"8.0.33\"</code> <code>deploykf_opt.deploykf_mysql.images.mysql.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_mysql.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_opt.deploykf_mysql.images.kubectl.tag</code> <code>\"1.26.6-debian-11-r8\"</code> <code>deploykf_opt.deploykf_mysql.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_mysql.persistence.enabled</code> <code>true</code> <code>deploykf_opt.deploykf_mysql.persistence.existingClaim</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.persistence.subPath</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.persistence.storageClass</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.persistence.accessMode</code> <code>\"ReadWriteOnce\"</code> <code>deploykf_opt.deploykf_mysql.persistence.size</code> <code>\"5Gi\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.password</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.existingSecret</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.existingSecretPasswordKey</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.generateSecret</code> <code>false</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.username</code> <code>\"kubeflow\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.password</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.existingSecret</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.existingSecretUsernameKey</code> <code>\"username\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.existingSecretPasswordKey</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.generateSecret</code> <code>false</code> <code>deploykf_opt.deploykf_mysql.customUsers</code> <code>[]</code> <code>deploykf_opt.deploykf_mysql.customDatabases</code> <code>[]</code> <code>deploykf_opt.deploykf_mysql.configuration</code> [mysqld]disable_log_bindefault_authentication_plugin=mysql_native_password"},{"location":"reference/deploykf-values/#deploykf_optdeploykf_minio","title":"<code>deploykf_opt.deploykf_minio</code>","text":"Value Default <code>deploykf_opt.deploykf_minio.enabled</code> <code>false</code> <code>deploykf_opt.deploykf_minio.namespace</code> <code>\"deploykf-minio\"</code> <code>deploykf_opt.deploykf_minio.extraManifests</code> <code>[]</code> <code>deploykf_opt.deploykf_minio.images.minio.repository</code> <code>\"docker.io/minio/minio\"</code> <code>deploykf_opt.deploykf_minio.images.minio.tag</code> <code>\"RELEASE.2023-08-04T17-40-21Z\"</code> <code>deploykf_opt.deploykf_minio.images.minio.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_minio.images.minioMc.repository</code> <code>\"docker.io/minio/mc\"</code> <code>deploykf_opt.deploykf_minio.images.minioMc.tag</code> <code>\"RELEASE.2023-08-01T23-30-57Z\"</code> <code>deploykf_opt.deploykf_minio.images.minioMc.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_minio.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_opt.deploykf_minio.images.kubectl.tag</code> <code>\"1.26.6-debian-11-r8\"</code> <code>deploykf_opt.deploykf_minio.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_minio.persistence.enabled</code> <code>true</code> <code>deploykf_opt.deploykf_minio.persistence.existingClaim</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.persistence.subPath</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.persistence.storageClass</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.persistence.accessMode</code> <code>\"ReadWriteOnce\"</code> <code>deploykf_opt.deploykf_minio.persistence.size</code> <code>\"5Gi\"</code> <code>deploykf_opt.deploykf_minio.rootUser.username</code> <code>\"minioadmin\"</code> <code>deploykf_opt.deploykf_minio.rootUser.password</code> <code>\"minioadmin\"</code> <code>deploykf_opt.deploykf_minio.rootUser.existingSecret</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.rootUser.existingSecretUsernameKey</code> <code>\"username\"</code> <code>deploykf_opt.deploykf_minio.rootUser.existingSecretPasswordKey</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_minio.rootUser.generateSecret</code> <code>false</code> <code>deploykf_opt.deploykf_minio.rootUser.serviceAccounts</code> <code>[]</code> <code>deploykf_opt.deploykf_minio.identity.openid.policyClaim</code> <code>\"email\"</code> <code>deploykf_opt.deploykf_minio.identity.openid.scopes</code> <code>\"openid,email,groups,profile,offline_access\"</code> <code>deploykf_opt.deploykf_minio.buckets</code> <code>[]</code> <code>deploykf_opt.deploykf_minio.policies</code> <code>[]</code>"},{"location":"reference/deploykf-values/#deploykf-tools","title":"deployKF Tools","text":"<p>Values for configuring MLOps tools from the deployKF ecosystem.</p>"},{"location":"reference/deploykf-values/#kubeflow-dependencies","title":"Kubeflow Dependencies","text":"<p>Values for configuring dependencies of Kubeflow's MLOps tools.</p>"},{"location":"reference/deploykf-values/#kubeflow_dependencieskubeflow_argo_workflows","title":"<code>kubeflow_dependencies.kubeflow_argo_workflows</code>","text":"Value Default <code>kubeflow_dependencies.kubeflow_argo_workflows.enabled</code> <code>false</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.namespace</code> <code>\"kubeflow-argo-workflows\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.extraManifests</code> <code>[]</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoCli.repository</code> <code>\"quay.io/argoproj/argocli\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoCli.tag</code> <code>\"v3.4.8\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoCli.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoExecutor.repository</code> <code>\"quay.io/argoproj/argoexec\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoExecutor.tag</code> <code>\"v3.3.10\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoExecutor.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoWorkflowController.repository</code> <code>\"quay.io/argoproj/workflow-controller\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoWorkflowController.tag</code> <code>\"v3.3.10\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoWorkflowController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.artifactRepository.keyFormat</code> <code>\"artifacts/{{ workflow.namespace }}/{{ workflow.name }}/{{ workflow.creationTimestamp.Y }}/{{ workflow.creationTimestamp.m }}/{{ workflow.creationTimestamp.d }}/{{ pod.name }}\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.controller.serviceAccount.create</code> <code>true</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.controller.serviceAccount.name</code> <code>\"argo-workflow-controller\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.server.serviceAccount.create</code> <code>true</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.server.serviceAccount.name</code> <code>\"argo-server\"</code>"},{"location":"reference/deploykf-values/#kubeflow-tools","title":"Kubeflow Tools","text":"<p>Values for configuring MLOps tools from the Kubeflow ecosystem.</p>"},{"location":"reference/deploykf-values/#kubeflow_toolsnotebooks","title":"<code>kubeflow_tools.notebooks</code>","text":"Value Default <code>kubeflow_tools.notebooks.enabled</code> <code>false</code> <code>kubeflow_tools.notebooks.extraManifests</code> <code>[]</code> <code>kubeflow_tools.notebooks.images.jupyterWebApp.repository</code> <code>\"docker.io/kubeflownotebookswg/jupyter-web-app\"</code> <code>kubeflow_tools.notebooks.images.jupyterWebApp.tag</code> <code>nil</code> <code>kubeflow_tools.notebooks.images.notebookController.repository</code> <code>\"docker.io/kubeflownotebookswg/notebook-controller\"</code> <code>kubeflow_tools.notebooks.images.notebookController.tag</code> <code>nil</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.allowCustomImage</code> <code>true</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.hideRegistry</code> <code>true</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.hideTag</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imagePullPolicy.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imagePullPolicy.value</code> <code>\"IfNotPresent\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.image.value</code> <code>\"kubeflownotebookswg/jupyter-scipy:v1.7.0\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.image.options</code> <code>[\"kubeflownotebookswg/jupyter-scipy:v1.7.0\", \"kubeflownotebookswg/jupyter-pytorch-full:v1.7.0\", \"kubeflownotebookswg/jupyter-pytorch-cuda-full:v1.7.0\", \"kubeflownotebookswg/jupyter-tensorflow-full:v1.7.0\", \"kubeflownotebookswg/jupyter-tensorflow-cuda-full:v1.7.0\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupOne.value</code> <code>\"kubeflownotebookswg/codeserver-python:v1.7.0\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupOne.options</code> <code>[\"kubeflownotebookswg/codeserver-python:v1.7.0\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupTwo.value</code> <code>\"kubeflownotebookswg/rstudio-tidyverse:v1.7.0\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupTwo.options</code> <code>[\"kubeflownotebookswg/rstudio-tidyverse:v1.7.0\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu.value</code> <code>\"0.5\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu.limitFactor</code> <code>\"1.2\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory.value</code> <code>\"1.0Gi\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory.limitFactor</code> <code>\"1.2\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.value.vendor</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.value.vendors</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.value.num</code> <code>\"none\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.mount</code> <code>\"/home/jovyan\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.metadata.name</code> <code>\"{notebook-name}-workspace\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.spec.resources.requests.storage</code> <code>\"5Gi\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.spec.accessModes</code> <code>[\"ReadWriteOnce\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.dataVolumes.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.dataVolumes.value</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig.value</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig.options</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup.value</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup.options</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.shm.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.shm.value</code> <code>true</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.configurations.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.configurations.value</code> <code>[]</code> <code>kubeflow_tools.notebooks.notebookTemplate</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupOne.icon</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupOne.logo</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupTwo.icon</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupTwo.logo</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.notebookCulling.enabled</code> <code>false</code> <code>kubeflow_tools.notebooks.notebookCulling.idleTime</code> <code>1440</code> <code>kubeflow_tools.notebooks.notebookCulling.idlenessCheckPeriod</code> <code>1</code>"},{"location":"reference/deploykf-values/#kubeflow_toolskatib","title":"<code>kubeflow_tools.katib</code>","text":"Value Default <code>kubeflow_tools.katib.enabled</code> <code>false</code> <code>kubeflow_tools.katib.extraManifests</code> <code>[]</code> <code>kubeflow_tools.katib.images.katibController.repository</code> <code>\"docker.io/kubeflowkatib/katib-controller\"</code> <code>kubeflow_tools.katib.images.katibController.tag</code> <code>nil</code> <code>kubeflow_tools.katib.images.katibDbManager.repository</code> <code>\"docker.io/kubeflowkatib/katib-db-manager\"</code> <code>kubeflow_tools.katib.images.katibDbManager.tag</code> <code>nil</code> <code>kubeflow_tools.katib.images.katibUi.repository</code> <code>\"docker.io/kubeflowkatib/katib-ui\"</code> <code>kubeflow_tools.katib.images.katibUi.tag</code> <code>nil</code> <code>kubeflow_tools.katib.mysql.useExternal</code> <code>false</code> <code>kubeflow_tools.katib.mysql.host</code> <code>\"mysql.example.com\"</code> <code>kubeflow_tools.katib.mysql.port</code> <code>3306</code> <code>kubeflow_tools.katib.mysql.auth.username</code> <code>\"kubeflow\"</code> <code>kubeflow_tools.katib.mysql.auth.password</code> <code>\"password\"</code> <code>kubeflow_tools.katib.mysql.auth.existingSecret</code> <code>\"\"</code> <code>kubeflow_tools.katib.mysql.auth.existingSecretUsernameKey</code> <code>\"username\"</code> <code>kubeflow_tools.katib.mysql.auth.existingSecretPasswordKey</code> <code>\"password\"</code> <code>kubeflow_tools.katib.mysqlDatabase</code> <code>\"katib\"</code>"},{"location":"reference/deploykf-values/#kubeflow_toolspipelines","title":"<code>kubeflow_tools.pipelines</code>","text":"Value Default <code>kubeflow_tools.pipelines.enabled</code> <code>false</code> <code>kubeflow_tools.pipelines.extraManifests</code> <code>[]</code> <code>kubeflow_tools.pipelines.images.kfpCacheServer.repository</code> <code>\"gcr.io/ml-pipeline/cache-server\"</code> <code>kubeflow_tools.pipelines.images.kfpCacheServer.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpMetadataEnvoy.repository</code> <code>\"gcr.io/ml-pipeline/metadata-envoy\"</code> <code>kubeflow_tools.pipelines.images.kfpMetadataEnvoy.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpMetadataWriter.repository</code> <code>\"gcr.io/ml-pipeline/metadata-writer\"</code> <code>kubeflow_tools.pipelines.images.kfpMetadataWriter.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpApiServer.repository</code> <code>\"gcr.io/ml-pipeline/api-server\"</code> <code>kubeflow_tools.pipelines.images.kfpApiServer.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpPersistenceagent.repository</code> <code>\"gcr.io/ml-pipeline/persistenceagent\"</code> <code>kubeflow_tools.pipelines.images.kfpPersistenceagent.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpScheduledworkflow.repository</code> <code>\"gcr.io/ml-pipeline/scheduledworkflow\"</code> <code>kubeflow_tools.pipelines.images.kfpScheduledworkflow.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpFrontend.repository</code> <code>\"gcr.io/ml-pipeline/frontend\"</code> <code>kubeflow_tools.pipelines.images.kfpFrontend.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpViewerCrdController.repository</code> <code>\"gcr.io/ml-pipeline/viewer-crd-controller\"</code> <code>kubeflow_tools.pipelines.images.kfpViewerCrdController.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpVisualizationServer.repository</code> <code>\"gcr.io/ml-pipeline/visualization-server\"</code> <code>kubeflow_tools.pipelines.images.kfpVisualizationServer.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.tfxMlMetadataStoreServer.repository</code> <code>\"gcr.io/tfx-oss-public/ml_metadata_store_server\"</code> <code>kubeflow_tools.pipelines.images.tfxMlMetadataStoreServer.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.bucket.name</code> <code>\"kubeflow-pipelines\"</code> <code>kubeflow_tools.pipelines.bucket.region</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.objectStore.useExternal</code> <code>false</code> <code>kubeflow_tools.pipelines.objectStore.host</code> <code>\"s3.amazonaws.com\"</code> <code>kubeflow_tools.pipelines.objectStore.port</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.objectStore.useSSL</code> <code>true</code> <code>kubeflow_tools.pipelines.objectStore.auth.fromEnv</code> <code>false</code> <code>kubeflow_tools.pipelines.objectStore.auth.accessKey</code> <code>\"my-access-key\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.secretKey</code> <code>\"my-secret-key\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.existingSecret</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.existingSecretAccessKeyKey</code> <code>\"AWS_ACCESS_KEY_ID\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.existingSecretSecretKeyKey</code> <code>\"AWS_SECRET_ACCESS_KEY\"</code> <code>kubeflow_tools.pipelines.mysql.useExternal</code> <code>false</code> <code>kubeflow_tools.pipelines.mysql.host</code> <code>\"mysql.example.com\"</code> <code>kubeflow_tools.pipelines.mysql.port</code> <code>3306</code> <code>kubeflow_tools.pipelines.mysql.auth.username</code> <code>\"kubeflow\"</code> <code>kubeflow_tools.pipelines.mysql.auth.password</code> <code>\"password\"</code> <code>kubeflow_tools.pipelines.mysql.auth.existingSecret</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.mysql.auth.existingSecretUsernameKey</code> <code>\"username\"</code> <code>kubeflow_tools.pipelines.mysql.auth.existingSecretPasswordKey</code> <code>\"password\"</code> <code>kubeflow_tools.pipelines.mysqlDatabases.cacheDatabase</code> <code>\"kfp_cache\"</code> <code>kubeflow_tools.pipelines.mysqlDatabases.metadataDatabase</code> <code>\"kfp_metadata\"</code> <code>kubeflow_tools.pipelines.mysqlDatabases.pipelinesDatabase</code> <code>\"kfp_pipelines\"</code> <code>kubeflow_tools.pipelines.kfpV2.defaultPipelineRoot</code> <code>\"minio://{bucket_name}/v2/artifacts/{profile_name}\"</code> <code>kubeflow_tools.pipelines.kfpV2.minioFix</code> <code>false</code> <code>kubeflow_tools.pipelines.kfpV2.launcherImage</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.cache.image</code> <code>\"gcr.io/google-containers/busybox:1.27\"</code> <code>kubeflow_tools.pipelines.cache.maximumMaxCacheStaleness</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.cache.defaultMaxCacheStaleness</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.cache.namespaceRedirect</code> <code>true</code> <code>kubeflow_tools.pipelines.profileResourceGeneration.kfpApiTokenPodDefault</code> <code>false</code>"},{"location":"reference/deploykf-values/#kubeflow_toolstensorboards","title":"<code>kubeflow_tools.tensorboards</code>","text":"Value Default <code>kubeflow_tools.tensorboards.enabled</code> <code>false</code> <code>kubeflow_tools.tensorboards.extraManifests</code> <code>[]</code> <code>kubeflow_tools.tensorboards.images.tensorboardController.repository</code> <code>\"docker.io/kubeflownotebookswg/tensorboard-controller\"</code> <code>kubeflow_tools.tensorboards.images.tensorboardController.tag</code> <code>nil</code> <code>kubeflow_tools.tensorboards.images.tensorboardsWebApp.repository</code> <code>\"docker.io/kubeflownotebookswg/tensorboards-web-app\"</code> <code>kubeflow_tools.tensorboards.images.tensorboardsWebApp.tag</code> <code>nil</code> <code>kubeflow_tools.tensorboards.images.kubeRbacProxy.repository</code> <code>\"gcr.io/kubebuilder/kube-rbac-proxy\"</code> <code>kubeflow_tools.tensorboards.images.kubeRbacProxy.tag</code> <code>nil</code> <code>kubeflow_tools.tensorboards.tensorboardImage</code> <code>\"docker.io/tensorflow/tensorflow:2.5.1\"</code>"},{"location":"reference/deploykf-values/#kubeflow_toolsvolumes","title":"<code>kubeflow_tools.volumes</code>","text":"Value Default <code>kubeflow_tools.volumes.enabled</code> <code>false</code> <code>kubeflow_tools.volumes.extraManifests</code> <code>[]</code> <code>kubeflow_tools.volumes.images.volumesWebApp.repository</code> <code>\"docker.io/kubeflownotebookswg/volumes-web-app\"</code> <code>kubeflow_tools.volumes.images.volumesWebApp.tag</code> <code>nil</code>"},{"location":"reference/deploykf-values/#kubeflow_toolstraining_operator","title":"<code>kubeflow_tools.training_operator</code>","text":"Value Default <code>kubeflow_tools.training_operator.enabled</code> <code>false</code> <code>kubeflow_tools.training_operator.extraManifests</code> <code>[]</code> <code>kubeflow_tools.training_operator.images.trainingOperator.repository</code> <code>\"docker.io/kubeflow/training-operator\"</code> <code>kubeflow_tools.training_operator.images.trainingOperator.tag</code> <code>nil</code>"},{"location":"reference/deploykf-values/#kubeflow_toolspoddefaults_webhook","title":"<code>kubeflow_tools.poddefaults_webhook</code>","text":"Value Default <code>kubeflow_tools.poddefaults_webhook.enabled</code> <code>false</code> <code>kubeflow_tools.poddefaults_webhook.extraManifests</code> <code>[]</code> <code>kubeflow_tools.poddefaults_webhook.images.poddefaultsWebhook.repository</code> <code>\"docker.io/kubeflownotebookswg/poddefaults-webhook\"</code> <code>kubeflow_tools.poddefaults_webhook.images.poddefaultsWebhook.tag</code> <code>nil</code>"},{"location":"reference/future-tools/","title":"Future ML &amp; Data Tools","text":"<p>This page lists the ML &amp; Data tools which are planned for future versions of deployKF.</p> <p>How do I request or contribute a tool?</p> <p>If you would like to request or contribute support for a tool, please raise an issue on GitHub, or join the discussion on an existing issue.</p>"},{"location":"reference/future-tools/#tool-roadmap","title":"Tool Roadmap","text":"<p>The following is a roadmap of planned tools, grouped by priority.</p> <p>Tip</p> <p>Click the name of a tool for more information about it.</p>"},{"location":"reference/future-tools/#higher-priority","title":"Higher Priority","text":"Name Purpose MLflow Model Registry Model Registry Apache Airflow Workflow Orchestration"},{"location":"reference/future-tools/#medium-priority","title":"Medium Priority","text":"Name Purpose Feast Feature Store KServe Model Serving Seldon Core Model Serving"},{"location":"reference/future-tools/#lower-priority","title":"Lower Priority","text":"Name Purpose DataHub Data Catalog Airbyte Data Integration Label Studio Data Labeling BentoML Yatai Model Serving"},{"location":"reference/future-tools/#tool-details","title":"Tool Details","text":"<p>The following sections provide details and descriptions for each tool.</p>"},{"location":"reference/future-tools/#mlflow-model-registry","title":"MLflow Model Registry","text":"<p>MLflow Model Registry is an open source machine learning model registry.</p> PurposeModel Registry MaintainerDatabricks DocumentationDocumentation Source Code<code>mlflow/mlflow</code> Roadmap PriorityHigher <p>A model registry decouples model training from model deployment, allowing you to break the model lifecycle down into three separate concerns.  This separation enables you to have well-scoped pipelines, rather than trying to go from training to deployment all at once.</p> <ol> <li>Model Training: Training new versions of models and logging them into the registry.</li> <li>Model Evaluation: Evaluating versions of models and logging the results into the registry.</li> <li>Model Deployment: Making informed decisions about which models to deploy and then deploying them.</li> </ol> <p>The key features of MLflow Model Registry are:</p> <ul> <li>Model Versioning: Version your model artifacts and attach metadata to each version.</li> <li>Model Stage Transitions: Transition models between stages (e.g. staging to production).</li> <li>Web UI: A graphical web interface for managing models.</li> <li>Python API: A Python API for managing models.</li> <li>REST API: A REST API for managing models.</li> </ul>"},{"location":"reference/future-tools/#apache-airflow","title":"Apache Airflow","text":"<p>Apache Airflow is by far the most popular open-source workflow orchestration tool in the world.</p> PurposeWorkflow Orchestration MaintainerApache Software Foundation DocumentationDocumentation Source Code<code>apache/airflow</code> Roadmap PriorityHigher <p>The versatility and extensibility of Apache Airflow make it a great fit for many different use cases, including machine learning.</p> <p>The key features of Apache Airflow are:</p> <ul> <li>Python Centered: Airflow is written in Python and uses a Python DSL to define workflows.</li> <li>Dynamic Workflows: Airflow's code-driven workflow definitions enable powerful patterns like dynamically generating workflows.</li> <li>Extensive Plugins: Airflow has a rich ecosystem of plugins and integrations with other tools.</li> <li>User Interface: Airflow is known for its powerful user interface which allows users to monitor and manage workflows.</li> </ul>"},{"location":"reference/future-tools/#feast","title":"Feast","text":"<p>Feast is an open-source feature store for machine learning.</p> PurposeFeature Store MaintainerTecton DocumentationDocumentation Source Code<code>feast-dev/feast</code> Roadmap PriorityMedium <p>A good way to understand the purpose of a feature store is to think about the data access patterns encountered during the model lifecycle.  A feature store should somehow make these data access patterns easier.</p> <ul> <li>Feature Engineering: Accesses and transforms historical data to create features.</li> <li>Target Engineering: Accesses and transforms historical data to create targets.</li> <li>Model Training: Accesses features and targets to train and evaluate the model.</li> <li>Model Inference: Accesses features of new data to predict the target.</li> </ul> <p>The key features of Feast are:</p> <ul> <li>Feature Registry: Where Feast persists feature definitions (not data) that are registered with with it (e.g. Local-Files, S3, GCS).</li> <li>Python SDK: The primary interface for managing feature definitions, and retrieving feature values from Feast.</li> <li>Offline Data Stores: A store which Feast can read feature values from, for historical data retrieval (e.g. Snowflake, BigQuery, Redshift).</li> <li>Online Data Stores: A store which Feast can materialize (write) feature values into, for online model inference (e.g. Snowflake, Redis, DynamoDB, Bigtable).</li> <li>Batch Materialization Engine: A data processing engine which Feast can use to materialize feature values from an Offline Store into an Online Store (e.g. Snowflake, Spark, Bytewax).</li> </ul> <p>A good feature store is NOT a database, but rather a data access layer between your data sources and your ML models. Be very wary of any feature store that requires you to load your data into it directly.</p>"},{"location":"reference/future-tools/#kserve","title":"KServe","text":"<p>KServe provides comprehensive interfaces for deploying, managing, and monitoring ML models on Kubernetes.</p> PurposeModel Serving MaintainerLinux Foundation DocumentationDocumentation Source Code<code>kserve/kserve</code> Roadmap PriorityMedium <p>The core features of KServe are:</p> <ul> <li>Support for Many Frameworks: KServe natively supports many ML frameworks (e.g. PyTorch, TensorFlow, scikit-learn, XGBoost).</li> <li>Autoscaling, Even to Zero: KServe can autoscale model replicas to meet demand, even scaling to zero when there are no requests.</li> <li>Model Monitoring: KServe integrates tools like Alibi Detect to provide model monitoring for drift and outlier detection.</li> <li>Model Explainability: KServe integrates tools like Alibi Explain to provide model explainability.</li> <li>Request Batching: KServe can batch requests to your model, improving throughput and reducing cost.</li> <li>Canary Deployments: KServe can deploy new versions of your model alongside old versions, and route requests to the new version based on a percentage.</li> <li>Feature Transformers: KServe can do feature pre/post processing alongside model inference (e.g. using Feast).</li> <li>Inference Graphs: KServe can chain multiple models together to form an inference graph.</li> </ul>"},{"location":"reference/future-tools/#seldon-core","title":"Seldon Core","text":"<p>Seldon Core provides interfaces for converting ML models into REST/gRPC microservices on Kubernetes.</p> PurposeModel Serving MaintainerSeldon DocumentationDocumentation Source Code<code>SeldonIO/seldon-core</code> Roadmap PriorityMedium <p>The core features of Seldon Core are:</p> <ul> <li>Support for Many Frameworks: Seldon Core natively supports many ML frameworks (e.g. TensorFlow, scikit-learn, XGBoost, HuggingFace, NVIDIA Triton).</li> <li>Reusable Model Servers: Seldon Core removes the need to build a container image for each model, by providing a system to download model artifacts at runtime.</li> <li>Model Deployment CRD Seldon Core provides a simple, yet powerful, Kubernetes CRD for deploying models.</li> </ul>"},{"location":"reference/future-tools/#datahub","title":"DataHub","text":"<p>DataHub is an open-source metadata platform for discovering, managing, and understanding data.</p> PurposeData Catalog MaintainerAcryl Data DocumentationDocumentation Source Code<code>datahub-project/datahub</code> Roadmap PriorityLower <p>The core features of DataHub are:</p> <ul> <li>Support for Many Data Sources: DataHub supports ingestion of metadata from many sources.</li> <li>Search &amp; Discovery: DataHub provides a search interface for discovering data.</li> <li>Data Lineage: DataHub can capture and visualize complex data lineage.</li> </ul>"},{"location":"reference/future-tools/#airbyte","title":"Airbyte","text":"<p>Airbyte is a data integration platform which aims to make it easy to move data from any source to any destination.</p> PurposeData Integration MaintainerAirbyte DocumentationDocumentation Source Code<code>airbytehq/airbyte</code> Roadmap PriorityLower <p>The core features of Airbyte are:</p> <ul> <li>Comprehensive Connector Catalog: Airbyte has an extremely large catalog of connectors for data sources and destinations.</li> <li>Airbyte Web UI: Airbyte provides a graphical web interface for managing data connectors and orchestrating data syncs.</li> </ul>"},{"location":"reference/future-tools/#label-studio","title":"Label Studio","text":"<p>Label Studio is an open-source data labeling platform which supports a variety of data types and labeling tasks.</p> PurposeData Labeling MaintainerHeartex DocumentationDocumentation Source Code<code>heartexlabs/label-studio</code> Roadmap PriorityLower <p>The core features of Label Studio are:</p> <ul> <li>Data Types: Label Studio supports a variety of data types, including text, images, audio, video, and time series.</li> <li>Task Templates: Label Studio provides many templates for common labeling tasks, including text classification, named entity recognition, and object detection.</li> <li>Label Studio Web UI: Label Studio provides a graphical web interface for labeling data and managing labeling projects.</li> </ul>"},{"location":"reference/future-tools/#bentoml-yatai","title":"BentoML Yatai","text":"<p>BentoML Yatai is a platform for managing the lifecycle of BentoML models on Kubernetes.</p> PurposeModel Serving MaintainerBentoML DocumentationDocumentation Source Code<code>bentoml/Yatai</code> Roadmap PriorityLower <p>The core features of BentoML Yatai are:</p> <ul> <li>Model Registry: A central registry for packaged Bentos.</li> <li>Model Deployment: Managing the deployment of BentoML models to Kubernetes, including building model container images.</li> <li>Web UI: A graphical web interface for viewing, deploying, and monitoring models.</li> <li>REST APIs: A REST API for viewing, deploying, and monitoring models.</li> <li>Kubernetes CRDs: Manage the deployment of models in a DevOps-friendly way.</li> </ul>"},{"location":"reference/tools/","title":"Current ML &amp; Data Tools","text":"<p>This page lists ML &amp; Data tools which are currently supported by deployKF.</p> <p>What versions of each tool are supported?</p> <p>See the version matrix to learn which versions of each tool are supported by each version of deployKF.</p> <p>What tools are planned for future releases?</p> <p>See the future tools page for a list of tools which are planned for future releases.</p>"},{"location":"reference/tools/#tool-index","title":"Tool Index","text":"<p>The following is an index of currently supported tools, grouped by ecosystem.</p> <p>Tip</p> <p>Click the name of a tool for more information about it.</p>"},{"location":"reference/tools/#kubeflow-ecosystem","title":"Kubeflow Ecosystem","text":"<p>Kubeflow is an \"MLOps on Kubernetes\" ecosystem which is owned by the CNCF, and provides various tools for building and deploying ML applications on Kubernetes.</p> Name Purpose Since deployKF Kubeflow Pipelines Workflow Orchestration <code>0.1.0</code> Kubeflow Notebooks Hosting Developer Environments <code>0.1.0</code> Katib Automated Machine Learning <code>0.1.0</code> Kubeflow Training Operator Managing Training Jobs <code>0.1.0</code> Kubeflow Volumes Managing Kubernetes Volumes <code>0.1.0</code> Kubeflow TensorBoards Managing TensorBoards <code>0.1.0</code>"},{"location":"reference/tools/#deploykf-ecosystem","title":"deployKF Ecosystem","text":"<p>Coming soon... See future tools for more information.</p>"},{"location":"reference/tools/#tool-details","title":"Tool Details","text":"<p>The following sections provide details and descriptions for each tool.</p>"},{"location":"reference/tools/#kubeflow-pipelines","title":"Kubeflow Pipelines","text":"<p>Kubeflow Pipelines (KFP) is a platform for building and running machine learning workflows on Kubernetes.</p> PurposeWorkflow Orchestration MaintainerKubeflow Project DocumentationDocumentation Source Code<code>kubeflow/pipelines</code> deployKF Configs<code>kubeflow_tools.pipelines</code> Since deployKF<code>0.1.0</code> <p>KFP provides higher-level abstractions for Argo Workflows to reduce repetition when defining machine learning tasks.   KFP has abstractions for defining pipelines and reusable components which it can compile and execute as Argo <code>Workflows</code>.</p> <p>The primary interface of KFP is the Python SDK, which allows you to define pipelines and reusable components with Python.  KFP also provides a Web UI for managing and tracking experiments, pipeline definitions, and pipeline runs.  Finally, KFP provides a REST API that allows programmatic access to the platform.</p>"},{"location":"reference/tools/#kubeflow-notebooks","title":"Kubeflow Notebooks","text":"<p>Kubeflow Notebooks lets you run web-based development environments inside a Kubernetes cluster.</p> PurposeHosting Developer Environments MaintainerKubeflow Project DocumentationDocumentation Source Code<code>kubeflow/kubeflow</code> deployKF Configs<code>kubeflow_tools.notebooks</code> Since deployKF<code>0.1.0</code> <p>Kubeflow Notebooks can run any web-based tool, but comes with pre-built images for JupyterLab, RStudio, and Visual Studio Code.</p> <p>Running development environments inside a Kubernetes cluster has several advantages:</p> <ul> <li>Remote Resources: Users can work directly on the cluster, rather than locally on their workstations.</li> <li>Standard Environments: Cluster admins can provide standard environment images for their organization, with required and approved packages pre-installed.</li> <li>Sharing &amp; Access Control: Access is managed via role-based-access-control (RBAC), enabling easier notebook sharing and collaboration across the organization.</li> </ul>"},{"location":"reference/tools/#katib","title":"Katib","text":"<p>Katib is an Automated Machine Learning (AutoML) platform for Kubernetes.</p> PurposeAutomated Machine Learning MaintainerKubeflow Project DocumentationDocumentation Source Code<code>kubeflow/katib</code> deployKF Configs<code>kubeflow_tools.katib</code> Since deployKF<code>0.1.0</code> <p>The key features of Katib are:</p> <ul> <li>Support for Multiple Techniques: Katib supports techniques like Hyperparameter Tuning, Early Stopping, and Neural Architecture Search.</li> <li>Support for ML Frameworks: Katib natively supports many ML frameworks like TensorFlow, PyTorch, XGBoost, and more.</li> <li>Kubernetes Native: Katib can manage training jobs on any Kubernetes Resource, and has out-of-the-box support for Kubeflow Training Operator, Argo Workflows, Tekton Pipelines, and more.</li> </ul>"},{"location":"reference/tools/#kubeflow-training-operator","title":"Kubeflow Training Operator","text":"<p>Kubeflow Training Operator helps you run machine learning training jobs on Kubernetes.</p> PurposeManaging Training Jobs MaintainerKubeflow Project DocumentationDocumentation Source Code<code>kubeflow/training-operator</code> deployKF Configs<code>kubeflow_tools.training_operator</code> Since deployKF<code>0.1.0</code> <p>The core function of the  Kubeflow Training Operator is to provide Kubernetes Custom Resources (CRDs) that define and monitor training jobs on Kubernetes.</p> <p>Many popular ML frameworks have been integrated with the Training Operator, including:</p> <ul> <li>PyTorch</li> <li>TensorFlow</li> <li>XGBoost</li> <li>MPI</li> </ul>"},{"location":"reference/tools/#kubeflow-volumes","title":"Kubeflow Volumes","text":"<p>Kubeflow Volumes is a web-based UI for creating and managing Kubernetes Persistent Volumes.</p> PurposeManaging Kubernetes Volumes MaintainerKubeflow Project DocumentationN/A Source Code<code>kubeflow/kubeflow</code> deployKF Configs<code>kubeflow_tools.volumes</code> Since deployKF<code>0.1.0</code>"},{"location":"reference/tools/#kubeflow-tensorboards","title":"Kubeflow TensorBoards","text":"<p>Kubeflow TensorBoards is a web-based UI for creating and managing TensorBoard instances on Kubernetes.</p> PurposeManaging TensorBoards MaintainerKubeflow Project DocumentationN/A Source Code<code>kubeflow/kubeflow</code> deployKF Configs<code>kubeflow_tools.tensorboards</code> Since deployKF<code>0.1.0</code>"},{"location":"releases/changelog-deploykf-cli/","title":"Changelog - deployKF CLI","text":"<p>This changelog lists releases of the deployKF CLI that are found in the <code>deployKF/cli</code> repository.</p> <p>Pre-releases</p> <p>For a changelog that shows pre-releases, see the full-changelog page.</p>"},{"location":"releases/changelog-deploykf-cli/#012-2023-08-09","title":"0.1.2 - 2023-08-09","text":""},{"location":"releases/changelog-deploykf-cli/#whats-changed","title":"What's Changed","text":""},{"location":"releases/changelog-deploykf-cli/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>fix: nil pointer on download error by @thesuperzapper in #12</li> </ul>"},{"location":"releases/changelog-deploykf-cli/#011-2023-08-07","title":"0.1.1 - 2023-08-07","text":""},{"location":"releases/changelog-deploykf-cli/#whats-changed_1","title":"What's Changed","text":""},{"location":"releases/changelog-deploykf-cli/#new-features","title":"New Features","text":"<ul> <li>feat: publish container image for cli by @thesuperzapper in #11</li> </ul>"},{"location":"releases/changelog-deploykf-cli/#010-2023-07-09","title":"0.1.0 - 2023-07-09","text":""},{"location":"releases/changelog-deploykf-cli/#whats-changed_2","title":"What's Changed","text":""},{"location":"releases/changelog-deploykf-cli/#significant-changes","title":"Significant Changes","text":"<ul> <li>initial release \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 </li> </ul>"},{"location":"releases/changelog-deploykf/","title":"Changelog - deployKF","text":"<p>This changelog lists releases of deployKF that are found in the <code>deployKF/deployKF</code> repository.</p> <p>Pre-releases</p> <p>For a changelog that shows pre-releases, see the full-changelog page.</p>"},{"location":"releases/changelog-deploykf/#013-2023-10-31","title":"0.1.3 - 2023-10-31","text":""},{"location":"releases/changelog-deploykf/#important-notes","title":"Important Notes","text":"<ul> <li>For more information about using the new \"browser login flow\" with Kubeflow Pipelines SDK, please see the updated Access Kubeflow Pipelines API guide.</li> </ul>"},{"location":"releases/changelog-deploykf/#whats-changed","title":"What's Changed","text":""},{"location":"releases/changelog-deploykf/#significant-changes","title":"Significant Changes","text":"<ul> <li>feat: browser-based KFP SDK auth by @thesuperzapper in #45</li> </ul>"},{"location":"releases/changelog-deploykf/#new-features","title":"New Features","text":"<ul> <li>feat: update oauth2-proxy to 7.5.1 by @thesuperzapper in #44</li> <li>feat: kyverno policy for image-pull-secrets by @thesuperzapper in #47</li> <li>feat: add values for kyverno replicas by @thesuperzapper in #50</li> </ul>"},{"location":"releases/changelog-deploykf/#improvements","title":"Improvements","text":"<ul> <li>improve: limit trigger operations for kyverno policies by @thesuperzapper in #49</li> </ul>"},{"location":"releases/changelog-deploykf/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>fix: don't mount trust bundles with own cert-manager by @thesuperzapper in #46</li> <li>fix: ensure kyverno has permission to manage PodDefaults by @thesuperzapper in #51</li> </ul>"},{"location":"releases/changelog-deploykf/#documentation","title":"Documentation","text":"<ul> <li>docs: update sync script to force update kyverno policies by @thesuperzapper in #40</li> <li>docs: add requirement checks to argocd sync script by @thesuperzapper in #42</li> <li>docs: update reference argocd version to 2.8.5 by @thesuperzapper in #52</li> </ul>"},{"location":"releases/changelog-deploykf/#miscellaneous","title":"Miscellaneous","text":"<ul> <li>refactor: always use <code>v1</code> kyverno resources by @thesuperzapper in #48</li> </ul>"},{"location":"releases/changelog-deploykf/#012-2023-09-22","title":"0.1.2 - 2023-09-22","text":""},{"location":"releases/changelog-deploykf/#important-notes_1","title":"Important Notes","text":"<ul> <li>If you are using the <code>deployKF ArgoCD Plugin</code>, you MUST update to the latest version of the plugin BEFORE upgrading to this version (see: #29).</li> </ul>"},{"location":"releases/changelog-deploykf/#whats-changed_1","title":"What's Changed","text":""},{"location":"releases/changelog-deploykf/#significant-changes_1","title":"Significant Changes","text":"<ul> <li>docs: add reference <code>sync_argocd_apps.sh</code> script by @thesuperzapper in #38</li> </ul>"},{"location":"releases/changelog-deploykf/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>fix: set kyverno webhook failure policy to ignore (fix uninstall deadlock) by @thesuperzapper in #26</li> <li>fix: resolve cert-manager race conditions by @thesuperzapper in #28</li> <li>fix: argocd plugin with \"file://\" dependencies (needed for helm forks) by @thesuperzapper in #29</li> <li>fix: create separate namespaces app, if destination is remote by @thesuperzapper in #30</li> <li>fix: ensure namespaces are never deleted or pruned by @thesuperzapper in #31</li> <li>fix: add sync waves to argocd apps (fix deletion) by @thesuperzapper in #32</li> <li>fix: resolve profile generator race condition by @thesuperzapper in #33</li> <li>fix: resolve race conditions with cloned secrets by @thesuperzapper in #34</li> <li>fix: app-of-apps should always target argocd cluster by @thesuperzapper in #35</li> </ul>"},{"location":"releases/changelog-deploykf/#documentation_1","title":"Documentation","text":"<ul> <li>docs: move guides to website by @thesuperzapper in #20</li> <li>docs: improve example app-of-apps for plugin by @thesuperzapper in #37</li> <li>docs: improve sample values, add reference overrides by @thesuperzapper in #36</li> </ul>"},{"location":"releases/changelog-deploykf/#011-2023-08-08","title":"0.1.1 - 2023-08-08","text":""},{"location":"releases/changelog-deploykf/#whats-changed_2","title":"What's Changed","text":""},{"location":"releases/changelog-deploykf/#significant-changes_2","title":"Significant Changes","text":"<ul> <li>feat: create argocd plugin by @thesuperzapper in #16</li> </ul>"},{"location":"releases/changelog-deploykf/#new-features_1","title":"New Features","text":"<ul> <li>feat: allow custom documentation links in dashboard by @yankcrime in #12</li> <li>feat: allow a single ArgoCD to manage deployKF across multiple clusters by @thesuperzapper in #17</li> </ul>"},{"location":"releases/changelog-deploykf/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>fix: set <code>securityContext.fsGroup</code> on minio pods by @thesuperzapper in #14</li> <li>fix: minio-console user permissions (update minio) by @thesuperzapper in #18</li> </ul>"},{"location":"releases/changelog-deploykf/#documentation_2","title":"Documentation","text":"<ul> <li>docs: improve getting started formatting by @thesuperzapper in #8</li> <li>docs: add links to important values in readme by @thesuperzapper in #9</li> <li>docs: improve getting started guide by @thesuperzapper in #11</li> <li>docs: add link to youtube demo by @thesuperzapper in #13</li> </ul>"},{"location":"releases/changelog-deploykf/#010-2023-07-10","title":"0.1.0 - 2023-07-10","text":""},{"location":"releases/changelog-deploykf/#whats-changed_3","title":"What's Changed","text":""},{"location":"releases/changelog-deploykf/#significant-changes_3","title":"Significant Changes","text":"<ul> <li>initial release \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 </li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/","title":"Changelog (all releases) - deployKF CLI","text":"<p>This changelog lists ALL releases of the deployKF CLI (including pre-releases) that are found in the <code>deployKF/cli</code> repository.</p> <p>Main Changelog</p> <p>For a changelog that hides pre-releases, see the main changelog page.</p>"},{"location":"releases/full-changelog-deploykf-cli/#012-2023-08-09","title":"0.1.2 - 2023-08-09","text":""},{"location":"releases/full-changelog-deploykf-cli/#whats-changed","title":"What's Changed","text":""},{"location":"releases/full-changelog-deploykf-cli/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>fix: nil pointer on download error by @thesuperzapper in #12</li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#011-2023-08-07","title":"0.1.1 - 2023-08-07","text":""},{"location":"releases/full-changelog-deploykf-cli/#whats-changed_1","title":"What's Changed","text":""},{"location":"releases/full-changelog-deploykf-cli/#new-features","title":"New Features","text":"<ul> <li>feat: publish container image for cli by @thesuperzapper in #11</li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#010-2023-07-09","title":"0.1.0 - 2023-07-09","text":""},{"location":"releases/full-changelog-deploykf-cli/#whats-changed_2","title":"What's Changed","text":""},{"location":"releases/full-changelog-deploykf-cli/#significant-changes","title":"Significant Changes","text":"<ul> <li>initial release \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 </li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#010-alpha3-2023-05-23","title":"0.1.0-alpha.3 - 2023-05-23","text":""},{"location":"releases/full-changelog-deploykf-cli/#whats-changed_3","title":"What's Changed","text":""},{"location":"releases/full-changelog-deploykf-cli/#new-features_1","title":"New Features","text":"<ul> <li>feat: write runtime templates &amp; other fixes by @thesuperzapper in #7</li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#010-alpha2-2023-04-28","title":"0.1.0-alpha.2 - 2023-04-28","text":""},{"location":"releases/full-changelog-deploykf-cli/#whats-changed_4","title":"What's Changed","text":""},{"location":"releases/full-changelog-deploykf-cli/#new-features_2","title":"New Features","text":"<ul> <li>feat: dont use \"v\" prefix for --source-version by @thesuperzapper in #4</li> <li>feat: check generator schema version by @thesuperzapper in #6</li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>fix: precedence of --values by @thesuperzapper in #5</li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#010-alpha1-2023-04-09","title":"0.1.0-alpha.1 - 2023-04-09","text":""},{"location":"releases/full-changelog-deploykf-cli/#010-alpha0-2023-04-09","title":"0.1.0-alpha.0 - 2023-04-09","text":""},{"location":"releases/full-changelog-deploykf/","title":"Changelog (all releases) - deployKF","text":"<p>This changelog lists ALL releases of deployKF (including pre-releases) that are found in the <code>deployKF/deployKF</code> repository.</p> <p>Main Changelog</p> <p>For a changelog that hides pre-releases, see the main changelog page.</p>"},{"location":"releases/full-changelog-deploykf/#013-2023-10-31","title":"0.1.3 - 2023-10-31","text":""},{"location":"releases/full-changelog-deploykf/#important-notes","title":"Important Notes","text":"<ul> <li>For more information about using the new \"browser login flow\" with Kubeflow Pipelines SDK, please see the updated Access Kubeflow Pipelines API guide.</li> </ul>"},{"location":"releases/full-changelog-deploykf/#whats-changed","title":"What's Changed","text":""},{"location":"releases/full-changelog-deploykf/#significant-changes","title":"Significant Changes","text":"<ul> <li>feat: browser-based KFP SDK auth by @thesuperzapper in #45</li> </ul>"},{"location":"releases/full-changelog-deploykf/#new-features","title":"New Features","text":"<ul> <li>feat: update oauth2-proxy to 7.5.1 by @thesuperzapper in #44</li> <li>feat: kyverno policy for image-pull-secrets by @thesuperzapper in #47</li> <li>feat: add values for kyverno replicas by @thesuperzapper in #50</li> </ul>"},{"location":"releases/full-changelog-deploykf/#improvements","title":"Improvements","text":"<ul> <li>improve: limit trigger operations for kyverno policies by @thesuperzapper in #49</li> </ul>"},{"location":"releases/full-changelog-deploykf/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>fix: don't mount trust bundles with own cert-manager by @thesuperzapper in #46</li> <li>fix: ensure kyverno has permission to manage PodDefaults by @thesuperzapper in #51</li> </ul>"},{"location":"releases/full-changelog-deploykf/#documentation","title":"Documentation","text":"<ul> <li>docs: update sync script to force update kyverno policies by @thesuperzapper in #40</li> <li>docs: add requirement checks to argocd sync script by @thesuperzapper in #42</li> <li>docs: update reference argocd version to 2.8.5 by @thesuperzapper in #52</li> </ul>"},{"location":"releases/full-changelog-deploykf/#miscellaneous","title":"Miscellaneous","text":"<ul> <li>refactor: always use <code>v1</code> kyverno resources by @thesuperzapper in #48</li> </ul>"},{"location":"releases/full-changelog-deploykf/#012-2023-09-22","title":"0.1.2 - 2023-09-22","text":""},{"location":"releases/full-changelog-deploykf/#important-notes_1","title":"Important Notes","text":"<ul> <li>If you are using the <code>deployKF ArgoCD Plugin</code>, you MUST update to the latest version of the plugin BEFORE upgrading to this version (see: #29).</li> </ul>"},{"location":"releases/full-changelog-deploykf/#whats-changed_1","title":"What's Changed","text":""},{"location":"releases/full-changelog-deploykf/#significant-changes_1","title":"Significant Changes","text":"<ul> <li>docs: add reference <code>sync_argocd_apps.sh</code> script by @thesuperzapper in #38</li> </ul>"},{"location":"releases/full-changelog-deploykf/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>fix: set kyverno webhook failure policy to ignore (fix uninstall deadlock) by @thesuperzapper in #26</li> <li>fix: resolve cert-manager race conditions by @thesuperzapper in #28</li> <li>fix: argocd plugin with \"file://\" dependencies (needed for helm forks) by @thesuperzapper in #29</li> <li>fix: create separate namespaces app, if destination is remote by @thesuperzapper in #30</li> <li>fix: ensure namespaces are never deleted or pruned by @thesuperzapper in #31</li> <li>fix: add sync waves to argocd apps (fix deletion) by @thesuperzapper in #32</li> <li>fix: resolve profile generator race condition by @thesuperzapper in #33</li> <li>fix: resolve race conditions with cloned secrets by @thesuperzapper in #34</li> <li>fix: app-of-apps should always target argocd cluster by @thesuperzapper in #35</li> </ul>"},{"location":"releases/full-changelog-deploykf/#documentation_1","title":"Documentation","text":"<ul> <li>docs: move guides to website by @thesuperzapper in #20</li> <li>docs: improve example app-of-apps for plugin by @thesuperzapper in #37</li> <li>docs: improve sample values, add reference overrides by @thesuperzapper in #36</li> </ul>"},{"location":"releases/full-changelog-deploykf/#011-2023-08-08","title":"0.1.1 - 2023-08-08","text":""},{"location":"releases/full-changelog-deploykf/#whats-changed_2","title":"What's Changed","text":""},{"location":"releases/full-changelog-deploykf/#significant-changes_2","title":"Significant Changes","text":"<ul> <li>feat: create argocd plugin by @thesuperzapper in #16</li> </ul>"},{"location":"releases/full-changelog-deploykf/#new-features_1","title":"New Features","text":"<ul> <li>feat: allow custom documentation links in dashboard by @yankcrime in #12</li> <li>feat: allow a single ArgoCD to manage deployKF across multiple clusters by @thesuperzapper in #17</li> </ul>"},{"location":"releases/full-changelog-deploykf/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>fix: set <code>securityContext.fsGroup</code> on minio pods by @thesuperzapper in #14</li> <li>fix: minio-console user permissions (update minio) by @thesuperzapper in #18</li> </ul>"},{"location":"releases/full-changelog-deploykf/#documentation_2","title":"Documentation","text":"<ul> <li>docs: improve getting started formatting by @thesuperzapper in #8</li> <li>docs: add links to important values in readme by @thesuperzapper in #9</li> <li>docs: improve getting started guide by @thesuperzapper in #11</li> <li>docs: add link to youtube demo by @thesuperzapper in #13</li> </ul>"},{"location":"releases/full-changelog-deploykf/#010-2023-07-10","title":"0.1.0 - 2023-07-10","text":""},{"location":"releases/full-changelog-deploykf/#whats-changed_3","title":"What's Changed","text":""},{"location":"releases/full-changelog-deploykf/#significant-changes_3","title":"Significant Changes","text":"<ul> <li>initial release \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 </li> </ul>"},{"location":"releases/version-matrix/","title":"Version Matrix","text":"<p>These tables summarize the tools and dependency versions which are supported by each version of deployKF.</p> <p>Version Key</p> <p>The version wrapped with <code>()</code> is the default version included with that version of deployKF.</p> <p>Versions that are <code>struck through</code> do not work with that version of deployKF.</p>"},{"location":"releases/version-matrix/#deploykf-dependencies","title":"deployKF Dependencies","text":"<p>Dependencies of deployKF.</p> deployKF <code>0.1</code> Kubernetes <code>1.22</code>, <code>1.23</code>, <code>1.24</code>, <code>1.25</code>, <code>1.26</code>, <code>1.27</code>, <code>1.28</code> Argo CD <code>2.3+</code> Istio <code>1.14</code><sup>[1]</sup>, <code>1.15</code>, <code>1.16</code>, (<code>1.17</code>), <code>1.18</code>, <code>1.19</code> cert-manager (<code>1.12</code>) Kyverno <code>1.9.X</code>, (<code>1.10.0</code>), <code>1.10.1+</code><sup>[2]</sup>"},{"location":"releases/version-matrix/#deploykf-core","title":"deployKF Core","text":"<p>Core components of deployKF like <code>deploykf-auth</code> and <code>deploykf-dashboard</code>.</p> deployKF <code>0.1</code> Dex<sub><code>deploykf-auth</code></sub> (<code>2.37</code>) OAuth2 Proxy<sub><code>deploykf-auth</code></sub> <code>7.4</code>, (<code>7.5</code>) deployKF Dashboard<sub><code>deploykf-dashboard</code></sub> (<code>0.1</code>) KF: Access Management API<sub><code>deploykf-dashboard</code></sub> (<code>1.7</code>) KF: Profile Controller<sub><code>deploykf-dashboard</code></sub> (<code>1.7</code>)"},{"location":"releases/version-matrix/#deploykf-opt","title":"deployKF Opt","text":"<p>Optional embedded applications that are used when external alternatives are not configured.</p> deployKF <code>0.1</code> MinIO<sub><code>Argo Workflows</code><code>Kubeflow Pipelines</code></sub> (<code>2023-08-04T17-40-21Z</code>) MySQL<sub><code>Kubeflow Pipelines</code><code>Katib</code></sub> (<code>8.0</code>)"},{"location":"releases/version-matrix/#deploykf-tools","title":"deployKF Tools","text":"<p>MLOps tools from the deployKF ecosystem.</p> <p>Tip</p> <p>For detailed information about each tool, see the supported tools page.</p> deployKF <code>0.1</code> . ."},{"location":"releases/version-matrix/#kubeflow-dependencies","title":"Kubeflow Dependencies","text":"<p>Dependencies of Kubeflow's MLOps tools.</p> deployKF <code>0.1</code> Argo Workflows<sub><code>Kubeflow Pipelines</code></sub> (<code>3.3</code>), <code>3.4</code><sup>[1]</sup> <sup>[2]</sup>"},{"location":"releases/version-matrix/#kubeflow-tools","title":"Kubeflow Tools","text":"<p>MLOps tools from the Kubeflow ecosystem.</p> <p>Tip</p> <p>See our current tools page for for detailed information about each tool in the Kubeflow ecosystem.</p> deployKF <code>0.1</code> Kubeflow Pipelines (<code>2.0.0-alpha.7</code>) Kubeflow Notebooks: Web App (<code>1.7</code>) Kubeflow Notebooks: Controller (<code>1.7</code>) Volumes: Web App (<code>1.7</code>) Katib (<code>0.15.0</code>) Kubeflow Training Operator (<code>1.6.0</code>) PodDefaults Webhook (<code>1.7</code>) TensorBoards: Web App (<code>1.7</code>) TensorBoards: Controller (<code>1.7</code>)"},{"location":"user-guides/access-kubeflow-pipelines-api/","title":"Access Kubeflow Pipelines API","text":"<p>This guide explains how to access the Kubeflow Pipelines API with the Kubeflow Pipelines Python SDK and authenticate with deployKF.</p> <p>Kubeflow Pipelines SDK Version</p> <p>deployKF 0.1 includes Kubeflow Pipelines version <code>2.0.0-alpha.7</code>, confusingly, this is actually part of the v1 line. Therefore, when using deployKF 0.1, ensure you have a <code>1.X.X</code> version of the <code>kfp</code> SDK installed.</p> <p>For example, to install <code>1.8.22</code> of the <code>kfp</code> SDK, run:</p> <pre><code>pip install kfp==1.8.22\n</code></pre>"},{"location":"user-guides/access-kubeflow-pipelines-api/#overview","title":"Overview","text":"<p>The Kubeflow Pipelines SDK is the Python client for Kubeflow Pipelines. This SDK is used to author, compile, and then submit workflows to the Kubeflow Pipelines API.</p> <p>This table outlines the SDK authentication methods available in deployKF:</p> Authentication Method In Cluster Outside Cluster No User Interaction Browser Login Flow Dex Static Credentials Kubernetes ServiceAccount Token"},{"location":"user-guides/access-kubeflow-pipelines-api/#browser-login-flow","title":"Browser Login Flow","text":"<p>The browser login flow (also known as \"out-of-band\" OIDC login) allows users to authenticate their local SDK using a web browser. This flow is suitable for interactive workflows, such as Jupyter Notebooks, or other situations that have access to a web browser.</p> <p>A significant benefit of this flow is that it allows users to act as themselves, rather than a service account, and supports all external identity providers that may be configured in deployKF.</p> <p>Minimum deployKF Version</p> <p>The \"out-of-band\" OIDC login flow requires deployKF v0.1.3, or later.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#authentication-flow","title":"Authentication Flow","text":"<p>The flow to authenticate the SDK using an \"out-of-band\" OIDC login is:</p> <ol> <li>The credential provider attempts to read a cached token, from the user's home directory:<ul> <li>If an unexpired token is found, it is returned to the SDK.</li> <li>If an expired token is found, the credential provider attempts to refresh the token.</li> </ul> </li> <li>Otherwise, the credential provider starts a new \"out-of-band\" OIDC login flow:<ul> <li>The user is prompted to open a URL in their browser.</li> <li>Once the user has authenticated, a code is provided to the user.</li> <li>The user copies the code from the browser and pastes it into the terminal.</li> <li>The token is persisted to the user's home directory, and returned to the SDK.</li> </ul> </li> </ol>"},{"location":"user-guides/access-kubeflow-pipelines-api/#reference-implementation","title":"Reference Implementation","text":"<p>The following reference implementation shows how to authenticate the Kubeflow Pipelines SDK using an \"out-of-band\" OIDC login flow.</p> <p>Refresh Token Expiry</p> <p>By default, deployKF allows refresh tokens to be used for 90 days in total, as long as they are used at least once every 7 days. While these defaults are usually sufficient, the following values control the refresh token expiry:</p> <ul> <li><code>deploykf_core.deploykf_auth.dex.expiry.refreshToken.idle</code></li> <li><code>deploykf_core.deploykf_auth.dex.expiry.refreshToken.total</code></li> </ul> <p>First, we define the <code>DeployKFCredentialsOutOfBand()</code> class which extends <code>TokenCredentialsBase()</code> to create a custom credential provider:</p> <pre><code>import base64\nimport hashlib\nimport json\nimport logging\nimport os\nimport sys\nimport time\nfrom typing import Optional\n\nimport requests\nimport urllib3\nfrom kubernetes.client import configuration\nfrom requests_oauthlib import OAuth2Session\n\ntry:\n    # for kubeflow pipelines v2\n    from kfp.client.token_credentials_base import TokenCredentialsBase\nexcept ImportError:\n    # for kubeflow pipelines v1\n    from kfp.auth import TokenCredentialsBase\n\n\nclass DeployKFCredentialsOutOfBand(TokenCredentialsBase):\n    \"\"\"\n    A Kubeflow Pipelines credential provider which uses an \"out-of-band\" OIDC login flow.\n\n    WARNING: intended for deployKF clusters only, unlikely to work with other Kubeflow clusters.\n\n    Key features:\n     - uses the OIDC client named 'kubeflow-pipelines-sdk', which is pre-configured in deployKF\n     - stores tokens in the user's home directory '~/.config/kfp/dkf_credentials.json'\n       (this file is indexed by issuer URL, so multiple clusters can be used concurrently)\n     - attempts to use the \"refresh_token\" grant before prompting the user to login again\n       (in deployKF, refresh tokens are valid if used at least once every 7 days, and not longer than 90 days in total)\n    \"\"\"\n\n    def __init__(self, issuer_url: str, skip_tls_verify: bool = False):\n        \"\"\"\n        Initialize a DeployKFTokenCredentials instance.\n\n        :param issuer_url: the OIDC issuer URL (e.g. 'https://deploykf.example.com:8443/dex')\n        :param skip_tls_verify: if True, skip TLS verification\n        \"\"\"\n        # oidc configuration\n        self.oidc_issuer_url = issuer_url\n        self.oidc_client_id = \"kubeflow-pipelines-sdk\"\n        self.oidc_redirect_uri = \"urn:ietf:wg:oauth:2.0:oob\"\n        self.oidc_scope = [\"openid\", \"email\", \"groups\", \"profile\", \"offline_access\"]\n\n        # other configuration\n        self.http_timeout = 15\n        self.local_credentials_path = os.path.join(\n            os.path.expanduser(\"~\"), \".config\", \"kfp\", \"dkf_credentials.json\"\n        )\n\n        # setup logging\n        self.log = logging.getLogger(__name__)\n        self._setup_logging()\n\n        # disable SSL verification, if requested\n        self.skip_tls_verify = skip_tls_verify\n        if self.skip_tls_verify:\n            self.log.warning(\"TLS verification is disabled\")\n            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n            os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n\n        # discover the OIDC issuer configuration\n        self._discover_oidc()\n\n        # perform the initial login, if necessary\n        self.get_token()\n\n    def _setup_logging(self):\n        self.log.propagate = False\n        self.log.setLevel(logging.INFO)\n        if not self.log.hasHandlers():\n            handler = logging.StreamHandler()\n            formatter = logging.Formatter(\n                fmt=\"%(asctime)s %(levelname)-8s %(message)s\",\n                datefmt=\"%Y-%m-%d %H:%M:%S\",\n            )\n            handler.setFormatter(formatter)\n            self.log.addHandler(handler)\n\n    def _discover_oidc(self):\n        \"\"\"\n        Discover the OIDC issuer configuration.\n        https://openid.net/specs/openid-connect-discovery-1_0.html\n        \"\"\"\n        oidc_discovery_url = f\"{self.oidc_issuer_url}/.well-known/openid-configuration\"\n        self.log.info(\"Discovering OIDC configuration from: %s\", oidc_discovery_url)\n        response = requests.get(\n            url=oidc_discovery_url,\n            timeout=self.http_timeout,\n            verify=not self.skip_tls_verify,\n        )\n        response.raise_for_status()\n        oidc_issuer_config = response.json()\n        self.oidc_issuer = oidc_issuer_config[\"issuer\"]\n        self.oidc_auth_endpoint = oidc_issuer_config[\"authorization_endpoint\"]\n        self.oidc_token_endpoint = oidc_issuer_config[\"token_endpoint\"]\n\n    def _read_credentials(self) -&gt; dict:\n        \"\"\"\n        Read credentials from the JSON file for the current issuer.\n        \"\"\"\n        self.log.debug(\n            \"Checking for existing credentials in: %s\", self.local_credentials_path\n        )\n        if os.path.exists(self.local_credentials_path):\n            with open(self.local_credentials_path, \"r\") as file:\n                data = json.load(file)\n                return data.get(self.oidc_issuer, {})\n        return {}\n\n    def _write_credentials(self, token: str):\n        \"\"\"\n        Write the provided token to the local credentials file (under the current issuer).\n        \"\"\"\n        # Create the directory, if it doesn't exist\n        credential_dir = os.path.dirname(self.local_credentials_path)\n        if not os.path.exists(credential_dir):\n            os.makedirs(credential_dir, exist_ok=True)\n\n        # Read all existing credentials from the JSON file\n        credentials_data = {}\n        if os.path.exists(self.local_credentials_path):\n            with open(self.local_credentials_path, \"r\") as f:\n                data = json.load(f)\n\n        # Update the credentials for the given issuer\n        credentials_data[self.oidc_issuer] = token\n        self.log.info(\"Writing credentials to: %s\", self.local_credentials_path)\n        with open(self.local_credentials_path, \"w\") as f:\n            json.dump(credentials_data, f)\n\n    def _generate_pkce_verifier(self) -&gt; (str, str):\n        \"\"\"\n        Generate a PKCE code verifier and its derived challenge.\n        https://tools.ietf.org/html/rfc7636#section-4.1\n        \"\"\"\n        # Generate a code_verifier of length between 43 and 128 characters\n        code_verifier = base64.urlsafe_b64encode(os.urandom(96)).decode(\"utf-8\")\n        code_verifier = code_verifier.rstrip(\"=\")\n        code_verifier = code_verifier[:128]\n\n        # Generate the code_challenge using the S256 method\n        sha256_digest = hashlib.sha256(code_verifier.encode(\"utf-8\")).digest()\n        code_challenge = (\n            base64.urlsafe_b64encode(sha256_digest).decode(\"utf-8\").rstrip(\"=\")\n        )\n\n        return code_verifier, code_challenge\n\n    def _refresh_token(self, oauth_session: OAuth2Session) -&gt; Optional[dict]:\n        \"\"\"\n        Attempt to refresh the provided token.\n        https://requests-oauthlib.readthedocs.io/en/latest/oauth2_workflow.html#refreshing-tokens\n        \"\"\"\n        if not oauth_session.token.get(\"refresh_token\", None):\n            return None\n\n        self.log.warning(\"Attempting to refresh token...\")\n        try:\n            new_token = oauth_session.refresh_token(\n                self.oidc_token_endpoint,\n                client_id=self.oidc_client_id,\n                timeout=self.http_timeout,\n                verify=not self.skip_tls_verify,\n            )\n            self.log.info(\"Successfully refreshed token!\")\n            self._write_credentials(new_token)\n            return new_token\n        except Exception as ex:\n            self.log.error(\"Failed to refresh token!\", exc_info=ex)\n\n    def _login(self, oauth_session: OAuth2Session) -&gt; dict:\n        \"\"\"\n        Start a new \"out-of-band\" login flow.\n        \"\"\"\n        self.log.info(\"Starting new 'out-of-band' login flow...\")\n\n        verifier, challenge = self._generate_pkce_verifier()\n        authorization_url, state = oauth_session.authorization_url(\n            self.oidc_auth_endpoint,\n            code_challenge_method=\"S256\",\n            code_challenge=challenge,\n        )\n\n        # ensure everything is printed to the console before continuing\n        sys.stderr.flush()\n        time.sleep(0.5)\n\n        # Get the authorization code from the user\n        print(\n            f\"\\nPlease open this URL in a browser to continue:\\n &gt; {authorization_url}\\n\",\n            flush=True,\n        )\n        user_input = input(\"Enter the authorization code:\\n &gt; \")\n        authorization_code = user_input.strip()\n\n        # Exchange the authorization code for a token\n        new_token = oauth_session.fetch_token(\n            self.oidc_token_endpoint,\n            code=authorization_code,\n            code_verifier=verifier,\n            include_client_id=True,\n            state=state,\n            timeout=self.http_timeout,\n            verify=not self.skip_tls_verify,\n        )\n        self.log.info(\"Successfully fetched new token!\")\n        self._write_credentials(new_token)\n        return new_token\n\n    def get_token(self) -&gt; str:\n        \"\"\"\n        Get the current auth token.\n        Will attempt to use \"refresh_token\" before prompting the user to login again.\n        \"\"\"\n        # return the existing token, if it's valid for at least 5 minutes\n        stored_token = self._read_credentials()\n        if stored_token:\n            expires_at = stored_token.get(\"expires_at\", 0)\n            expires_in = expires_at - time.time()\n            if expires_in &gt; 300:\n                self.log.info(\n                    \"Using cached auth token (expires in %d seconds)\", expires_in\n                )\n                return stored_token[\"id_token\"]\n            elif expires_in &gt; 0:\n                self.log.warning(\n                    \"Existing auth token expires in %d seconds\",\n                    expires_in,\n                )\n            else:\n                self.log.warning(\"Existing auth token has expired!\")\n\n        oauth_session = OAuth2Session(\n            self.oidc_client_id,\n            redirect_uri=self.oidc_redirect_uri,\n            scope=self.oidc_scope,\n            token=stored_token,\n        )\n\n        # try to refresh the token, or start a new login flow\n        new_token = self._refresh_token(oauth_session)\n        if not new_token:\n            new_token = self._login(oauth_session)\n\n        return new_token[\"id_token\"]\n\n    def refresh_api_key_hook(self, config: configuration.Configuration):\n        config.verify_ssl = not self.skip_tls_verify\n        config.api_key[\"authorization\"] = self.get_token()\n</code></pre> <p>Next, we create a <code>kfp.Client()</code> which uses the <code>DeployKFCredentialsOutOfBand()</code> class for authentication:</p> Kubeflow Pipelines v1Kubeflow Pipelines v2 <pre><code>import kfp\n\n# initialize a credentials instance \ncredentials = DeployKFCredentialsOutOfBand(\n    issuer_url=\"https://deploykf.example.com:8443/dex\", \n    skip_tls_verify=True,\n)\n\n# creates a patched client that supports disabling SSL verification\n# required before kfp v2: https://github.com/kubeflow/pipelines/pull/7174\ndef patched_kfp_client(verify_ssl=True):\n    _original_load_config = kfp.Client._load_config\n\n    def _patched_load_config(client_self, *args, **kwargs):\n        config = _original_load_config(client_self, *args, **kwargs)\n        config.verify_ssl = verify_ssl\n        return config\n\n    _patched_client = kfp.Client\n    _patched_client._load_config = _patched_load_config\n\n    return _patched_client\n\n# initialize a client instance\nkfp_client = patched_kfp_client(verify_ssl=not credentials.skip_tls_verify)(\n    host=\"https://deploykf.example.com:8443/pipeline\",\n    credentials=credentials,\n)\n\n# test the client by listing experiments\nexperiments = kfp_client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre> <pre><code>import kfp\n\n# initialize a credentials instance \ncredentials = DeployKFCredentialsOutOfBand(\n    issuer_url=\"https://deploykf.example.com:8443/dex\", \n    skip_tls_verify=True,\n)\n\n# initialize a client instance\nkfp_client = kfp.Client(\n    host=\"https://deploykf.example.com:8443/pipeline\",\n    verify_ssl=not credentials.skip_tls_verify,\n    credentials=credentials,\n)\n\n# test the client by listing experiments\nexperiments = kfp_client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre>"},{"location":"user-guides/access-kubeflow-pipelines-api/#dex-static-credentials","title":"Dex Static Credentials","text":"<p>Dex static credentials work from both inside and outside the cluster without needing user interaction during authentication. This makes them suitable for use in CI/CD pipelines, or other privileged automated workflows that need to access Kubeflow Pipelines.</p> <p>Provision Static Credentials</p> <p>Dex static credentials are managed by config values and are provisioned by the cluster administrator. The user authentication admin guide provides information about managing static credentials in deployKF.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#authentication-flow_1","title":"Authentication Flow","text":"<p>The flow to authenticate the SDK using Dex static credentials is:</p> <ol> <li>The client sends an unauthenticated request to the Kubeflow Pipelines API.</li> <li>The request is redirected to Dex for authentication.</li> <li>The client authenticates with Dex using the static credentials.</li> <li>The client is issued a session cookie by OAuth2 Proxy.</li> <li>The client uses the session cookie with all subsequent requests.</li> </ol>"},{"location":"user-guides/access-kubeflow-pipelines-api/#reference-implementation_1","title":"Reference Implementation","text":"<p>The following reference implementation shows how to authenticate the Kubeflow Pipelines SDK using Dex static credentials.</p> <p>Supported Authentication Methods</p> <p>The <code>KFPClientManager</code> class ONLY supports authentication with static (<code>local</code>) or LDAP (<code>ldap</code>) credentials, as determined by the <code>dex_auth_type</code> class parameter. Due to the nature of other authentication methods, it is not likely that they could be supported by this class in the future.</p> <p>First, we define the <code>KFPClientManager()</code> class which creates authenticated <code>kfp.Client()</code> instances when its <code>create_kfp_client()</code> method is called:</p> <pre><code>import re\nfrom urllib.parse import urlsplit\n\nimport kfp\nimport requests\nimport urllib3\n\n\nclass KFPClientManager:\n    \"\"\"\n    A class that creates `kfp.Client` instances with Dex authentication.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_url: str,\n        dex_username: str,\n        dex_password: str,\n        dex_auth_type: str = \"local\",\n        skip_tls_verify: bool = False,\n    ):\n        \"\"\"\n        Initialize the KfpClient\n\n        :param api_url: the Kubeflow Pipelines API URL\n        :param skip_tls_verify: if True, skip TLS verification\n        :param dex_username: the Dex username\n        :param dex_password: the Dex password\n        :param dex_auth_type: the auth type to use if Dex has multiple enabled, one of: ['ldap', 'local']\n        \"\"\"\n        self._api_url = api_url\n        self._skip_tls_verify = skip_tls_verify\n        self._dex_username = dex_username\n        self._dex_password = dex_password\n        self._dex_auth_type = dex_auth_type\n        self._client = None\n\n        # disable SSL verification, if requested\n        if self._skip_tls_verify:\n            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\n        # ensure `dex_default_auth_type` is valid\n        if self._dex_auth_type not in [\"ldap\", \"local\"]:\n            raise ValueError(\n                f\"Invalid `dex_auth_type` '{self._dex_auth_type}', must be one of: ['ldap', 'local']\"\n            )\n\n    def _get_session_cookies(self) -&gt; str:\n        \"\"\"\n        Get the session cookies by authenticating against Dex\n        :return: a string of session cookies in the form \"key1=value1; key2=value2\"\n        \"\"\"\n\n        # use a persistent session (for cookies)\n        s = requests.Session()\n\n        # GET the api_url, which should redirect to Dex\n        resp = s.get(\n            self._api_url, allow_redirects=True, verify=not self._skip_tls_verify\n        )\n        if resp.status_code != 200:\n            raise RuntimeError(\n                f\"HTTP status code '{resp.status_code}' for GET against: {self._api_url}\"\n            )\n\n        # if we were NOT redirected, then the endpoint is unsecured\n        if len(resp.history) == 0:\n            # no cookies are needed\n            return \"\"\n\n        # if we are at `/auth?=xxxx` path, we need to select an auth type\n        url_obj = urlsplit(resp.url)\n        if re.search(r\"/auth$\", url_obj.path):\n            url_obj = url_obj._replace(\n                path=re.sub(r\"/auth$\", f\"/auth/{self._dex_auth_type}\", url_obj.path)\n            )\n\n        # if we are at `/auth/xxxx/login` path, then we are at the login page\n        if re.search(r\"/auth/.*/login$\", url_obj.path):\n            dex_login_url = url_obj.geturl()\n        else:\n            # otherwise, we need to follow a redirect to the login page\n            resp = s.get(\n                url_obj.geturl(), allow_redirects=True, verify=not self._skip_tls_verify\n            )\n            if resp.status_code != 200:\n                raise RuntimeError(\n                    f\"HTTP status code '{resp.status_code}' for GET against: {url_obj.geturl()}\"\n                )\n            dex_login_url = resp.url\n\n        # attempt Dex login\n        resp = s.post(\n            dex_login_url,\n            data={\"login\": self._dex_username, \"password\": self._dex_password},\n            allow_redirects=True,\n            verify=not self._skip_tls_verify,\n        )\n        if resp.status_code != 200:\n            raise RuntimeError(\n                f\"HTTP status code '{resp.status_code}' for POST against: {dex_login_url}\"\n            )\n\n        # if we were NOT redirected, then the login credentials were probably invalid\n        if len(resp.history) == 0:\n            raise RuntimeError(\n                f\"Login credentials are probably invalid - \"\n                f\"No redirect after POST to: {dex_login_url}\"\n            )\n\n        return \"; \".join([f\"{c.name}={c.value}\" for c in s.cookies])\n\n    def _create_kfp_client(self) -&gt; kfp.Client:\n        try:\n            session_cookies = self._get_session_cookies()\n        except Exception as ex:\n            raise RuntimeError(f\"Failed to get Dex session cookies\") from ex\n\n        # monkey patch the kfp.Client to support disabling SSL verification\n        # kfp only added support in v2: https://github.com/kubeflow/pipelines/pull/7174\n        original_load_config = kfp.Client._load_config\n\n        def patched_load_config(client_self, *args, **kwargs):\n            config = original_load_config(client_self, *args, **kwargs)\n            config.verify_ssl = not self._skip_tls_verify\n            return config\n\n        patched_kfp_client = kfp.Client\n        patched_kfp_client._load_config = patched_load_config\n\n        return patched_kfp_client(\n            host=self._api_url,\n            cookies=session_cookies,\n        )\n\n    def create_kfp_client(self) -&gt; kfp.Client:\n        \"\"\"Get a newly authenticated Kubeflow Pipelines client.\"\"\"\n        return self._create_kfp_client()\n</code></pre> <p>Next, we use the <code>KFPClientManager()</code> class to create an authenticated <code>kfp.Client()</code>:</p> <pre><code># initialize a KFPClientManager\nkfp_client_manager = KFPClientManager(\n    api_url=\"https://deploykf.example.com:8443/pipeline\",\n    skip_tls_verify=True,\n\n    dex_username=\"user1@example.com\",\n    dex_password=\"user1\",\n\n    dex_auth_type=\"local\",\n)\n\n# get a newly authenticated KFP client\n# TIP: long-lived sessions might need to get a new client when their session expires\nkfp_client = kfp_client_manager.create_kfp_client()\n\n# test the client by listing experiments\nexperiments = kfp_client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre>"},{"location":"user-guides/access-kubeflow-pipelines-api/#kubernetes-serviceaccount-token","title":"Kubernetes ServiceAccount Token","text":"<p>The Kubeflow Pipelines backend has a trust relationship with the Kubernetes ServiceAccount system. This means that if a request is made to the Kubeflow Pipelines API (internal service) that presents a Kubernetes ServiceAccount bearer token, the request will be authenticated as that ServiceAccount.</p> <p>This authentication method provides a reliable way to authenticate with the Kubeflow Pipelines API from inside the cluster, without needing user interaction during authentication.</p> <p>RBAC Access</p> <p>The level of Kubeflow Pipelines access which a Kubernetes ServiceAccount has, is defined by Kubernetes RBAC, rather than deployKF profile definitions.</p> <p>By default, the ServiceAccount used by Kubeflow Pipelines and Kubeflow Notebooks (called <code>default-editor</code>), will have read/write access to all Kubeflow Pipelines resources in the same namespace as the Pod.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#authentication-flow_2","title":"Authentication Flow","text":"<p>The flow to authenticate the SDK using a Kubernetes ServiceAccount token is:</p> <ol> <li>The Pod where the client is running, has a ServiceAccount token volume mounted.</li> <li>The client uses the bearer token to authenticate with the Kubeflow Pipelines API.</li> <li>Kubernetes itself manages the token's expiry and rotation.</li> </ol>"},{"location":"user-guides/access-kubeflow-pipelines-api/#reference-implementation_2","title":"Reference Implementation","text":"<p>The following reference implementation shows how to authenticate the Kubeflow Pipelines SDK using a Kubernetes ServiceAccount token.</p> <p>Kubernetes has a feature called ServiceAccount token volume projection which mounts and automatically manages ServiceAccount tokens for Pods.</p> Pod Definition (Manual)PodDefault Injection (Automatic) <p>You may adjust the definition of any Pod to mount a ServiceAccount token volume that can be used to authenticate with the Kubeflow Pipelines API.</p> <p>The following Pod will have a ServiceAccount token volume mounted at the path <code>/var/run/secrets/kubeflow/pipelines/token</code>:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: access-kfp-example\nspec:\n  ## NOTE: the token will be for the service account of the Pod\n  serviceAccountName: default-editor\n  containers:\n    - image: hello-world:latest\n      name: hello-world\n      env:\n        - name: KF_PIPELINES_SA_TOKEN_PATH\n          value: /var/run/secrets/kubeflow/pipelines/token\n      volumeMounts:\n        - mountPath: /var/run/secrets/kubeflow/pipelines\n          name: volume-kf-pipeline-token\n          readOnly: true\n  volumes:\n    - name: volume-kf-pipeline-token\n      projected:\n        sources:\n          - serviceAccountToken:\n              path: token\n              expirationSeconds: 7200\n              audience: pipelines.kubeflow.org      \n</code></pre> <p>In addition to manually mounting the ServiceAccount token volume, deployKF can automatically inject the volume using a PodDefault resource based on a Pod's labels.</p> <p>When the <code>kubeflow_tools.pipelines.profileResourceGeneration.kfpApiTokenPodDefault</code> value is <code>true</code>, a PodDefault named <code>\"kubeflow-pipelines-api-token\"</code> is automatically created in each profile namespace. This means that any Pod with the <code>kubeflow-pipelines-api-token=true</code> label will automatically have a ServiceAccount token volume mounted to the Pod.</p> <p>Kubeflow Notebooks Integration</p> <p>Kubeflow Notebooks detects any PodDefaults which are in a Profile Namespace. Users may tick a checkbox under \"Advanced Options\" \u2192 \"Configurations\" to apply a PodDefault when spawning a new Notebook.</p> <p>If you wish to apply a PodDefault to all new Notebooks, see the \"advanced pod options\" section of Configure Kubeflow Notebooks.</p> How can I define my own PodDefault? <p>If you wish to define your own PodDefault, you may do so by creating one in a Profile Namespace.</p> <p>For example, the following PodDefault will inject a ServiceAccount token volume into any Pod with the label <code>my-kfp-api-token=true</code>:</p> <pre><code>apiVersion: kubeflow.org/v1alpha1\nkind: PodDefault\nmetadata:\n  name: my-kfp-api-token\n  namespace: \"&lt;YOUR_USER_PROFILE_NAMESPACE&gt;\"\nspec:\n  desc: \"Mount a serviceAccountToken to authenticate with Kubeflow Pipelines API\"\n  selector:\n    matchLabels:\n      my-kfp-api-token: \"true\"\n  env:\n    - name: KF_PIPELINES_SA_TOKEN_PATH\n      value: /var/run/secrets/kubeflow/pipelines/token\n  volumes:\n    - name: volume-kf-pipeline-token\n      projected:\n        sources:\n          - serviceAccountToken:\n              path: token\n              expirationSeconds: 7200\n              audience: pipelines.kubeflow.org      \n  volumeMounts:\n    - mountPath: /var/run/secrets/kubeflow/pipelines\n      name: volume-kf-pipeline-token\n      readOnly: true\n</code></pre> <p>The following Python code creates a <code>kfp.Client()</code> using a ServiceAccount token for authentication (when run from inside the cluster):</p> <pre><code>import kfp\n\n# by default, when run from inside a Kubernetes cluster:\n#  - the token is read from the `KF_PIPELINES_SA_TOKEN_PATH` path\n#  - the host is set to `http://ml-pipeline-ui.kubeflow.svc.cluster.local`\nkfp_client = kfp.Client()\n\n# test the client by listing experiments\nexperiments = kfp_client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre> How can I specify a different token path or host? <p>By default, when <code>kfp.Client()</code> is run from inside a Kubernetes Pod, the token is read from <code>/var/run/secrets/kubeflow/pipelines/token</code> (or the value of the <code>KF_PIPELINES_SA_TOKEN_PATH</code> environment variable), and <code>http://ml-pipeline-ui.kubeflow.svc.cluster.local</code> is used for the host.</p> <p>You may also explicitly initialize a <code>ServiceAccountTokenVolumeCredentials</code> instance and pass it to the <code>kfp.Client()</code> constructor as the <code>credentials</code> parameter.</p> <p>For example to read the token from <code>/var/run/secrets/kubeflow/pipelines/token2</code>:</p> <pre><code>import kfp\n\ntry:\n    # for kubeflow pipelines v2\n    from kfp.client.set_volume_credentials import ServiceAccountTokenVolumeCredentials\nexcept ImportError:\n    # for kubeflow pipelines v1\n    from kfp.auth import ServiceAccountTokenVolumeCredentials\n\n# initialize a credentials instance\ncredentials = ServiceAccountTokenVolumeCredentials(\n    path=\"/var/run/secrets/kubeflow/pipelines/token2\"\n)\n\n# initialize a client instance\n# NOTE: we must use the `Service/ml-pipeline-ui` service, NOT the public gateway\nkfp_client = kfp.Client(\n    host=\"http://ml-pipeline-ui.kubeflow.svc.cluster.local\",\n    credentials=credentials,\n)\n\n# test the client by listing experiments\nexperiments = kfp_client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre>"},{"location":"user-guides/gitops-for-kubeflow-pipelines/","title":"GitOps for Kubeflow Pipelines Schedules","text":"<p>This guide explains how to use GitOps to manage Kubeflow Pipelines, including pipeline definitions and pipeline schedules.</p>"},{"location":"user-guides/gitops-for-kubeflow-pipelines/#overview","title":"Overview","text":"<p>Initially, most users of Kubeflow Pipelines manually create and run workflows with the UI or Python SDK, as this is the fastest way to get started. When the number of pipelines grows, it becomes increasingly difficult and error-prone to manage them manually; this is where GitOps comes in.</p>"},{"location":"user-guides/gitops-for-kubeflow-pipelines/#reference-implementation","title":"Reference Implementation","text":"<p>We provide a reference implementation for managing pipeline definitions and their schedules using GitOps in the <code>deployKF/kubeflow-pipelines-gitops</code> GitHub repo.</p> <p> Check out the Reference Repository</p> <p>The reference architecture is logically grouped into four steps:</p> Step Description Step 1: Render Pipelines Render pipeline definitions into their static YAML representation. Step 2: Run Pipelines Run the rendered pipelines ad-hoc. Step 3: Schedule Pipelines Schedule the rendered pipelines. Step 4: Automatic Reconciliation Automatically reconcile the schedule configs."}]}