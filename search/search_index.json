{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Frequently asked questions about deployKF.</p> What is deployKF? Why use deployKF? Is there commercial support for deployKF? Which ML and AI tools are in deployKF? Who created deployKF? Who has adopted deployKF? How are Kubeflow and deployKF related? How can I get involved with deployKF? How is deployKF licensed?"},{"location":"faq/#what-is-deploykf","title":"What is deployKF?","text":"<p>deployKF builds machine learning platforms on Kubernetes. We combine the best of   Kubeflow,   Airflow<sup>\u2020</sup>, and   MLflow<sup>\u2020</sup> into a complete platform that is easy to deploy and maintain.</p> <p><sup>\u2020</sup>Coming soon, see our current and future tools.</p>"},{"location":"faq/#why-use-deploykf","title":"Why use deployKF?","text":"<p>deployKF combines the ease of a managed service with the flexibility of a self-hosted solution. </p> <p>Our vision is that anyone with Kubernetes experience can build a machine learning platform for their organization, without needing specialized MLOps knowledge, and a team of experts to maintain it.</p> <p>The key features of deployKF are:</p> <ul> <li>Run on any Kubernetes cluster, including on-premises and in the cloud</li> <li>Intuitive centralized configs for all aspects of the platform</li> <li>Seamless in-place upgrades and config updates</li> <li>Connect your existing  Istio,  cert-manager,  Kyverno,  S3, and  MySQL</li> <li>Use any identity provider via OpenID Connect or LDAP</li> <li>Native support for GitOps with ArgoCD</li> </ul>"},{"location":"faq/#is-there-commercial-support-for-deploykf","title":"Is there commercial support for deployKF?","text":"<p>To discuss commercial support options for deployKF, please connect with  Aranui Solutions, the company started by the creators of deployKF.</p> <p> Visit Website  Email Aranui Solutions</p>"},{"location":"faq/#which-ml-and-ai-tools-are-in-deploykf","title":"Which ML and AI tools are in deployKF?","text":"<p>deployKF supports all tools from the Kubeflow Ecosystem including Kubeflow Pipelines and Kubeflow Notebooks. We are actively adding support for other popular tools such as MLflow, Airflow, and Feast.  For more information, please see our current and future tools!</p>"},{"location":"faq/#who-created-deploykf","title":"Who created deployKF?","text":"<p>deployKF was originally created and is maintained by Mathew Wicks (GitHub: @thesuperzapper), a Kubeflow lead and maintainer of the popular Apache Airflow Helm Chart. deployKF is a community-led project that welcomes contributions from anyone who wants to help.</p>"},{"location":"faq/#who-has-adopted-deploykf","title":"Who has adopted deployKF?","text":"<p>deployKF is a new project, and we are still building our community, consider adding your organization to our list of adopters.</p>"},{"location":"faq/#how-are-kubeflow-and-deploykf-related","title":"How are Kubeflow and deployKF related?","text":"<p>Kubeflow and deployKF are two different but related projects. For more details, please see our deployKF vs Kubeflow comparison.</p>"},{"location":"faq/#how-can-i-get-involved-with-deploykf","title":"How can I get involved with deployKF?","text":"<p>The deployKF project is a welcoming community of contributors and users.  We encourage participation from anyone who shares our mission of making it easy to build open ML Platforms on Kubernetes. For more details, see our community page.</p>"},{"location":"faq/#how-is-deploykf-licensed","title":"How is deployKF licensed?","text":"<p>deployKF is licensed under the Apache License 2.0. However, some of the tools that deployKF can help deploy are licensed differently. Please ensure you are aware of how the tools you deploy are licenced.</p>"},{"location":"about/architecture/","title":"Architecture of deployKF","text":"<p>Learn about the architecture of deployKF and its components.</p>"},{"location":"about/architecture/#overview","title":"Overview","text":"<p>deployKF has three user-facing components:</p> Component(Click for Details) Description deployKF Generator A versioned <code>.zip</code> package with the templates and helpers needed to generate the manifests deployKF CLI A command line program to generate a the Kubernetes manifests, from configs provided in one or more values files deployKF ArgoCD Plugin A plugin for ArgoCD which allows you to use deployKF without rendering manifests into a git repo"},{"location":"about/architecture/#deploykf-generator","title":"deployKF Generator","text":"<p>The deployKF Generator is a versioned ZIP package which contains all the templates and helpers needed to generate the output folders.</p> <p>The generator is developed in the <code>deployKF/deployKF</code>  GitHub repo.</p>"},{"location":"about/architecture/#generator-templates","title":"Generator Templates","text":"<p>The generator templates are rendered using a version of gomplate that is embedded in the deployKF CLI.</p> <p>Note, the template delimiters are set to <code>{{&lt;</code> and <code>&gt;}}</code> as to avoid conflicts with Helm and other Go-like templates.</p>"},{"location":"about/architecture/#generator-zip-structure","title":"Generator ZIP Structure","text":""},{"location":"about/architecture/#tree-view","title":"Tree View","text":"<pre><code>.\n\u251c\u2500\u2500 .deploykf_generator\n\u251c\u2500\u2500 default_values.yaml\n\u251c\u2500\u2500 helpers/\n\u2514\u2500\u2500 templates/\n    \u251c\u2500\u2500 .gomplateignore_template\n    \u251c\u2500\u2500 app-of-apps.yaml\n    \u251c\u2500\u2500 argocd/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 kustomization.yaml\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 applications/\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 kustomization.yaml\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 namespaces.yaml\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-core/\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-dependencies/\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-opt/\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-tools/\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 kubeflow-dependencies/\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 kubeflow-tools/\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 namespaces/\n    \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 kustomization.yaml\n    \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 deploykf-core/\n    \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 deploykf-dependencies/\n    \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 deploykf-opt/\n    \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 deploykf-tools/\n    \u2502\u00a0\u00a0  \u00a0\u00a0 \u251c\u2500\u2500 kubeflow-dependencies/\n    \u2502\u00a0\u00a0  \u00a0\u00a0 \u2514\u2500\u2500 kubeflow-tools/\n    \u2514\u2500\u2500 manifests/\n        \u251c\u2500\u2500 deploykf-core/\n        \u251c\u2500\u2500 deploykf-dependencies/\n        \u251c\u2500\u2500 deploykf-opt/\n        \u251c\u2500\u2500 deploykf-tools/\n        \u251c\u2500\u2500 kubeflow-dependencies/\n        \u2514\u2500\u2500 kubeflow-tools/\n</code></pre>"},{"location":"about/architecture/#_1","title":"<code>./</code>","text":"<ul> <li><code>.deploykf_generator</code> metadata about the generator:<ul> <li>(JSON format, includes the <code>generator_schema</code> version to ensure compatibility with the CLI)</li> </ul> </li> <li><code>default_values.yaml</code> default values for the generator</li> <li><code>helpers/</code> helpers that are used in the <code>templates/</code></li> <li><code>templates/</code> templates that are used to generate the output</li> </ul>"},{"location":"about/architecture/#templates","title":"<code>./templates/</code>","text":"<ul> <li><code>.gomplateignore_template</code> template of a <code>.gomplateignore</code> file</li> <li><code>app-of-apps.yaml</code> an Argo CD app-of-apps (points to <code>./argocd/kustomization.yaml</code>)</li> <li><code>argocd/</code> templates for Argo CD applications and namespaces</li> <li><code>manifests/</code> templates for Helm &amp; Kustomize apps</li> </ul>"},{"location":"about/architecture/#templatesargocd","title":"<code>./templates/argocd/</code>","text":"<ul> <li><code>kustomization.yaml</code> a Kustomize file pointing to <code>applications/</code> and <code>namespaces/</code></li> <li><code>applications/</code> templates for Argo CD Applications</li> <li><code>namespaces/</code> templates for Kubernetes Namespaces</li> </ul>"},{"location":"about/architecture/#templatesargocdapplications","title":"<code>./templates/argocd/applications/</code>","text":"<ul> <li><code>kustomization.yaml</code> a Kustomize file pointing to the Argo CD applications</li> <li><code>deploykf-core/</code> Argo CD applications for <code>deploykf-core</code></li> <li><code>deploykf-dependencies/</code> Argo CD applications for <code>deploykf-dependencies</code></li> <li><code>deploykf-opt/</code>Argo CD applications for <code>deploykf-opt</code></li> <li><code>deploykf-tools/</code> Argo CD applications for <code>deploykf-tools</code></li> <li><code>kubeflow-dependencies/</code> Argo CD applications for <code>kubeflow-dependencies</code></li> <li><code>kubeflow-tools/</code> Argo CD applications for <code>kubeflow-tools</code></li> </ul>"},{"location":"about/architecture/#templatesargocdnamespaces","title":"<code>./templates/argocd/namespaces/</code>","text":"<ul> <li><code>kustomization.yaml</code> a Kustomize file pointing to the Kubernetes Namespaces</li> <li><code>deploykf-core/</code> Kubernetes Namespaces for <code>deploykf-core</code></li> <li><code>deploykf-dependencies/</code> Kubernetes Namespaces for <code>deploykf-dependencies</code></li> <li><code>deploykf-opt/</code> Kubernetes Namespaces for <code>deploykf-opt</code></li> <li><code>deploykf-tools/</code> Kubernetes Namespaces for <code>deploykf-tools</code></li> <li><code>kubeflow-dependencies/</code> Kubernetes Namespaces for <code>kubeflow-dependencies</code></li> <li><code>kubeflow-tools/</code> Kubernetes Namespaces for <code>kubeflow-tools</code></li> </ul>"},{"location":"about/architecture/#templatesmanifests","title":"<code>./templates/manifests/</code>","text":"<ul> <li><code>kustomization.yaml</code> a Kustomize file pointing to the Helm &amp; Kustomize apps</li> <li><code>deploykf-core/</code> templated Helm &amp; Kustomize apps for <code>deploykf-core</code></li> <li><code>deploykf-dependencies/</code> templated Helm &amp; Kustomize apps for <code>deploykf-dependencies</code></li> <li><code>deploykf-opt/</code> templated Helm &amp; Kustomize apps for <code>deploykf-opt</code></li> <li><code>deploykf-tools/</code> templated Helm &amp; Kustomize apps for <code>deploykf-tools</code></li> <li><code>kubeflow-dependencies/</code> templated Helm &amp; Kustomize apps for <code>kubeflow-dependencies</code></li> <li><code>kubeflow-tools/</code> templated Helm &amp; Kustomize apps for <code>kubeflow-tools</code></li> </ul>"},{"location":"about/architecture/#deploykf-cli","title":"deployKF CLI","text":"<p>The deployKF CLI is a command line program written in Go.</p> <p>The CLI is developed in the <code>deployKF/cli</code> GitHub repo.</p>"},{"location":"about/architecture/#deploykf-generate","title":"<code>deploykf generate</code>","text":"<p>Code</p> <p>The code which defines the <code>deploykf generate</code> command is found in <code>cmd/deploykf/generate.go</code>.</p> <p>Implementation</p> <p>The <code>deploykf generate</code> command is implemented as follows:</p> <ol> <li>Locate the deployKF Generator to use, depending on which arguments were provided:<ul> <li><code>--source-version</code>: download a generator ZIP from the GitHub releases of <code>deploykf/deploykf</code></li> <li><code>--source-path</code>: use a local generator ZIP or folder with unzipped generator files</li> </ul> </li> <li>Unzip or copy the generator into a temporary folder:<ul> <li>The folder is automatically deleted after the command is run, or if the command fails</li> </ul> </li> <li>Read the <code>.deploykf_generator</code> marker file from the root of the generator:<ul> <li>The <code>.deploykf_generator</code> file contains JSON data with information like the <code>generator_schema</code> version</li> <li>If the CLI does not support the encountered <code>generator_schema</code> version, the CLI will exit with an error</li> </ul> </li> <li>Clean the folder currently at the <code>--output-dir</code> target:<ul> <li>The CLI will only remove the contents of a non-empty target if there is a <code>.deploykf_output</code> marker file at its root</li> </ul> </li> <li>Render the manifests into <code>--output-dir</code> in two phases, using the provided <code>--values</code> files:<ol> <li>PHASE 1: render the <code>.gomplateignore_template</code> files into <code>.gomplateignore</code> files (still in the temporary folder)<ul> <li>Note, these files behave like <code>.gitignore</code> files, and are used to exclude files from the output in the second phase</li> </ul> </li> <li>PHASE 2: render the templates from the <code>templates</code> folder into the <code>--output-dir</code><ul> <li>Note, the resulting output folder will be structured identically to the <code>templates</code> folder (subject to the <code>.gomplateignore</code> files)</li> </ul> </li> </ol> </li> </ol> <p>The output folder will contain a <code>.deploykf_output</code> marker file with the following information in JSON format:</p> <ul> <li><code>generated_at</code>: the time the generator was run</li> <li><code>source_version</code>: the source version that was used (if <code>--source-version</code> was provided)</li> <li><code>source_path</code>: the path of the source artifact that was used </li> <li><code>source_hash</code>: the SHA256 hash of the source artifact that was used</li> <li><code>cli_version</code>: the version of the deployKF CLI that was used</li> </ul>"},{"location":"about/architecture/#deploykf-argocd-plugin","title":"deployKF ArgoCD Plugin","text":"<p>The deployKF ArgoCD Plugin is a plugin for ArgoCD which allows you to use deployKF without rendering manifests into a git repo (or using the CLI directly).</p> <p>The plugin is developed in the <code>deployKF/deployKF</code> GitHub repo.</p>"},{"location":"about/community/","title":"Community","text":"<p>Join the deployKF community! Learn how to get involved with the deployKF community.</p>"},{"location":"about/community/#about-the-community","title":"About the Community","text":"<p>The deployKF project is a welcoming community of contributors and users. We encourage participation from anyone who shares our mission of making it easy to build open ML Platforms on Kubernetes.</p>"},{"location":"about/community/#slack","title":"Slack","text":"<p>The deployKF community has a Slack server for informal discussions among users and contributors:</p> <p>Join the Slack</p>"},{"location":"about/community/#mailing-lists","title":"Mailing Lists","text":"<p>The deployKF community has two mailing lists which are hosted on Google Groups:</p> <p> Join User Mailing List  Join Contributor Mailing List</p>"},{"location":"about/community/#contact-us","title":"Contact Us","text":"<p>Are you a vendor who wants to support deployKF, or just have something else to discuss?</p> <p>Get in touch with the maintainers of deployKF:</p> <p> Email the Team</p>"},{"location":"about/introduction/","title":"Introduction","text":"<p>An introduction to deployKF.</p>"},{"location":"about/introduction/#about-deploykf","title":"About deployKF","text":"<p>deployKF builds machine learning platforms on Kubernetes. We combine the best of   Kubeflow,   Airflow<sup>\u2020</sup>, and   MLflow<sup>\u2020</sup> into a complete platform that is easy to deploy and maintain.</p> <p><sup>\u2020</sup>Coming soon, see our current and future tools.</p>"},{"location":"about/introduction/#why-use-deploykf","title":"Why use deployKF?","text":"<p>deployKF combines the ease of a managed service with the flexibility of a self-hosted solution. </p> <p>Our goal is that any Kubernetes user can build a machine learning platform for their organization,  without needing specialized MLOps knowledge, or a team of experts to maintain it.</p> <p>The key features of deployKF are:</p> <ul> <li>Run on any Kubernetes cluster, including on-premises and in the cloud</li> <li>Intuitive centralized configs for all aspects of the platform</li> <li>Seamless in-place upgrades and config updates</li> <li>Connect your existing  Istio,  cert-manager,  Kyverno,  S3, and  MySQL</li> <li>Use any identity provider via OpenID Connect or LDAP</li> <li>Native support for GitOps with ArgoCD</li> </ul>"},{"location":"about/introduction/#video-introduction","title":"Video Introduction","text":"<p>      Our presentation from Kubeflow Summit 2023, where we introduced deployKF to the community. </p>"},{"location":"about/introduction/#user-stories","title":"User Stories","text":"<p>We are always excited to see how and where deployKF is being used!</p> <p>Here are some stories of deployKF being used in the wild:</p> Organization Article / Video  Cloudflare A look inside the Cloudflare ML Ops platform Your Organization here! Join <code>ADOPTERS.md</code> List // Contact Us"},{"location":"about/introduction/#use-deploykf","title":"Use deployKF","text":"<p>Now that you know what deployKF is, you can get started with the following guides:</p> <p>Full Deployment Try Locally</p>"},{"location":"about/introduction/#support-the-project","title":"Support the Project","text":"<p>deployKF is a new and growing project. If you like what we are doing, please help others discover us by sharing the project with your colleagues and/or the wider community.</p> <p>We greatly appreciate GitHub Stars  on the <code>deployKF/deployKF</code> repository:</p> <p> </p>"},{"location":"about/introduction/#other-resources","title":"Other Resources","text":""},{"location":"about/introduction/#community","title":"Community","text":"<p>The deployKF community has a Slack server for informal discussions among users and contributors:</p> <p>Join the Slack</p>"},{"location":"about/introduction/#support","title":"Support","text":"<p>Both commercial and open-source support is available for deployKF.</p> <p> Commercial Support  Open-Source Support</p>"},{"location":"about/introduction/#history-of-deploykf","title":"History of deployKF","text":"<p>deployKF was originally created and is maintained by Mathew Wicks (GitHub: @thesuperzapper), a Kubeflow lead and maintainer of the popular Apache Airflow Helm Chart. deployKF is a community-led project that welcomes contributions from anyone who wants to help.</p>"},{"location":"about/kubeflow-vs-deploykf/","title":"Kubeflow vs deployKF","text":"<p>Understand the differences between Kubeflow and deployKF.</p>"},{"location":"about/kubeflow-vs-deploykf/#introduction","title":"Introduction","text":"<p>Kubeflow and deployKF are different but related projects. By using deployKF, you get everything that Kubeflow offers, plus a lot more.</p> <p>Before we dive into the differences, let's define each project:</p> Project What is it? deployKF A tool for building Data and Machine Learning platforms on Kubernetes. Kubeflow A CNCF project to develop MLOps tools that run on Kubernetes. Kubeflow Manifests A collection of Kustomize manifests provided by the Kubeflow project. <p>Migrate to deployKF</p> <p>When you're ready to start migrating from vanilla Kubeflow to deployKF, check out our migration guide:</p> <p>Migrate from   Kubeflow Distributions</p>"},{"location":"about/kubeflow-vs-deploykf/#deploykf-vs-kubeflow-manifests","title":"deployKF vs Kubeflow Manifests","text":"<p>deployKF and Kubeflow Manifests are both used to deploy Kubeflow. However, they are designed for different purposes and have different features.</p>  deployKF  Kubeflow Manifests Purpose Enable organizations to build their Data and ML Platforms on Kubernetes. To be used as a base for packaged Kubeflow distributions by vendors. Key Feature A centralized config system to manage all aspects of the platform, very similar to Helm Chart values. A collection of Kustomize manifests requiring significant manual patching to use in production."},{"location":"about/kubeflow-vs-deploykf/#area-ease-of-use","title":"Area: Ease of Use","text":"Feature  deployKF  Kubeflow ManifestsEasy Configuration Configured with centralized values. Manual patching of Kustomize manifests.Easy Upgrades In-place upgrades are supported.Bring values forward to new versions. Must start from scratch with each new version.Easy Uninstall Straightforward uninstall process. No built-in uninstall process."},{"location":"about/kubeflow-vs-deploykf/#area-tools-and-ecosystem","title":"Area: Tools and Ecosystem","text":"Feature  deployKF  Kubeflow ManifestsKubeflow Ecosystem Optionally included. Included.Argo Server(Web interface of Argo Workflows) Optionally included.Integrated with single sign-on.User access is aligned to profile memberships. Not included.MinIO Console(Web interface of MinIO) Optionally included.Integrated with single sign-on.User access is aligned to profile memberships. Not included."},{"location":"about/kubeflow-vs-deploykf/#area-flexibility-and-customization","title":"Area: Flexibility and Customization","text":"Feature  deployKF  Kubeflow ManifestsSelectively Enable Tools Each tool has as single <code>enabled</code> value. Requires manual patching of Kustomize manifests.Use Existing Cluster Dependencies Easily use existing cluster dependencies.Connect your existing Istio.Connect your existing cert-manager.Connect your existing Kyverno. Requires manual patching of Kustomize manifests.Connect to Identity Providers Easily connect any identity provider.Connect via OpenID Connect or LDAP. Requires manual patching of Kustomize manifests.Connect to External Services Easily connect external services.Connect external S3 / Object Store.Connect external MySQL. Requires manual patching of Kustomize manifests."},{"location":"about/kubeflow-vs-deploykf/#area-special-features","title":"Area: Special Features","text":"Feature  deployKF  Kubeflow ManifestsArgoCD Support(GitOps) Native support for GitOps with ArgoCD. No built-in support for ArgoCD.Automatic Restarts(Config and Secret Changes) When a config or secret is changed, any affected components are automatically restarted using Kyverno. Manual pod restarts are required.Declarative Profiles(Users and team access) Profiles are defined via values.Easily assign multiple users to a profile. Profiles are manually created.Browser Login Flow(Kubeflow Pipelines) Users can authenticate the Kubeflow Pipelines SDK from off-cluster, using a web browser. Not supported."},{"location":"about/kubeflow-vs-deploykf/#area-security","title":"Area: Security","text":"Feature  deployKF  Kubeflow ManifestsRandom Secrets Secrets are randomly generated at install time. Secrets are hardcoded in manifests.Hardened Kubeflow Pipelines Object Store access keys are isolated to each profile and scoped to the minimum required permissions. All access keys are randomly generated. Object Store access keys are shared across all profiles. Access keys are not randomly generated.Hardened Istio Easy to update Istio.Uses distroless images.Additional security patches. Istio is difficult to update.Standard images.Standard Auth Tools Uses standard tools including Envoy (via Istio), oauth2-proxy, and dex. Uses non-standard <code>arrikto/oidc-authservice</code> and often outdated dex.HTTPS by Default HTTPS is enabled by default. HTTPS is NOT enabled by default."},{"location":"about/kubeflow-vs-deploykf/#next-steps","title":"Next Steps","text":"<ul> <li>If you're ready to start migrating from Kubeflow to deployKF, check out the Migrate from Kubeflow Distributions guide.</li> </ul>"},{"location":"about/support/","title":"Get Support","text":"<p>Learn how to get support for deployKF. See options for commercial support, open-source support, reporting a bug, or requesting a feature.</p>"},{"location":"about/support/#commercial-support","title":"Commercial Support","text":"<p>Commercial support is available for deployKF.</p> <p>Please connect with  Aranui Solutions, the company started by the creators of deployKF:</p> <p> Email our Team  Visit our Website</p>"},{"location":"about/support/#open-source-support","title":"Open-Source Support","text":"<p>We provide best-effort support to open-source users of deployKF through the following channels:</p> <ol> <li>Post a message on the Slack</li> <li>Start a GitHub Discussion</li> <li>Start a thread on the Users Mailing List</li> </ol>"},{"location":"about/support/#bugs-and-feature-requests","title":"Bugs and Feature Requests","text":"<p>We welcome your feedback!</p> <p>To report a bug or request a feature, please raise an issue on the relevant deployKF repository:</p> Component Repository Issues deployKF <code>deployKF/deployKF</code>  Issues deployKF CLI <code>deployKF/cli</code>  Issues deployKF Website <code>deployKF/website</code>  Issues"},{"location":"guides/cluster-dependencies/","title":"Cluster Dependencies","text":"<p>Learn about the cluster dependencies of deployKF and how to configure them.</p>"},{"location":"guides/cluster-dependencies/#overview","title":"Overview","text":"<p>deployKF has \"cluster dependencies\" which are required to run the platform. In this case \"cluster\" means Kubernetes applications or services (e.g. istio, cert-manager).</p> <p>Existing Versions</p> <p>By default, all cluster dependencies are installed as part of deployKF. However, you may use existing versions of these dependencies, if you already have them installed.</p>"},{"location":"guides/cluster-dependencies/#cluster-dependency-guides","title":"Cluster Dependency Guides","text":"<p>The following table lists the cluster dependencies, and how to use an existing version:</p> Dependency Purpose in deployKF Use Existing Version Argo CD Used to deploy and manage the lifecycle of the platform. Required Cert-Manager Generating and maintaining TLS/HTTPS certificates. Optional Istio Network service mesh for the platform, used to enforce client authentication and secure internal traffic. Optional Kyverno Mutating resources, replicating secrets across namespaces, and restarting Pods when configs change. Optional(coming soon)"},{"location":"guides/configs/","title":"Configuration","text":"<p>Learn how to configure deployKF to meet your organization's needs.</p>"},{"location":"guides/configs/#overview","title":"Overview","text":"<p>deployKF is incredibly configurable via its centralized values system, which allows you to define all aspects of the platform in a single YAML file (or multiple, if you prefer).</p>"},{"location":"guides/configs/#configuration-guides","title":"Configuration Guides","text":"<p>To help you get started with common configuration tasks, we have created the following guides.</p>"},{"location":"guides/configs/#platform-configuration-guides","title":"Platform Configuration Guides","text":"<p>The following guides help you configure the deployKF platform itself, including user authentication, authorization, and branding.</p> Guide(Click for Details) Description User Authentication and External Identity Providers Integrate with an existing user authentication system (GitHub, Google, Okta, etc.) or define static user accounts. User Authorization and Profile Management Define profiles (namespaces) and assign users to them. Expose Gateway and configure HTTPS Expose the deployKF gateway with a LoadBalancer or Ingress, and configure valid HTTPS certificates. Customize the Dashboard Customize the deployKF dashboard with your own branding and links. Image Pull Secrets Configure image pull secrets, avoid Docker Hub rate limits, or use a private container registry. Air-Gapped Clusters and Private Registries Use deployKF in air-gapped environments, private container registries, and private Helm repositories."},{"location":"guides/configs/#tool-configuration-guides","title":"Tool Configuration Guides","text":"<p>The following guides help you configure the ML &amp; Data tools which are part of the deployKF platform.</p> Guide(Click for Details) Description Configure Kubeflow Notebooks Configure Kubeflow Notebooks with custom server images and compute resources (including GPUs)."},{"location":"guides/deploykf-cli/","title":"Install deployKF CLI","text":"<p>Learn how to install the deployKF CLI (command line interface).</p>"},{"location":"guides/deploykf-cli/#about-the-cli","title":"About the CLI","text":"<p>The deployKF CLI is used to generate GitOps-ready Kubernetes manifests from one or more values files. This example generates manifests under the <code>./GENERATOR_OUTPUT</code> directory from the <code>0.1.5</code> source version with the values specified in the <code>./custom-values.yaml</code> file.</p> <pre><code>deploykf generate \\\n  --source-version \"0.1.5\" \\\n  --values ./custom-values.yaml \\\n  --output-dir ./GENERATOR_OUTPUT\n</code></pre> <p>Source Version</p> <p>The <code>--source-version</code> is a tagged release of the deployKF generator, without the \"v\" prefix.</p> <p>The version of the CLI does NOT need to match the <code>--source-version</code>.  If a breaking change is ever needed, the CLI will fail to generate with newer source versions, and will print message telling you to upgrade the CLI.</p> <p>deployKF ArgoCD Plugin</p> <p>If you are using the deployKF ArgoCD Plugin, it is NOT necessary to install the deployKF CLI, this is because the manifests generation will happen inside the ArgoCD plugin, rather than on your local machine.</p>"},{"location":"guides/deploykf-cli/#install-the-cli","title":"Install the CLI","text":"<p>You can install the CLI on your local machine by following the instructions below that are appropriate for your operating system.</p> <p>Latest Version</p> <p>You can find the latest version of the CLI on the GitHub releases page, which is currently <code>v0.1.2</code>.</p> macOSLinuxWindows <p>macOS Security</p> <p>macOS has security features that will prevent you running the CLI if you downloaded it via a web browser. However, if you download it from the command line (for example, using <code>curl</code> or <code>wget</code>) it should be allowed to run.</p> <p>Either way, if you encounter a \"this app is from an unidentified developer\" error you can go to <code>System Preferences &gt; Privacy &amp; Security</code> and click <code>Open Anyway</code> to allow the CLI to run.</p> <p>The following commands will download the CLI for macOS and place it in <code>/usr/local/bin</code>:</p> <pre><code>DKF_CLI_VERSION=\"0.1.2\"\nDKF_CLI_ARCH=$(uname -m | sed -e 's/x86_64/amd64/')\nDFK_CLI_DEST=/usr/local/bin/deploykf\n\n# download the binary\nsudo curl -fL \"https://github.com/deploykf/cli/releases/download/v${DKF_CLI_VERSION}/deploykf-darwin-${DKF_CLI_ARCH}\" -o \"${DFK_CLI_DEST}\"\n\n# make the binary executable\nsudo chmod +x \"${DFK_CLI_DEST}\"\n\n# test the binary\ndeploykf version\n</code></pre> <p>Alternatively, you can manually download the latest <code>deploykf-darwin-{ARCH}</code> binary from the <code>v0.1.2</code> GitHub Release and place it in a directory on your <code>PATH</code> environment variable.</p> <p>Apple Silicon</p> <p>If you have a Mac with an Apple Silicon processor (M1, M2, etc), you will need to download the <code>deploykf-darwin-arm64</code> binary. If you have a Mac with an Intel processor, you will need to download the <code>deploykf-darwin-amd64</code> binary.</p> <p>The following commands will download the CLI for Linux and place it in <code>/usr/local/bin</code>:</p> <pre><code>DKF_CLI_VERSION=\"0.1.2\"\nDKF_CLI_ARCH=$(uname -m | sed -e 's/x86_64/amd64/' -e 's/aarch64/arm64/')\nDFK_CLI_DEST=/usr/local/bin/deploykf\n\n# download the binary\nsudo curl -fL \"https://github.com/deploykf/cli/releases/download/v${DKF_CLI_VERSION}/deploykf-linux-${DKF_CLI_ARCH}\" -o \"${DFK_CLI_DEST}\"\n\n# make the binary executable\nsudo chmod +x \"${DFK_CLI_DEST}\"\n\n# test the binary\ndeploykf version\n</code></pre> <p>Alternatively, you can manually download the latest <code>deploykf-linux-{ARCH}</code> binary from the <code>v0.1.2</code> GitHub Release and place it in a directory on your <code>PATH</code> environment variable.</p> <p>Processor Architecture</p> <p>If you are using a Linux machine with an ARM64 processor, you will need to download the <code>deploykf-linux-arm64</code> binary. If you are using a Linux machine with an X86/AMD64 processor, you will need to download the <code>deploykf-linux-amd64</code> binary.</p> <p>Elevated PowerShell Prompt</p> <p>You will need to run the following commands in an elevated PowerShell prompt (right-click and select <code>Run as administrator</code>).</p> <p>Windows Security</p> <p>Windows has security features that may prevent you from running the CLI. If you encounter a \"Windows protected your PC\" error you can click <code>More info</code> and then <code>Run anyway</code> to allow the CLI to run.</p> <p>The following PowerShell commands will download the CLI for Windows and place it in <code>C:\\Windows\\System32</code>:</p> <pre><code>$DKF_CLI_VERSION=\"0.1.2\"\n$DFK_CLI_DEST=\"C:\\Windows\\System32\\deploykf.exe\"\n\n# download the binary\nInvoke-WebRequest -Uri \"https://github.com/deploykf/cli/releases/download/v${DKF_CLI_VERSION}/deploykf-windows-amd64.exe\" -OutFile \"${DFK_CLI_DEST}\"\n\n# test the binary\ndeploykf version\n</code></pre> <p>Alternatively, you can manually download the latest <code>deploykf-windows-amd64.exe</code> binary from the <code>v0.1.2</code> GitHub Release and place it in a directory on your <code>PATH</code> environment variable.</p>"},{"location":"guides/external-dependencies/","title":"External Dependencies","text":"<p>Learn about the external dependencies of deployKF and how to configure them.</p>"},{"location":"guides/external-dependencies/#overview","title":"Overview","text":"<p>deployKF has \"external dependencies\" which are required to run the platform. In this case \"external\" means non-Kubernetes applications or services (e.g. databases, object stores).</p> <p>External Versions</p> <p>By default, we deploy embedded (on-cluster) versions of the external dependencies so that you can get started quickly. However, we recommend connecting to external versions for better performance and reliability.</p>"},{"location":"guides/external-dependencies/#external-dependency-guides","title":"External Dependency Guides","text":"<p>The following table lists the external dependencies, and how to use an existing version:</p> Dependencies Purpose in deployKF Use External Version MySQL Persisting state in Kubeflow Pipelines and Katib. Optional recommended  Object Store(S3-compatible) Storing pipelines and their results in Kubeflow Pipelines. Optional recommended"},{"location":"guides/getting-started/","title":"Getting Started","text":"<p>Learn how to use deployKF in production.  Easily deploy the best of Kubeflow and other MLOps tools as a complete platform!</p>","boost":2},{"location":"guides/getting-started/#introduction","title":"Introduction","text":"<p>This page is about using deployKF in production. We will cover requirements, configuration, the deployment process, and basic usage of the platform.</p> <p>We suggest new users start with the introduction and local quickstart pages.</p> <p>About deployKF(Introduction) Local Quickstart(Try Locally)</p> <p>For existing Kubeflow users, we have a migration guide.</p> <p>Migrate from   Kubeflow Distributions</p> <p>We encourage everyone to join our community and learn how to get support!</p> <p> Join the Community  Get Support</p>","boost":2},{"location":"guides/getting-started/#1-requirements","title":"1. Requirements","text":"<p>Please ensure you meet the following requirements before using deployKF in production.</p>","boost":2},{"location":"guides/getting-started/#kubernetes-cluster","title":"Kubernetes Cluster","text":"<p>deployKF can run on any   Kubernetes cluster, in any cloud or environment. See the version matrix for a list of supported Kubernetes versions.</p> <p>For example, deployKF can run on the following Kubernetes distributions:</p> Target Platform Kubernetes Distribution Amazon Web Services Amazon Elastic Kubernetes Service (EKS) Microsoft Azure Azure Kubernetes Service (AKS) see special requirements Google Cloud Google Kubernetes Engine (GKE) IBM Cloud IBM Cloud Kubernetes Service (IKS) Self-Hosted Rancher (RKE) // kOps // Kubespray // kubeadm Edge k3s // k0s // MicroK8s Local Machine k3d // Kind // Minikube <p>Dedicated Cluster</p> <p>We strongly recommend using a dedicated cluster for deployKF. This is because deployKF has a number of cluster-level dependencies which may conflict with other applications.</p> <p>If you are unable to create a new Kubernetes cluster, you may consider using vCluster to create a virtual Kubernetes cluster within an existing one.</p>","boost":2},{"location":"guides/getting-started/#argo-cd-dependency","title":"Argo CD Dependency","text":"<p>deployKF requires   Argo CD for managing the platform.</p> <p>You may either use deployKF with an existing ArgoCD, or deploy a new one (if you don't already have it), both options are covered later in this guide.</p> Can I use &lt;other tool&gt; instead of Argo CD? <p>Not yet.</p> <p>While we believe that Argo CD is currently the best in its category, we recognize that it's not the only option. In the future, we may support other Kubernetes GitOps tools (like Flux CD), or even build a deployKF-specific solution.</p> <p>deployKF will make your MLOps life so much easier, that it's still worth using, even if you don't already love Argo CD. If you want, you can largely treat Argo CD as a \"black box\" and just use the provided sync scripts to manage the platform.</p> <p>To learn more about this decision, and participate in the discussion, see <code>deployKF/deployKF#110</code>.</p>","boost":2},{"location":"guides/getting-started/#kubernetes-requirements","title":"Kubernetes Requirements","text":"<p>Your Kubernetes cluster must meet the following requirements:</p> Configuration Requirement Notes Node Resources The nodes must collectively have at least <code>4 vCPUs</code> and <code>16 GB RAM</code>, and <code>64 GB Storage</code>. CPU Architecture The cluster must have  <code>x86_64</code> CPU Nodes. ARM64 Support Internet Access The cluster must have internet access for pulling images and installing dependencies. Offline Clusters Cluster Domain The <code>clusterDomain</code> of your kubelet must be <code>\"cluster.local\"</code>. Service Type By default, the cluster must have a <code>LoadBalancer</code> service type. Override Service Type Default StorageClass The default <code>StorageClass</code> must support the <code>ReadWriteOnce</code> access mode. Override StorageClass Existing Argo Workflows The cluster must NOT already have Argo Workflows installed. Note, other Argo tools like Argo CD are fine. Join the discussion: <code>deployKF#116</code> ARM64 Support Offline Clusters Override Service Type Override StorageClass","boost":2},{"location":"guides/getting-started/#arm64-support","title":"ARM64 Support","text":"<p>Currently, deployKF only supports <code>x86_64</code> architecture clusters.</p> <p>The next minor version of deployKF (<code>v0.2.0</code>) should have native <code>ARM64</code> for all core components. However, some upstream apps like Kubeflow Pipelines will need extra work to be production ready (<code>#10309</code>, <code>#10308</code>).</p>","boost":2},{"location":"guides/getting-started/#offline-clusters","title":"Offline Clusters","text":"<p>deployKF can be used in offline and air-gapped clusters, but there are additional steps required.</p> <p>Please see the Air-Gapped Clusters guide for more information.</p>","boost":2},{"location":"guides/getting-started/#override-service-type","title":"Override Service Type","text":"<p>By default, deployKF uses a <code>LoadBalancer</code> service type for the gateway.</p> <p>For real-world usage, you should review the Expose the Gateway Service guide.</p> <p>In some clusters, the <code>LoadBalancer</code> service type will create a public IP address. Consider the security implications before deploying, or use a different service type.</p> <p>If you do not want this, you may override the service type to <code>ClusterIP</code> by setting the following value:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n    gatewayService:\n      type: \"ClusterIP\"\n</code></pre>","boost":2},{"location":"guides/getting-started/#override-storageclass","title":"Override StorageClass","text":"<p>By default, deployKF requires a default StorageClass that supports the <code>ReadWriteOnce</code> access mode.</p> <p>If you do NOT have a compatible default StorageClass, you might consider the following options:</p> <ol> <li>Configure a default StorageClass that has <code>ReadWriteOnce</code> support</li> <li>Explicitly set the <code>storageClass</code> value for the following components:<ul> <li><code>deploykf_opt.deploykf_minio.persistence.storageClass</code></li> <li><code>deploykf_opt.deploykf_mysql.persistence.storageClass</code></li> </ul> </li> <li>Disable components which require the StorageClass, and use external alternatives:<ul> <li>Connect an External Object Store</li> <li>Connect an External MySQL</li> </ul> </li> </ol>","boost":2},{"location":"guides/getting-started/#linux-node-requirements","title":"Linux Node Requirements","text":"<p>If you are self-hosting your Kubernetes cluster, you must ensure that your Linux nodes meet the following requirements:</p> Configuration Requirement Notes Inotify Limits Linux nodes must have sufficient <code>inotify</code> limits. Note, common distributions like Ubuntu do not ship with sufficient defaults. Increase Inotify Limits Kernel Modules Linux nodes must have the required kernel modules for Istio. Istio Kernel Modules Increase Inotify Limits Istio Kernel Modules","boost":2},{"location":"guides/getting-started/#increase-inotify-limits","title":"Increase Inotify Limits","text":"<p>You may need to increase the <code>fs.inotify.max_user_*</code> sysctl values on your nodes (only for Linux nodes). Otherwise, you may encounter Pod crashes with an error message like this:</p> <p><code>too many open files</code></p> <p>This error has been discussed in the upstream Kubeflow repo (<code>kubeflow/manifests#2087</code>), to resolve it, you will need to increase your system's open/watched file limits:</p> <ol> <li> <p>Modify <code>/etc/sysctl.conf</code> to include the following lines:</p> <pre><code>fs.inotify.max_user_instances = 1280\nfs.inotify.max_user_watches = 655360\n</code></pre> </li> <li> <p>Now, apply immediately the changes with the following command:</p> <pre><code>sudo sysctl -p\n</code></pre> </li> </ol>","boost":2},{"location":"guides/getting-started/#istio-kernel-modules","title":"Istio Kernel Modules","text":"<p>Your nodes must have the required kernel modules for Istio. Otherwise, you may encounter crashes in the Istio sidecars or other strange network behaviour.</p> <ol> <li> <p>Get a list of the currently loaded kernel modules by running <code>lsmod</code>:</p> <pre><code>lsmod | awk '{print $1}' | sort\n</code></pre> </li> <li> <p>At the time of writing, the following command will enable the required kernel modules on boot:</p> <pre><code>## NOTE: if you are using Istio ambient mode, there are additional modules required\ncat &lt;&lt;EOF | sudo tee /etc/modules-load.d/99-istio-modules.conf\nbr_netfilter\nip_tables\niptable_filter\niptable_mangle\niptable_nat\niptable_raw\nnf_nat\nx_tables\nxt_REDIRECT\nxt_conntrack\nxt_multiport\nxt_owner\nxt_tcpudp\nEOF\n</code></pre> </li> <li> <p>Now, either reboot your nodes or immediately load the modules with the following commands (which will also indicate if any modules are missing):</p> <pre><code>sudo modprobe br_netfilter\nsudo modprobe ip_tables\nsudo modprobe iptable_filter\nsudo modprobe iptable_mangle\nsudo modprobe iptable_nat\nsudo modprobe iptable_raw\nsudo modprobe nf_nat\nsudo modprobe x_tables\nsudo modprobe xt_REDIRECT\nsudo modprobe xt_conntrack\nsudo modprobe xt_multiport\nsudo modprobe xt_owner\nsudo modprobe xt_tcpudp\n</code></pre> </li> </ol>","boost":2},{"location":"guides/getting-started/#2-platform-configuration","title":"2. Platform Configuration","text":"<p>deployKF is very configurable, you can use it to deploy a wide variety of machine learning platforms and integrate with your existing infrastructure.</p>","boost":2},{"location":"guides/getting-started/#deploykf-values","title":"deployKF Values","text":"<p>All aspects of your deployKF platform are configured with YAML-based configs named \"values\". See the values page for more information.</p>","boost":2},{"location":"guides/getting-started/#deploykf-versions","title":"deployKF Versions","text":"<p>The \"version\" of your platform is the version of the generator package you are using. For information about upgrading, see the upgrade guide and changelog.</p> Can I be notified of new releases? <p>Yes. Watch the <code>deployKF/deployKF</code> repo on GitHub.  At the top right, click <code>Watch</code> \u2192 <code>Custom</code> \u2192 <code>Releases</code> then confirm by selecting <code>Apply</code>.</p>","boost":2},{"location":"guides/getting-started/#cluster-dependencies","title":"Cluster Dependencies","text":"<p>deployKF has a number of cluster dependencies including Istio, cert-manager, and Kyverno. See the cluster dependencies page for an overview.</p> <p>Existing Cluster Dependencies</p> <p>deployKF installs its own versions of the cluster dependencies by default.  If you have existing versions on the cluster, you MUST configure deployKF to use them:</p> <ul> <li>Use Existing Istio</li> <li>Use Existing cert-manager</li> <li>Use Existing Kyverno (coming soon)</li> </ul>","boost":2},{"location":"guides/getting-started/#external-dependencies","title":"External Dependencies","text":"<p>deployKF has a number of external dependencies including MySQL and an Object Store. See the external dependencies page for an overview.</p> <p>Connect External Dependencies</p> <p>deployKF includes embedded versions of MySQL and MinIO for development and testing.  We strongly recommend connecting external versions for production use:</p> <ul> <li>Connect External MySQL</li> <li>Connect External Object Store</li> </ul>","boost":2},{"location":"guides/getting-started/#3-deploy-the-platform","title":"3. Deploy the Platform","text":"","boost":2},{"location":"guides/getting-started/#create-argocd-applications","title":"Create ArgoCD Applications","text":"<p>deployKF uses ArgoCD to manage the deployment of the platform. The process to create the ArgoCD <code>Applications</code> will depend on which mode of operation you have chosen.</p>  ArgoCD Plugin Mode Manifests Repo Mode Step 1 - Prepare ArgoCD <p>You will need to have ArgoCD deployed on your cluster, this ArgoCD instance must have the deployKF ArgoCD Plugin installed. Follow the appropriate guide for your situation:</p> <ul> <li>New ArgoCD</li> <li>Existing ArgoCD (Deployed with Helm)</li> <li>Existing ArgoCD (Deployed with Kustomize)</li> </ul> <p>Tips</p> <ul> <li>If you use the ArgoCD \"management cluster\" pattern, please see: Off-Cluster ArgoCD</li> <li>If you have an offline cluster, please see: Air-Gapped Clusters</li> </ul> Step 2 - Learn about Values <p>deployKF is configured by centralized values which define the desired state of the platform.</p> <p>Sample Values:</p> <p>Each version of deployKF has sample values with all ML &amp; Data tools enabled, along with some sensible security defaults. We recommend using the sample values as a starting point for your custom values.</p> <p>Here are the <code>sample-values.yaml</code> for deployKF <code>0.1.5</code>.</p> <p>Custom Values:</p> <p>In ArgoCD Plugin Mode, values can be defined inline (<code>values</code>), or from a  git repository (<code>values_files</code>).</p> <p>Both methods may be used together. When a value is defined in multiple places, the result is calculated by merging, with files listed later taking precedence, and inline values having the highest precedence.</p> <p>Tip</p> <p>Learn about common configuration tasks in the  Configure deployKF  guide.</p> Step 3 - Define an App-of-Apps <p>Create a local file named <code>deploykf-app-of-apps.yaml</code> with the contents of the YAML below.</p> <p>In this example, we will define an app-of-apps that:</p> <ul> <li>Clones the <code>deploykf/deploykf</code> repo at the <code>v0.1.5</code> tag.</li> <li>Sets the <code>source_version</code> parameter to use deployKF version <code>0.1.5</code>.</li> <li>Sets the <code>values_files</code> parameter to read the <code>sample-values.yaml</code> from the repo.</li> <li>Sets the <code>values</code> parameter with inline values that override the <code>sample-values.yaml</code>.</li> </ul> What is an App-of-Apps? <p>An app-of-apps is a special ArgoCD <code>Application</code> which manages other applications.</p> Can I read values from my own repo? <p>Yes. In this example, we only use the <code>deploykf/deploykf</code> repo to easily read the default <code>sample-values.yaml</code> file. See Step 4 to read values from a different repo.</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: deploykf-app-of-apps\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: deploykf-app-of-apps\n    app.kubernetes.io/part-of: deploykf\nspec:\n\n  ## NOTE: if not \"default\", you MUST ALSO set the `argocd.project` value\n  project: \"default\"\n\n  source:\n    ## source git repo configuration\n    ##  - we use the 'deploykf/deploykf' repo so we can read its 'sample-values.yaml'\n    ##    file, but you may use any repo (even one with no files)\n    ##\n    repoURL: \"https://github.com/deployKF/deployKF.git\"\n    targetRevision: \"v0.1.5\"\n    path: \".\"\n\n    ## plugin configuration\n    ##\n    plugin:\n      name: \"deploykf\"\n      parameters:\n\n        ## the deployKF generator version\n        ##  - available versions: https://github.com/deployKF/deployKF/releases\n        ##\n        - name: \"source_version\"\n          string: \"0.1.5\"\n\n        ## paths to values files within the `repoURL` repository\n        ##  - the values in these files are merged, with later files taking precedence\n        ##  - we strongly recommend using 'sample-values.yaml' as the base of your values\n        ##    so you can easily upgrade to newer versions of deployKF\n        ##\n        - name: \"values_files\"\n          array:\n            - \"./sample-values.yaml\"\n\n        ## a string containing the contents of a values file\n        ##  - this parameter allows defining values without needing to create a file in the repo\n        ##  - these values are merged with higher precedence than those defined in `values_files`\n        ##\n        - name: \"values\"\n          string: |\n            ##\n            ## This demonstrates how you might structure overrides for the 'sample-values.yaml' file.\n            ## For a more comprehensive example, see the 'sample-values-overrides.yaml' in the main repo.\n            ##\n            ## Notes:\n            ##  - YAML maps are RECURSIVELY merged across values files\n            ##  - YAML lists are REPLACED in their entirety across values files\n            ##  - Do NOT include empty/null sections, as this will remove ALL values from that section.\n            ##    To include a section without overriding any values, set it to an empty map: `{}`\n            ##\n\n            ## --------------------------------------------------------------------------------\n            ##                                      argocd\n            ## --------------------------------------------------------------------------------\n            argocd:\n              namespace: argocd\n              project: default\n\n            ## --------------------------------------------------------------------------------\n            ##                                    kubernetes\n            ## --------------------------------------------------------------------------------\n            kubernetes:\n              {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                              deploykf-dependencies\n            ## --------------------------------------------------------------------------------\n            deploykf_dependencies:\n\n              ## --------------------------------------\n              ##             cert-manager\n              ## --------------------------------------\n              cert_manager:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##                 istio\n              ## --------------------------------------\n              istio:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##                kyverno\n              ## --------------------------------------\n              kyverno:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                  deploykf-core\n            ## --------------------------------------------------------------------------------\n            deploykf_core:\n\n              ## --------------------------------------\n              ##             deploykf-auth\n              ## --------------------------------------\n              deploykf_auth:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##        deploykf-istio-gateway\n              ## --------------------------------------\n              deploykf_istio_gateway:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##      deploykf-profiles-generator\n              ## --------------------------------------\n              deploykf_profiles_generator:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                   deploykf-opt\n            ## --------------------------------------------------------------------------------\n            deploykf_opt:\n\n              ## --------------------------------------\n              ##            deploykf-minio\n              ## --------------------------------------\n              deploykf_minio:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##            deploykf-mysql\n              ## --------------------------------------\n              deploykf_mysql:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                  kubeflow-tools\n            ## --------------------------------------------------------------------------------\n            kubeflow_tools:\n\n              ## --------------------------------------\n              ##                 katib\n              ## --------------------------------------\n              katib:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##               notebooks\n              ## --------------------------------------\n              notebooks:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##               pipelines\n              ## --------------------------------------\n              pipelines:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  destination:\n    server: \"https://kubernetes.default.svc\"\n    namespace: \"argocd\"\n</code></pre> Step 4 - Read Values from Git (optional) <p>You may use the <code>values_files</code> parameter to read values from a git repo. This lets you version your values files in git, and easily update them without changing the app-of-apps resource.</p> <p>Danger</p> <p>We STRONGLY RECOMMEND using a PRIVATE repo for your values files!</p> <p>If your git repo is private, you must configure ArgoCD with credentials to access the repo. For example, when using a GitHub repo, you might create a Secret with a Personal Access Token (PAT) as follows:</p> <pre><code># create a secret with your GitHub credentials\n# NOTE: kubectl can't create and label a secret in one command, so we use a pipe\nkubectl create secret generic --dry-run=client -o yaml \\\n    \"argocd-repository--MY_GITHUB_REPO\" \\\n    --namespace \"argocd\" \\\n    --from-literal=type=\"git\" \\\n    --from-literal=url=\"https://github.com/MY_GITHUB_ORG/MY_GITHUB_REPO.git\" \\\n    --from-literal=username=\"MY_GITHUB_USERNAME\" \\\n    --from-literal=password=\"MY_GITHUB_PAT\" \\\n  | kubectl label --local --dry-run=client -o yaml -f - \\\n    \"argocd.argoproj.io/secret-type\"=\"repository\" \\\n  | kubectl apply -f -\n</code></pre> <p>If you use the upstream <code>sample-values.yaml</code> as a base, you will also need to push that file to your repo.</p> <p>The following command will download the <code>sample-values.yaml</code> file for deployKF <code>0.1.5</code>:</p> <pre><code># download the `sample-values.yaml` file\ncurl -fL -o \"sample-values-0.1.5.yaml\" \\\n  \"https://raw.githubusercontent.com/deployKF/deployKF/v0.1.5/sample-values.yaml\"\n</code></pre> <p>For example, say you now have the following files in your repo:</p> <ul> <li><code>sample-values-0.1.5.yaml</code></li> <li><code>values-1.yaml</code></li> <li><code>values-2.yaml</code></li> </ul> <p>Your app-of-apps resource may then be updated to look like this:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: deploykf-app-of-apps\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: deploykf-app-of-apps\n    app.kubernetes.io/part-of: deploykf\nspec:\n  project: \"default\"\n  source:\n\n    ## source git repo configuration\n    ##\n    repoURL: \"https://github.com/MY_GITHUB_ORG/MY_GITHUB_REPO.git\"\n    targetRevision: \"main\"\n    path: \".\"\n\n    ## plugin configuration\n    ##\n    plugin:\n      name: \"deploykf\"\n      parameters:\n\n        ## the deployKF generator version\n        ##\n        - name: \"source_version\"\n          string: \"0.1.5\"\n\n        ## paths to values files within the `repoURL` repository\n        ##\n        - name: \"values_files\"\n          array:\n            - \"./sample-values-0.1.5.yaml\"\n            - \"./values-1.yaml\"\n            - \"./values-2.yaml\"\n\n        ## a string containing the contents of a values file\n        ##  - this parameter allows defining values without needing to create a file in the repo\n        ##  - these values are merged with higher precedence than those defined in `values_files`\n        ##\n        #- name: \"values\"\n        #  string: |\n        #    ...\n        #    values file contents\n        #    ...\n\n  destination:\n    server: \"https://kubernetes.default.svc\"\n    namespace: \"argocd\"\n</code></pre> Step 5 - Apply App-of-Apps Resource <p>Apply the <code>deploykf-app-of-apps.yaml</code> file to your cluster with the following command:</p> <pre><code>kubectl apply -f ./deploykf-app-of-apps.yaml\n</code></pre> Step 1 - Prepare ArgoCD <p>If you have not already deployed ArgoCD on your cluster, you will need to do so.  Please see the ArgoCD Getting Started Guide for instructions.</p> <p>TIP: If you use an ArgoCD \"management cluster\" pattern, see the off-cluster ArgoCD guide.</p> Step 2 - Install the deployKF CLI <p>If you have not already installed the <code>deploykf</code> CLI on your local machine, you will need to do so.</p> <p>Please see the CLI Installation Guide for instructions.</p> Step 3 - Prepare a Git Repo <p>You will need to create a git repo to store your generated manifests.</p> <p>Danger</p> <p>We STRONGLY RECOMMEND using a PRIVATE repo for your manifests!</p> <p>If your git repo is private, you must configure ArgoCD with credentials to access the repo. For example, when using a GitHub repo, you might create a Secret with a Personal Access Token (PAT) as follows:</p> <pre><code># create a secret with your GitHub credentials\n# NOTE: kubectl can't create and label a secret in one command, so we use a pipe\nkubectl create secret generic --dry-run=client -o yaml \\\n    \"argocd-repository--MY_GITHUB_REPO\" \\\n    --namespace \"argocd\" \\\n    --from-literal=type=\"git\" \\\n    --from-literal=url=\"https://github.com/MY_GITHUB_ORG/MY_GITHUB_REPO.git\" \\\n    --from-literal=username=\"MY_GITHUB_USERNAME\" \\\n    --from-literal=password=\"MY_GITHUB_PAT\" \\\n  | kubectl label --local --dry-run=client -o yaml -f - \\\n    \"argocd.argoproj.io/secret-type\"=\"repository\" \\\n  | kubectl apply -f -\n</code></pre> Step 4 - Create Values Files <p>deployKF is configured by centralized values which define the desired state of the platform.</p> <p>Sample Values:</p> <p>Each version of deployKF has sample values with all ML &amp; Data tools enabled, along with some sensible security defaults. We recommend using the sample values as a starting point for your custom values.</p> <p>The following command will download the <code>sample-values.yaml</code> file for deployKF <code>0.1.5</code>:</p> <pre><code># download the `sample-values.yaml` file\ncurl -fL -o \"sample-values-0.1.5.yaml\" \\\n  \"https://raw.githubusercontent.com/deployKF/deployKF/v0.1.5/sample-values.yaml\"\n</code></pre> <p>Custom Values:</p> <p>In Manifests Repo Mode, values are passed to the <code>deploykf generate</code> command as YAML files. When a value is defined in multiple files, the result is calculated by merging, with files listed later taking precedence.</p> <p>To make upgrades easier, we recommend using the sample values as a base, and applying custom override files with only the values you want to change. This allows you to swap out the sample values for a newer version in the future.</p> <p>Tip</p> <p>Learn about common configuration tasks in the  Configure deployKF  guide.</p> <p>For example, you might structure your <code>custom-overrides.yaml</code> file like this:</p> <pre><code>##\n## Notes:\n##  - YAML maps are RECURSIVELY merged across values files\n##  - YAML lists are REPLACED in their entirety across values files\n##  - Do NOT include empty/null sections, as this will remove ALL values from that section.\n##    To include a section without overriding any values, set it to an empty map: `{}`\n##\n\n## --------------------------------------------------------------------------------\n##                                      argocd\n## --------------------------------------------------------------------------------\nargocd:\n  namespace: argocd\n  project: default\n\n  source:\n    ## the git repo where you will store your generated manifests\n    ##  - url: the URL of the git repo\n    ##  - revision: the git branch/tag/commit to read from\n    ##  - path: the repo folder path where the generated manifests are stored\n    ##\n    repo:\n      url: \"https://github.com/deployKF/examples.git\"\n      revision: \"main\"\n      path: \"./GENERATOR_OUTPUT/\"\n\n## --------------------------------------------------------------------------------\n##                                    kubernetes\n## --------------------------------------------------------------------------------\nkubernetes:\n  {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n## --------------------------------------------------------------------------------\n##                              deploykf-dependencies\n## --------------------------------------------------------------------------------\ndeploykf_dependencies:\n\n  ## --------------------------------------\n  ##             cert-manager\n  ## --------------------------------------\n  cert_manager:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  ## --------------------------------------\n  ##                 istio\n  ## --------------------------------------\n  istio:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  ## --------------------------------------\n  ##                kyverno\n  ## --------------------------------------\n  kyverno:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n## --------------------------------------------------------------------------------\n##                                  deploykf-core\n## --------------------------------------------------------------------------------\ndeploykf_core:\n\n  ## --------------------------------------\n  ##             deploykf-auth\n  ## --------------------------------------\n  deploykf_auth:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  ## --------------------------------------\n  ##        deploykf-istio-gateway\n  ## --------------------------------------\n  deploykf_istio_gateway:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  ## --------------------------------------\n  ##      deploykf-profiles-generator\n  ## --------------------------------------\n  deploykf_profiles_generator:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n## --------------------------------------------------------------------------------\n##                                   deploykf-opt\n## --------------------------------------------------------------------------------\ndeploykf_opt:\n\n  ## --------------------------------------\n  ##            deploykf-minio\n  ## --------------------------------------\n  deploykf_minio:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  ## --------------------------------------\n  ##            deploykf-mysql\n  ## --------------------------------------\n  deploykf_mysql:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n## --------------------------------------------------------------------------------\n##                                  kubeflow-tools\n## --------------------------------------------------------------------------------\nkubeflow_tools:\n\n  ## --------------------------------------\n  ##                 katib\n  ## --------------------------------------\n  katib:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  ## --------------------------------------\n  ##               notebooks\n  ## --------------------------------------\n  notebooks:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  ## --------------------------------------\n  ##               pipelines\n  ## --------------------------------------\n  pipelines:\n    {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n</code></pre> Step 5 - Generate Manifests <p>The <code>deploykf generate</code> command writes manifests into a folder based on your values. When more than one <code>--values</code> file is provided, they are merged, with later files taking precedence.</p> <p>For example, to generate manifests using deployKF version <code>0.1.5</code> under <code>./GENERATOR_OUTPUT/</code>:</p> <pre><code>deploykf generate \\\n    --source-version \"0.1.5\" \\\n    --values ./sample-values-0.1.5.yaml \\\n    --values ./custom-overrides.yaml \\\n    --output-dir ./GENERATOR_OUTPUT\n</code></pre> <p>Do NOT Edit Manifests Directly</p> <p>In general, you should NOT edit the manifests generated by deployKF. Changes in the <code>--output-dir</code> will be overwritten each time the <code>deploykf generate</code> command runs.</p> <p>If you need to change something which is not configurable via values, please raise an issue so we can understand your use-case and potentially add a new configuration option.</p> Step 6 - Commit Generated Manifests <p>After running <code>deploykf generate</code>, you will need to commit the manifests to your repo, so ArgoCD can apply them to your cluster:</p> <pre><code># for example, to directly commit changes to the 'main' branch of your repo\ngit add GENERATOR_OUTPUT\ngit commit -m \"my commit message\"\ngit push origin main\n</code></pre> Step 7 - Apply App-of-Apps Manifest <p>The only manifest you need to manually apply is the app-of-apps, which creates all the other ArgoCD applications.</p> <p>The <code>app-of-apps.yaml</code> manifest is generated at the root of your <code>--output-dir</code> folder, so you can apply it with:</p> <pre><code>kubectl apply --filename GENERATOR_OUTPUT/app-of-apps.yaml\n</code></pre> Required Values - Azure AKS <p>When deploying on Azure AKS, you MUST set the following values, or the platform will not work correctly:</p> <pre><code>kubernetes:\n  azure:\n    admissionsEnforcerFix: true\n</code></pre> <p>For more information, please see the PR which introduced this value <code>deployKF/deployKF#85</code>.</p>","boost":2},{"location":"guides/getting-started/#sync-argocd-applications","title":"Sync ArgoCD Applications","text":"<p>Now that your deployKF app-of-apps has been applied, you must sync the ArgoCD applications to deploy your platform. Syncing an application will cause ArgoCD to reconcile the actual state in the cluster, to match the state defined by the application resource.</p> <p>Danger</p> <p>DO NOT sync all the <code>Applications</code> at once!!!</p> <p>The deployKF <code>Applications</code> depend on each other, they MUST be synced in the correct order to avoid errors. If you manually sync them all, you may need to uninstall and start over.</p> <p>There are a few ways to sync the applications, you only need to use ONE of them.</p>  Sync: Automated Script Sync: ArgoCD Web UI <p>The recommended way to sync the applications is with the automated script.</p> Step - Run the Sync Script <p>We provide the <code>sync_argocd_apps.sh</code> script to automatically sync the applications that make up deployKF. Learn more about the automated sync script from the <code>scripts</code> folder README .</p> <p>For example, to run the script, you might use the following commands:</p> <pre><code># download the latest version of the script\ncurl -fL -o \"sync_argocd_apps.sh\" \\\n  \"https://raw.githubusercontent.com/deployKF/deployKF/main/scripts/sync_argocd_apps.sh\"\n\n# ensure the script is executable\nchmod +x ./sync_argocd_apps.sh\n\n# ensure your kubectl context is set correctly\nkubectl config current-context\n\n# run the script\nbash ./sync_argocd_apps.sh\n</code></pre> <p>About the sync script</p> <ul> <li>The script can take around 5-10 minutes to run on first install.</li> <li>If the script fails or is interrupted, you can safely re-run it, and it will pick up where it left off.</li> <li>There are a number of configuration variables at the top of the script which change the default behavior.</li> <li>Learn more about the automated sync script from the <code>scripts</code> folder README in the deployKF repo.</li> </ul> <p>Please be aware of the following issue when using the automated sync script:</p> Bug in ArgoCD v2.9 <p>There is a known issue (<code>deploykf/deploykf#70</code>, <code>argoproj/argo-cd#16266</code>) with all <code>2.9.X</code> versions of the ArgoCD CLI that will cause the sync script to fail with the following error:</p> <pre><code>==========================================================================================\nLogging in to ArgoCD...\n==========================================================================================\nFATA[0000] cannot find pod with selector: [app.kubernetes.io/name=] - use the --{component}-name flag in this command or set the environmental variable (Refer to https://argo-cd.readthedocs.io/en/stable/user-guide/environment-variables), to change the Argo CD component name in the CLI\n</code></pre> <p>Please upgrade your <code>argocd</code> CLI to at least version <code>2.10.0</code> to resolve this issue.</p> <p>Alternatively, you can sync the applications using the ArgoCD Web UI.</p> Step 1 - Access ArgoCD Web UI <p>For production usage, you may want to expose ArgoCD with a <code>LoadBalancer</code> or <code>Ingress</code>.</p> <p>For testing, you may use <code>kubectl</code> port-forwarding to expose the ArgoCD Web UI on your local machine:</p> <pre><code>kubectl port-forward --namespace \"argocd\" svc/argocd-server 8090:https\n</code></pre> <p>The ArgoCD Web UI should now be available at the following URL:</p> <p> https://localhost:8090</p> <p>If this is the first time you are using ArgoCD, you will need to retrieve the initial password for the <code>admin</code> user:</p> <pre><code>echo $(kubectl -n argocd get secret/argocd-initial-admin-secret \\\n  -o jsonpath=\"{.data.password}\" | base64 -d)\n</code></pre> <p>Once you log in with the <code>admin</code> user and above password, the Web UI should look like this:</p> <p> </p> Step 2 - Sync Applications <p>You MUST sync the deployKF applications in the correct order. For each application, click the <code>SYNC</code> button, and wait for the application to become \"Healthy\" before syncing the next.</p> <p>The applications are grouped and ordered as follows:</p> <p>Group 0: \"app-of-apps\"</p> <p>First, you must sync the app-of-apps application:</p> <ol> <li><code>deploykf-app-of-apps</code></li> <li><code>deploykf-namespaces</code> (only exists when using off-cluster ArgoCD)</li> </ol> <p>Group 1: \"deploykf-dependencies\"</p> <p>Second, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-dependencies</code>:</p> <ol> <li><code>dkf-dep--cert-manager</code> (may fail on first attempt)</li> <li><code>dkf-dep--istio</code></li> <li><code>dkf-dep--kyverno</code></li> </ol> <p>WARNING: for this group, each application MUST be synced INDIVIDUALLY and the preceding application MUST be \"Healthy\" before syncing the next.</p> <p>Group 2: \"deploykf-core\"</p> <p>Third, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-core</code>:</p> <ol> <li><code>dkf-core--deploykf-istio-gateway</code></li> <li><code>dkf-core--deploykf-auth</code></li> <li><code>dkf-core--deploykf-dashboard</code></li> <li><code>dkf-core--deploykf-profiles-generator</code> (may fail on first attempt)</li> </ol> <p>Group 3: \"deploykf-opt\"</p> <p>Fourth, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-opt</code>:</p> <ul> <li><code>dkf-opt--deploykf-minio</code></li> <li><code>dkf-opt--deploykf-mysql</code></li> </ul> <p>Group 4: \"deploykf-tools\"</p> <p>Fifth, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-tools</code>:</p> <ul> <li>(none yet)</li> </ul> <p>Group 5: \"kubeflow-dependencies\"</p> <p>Sixth, you must sync the applications with the label <code>app.kubernetes.io/component=kubeflow-dependencies</code>:</p> <ul> <li><code>kf-dep--argo-workflows</code></li> </ul> <p>Group 6: \"kubeflow-tools\"</p> <p>Seventh, you must sync the applications with the label <code>app.kubernetes.io/component=kubeflow-tools</code>:</p> <ul> <li><code>kf-tools--katib</code></li> <li><code>kf-tools--notebooks--jupyter-web-app</code></li> <li><code>kf-tools--notebooks--notebook-controller</code></li> <li><code>kf-tools--pipelines</code></li> <li><code>kf-tools--poddefaults-webhook</code></li> <li><code>kf-tools--tensorboards--tensorboard-controller</code></li> <li><code>kf-tools--tensorboards--tensorboards-web-app</code></li> <li><code>kf-tools--training-operator</code></li> <li><code>kf-tools--volumes--volumes-web-app</code></li> </ul>","boost":2},{"location":"guides/getting-started/#4-use-the-platform","title":"4. Use the Platform","text":"<p>Now that you have a working deployKF machine learning platform, here are some things to try out!</p>","boost":2},{"location":"guides/getting-started/#expose-the-deploykf-dashboard","title":"Expose the deployKF Dashboard","text":"<p>The deployKF dashboard is the web-based interface for deployKF, it gives users authenticated access to tools like Kubeflow Pipelines, Kubeflow Notebooks, and Katib.</p> <p> </p> <p>All public deployKF services (including the dashboard) are accessed via the deployKF Istio Gateway, you will need to expose its Kubernetes Service.</p> Step 1 - Expose the Gateway <p>You may expose the deployKF Istio Gateway Service in a number of ways:</p> <ul> <li>Expose with: <code>kubectl port-forward</code> (for local testing only)</li> <li>Expose with: <code>LoadBalancer</code> Service</li> <li>Expose with: <code>Ingress</code></li> </ul> Step 2 - Configure DNS <p>Trying to access deployKF with an IP address will NOT work, you MUST use a domain name.</p> <p>See Configure DNS Records for more information.</p> <p>This step is REQUIRED, you MUST configure DNS records or local <code>/etc/hosts</code> entries.</p> Step 3 - Configure TLS (optional) <p>We recommend configuring valid TLS/HTTPS certificates to avoid browser warnings for your users.</p> <p>See the Configure TLS Certificates guide for more information.</p> <p>If you want to configure TLS later, just skip this step for now.  We use a self-signed certificate by default.</p> Step 4 - User Authentication (optional) <p>See the following guides to configure user authentication on your platform:</p> <ul> <li>External Identity Providers</li> <li>Static User/Password Combinations</li> </ul> <p>If you want to configure authentication later, just skip this step for now.  We provide a few static credentials by default.</p> Step 5 - Define Profiles (optional) <p>deployKF uses the concept of \"Profiles\" to group users and resources together. You might define profiles for different teams, projects, or even individual users.</p> <p>See the User Authorization and Profile Management guide for more information.</p> <p>If you want to define profiles later, just skip this step for now.  We provide default profiles named <code>team-1</code> and <code>team-1-prod</code>.</p> Step 6 - Log In <p>You should now be presented with a \"Log In\" screen when you visit the exposed URL.</p> <p>Remember, you can NOT access deployKF with an IP address, you MUST use a domain name.</p> <p>By default, there are a few static credentials set by the <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> value:</p> Credentials: User 1 <p>Username: <code>user1@example.com</code> Password: <code>user1</code></p> <ul> <li>This account has write access to <code>team-1</code> profile.</li> <li>This account has read access to <code>team-1-prod</code>.</li> </ul> Credentials: User 2 <p>Username: <code>user2@example.com</code> Password: <code>user2</code></p> <ul> <li>This account has write access to <code>team-1</code> profile.</li> <li>This account has read access to <code>team-1-prod</code>.</li> </ul> Credentials: Admin (DO NOT USE - will be removed in future versions) <p>Username: <code>admin@example.com</code> Password: <code>admin</code></p> <ul> <li>This account is the default \"owner\" of all profiles.</li> <li>This account does NOT have access to \"MinIO Console\" or \"Argo Server UI\".</li> <li>We recommend NOT using this account, and actually removing its <code>staticPasswords</code> entry.</li> <li>We recommend leaving this account as the default \"owner\", even with <code>@example.com</code> as the domain (because profile owners can't be changed).</li> </ul> Step 7 - Explore the Tools <p>deployKF includes many tools which address different stages of the data &amp; machine learning lifecycle:</p> <ul> <li>Kubeflow Pipelines</li> <li>Kubeflow Notebooks</li> <li>Other Tools</li> </ul> <p>We also provide a number of user-focused guides for these tools:</p> <p> Tool User Guide Kubeflow Pipelines Access Kubeflow Pipelines API Kubeflow Pipelines GitOps for Kubeflow Pipelines Schedules </p>","boost":2},{"location":"guides/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li> Join the deployKF community!</li> <li> Support us with a star on GitHub!</li> <li> Get support from our experts!</li> </ul>","boost":2},{"location":"guides/kubeflow-distributions/","title":"Migrate from Kubeflow Distributions","text":"<p>Learn about migrating to deployKF from other Kubeflow Distributions like Kubeflow Manifests, Kubeflow on AWS, Kubeflow on GCP and Charmed Kubeflow.</p>"},{"location":"guides/kubeflow-distributions/#about-migrating","title":"About Migrating","text":"<p>Here are some common questions about migrating from other Kubeflow Distributions to deployKF. To learn how to migrate, please see the Steps to Migrate section below.</p>"},{"location":"guides/kubeflow-distributions/#what-is-deploykf","title":"What is deployKF?","text":"<p>deployKF builds machine learning platforms on Kubernetes.</p> <p>To learn more about deployKF itself, please see the introduction page:</p> <p>Introduction to deployKF</p>"},{"location":"guides/kubeflow-distributions/#how-are-kubeflow-and-deploykf-related","title":"How are Kubeflow and deployKF related?","text":"<p>Kubeflow and deployKF are two different but related projects. By using deployKF, you get everything that Kubeflow offers, plus a lot more.</p> <p>To learn more about the differences, please see the comparison page:</p> <p>Comparison between  deployKF and  Kubeflow</p>"},{"location":"guides/kubeflow-distributions/#why-migrate-to-deploykf","title":"Why migrate to deployKF?","text":"<p>We have seen many users struggle with the complexity of deploying Kubeflow. Many users spend days or weeks trying to get Kubeflow working, only to give up in frustration. This is why we created deployKF.</p> <p>Unlike other distributions, deployKF behaves like a Helm Chart for Kubeflow, with centralized configuration values for all aspects of the platform, so you should never need to edit Kubernetes YAML files or deal with Kustomize patches.</p>"},{"location":"guides/kubeflow-distributions/#other-questions","title":"Other Questions","text":"Does deployKF support ArgoCD? <p>Yes, deployKF actually requires ArgoCD.</p> <p>In the future, we may add support for other GitOps tools or implement our own.  Also note, the deployKF ArgoCD Plugin can optionally be used, which makes deployKF behave even more like a Helm Chart.</p> Is deployKF a Helm Chart for Kubeflow? <p>No.  The very short answer is that Kubeflow is too complex to be deployed as a single Helm Chart, it's closer to an entire cloud platform than a single app.</p> <p>The slightly longer answer is that Kubeflow is a cluster-wide platform of many different components and dependencies. Helm lacks the sequencing and dependency management features required to deploy Kubeflow in a single chart. deployKF addresses these challenges by being a collection of Helm Charts (and some Kustomize apps) which are configured by a single set of values. You may think of them like \"global\" Helm values as they control multiple internal apps.</p>"},{"location":"guides/kubeflow-distributions/#steps-to-migrate","title":"Steps to Migrate","text":"<p>Once you have decided to migrate to deployKF, you will need to follow these steps.</p>"},{"location":"guides/kubeflow-distributions/#1-create-a-new-deployment","title":"1. Create a New Deployment","text":"<p>The best way to migrate from Kubeflow Manifests to deployKF is to spin up deployKF in a separate Kubernetes cluster, and then migrate your data manually.</p> <p>To create a new deployment of deployKF, follow the Getting Started guide.</p> <p>Warning</p> <p>Kubeflow Manifests and deployKF can NOT be deployed concurrently in the same Kubernetes cluster, doing so will result in unexpected behavior.</p>"},{"location":"guides/kubeflow-distributions/#2-migrate-your-data","title":"2. Migrate your data","text":"<p>Once you have a new deployment of deployKF, you can migrate the data from specific Kubeflow tools to their deployKF equivalents.</p> <p>For example, you will likely need to migrate your existing Kubeflow Pipelines (scheduled runs, pipeline definitions) and Kubeflow Notebooks (user volume data) to the new deployment.</p>"},{"location":"guides/local-quickstart/","title":"Local Quickstart","text":"<p>Learn how to quickly try deployKF on a local Kubernetes cluster.</p>"},{"location":"guides/local-quickstart/#introduction","title":"Introduction","text":"<p>This quickstart will guide you through setting up a local <code>k3d</code> Kubernetes cluster, installing ArgoCD, and running deployKF on top of it.</p> <p>Not for Production Use</p> <p>This quickstart is for testing purposes only. For production use, please see the Getting Started guide.</p>"},{"location":"guides/local-quickstart/#1-requirements","title":"1. Requirements","text":"<p>Ensure your machine meets the following minimum requirements: </p> Resource Minimum Requirement CPU Cores <code>4</code> RAM <code>16 GB</code> Storage <code>64 GB</code> <p>You will need to install the following dependencies:</p> macOSLinuxWindows <p>Apple Silicon</p> <p>Currently, deployKF does NOT support <code>arm64</code> clusters like Apple Silicon. Furthermore, some core components don't work under rosetta emulation. Please use an <code>x86_64</code> machine or cloud-instance to run this quickstart.</p> <p>If you use a cloud-instance, ensure it meets the minimum requirements.</p> Step 1 - Install Core Dependencies <p>First, install these core dependencies on your macOS host:</p> Requirement Notes Homebrew Install Guide Docker Desktop Install Guide Can I use Podman instead of Docker Desktop? <p>Yes. While we recommend using Docker Desktop, you may use Podman instead.</p> <p>Follow these steps to configure <code>k3d</code> to use Podman:</p> <ol> <li>Install Podman</li> <li>Enable Podman socket: <code>sudo systemctl enable --now podman.socket</code></li> <li>Link Docker socket to Podman: <code>sudo ln -s /run/podman/podman.sock /var/run/docker.sock</code></li> </ol> Step 2 - Configure Docker Desktop <p>You will need to allocate at least the following resources to Docker Desktop:</p> Resource Minimum Allocation CPU Cores <code>4</code> Memory <code>10 GB</code> Storage <code>64 GB</code> Step 3 - Install CLI Tools <p>Next, install these CLI tools on your macOS host:</p> Requirement Notes Bash 4.4+ RUN: <code>brew install bash</code>(macOS has bash <code>3.2</code> by default) CLI: <code>argocd</code> RUN: <code>brew install argocd</code> CLI: <code>jq</code> RUN: <code>brew install jq</code> CLI: <code>k3d</code> RUN: <code>brew install k3d</code> CLI: <code>kubectl</code> RUN: <code>brew install kubectl</code> <p>For example, all commands can be run in your terminal like this:</p> <pre><code>brew install bash argocd jq k3d kubectl\n</code></pre> Step 1 - Install Core Dependencies <p>First, install these core dependencies on your Linux host:</p> Requirement Notes Docker Engine Install GuideNote, you do not need to use Docker Desktop, Docker Engine is sufficient. Step 2 - Install CLI Tools <p>Next, install these CLI tools on your Linux host:</p> Requirement Notes CLI: <code>argocd</code> Install Guide <sup>(also on Homebrew for Linux)</sup> CLI: <code>jq</code> Install Guide <sup>(also on Homebrew for Linux)</sup> CLI: <code>k3d</code> Install Guide <sup>(also on Homebrew for Linux)</sup> CLI: <code>kubectl</code> Install Guide <sup>(also on Homebrew for Linux)</sup> How do I use Homebrew for Linux? <p>An easy way to install the requirements is with Homebrew. While traditionally a macOS tool, Homebrew supports linux as well. The following commands will install <code>brew</code> and add it to your PATH:</p> <pre><code># install Homebrew for Linux\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# add 'brew' to your PATH\n# NOTE: reopen your shell for this to take effect\n(echo; echo 'eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"') &gt;&gt; ~/.profile\n</code></pre> <p>After Homebrew is installed, you may install the requirements like this:</p> <pre><code>brew install argocd jq k3d kubectl\n</code></pre> Step 3 - Inotify Limits <p>On Linux, you may need to increase your system's open/watched file limits.</p> <ol> <li>Modify <code>/etc/sysctl.conf</code> to include the following lines:<ul> <li><code>fs.inotify.max_user_instances = 1280</code></li> <li><code>fs.inotify.max_user_watches = 655360</code></li> </ul> </li> <li>Reload sysctl configs by running <code>sudo sysctl -p</code></li> </ol> Step 1 - Install Host Dependencies <p>Install these dependencies on your Windows host:</p> Requirement Notes Windows Subsystem for Linux (WSL 2) Install Guide Docker Desktop Install Guide Step 2 - Configure WSL <p>Configure WSL to use our custom kernel that properly supports Kubernetes (specifically Istio).</p> <p>Run these commands in PowerShell (search <code>PowerShell</code> in start menu):</p> <pre><code># create a directory for custom kernels\nNew-Item -Path \"$env:USERPROFILE\\WSL2Kernels\" -ItemType Directory -Force | Out-Null\n\n# download our custom kernel\n$KERNEL_VERSION = \"linux-deploykf-wsl-5.15.133.1\"\n$KERNEL_URL = \"https://github.com/deployKF/WSL2-Linux-Kernel/releases/download/${KERNEL_VERSION}/linux-deploykf-wsl\"\n$KERNEL_PATH = \"$env:USERPROFILE\\WSL2Kernels\\linux-deploykf-wsl\"\nInvoke-WebRequest -Uri \"${KERNEL_URL}\" -OutFile \"${KERNEL_PATH}\"\n\n# set the custom kernel as the default\n# NOTE: this will overwrite any existing .wslconfig file\n$KERNEL_PATH_ESCAPED = (\"$env:USERPROFILE\\WSL2Kernels\\linux-deploykf-wsl\" -replace '\\\\', '\\\\')\n$WSLCONFIG_CONTENT = @\"\n[wsl2]\nkernel=\"${KERNEL_PATH_ESCAPED}\"\n\"@\nSet-Content -Path \"$env:USERPROFILE\\.wslconfig\" -Value \"${WSLCONFIG_CONTENT}\"\n\n# restart WSL\nwsl --shutdown\n</code></pre> <p>Restart Docker Desktop</p> <p>Now you must restart Docker Desktop to ensure it is using the new kernel.</p> <p>Right-click the Docker Desktop icon in the system tray, then select <code>Restart</code>.</p> <p>Why do we need a custom kernel?</p> <ul> <li>For context on why a custom kernel is needed, see <code>deployKF/deployKF#41</code>.</li> <li>To see what changes we have made to the kernel, review <code>deployKF/WSL2-Linux-Kernel</code>.</li> <li>Hopefully, once <code>microsoft/WSL#8153</code> is resolved, we will no longer need a custom kernel.</li> </ul> Step 3 - Install Homebrew and Dependencies <p>Install Homebrew for Linux within your WSL environment.</p> <p>Run these commands in an Ubuntu shell (search <code>Ubuntu</code> in start menu):</p> <pre><code># install Homebrew for Linux\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# add 'brew' to your PATH\n# NOTE: reopen your shell for this to take effect\n(echo; echo 'eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"') &gt;&gt; ~/.profile\n</code></pre> <p>Now you can install the requirements like this:</p> <pre><code>brew install argocd jq k3d kubectl\n</code></pre> <p>For the rest of the guide, unless otherwise instructed, run all commands in an Ubuntu shell.</p>"},{"location":"guides/local-quickstart/#2-prepare-kubernetes","title":"2. Prepare Kubernetes","text":"<p>deployKF can run on any  Kubernetes cluster, in any cloud or local environment.</p> <p>For this quickstart, we will be using the <code>k3d</code> command line tool which runs K3s Clusters inside Docker. K3s is an extremely lightweight Kubernetes distribution that is fully compliant with the Kubernetes API, while also being very similar to a cloud-based cluster.</p> Step 1 - Create a k3d Cluster <p>Run this command to create a local <code>k3d</code> cluster named <code>deploykf</code>:</p> <pre><code># NOTE: this will change your kubectl context to the new cluster\nk3d cluster create \"deploykf\" \\\n  --image \"rancher/k3s:v1.28.8-k3s1\"\n</code></pre> Can I use a different version of Kubernetes? <p>Yes. The <code>--image</code> flag allows you to specify the version of Kubernetes. You may use any version of the <code>rancher/k3s</code> image which corresponds to a version of Kubernetes that is supported by deployKF.</p> Step 2 - Wait for Cluster to be Ready <p>Wait until the cluster is ready before continuing, ensure all Pods are in a <code>Running</code> or <code>Completed</code> state.</p> <p>Here are some ways to check the status of Pods, we highly recommend trying <code>k9s</code>!</p> Get Pods Status: <code>kubectl</code> Get Pods Status: <code>k9s</code> <p>You can use <code>kubectl</code> to check the status of all pods, in all namespaces:</p> <pre><code>kubectl get -A pods\n</code></pre> <p>Wait for the list of pods to look like this (<code>STATUS</code> column is <code>Running</code> or <code>Completed</code>):</p> <pre><code>NAMESPACE    NAME                                      READY   STATUS      RESTARTS         AGE\nkube-system  helm-install-traefik-crd-q9mjn            0/1     Completed   0                1h\nkube-system  helm-install-traefik-2h5mn                0/1     Completed   0                1h\nkube-system  svclb-traefik-1d8d8195-8j89l              2/2     Running     0                1h\nkube-system  local-path-provisioner-76d776f6f9-pslbf   1/1     Running     0                1h\nkube-system  coredns-59b4f5bbd5-7vp9v                  1/1     Running     0                1h\nkube-system  traefik-56b8c5fb5c-q4hqp                  1/1     Running     0                1h\nkube-system  metrics-server-7b67f64457-qc5nt           1/1     Running     0                1h\n</code></pre> <p><code>k9s</code> makes interacting with Kubernetes much easier by providing a text-based management interface for any Kubernetes cluster. You can install <code>k9s</code> from Homebrew on macOS or Linux:</p> <pre><code>brew install k9s\n</code></pre> <p>To check the status of all pods in all namespaces:</p> <ol> <li>Run <code>k9s</code> in your terminal</li> <li>Presh <code>shift</code> + <code>:</code> to open the command prompt - (tip: press <code>escape</code> to close any prompt)</li> <li>Type <code>pods</code> and press <code>enter</code> - (tip: press <code>tab</code> to autocomplete resource names)</li> <li>Press <code>0</code> to show all namespaces</li> <li>Scroll through the list of pods and check the <code>STATUS</code> column</li> <li>Quit <code>k9s</code> by pressing <code>ctrl</code> + <code>c</code></li> </ol> <p>The resulting list of pods will look similar to this (see the <code>STATUS</code> column):</p> <pre><code> Context: k3d-deploykf                             &lt;0&gt; all           &lt;a&gt;      Attach     &lt;l&gt;       Logs               &lt;y&gt; YAML                    ____  __.________        \n Cluster: k3d-deploykf                             &lt;1&gt; default       &lt;ctrl-d&gt; Delete     &lt;p&gt;       Logs Previous                                 |    |/ _/   __   \\______ \n User:    admin@k3d-deploykf                                         &lt;d&gt;      Describe   &lt;shift-f&gt; Port-Forward                                  |      &lt; \\____    /  ___/ \n K9s Rev: v0.27.4                                                    &lt;e&gt;      Edit       &lt;s&gt;       Shell                                         |    |  \\   /    /\\___ \\  \n K8s Rev: v1.26.4+k3s1                                               &lt;?&gt;      Help       &lt;n&gt;       Show Node                                     |____|__ \\ /____//____  &gt; \n CPU:     0%                                                         &lt;ctrl-k&gt; Kill       &lt;f&gt;       Show PortForward                                      \\/            \\/  \n MEM:     22%                                                                                                                                                              \n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Pods(all)[7] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 NAMESPACE\u2191               NAME                                                      PF READY RESTARTS STATUS     CPU  MEM %CPU/R %CPU/L %MEM/R %MEM/L IP           NODE  \u2502\n\u2502 kube-system              coredns-59b4f5bbd5-7vp9v                                  \u25cf  1/1          0 Running      2   26      2    n/a     38     15 10.42.0.106  k3d-d \u2502\n\u2502 kube-system              helm-install-traefik-2h5mn                                \u25cf  0/1          0 Completed    0    0    n/a    n/a    n/a    n/a 10.42.0.2    k3d-d \u2502\n\u2502 kube-system              helm-install-traefik-crd-q9mjn                            \u25cf  0/1          0 Completed    0    0    n/a    n/a    n/a    n/a 10.42.0.5    k3d-d \u2502\n\u2502 kube-system              local-path-provisioner-76d776f6f9-pslbf                   \u25cf  1/1          0 Running      1   16    n/a    n/a    n/a    n/a 10.42.0.92   k3d-d \u2502\n\u2502 kube-system              metrics-server-7b67f64457-qc5nt                           \u25cf  1/1          0 Running     2\u2193  40\u2191     2\u2193    n/a    57\u2191    n/a 10.42.0.110  k3d-d \u2502\n\u2502 kube-system              svclb-traefik-1d8d8195-8j89l                              \u25cf  2/2          0 Running      0    2    n/a    n/a    n/a    n/a 10.42.0.90   k3d-d \u2502\n\u2502 kube-system              traefik-56b8c5fb5c-q4hqp                                  \u25cf  1/1          0 Running      1   69    n/a    n/a    n/a    n/a 10.42.0.133  k3d-d \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> What else can <code>k9s</code> do? <p>For more information about the features of <code>k9s</code>, see the k9s documentation, or press <code>?</code> to view the help menu.</p> <p>Some useful features:</p> <ul> <li>When viewing a list of resources, press <code>/</code> to open the search prompt - (tip: press <code>escape</code> to close any prompt)</li> <li>When highlighting any resource, press <code>y</code> to view its YAML</li> <li>When highlighting any resource, press <code>d</code> to describe it</li> <li>When highlighting any resource, press <code>e</code> to open a <code>vim</code> editor for its YAML</li> <li>When highlighting a pod, press <code>l</code> to view its logs</li> <li>When highlighting a pod, press <code>s</code> to open an interactive shell</li> <li>When highlighting a secret, press <code>x</code> to view its base64-decoded data</li> </ul> <p>Filtering by namespace:</p> <ol> <li>Press <code>shift</code> + <code>:</code> to open the command prompt</li> <li>Type <code>ns</code> and press <code>enter</code></li> <li>Select the namespace you want to view and press <code>enter</code> (will open list of pods in that namespace)</li> <li>Press <code>shift</code> + <code>:</code> to open the command prompt</li> <li>Type the name of a resource type (e.g. <code>service</code> or <code>secret</code>) and press <code>enter</code></li> </ol> <p>Note, recently viewed namespaces are given a number (e.g. <code>1</code>, <code>2</code>, <code>3</code>), press that number to show all instances of the currently selected resource type in that namespace.</p>"},{"location":"guides/local-quickstart/#3-prepare-argocd","title":"3. Prepare ArgoCD","text":"<p>deployKF uses  ArgoCD to apply manifests to your Kubernetes cluster.</p> <p>For this quickstart, we will use the deployKF ArgoCD Plugin which adds a special kind of ArgoCD <code>Application</code> that produces deployKF manifests. This allows us to define the platform using a single app-of-apps which only needs your values, and a deployKF version.</p> Step 1 - Verify kubectl Context <p>We need to ensure that our <code>kubectl</code> context is set to the new <code>k3d</code> cluster. This is so we don't accidentally install ArgoCD into the wrong cluster.</p> <p>Run this command and ensure the output is <code>k3d-deploykf</code> (or the name of your cluster):</p> <pre><code># get the name of the current kubectl context\nkubectl config current-context\n</code></pre> How do I change my kubectl context? <p>We recommend using <code>kubectx</code> to manage your <code>kubectl</code> contexts.</p> <p>You may install <code>kubectx</code> from Homebrew on macOS or Linux:</p> <pre><code># NOTE: the installing the 'fzf' package is optional,\n#       it will make 'kubectx' interactive\nbrew install kubectx fzf\n</code></pre> <p>To change your context with <code>kubectx</code>, run these commands:</p> <pre><code># list all contexts\nkubectx\n\n# set the current context to 'k3d-deploykf'\nkubectx \"k3d-deploykf\"\n</code></pre> Step 2 - Install ArgoCD <p>We will now install ArgoCD (and the deployKF ArgoCD Plugin) by running a script from the deployKF repo:</p> <pre><code># clone the deploykf repo\n# NOTE: we use 'main', as the latest plugin version always lives there\ngit clone -b main https://github.com/deployKF/deployKF.git ./deploykf\n\n# ensure the script is executable\nchmod +x ./deploykf/argocd-plugin/install_argocd.sh\n\n# run the install script\n# WARNING: this will install into your current kubectl context\nbash ./deploykf/argocd-plugin/install_argocd.sh\n</code></pre> Step 3 - Wait for ArgoCD to be Ready <p>After the script completes, wait for all pods in the <code>argocd</code> Namespace to be in a <code>Running</code> state:</p> <pre><code>kubectl get --namespace argocd pods\n</code></pre> <p>Wait for the list of pods to look like this (<code>STATUS</code> column is <code>Running</code>):</p> <pre><code>NAME                                                READY   STATUS    RESTARTS   AGE\nargocd-notifications-controller-c4bb67f9d-vbntb     1/1     Running   0          4m52s\nargocd-applicationset-controller-769d968b56-p822z   1/1     Running   0          4m52s\nargocd-redis-859479cd85-6l7nk                       1/1     Running   0          4m51s\nargocd-dex-server-6b7ddc68db-kb2x5                  1/1     Running   0          4m52s\nargocd-server-558686d846-5wmn6                      1/1     Running   0          4m52s\nargocd-application-controller-0                     1/1     Running   0          4m52s\nargocd-repo-server-bf7c47686-dd6w5                  2/2     Running   0          4m52s\n</code></pre>"},{"location":"guides/local-quickstart/#4-create-argocd-applications","title":"4. Create ArgoCD Applications","text":"<p>The only resource you manually create is the <code>deploykf-app-of-apps</code>, this resource generates all the other <code>Application</code> resources. Think of it as a \"single source of truth\" for the desired state of your platform.</p> Step 1 - Define App-of-Apps Resource <p>Create a local file named <code>deploykf-app-of-apps.yaml</code> with the contents of the YAML below.</p> <p>This will use deployKF version <code>0.1.5</code>,  read the <code>sample-values.yaml</code> from the <code>deploykf/deploykf</code> repo,  and combine those values with the overrides defined in the <code>values</code> parameter.</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: deploykf-app-of-apps\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: deploykf-app-of-apps\n    app.kubernetes.io/part-of: deploykf\nspec:\n  project: \"default\"\n  source:\n    ## source git repo configuration\n    ##  - we use the 'deploykf/deploykf' repo so we can read its 'sample-values.yaml'\n    ##    file, but you may use any repo (even one with no files)\n    ##\n    repoURL: \"https://github.com/deployKF/deployKF.git\"\n    targetRevision: \"v0.1.5\"\n    path: \".\"\n\n    ## plugin configuration\n    ##\n    plugin:\n      name: \"deploykf\"\n      parameters:\n\n        ## the deployKF generator version\n        ##  - available versions: https://github.com/deployKF/deployKF/releases\n        ##\n        - name: \"source_version\"\n          string: \"0.1.5\"\n\n        ## paths to values files within the `repoURL` repository\n        ##  - the values in these files are merged, with later files taking precedence\n        ##  - we strongly recommend using 'sample-values.yaml' as the base of your values\n        ##    so you can easily upgrade to newer versions of deployKF\n        ##\n        - name: \"values_files\"\n          array:\n            - \"./sample-values.yaml\"\n\n        ## a string containing the contents of a values file\n        ##  - this parameter allows defining values without needing to create a file in the repo\n        ##  - these values are merged with higher precedence than those defined in `values_files`\n        ##\n        - name: \"values\"\n          string: |\n            ##\n            ## This demonstrates how you might structure overrides for the 'sample-values.yaml' file.\n            ## For a more comprehensive example, see the 'sample-values-overrides.yaml' in the main repo.\n            ##\n            ## Notes:\n            ##  - YAML maps are RECURSIVELY merged across values files\n            ##  - YAML lists are REPLACED in their entirety across values files\n            ##  - Do NOT include empty/null sections, as this will remove ALL values from that section.\n            ##    To include a section without overriding any values, set it to an empty map: `{}`\n            ##\n\n            ## --------------------------------------------------------------------------------\n            ##                                      argocd\n            ## --------------------------------------------------------------------------------\n            argocd:\n              namespace: argocd\n              project: default\n\n            ## --------------------------------------------------------------------------------\n            ##                                    kubernetes\n            ## --------------------------------------------------------------------------------\n            kubernetes:\n              {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                              deploykf-dependencies\n            ## --------------------------------------------------------------------------------\n            deploykf_dependencies:\n\n              ## --------------------------------------\n              ##             cert-manager\n              ## --------------------------------------\n              cert_manager:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##                 istio\n              ## --------------------------------------\n              istio:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##                kyverno\n              ## --------------------------------------\n              kyverno:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                  deploykf-core\n            ## --------------------------------------------------------------------------------\n            deploykf_core:\n\n              ## --------------------------------------\n              ##             deploykf-auth\n              ## --------------------------------------\n              deploykf_auth:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##        deploykf-istio-gateway\n              ## --------------------------------------\n              deploykf_istio_gateway:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##      deploykf-profiles-generator\n              ## --------------------------------------\n              deploykf_profiles_generator:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                   deploykf-opt\n            ## --------------------------------------------------------------------------------\n            deploykf_opt:\n\n              ## --------------------------------------\n              ##            deploykf-minio\n              ## --------------------------------------\n              deploykf_minio:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##            deploykf-mysql\n              ## --------------------------------------\n              deploykf_mysql:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n            ## --------------------------------------------------------------------------------\n            ##                                  kubeflow-tools\n            ## --------------------------------------------------------------------------------\n            kubeflow_tools:\n\n              ## --------------------------------------\n              ##                 katib\n              ## --------------------------------------\n              katib:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##               notebooks\n              ## --------------------------------------\n              notebooks:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n              ## --------------------------------------\n              ##               pipelines\n              ## --------------------------------------\n              pipelines:\n                {} # &lt;-- REMOVE THIS, IF YOU INCLUDE VALUES UNDER THIS SECTION!\n\n  destination:\n    server: \"https://kubernetes.default.svc\"\n    namespace: \"argocd\"\n</code></pre> Step 2 - Apply App-of-Apps Resource <p>You will need to apply the <code>deploykf-app-of-apps</code> resource to your Kubernetes cluster.</p> <p>You can apply the resource using either the CLI or the ArgoCD Web UI:</p>  Apply: <code>kubectl</code> Apply: ArgoCD Web UI <ol> <li>Create a local file named <code>deploykf-app-of-apps.yaml</code> with the contents of the app-of-apps YAML above.</li> <li>Ensure your <code>kubectl</code> context is set to the <code>k3d-deploykf</code> cluster.</li> <li>Apply the resource to your cluster with the following command:</li> </ol> <pre><code>kubectl apply -f ./deploykf-app-of-apps.yaml\n</code></pre> <p>Use <code>kubectl</code> port-forwarding to expose the ArgoCD Web UI on your local machine:</p> <pre><code>kubectl port-forward --namespace \"argocd\" svc/argocd-server 8090:https\n</code></pre> <p>The ArgoCD Web UI should now be available at the following URL:</p> <p> https://localhost:8090</p> <p>Retrieve the initial password for the <code>admin</code> user:</p> <pre><code>echo $(kubectl -n argocd get secret/argocd-initial-admin-secret \\\n  -o jsonpath=\"{.data.password}\" | base64 -d)\n</code></pre> <p>Log in with the <code>admin</code> user, and the password you retrieved above.</p> <p>The ArgoCD Web UI will look like this (but without any applications):</p> <p> </p> <p>To create the app-of-apps, follow these steps:</p> <ol> <li>Click the <code>+ New App</code> button</li> <li>Click the <code>Edit as YAML</code> button</li> <li>Paste the application YAML into the editor</li> <li>Click the <code>Save</code> button</li> <li>Click the <code>Create</code> button</li> </ol>"},{"location":"guides/local-quickstart/#5-sync-argocd-applications","title":"5. Sync ArgoCD Applications","text":"<p>Now that your deployKF app-of-apps has been applied, you must sync the ArgoCD applications to deploy your platform. Syncing an application will cause ArgoCD to reconcile the actual state in the cluster, to match the state defined by the application resource.</p> <p>Danger</p> <p>DO NOT sync all the <code>Applications</code> at once!!!</p> <p>The deployKF <code>Applications</code> depend on each other, they MUST be synced in the correct order to avoid errors. If you manually sync them all, you may need to delete your <code>k3d</code> cluster and start over.</p> <p>For this quickstart, we will use the ArgoCD CLI via our automated <code>sync_argocd_apps.sh</code> script.</p> Step - Run the Sync Script <p>Run the following commands to use the sync script:</p> <pre><code># download the latest version of the script\ncurl -fL -o \"sync_argocd_apps.sh\" \\\n  \"https://raw.githubusercontent.com/deployKF/deployKF/main/scripts/sync_argocd_apps.sh\"\n\n# ensure the script is executable\nchmod +x ./sync_argocd_apps.sh\n\n# ensure your kubectl context is set correctly\nkubectl config current-context\n\n# run the script\nbash ./sync_argocd_apps.sh\n</code></pre> <p>About the sync script</p> <ul> <li>The script can take around 5-10 minutes to run on first install.</li> <li>If the script fails or is interrupted, you can safely re-run it, and it will pick up where it left off.</li> <li>There are a number of configuration variables at the top of the script which change the default behavior.</li> <li>Learn more about the automated sync script from the <code>scripts</code> folder README in the deployKF repo.</li> </ul> <p>Please be aware of the following issue when using the automated sync script:</p> Bug in ArgoCD v2.9 <p>There is a known issue (<code>deploykf/deploykf#70</code>, <code>argoproj/argo-cd#16266</code>) with all <code>2.9.X</code> versions of the ArgoCD CLI that will cause the sync script to fail with the following error:</p> <pre><code>==========================================================================================\nLogging in to ArgoCD...\n==========================================================================================\nFATA[0000] cannot find pod with selector: [app.kubernetes.io/name=] - use the --{component}-name flag in this command or set the environmental variable (Refer to https://argo-cd.readthedocs.io/en/stable/user-guide/environment-variables), to change the Argo CD component name in the CLI\n</code></pre> <p>Please upgrade your <code>argocd</code> CLI to at least version <code>2.10.0</code> to resolve this issue.</p>"},{"location":"guides/local-quickstart/#6-try-the-platform","title":"6. Try the Platform","text":"<p>The deployKF dashboard is the web-based interface for deployKF, it gives users authenticated access to tools like Kubeflow Pipelines, Kubeflow Notebooks, and Katib.</p> <p> </p> <p>All public deployKF services (including the dashboard) are accessed via your deployKF Istio Gateway, to use the gateway, you will need to expose its Kubernetes Service.</p> <p>For this quickstart, we will be using the port-forward feature of <code>kubectl</code> to expose the gateway locally on your machine:</p> Running on a Remote Server <p>If you are running this quickstart on a remote server or cloud-instance (rather than your local machine), you will have to do some different steps that depend on your network setup:</p> Direct Network Access <p>If you have direct network access to the remote server (e.g. are on the same network, or VPN), make the following changes to the steps:</p> <p>Step 1:</p> <p>When updating the hosts file, use the IP of the remote server, rather than <code>127.0.0.1</code>. For example, if the IP of the remote server is <code>192.168.50.15</code>, you would update the hosts file like this:</p> <pre><code>192.168.50.15 deploykf.example.com\n192.168.50.15 argo-server.deploykf.example.com\n192.168.50.15 minio-api.deploykf.example.com\n192.168.50.15 minio-console.deploykf.example.com\n</code></pre> <p>(NOTE: update the hosts file on your local machine, NOT the remote server)</p> <p>Step 2:</p> <p>Run <code>kubectl port-forward</code> on the remote server with the <code>--address 0.0.0.0</code> argument, rather than your local machine. For example, you might run the following command on the remote server:</p> <pre><code>kubectl port-forward \\\n  --namespace \"deploykf-istio-gateway\" \\\n  --address \"0.0.0.0\" \\\n  svc/deploykf-gateway 8080:http 8443:https\n</code></pre> <p>(NOTE: ensure the firewall on the remote server allows ports <code>8080</code> and <code>8443</code>)</p> <p>(WARNING: we don't recommend exposing the gateway to the public internet)</p> <p>Step 3:</p> <p>You still use the hostname set in your hosts file (NOT the IP of the remote server).</p> <p>For example: https://deploykf.example.com:8443/</p> Over SSH Tunnel <p>If you do not have direct network access to the remote server, you can create an SSH tunnel.</p> <p>For example, you might run the following command on your local machine to create the tunnel:</p> <pre><code>SSH_USER=\"user\"\nSSH_HOSTNAME=\"hostname\"\n\nssh -N \\\n  -L 8080:localhost:8080 \\\n  -L 8443:localhost:8443 \\\n  \"${SSH_USER}@${SSH_HOSTNAME}\"\n</code></pre> <p>Step 1:</p> <p>As the tunnel listens on your local machine, you still use <code>127.0.0.1</code> in the hosts file.</p> <p>Step 2:</p> <p>Run <code>kubectl port-forward</code> on the remote instance, rather than your local machine. For example, you might run the following command on the remote instance:</p> <pre><code>kubectl port-forward \\\n  --namespace \"deploykf-istio-gateway\" \\\n  svc/deploykf-gateway 8080:http 8443:https\n</code></pre> <p>Step 3:</p> <p>You still use the hostname set in your hosts file to access the dashboard.</p> <p>For example: https://deploykf.example.com:8443/</p> Step 1 - Modify Hosts <p>You can't access deployKF using <code>localhost</code>, <code>127.0.0.1</code>, or any other IP address.</p> <p>Without an HTTP Host header, deployKF won't know which service you are trying to access. You must update your hosts file to resolve <code>deploykf.example.com</code> and its subdomains to <code>127.0.0.1</code>.</p> <p>Edit the hosts file on your local machine (where you run your web browser), NOT the Kubernetes cluster itself.</p> macOSLinuxWindows <p>The <code>/etc/hosts</code> can ONLY be edited by a user with root privileges.</p> <p>Run the following command to open the hosts file in a text editor:</p> <pre><code>sudo nano /etc/hosts \n# OR: sudo vim /etc/hosts\n</code></pre> <p>Add the following lines to the END of your <code>/etc/hosts</code> file:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> <p>The <code>/etc/hosts</code> can ONLY be edited by a user with root privileges.</p> <p>Run the following command to open the hosts file in a text editor:</p> <pre><code>sudo nano /etc/hosts \n# OR: sudo vim /etc/hosts\n</code></pre> <p>Add the following lines to the END of your <code>/etc/hosts</code> file:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> <p>The hosts file can ONLY be edited by the Windows Administrator user.</p> <p>Run this PowerShell command to start an Administrator Notepad:</p> <pre><code>Start-Process notepad.exe -ArgumentList \"C:\\Windows\\System32\\drivers\\etc\\hosts\" -Verb RunAs\n</code></pre> <p>Add the following lines to the END of your <code>C:\\Windows\\System32\\drivers\\etc\\hosts</code> file:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> Step 2 - Port-Forward the Gateway <p>The <code>kubectl port-forward</code> command creates a private tunnel to the Kubernetes cluster. Run the following command on your local machine to expose the <code>deploykf-gateway</code> Service on <code>127.0.0.1</code>:</p> <pre><code>kubectl port-forward \\\n  --namespace \"deploykf-istio-gateway\" \\\n  svc/deploykf-gateway 8080:http 8443:https\n</code></pre> <p>If your browser suddenly stops working, press <code>CTRL+C</code> to stop the port-forward, and then run the command again (<code>kubernetes/kubernetes#74551</code>).</p> Step 3 - Log In <p>You should now be presented with a \"Log In\" screen when you visit the exposed URL:</p> <p> https://deploykf.example.com:8443/</p> <p>Remember that you can NOT access deployKF using <code>localhost</code> or <code>127.0.0.1</code>!</p> <p>By default, there are a few static credentials set by the <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> value:</p> Credentials: User 1 <p>Username: <code>user1@example.com</code> Password: <code>user1</code></p> <ul> <li>This account has write access to <code>team-1</code> profile.</li> <li>This account has read access to <code>team-1-prod</code>.</li> </ul> Credentials: User 2 <p>Username: <code>user2@example.com</code> Password: <code>user2</code></p> <ul> <li>This account has write access to <code>team-1</code> profile.</li> <li>This account has read access to <code>team-1-prod</code>.</li> </ul> Credentials: Admin (DO NOT USE - will be removed in future versions) <p>Username: <code>admin@example.com</code> Password: <code>admin</code></p> <ul> <li>This account is the default \"owner\" of all profiles.</li> <li>This account does NOT have access to \"MinIO Console\" or \"Argo Server UI\".</li> <li>We recommend NOT using this account, and actually removing its <code>staticPasswords</code> entry.</li> <li>We recommend leaving this account as the default \"owner\", even with <code>@example.com</code> as the domain (because profile owners can't be changed).</li> </ul> Step 4 - Explore the Tools <p>deployKF includes many tools which address different stages of the data &amp; machine learning lifecycle:</p> <ul> <li>Kubeflow Pipelines</li> <li>Kubeflow Notebooks</li> <li>Other Tools</li> </ul> <p>We also provide a number of user-focused guides for these tools:</p> <p> Tool User Guide Kubeflow Pipelines Access Kubeflow Pipelines API Kubeflow Pipelines GitOps for Kubeflow Pipelines Schedules </p>"},{"location":"guides/local-quickstart/#next-steps","title":"Next Steps","text":"<ul> <li> Build a production-ready deployKF platform!</li> <li> Join the deployKF community!</li> <li> Support us with a star on GitHub!</li> <li> Get support from our experts!</li> </ul>"},{"location":"guides/modes/","title":"Modes of Operation","text":"<p>Learn about the \"modes of operation\" in deployKF.</p>"},{"location":"guides/modes/#overview","title":"Overview","text":"<p>There are two ways to use deployKF which we call \"modes of operation\". These modes change how the Kubernetes manifests are generated and applied to your cluster.</p> <p>The following table summarizes the two modes:</p> Mode Description ArgoCD Plugin Mode You install the deployKF ArgoCD Plugin on your ArgoCD instance. The plugin adds a new kind of ArgoCD <code>Application</code> which understands deployKF config values and can generate manifests directly, without requiring a git repo. Manifests Repo Mode You use the <code>deploykf</code> CLI to generate manifests (including ArgoCD <code>Applications</code>). You commit these generated manifests to a git repo for ArgoCD to apply to your cluster. <p>To learn how to use each mode, see the Getting Started guide.</p> <p>Recommended Mode of Operation</p> <p>For most users, we recommend the ArgoCD Plugin Mode.</p>"},{"location":"guides/troubleshooting/","title":"Troubleshooting","text":"<p>Learn about common issues with deployKF and how to resolve them.</p>"},{"location":"guides/troubleshooting/#argo-server-ui","title":"Argo Server UI","text":"Cannot list resource \"workflows\" in API group \"argoproj.io\" at the cluster scope <p>Sometimes, users may open the \"Argo Server\" UI and see an error message like this:</p> <p>{\"code\":7,\"message\":\"workflows.argoproj.io is forbidden: User \\\"system:serviceaccount:kubeflow-argo-workflows:argo-server-user-b36a83701f1c3191e19722d6f90274bc1b5501fe69ebf33313e440fe4b0fe210\\\" cannot list resource \\\"workflows\\\" in API group \\\"argoproj.io\\\" at the cluster scope\"}: workflows.argoproj.io is forbidden: User \"system:serviceaccount:kubeflow-argo-workflows:argo-server-user-b36a83701f1c3191e19722d6f90274bc1b5501fe69ebf33313e440fe4b0fe210\" cannot list resource \"workflows\" in API group \"argoproj.io\" at the cluster scope</p> <p>This error is actually telling you that you need to set a namespace filter, as the Argo Server UI is trying to list ALL workflows in the cluster (but no user has permission to do that). Each user's access in the Argo Server UI corresponds to their profile memberships.</p> <p> </p>"},{"location":"guides/troubleshooting/#istio","title":"Istio","text":"Istio sidecars crash with <code>iptables-restore: unable to initialize table 'nat'</code> error <p>If you experience crashes in your Istio sidecars with an error message like this:</p> <pre><code>2024-08-25T10:50:29.229925Z info    Running command: iptables-restore --noflush\n2024-08-25T10:50:29.240073Z error   Command error output: xtables parameter problem: iptables-restore: unable to initialize table 'nat'\n</code></pre> <p>Then your nodes are likely missing some Linux kernel modules required by Istio. This error has been discussed in the upstream Istio repo (<code>istio#23009</code>, <code>istio#44118</code>).</p> <ol> <li> <p>Get a list of the currently loaded kernel modules by running <code>lsmod</code>:</p> <pre><code>lsmod | awk '{print $1}' | sort\n</code></pre> </li> <li> <p>At the time of writing, the following command will enable the required kernel modules on boot:</p> <pre><code>## NOTE: if you are using Istio ambient mode, there are additional modules required\ncat &lt;&lt;EOF | sudo tee /etc/modules-load.d/99-istio-modules.conf\nbr_netfilter\nip_tables\niptable_filter\niptable_mangle\niptable_nat\niptable_raw\nnf_nat\nx_tables\nxt_REDIRECT\nxt_conntrack\nxt_multiport\nxt_owner\nxt_tcpudp\nEOF\n</code></pre> </li> <li> <p>Now, either reboot your nodes or immediately load the modules with the following commands (which will also indicate if any modules are missing):</p> <pre><code>sudo modprobe br_netfilter\nsudo modprobe ip_tables\nsudo modprobe iptable_filter\nsudo modprobe iptable_mangle\nsudo modprobe iptable_nat\nsudo modprobe iptable_raw\nsudo modprobe nf_nat\nsudo modprobe x_tables\nsudo modprobe xt_REDIRECT\nsudo modprobe xt_conntrack\nsudo modprobe xt_multiport\nsudo modprobe xt_owner\nsudo modprobe xt_tcpudp\n</code></pre> </li> </ol>"},{"location":"guides/troubleshooting/#kubeflow","title":"Kubeflow","text":"Pods crash with <code>too many open files</code> error <p>If you experience pods crashing with an error message like this:</p> <pre><code>too many open files\n</code></pre> <p>You may need to increase the <code>fs.inotify.max_user_*</code> sysctl values on your nodes (only for Linux nodes). This error has been discussed in the upstream Kubeflow repo (<code>kubeflow/manifests#2087</code>)</p> <p>To resolve it, you will need to increase your system's open/watched file limits:</p> <ol> <li> <p>Modify <code>/etc/sysctl.conf</code> to include the following lines:</p> <pre><code>fs.inotify.max_user_instances = 1280\nfs.inotify.max_user_watches = 655360\n</code></pre> </li> <li> <p>Now, apply immediately the changes with the following command:</p> <pre><code>sudo sysctl -p\n</code></pre> </li> </ol>"},{"location":"guides/uninstall/","title":"Uninstall","text":"<p>Learn how to uninstall deployKF.</p>","boost":1.5},{"location":"guides/uninstall/#overview","title":"Overview","text":"<p>Uninstalling deployKF is usually a straightforward process. Take care to ensure you have backed up any important data before proceeding.</p>","boost":1.5},{"location":"guides/uninstall/#1-remove-applications","title":"1. Remove Applications","text":"<p>First, we will delete all the ArgoCD Applications that were installed by deployKF.  This should remove almost all the resources that were created by deployKF.</p> <p>Danger</p> <p>This will delete ALL resources that were created by deployKF (including Profile Namespaces). Ensure you have backed up any important data before proceeding (e.g. PersistentVolumeClaims).</p> <p>Warning</p> <p>Deleting the app-of-apps with <code>kubectl</code> will NOT delete the internal applications. You MUST delete the app-of-apps with the <code>argocd</code> CLI or the ArgoCD Web UI.</p> <p>If you accidentally delete the app-of-apps with <code>kubectl</code>, you will need to re-apply it so you can delete it properly.</p> <p>The following commands will delete the <code>deploykf-app-of-apps</code> application (and its internal apps) using the <code>argocd</code> CLI:</p> <pre><code># set configuration variables\nexport ARGOCD_NAMESPACE=\"argocd\"\nexport ARGOCD_USERNAME=\"admin\"\nexport ARGOCD_PASSWORD=$(\n  # NOTE: this will only work if you have not changed the password\n  #       otherwise, replace this with your password\n  kubectl get secret \\\n    \"argocd-initial-admin-secret\" \\\n    --namespace \"$ARGOCD_NAMESPACE\" \\\n    --output jsonpath=\"{.data.password}\" \\\n  | base64 -d\n)\n\n# login to argocd\nargocd login \\\n  --username \"$ARGOCD_USERNAME\" \\\n  --password \"$ARGOCD_PASSWORD\" \\\n  --port-forward \\\n  --port-forward-namespace \"$ARGOCD_NAMESPACE\"\n\n# delete the app-of-apps application\n# NOTE: you may see \"PermissionDenied\" if the app does not exist\nargocd app delete deploykf-app-of-apps \\\n  --port-forward \\\n  --port-forward-namespace \"$ARGOCD_NAMESPACE\"\n</code></pre>","boost":1.5},{"location":"guides/uninstall/#2-remove-webhooks","title":"2. Remove Webhooks","text":"<p>Kyverno is badly behaved and does not clean up its webhooks when it is uninstalled (<code>kyverno/kyverno#9551</code>).</p> <p>The following commands will delete the <code>ValidatingWebhookConfigurations</code> and <code>MutatingWebhookConfigurations</code> that were created by Kyverno:</p> <pre><code># remove ValidatingWebhookConfigurations\nkubectl delete validatingwebhookconfigurations \\\n  --selector=webhook.kyverno.io/managed-by=kyverno\n\n# remove MutatingWebhookConfigurations\nkubectl delete mutatingwebhookconfigurations \\\n  --selector=webhook.kyverno.io/managed-by=kyverno\n</code></pre>","boost":1.5},{"location":"guides/uninstall/#3-remove-namespaces","title":"3. Remove Namespaces","text":"<p>deployKF will leave behind all Namespaces that it creates (except for Profile Namespaces).</p> <p>The following command will delete all Namespaces that were created by deployKF:</p> <pre><code># WARNING: remove `--dry-run=client` after you have verified the output\n#          ONLY contains Namespaces you are happy to delete\nkubectl delete namespaces --dry-run=client \\\n  --selector=app.kubernetes.io/instance=deploykf-app-of-apps\n</code></pre>","boost":1.5},{"location":"guides/uninstall/#4-remove-argocd","title":"4. Remove ArgoCD","text":"<p>If you no longer need ArgoCD, you can remove it with the following command:</p> <pre><code>kubectl delete namespace argocd\n</code></pre>","boost":1.5},{"location":"guides/upgrade/","title":"Upgrading","text":"<p>Learn how to upgrade your deployKF version and update values.</p>","boost":2},{"location":"guides/upgrade/#overview","title":"Overview","text":"<p>Upgrading deployKF is usually a straightforward process. By \"upgrading\", we mean updating the version of deployKF and/or the values used to configure it.</p>","boost":2},{"location":"guides/upgrade/#upgrading-versions","title":"Upgrading Versions","text":"<p>Typically, you can upgrade deployKF in-place by updating your <code>source_version</code> and then re-syncing your ArgoCD Applications as normal. However, this may result in downtime, so you should plan accordingly.</p> <p>Read the Changelog!</p> <p>Before upgrading, review the changelog for any upgrade notes.</p> <p>Private Container Registries</p> <p>If you use a private container registry rather than the default image locations, check which images are used by the new version and ensure they are mirrored as well. Be careful to use the correct image tags when upgrading, otherwise you might break your deployment.</p>","boost":2},{"location":"guides/upgrade/#updating-values","title":"Updating Values","text":"<p>Typically, you can update your deployKF values by simply changing them and re-syncing your ArgoCD Applications. Depending on the changes, you may need to sync with pruning enabled to remove old resources.</p> <p>Pruning</p> <p>In general, if ArgoCD says pruning is required, you should sync with pruning enabled. Otherwise, deployKF may not function correctly.</p> <p>Due to an issue with ArgoCD (<code>argoproj/argo-cd#14338</code>), resources that we annotate as <code>argocd.argoproj.io/compare-options: IgnoreExtraneous</code> and <code>argocd.argoproj.io/sync-options: Prune=false</code> will show as \"requires pruning\" in the UI. These resources will NOT actually be pruned during a sync, but they are hard to distinguish from those that will.</p> <p>deployKF will always have a number of these \"extraneous\" resources. This is because we replicate secrets to other namespaces which are themselves managed by ArgoCD applications. ArgoCD tracks the resources it \"owns\" with the <code>app.kubernetes.io/instance</code> label (which will be unchanged in the replicated secret). This is actually a good thing, as it means if you delete the source application, the replicated secret will also be deleted.</p>","boost":2},{"location":"guides/values/","title":"Values","text":"<p>Learn deployKF values (configs) and how to configure them.</p>"},{"location":"guides/values/#overview","title":"Overview","text":"<p>All aspects of your deployKF platform are configured with YAML-based configs named \"values\". There are a very large number of values (more than 1500), but as deployKF supports in-place upgrades you can start with a few important ones, and then grow your values file over time.</p> <p>See the configuring deployKF page for guides that explain common configuration tasks.</p>"},{"location":"guides/values/#custom-values","title":"Custom Values","text":"<p>When you set a value, you are overriding its default. The defaults may vary between deployKF versions, and are found in the corresponding <code>default_values.yaml</code> file.</p> <p>For example, to connect Kubeflow Pipelines to an external MySQL database, you might set the following values in your <code>custom-values.yaml</code> file:</p> <pre><code>kubeflow_tools:\n  pipelines:\n    mysql:\n      useExternal: true\n      host: \"mysql.example.com\"\n      port: 3306\n      auth:\n        ## WARNING: in the real world, read the credentials from a secret\n        ##          see https://www.deploykf.org/guides/external/mysql/\n        username: my-username\n        password: my-password\n</code></pre> <p>YAML Syntax</p> <p>For a refresher on YAML syntax, we recommend the following resources:</p> <ul> <li>Learn YAML in Y minutes</li> <li>YAML Multiline Strings</li> </ul>"},{"location":"guides/values/#sample-values","title":"Sample Values","text":"<p>Each version of deployKF has a corresponding <code>sample-values.yaml</code> file with all supported ML &amp; Data tools enabled, along with some sensible security defaults. We recommend using these samples as a starting point for your custom values.</p> <p>There are two main ways to use the sample values file:</p> <ol> <li>Directly: Copy the <code>sample-values.yaml</code> file and make changes directly to that file.</li> <li>Overrides: Include the default <code>sample-values.yaml</code> file first, and then include one or more \"overrides\" files that only contain the values you want to change.</li> </ol> <p>The following command will download the sample values for the latest deployKF version:</p> <pre><code>curl -fL -o \"sample-values-0.1.5.yaml\" \\\n  \"https://raw.githubusercontent.com/deployKF/deployKF/v0.1.5/sample-values.yaml\"\n</code></pre> <p>We provide <code>sample-values-overrides.yaml</code> as an example of how you might structure an \"overrides\" file for the sample values.</p> <p>Additional Values</p> <p>The <code>sample-values.yaml</code> file is a great starting point, but it does NOT include all possible values. For your reference, ALL values and their defaults are listed on the values reference page,  which is generated from the full <code>default_values.yaml</code> file of the latest deployKF version.</p>"},{"location":"guides/values/#merging-values","title":"Merging Values","text":"<p>You may define your custom values in one or more files, which together form the complete \"desired state\" of your deployKF platform.</p> <p>When multiple values files are used, they are merged together in the order they are passed to the <code>deploykf</code> command or plugin. This means that if a value is defined in multiple files, the last one wins.</p> <p>Merging Lists</p> <p>List values are NOT merged. If a list is redefined, the new list will replace the old one in full.</p>"},{"location":"guides/values/#example","title":"Example","text":"<p>This example shows how values are merged together, including both map-type and list-type values.</p> <p>Consider the following two values files:</p> values-1.yaml <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      staticPasswords:\n        - email: \"user1@example.com\"\n          password:\n            value: \"password1\"\n\n        - email: \"user2@example.com\"\n          password:\n            value: \"password2\"\n\nkubeflow_tools:\n  pipelines:\n    mysql:\n      host: \"mysql_OLD.example.com\"\n</code></pre> values-2.yaml <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      staticPasswords:\n        - email: \"user3@example.com\"\n          password:\n            value: \"password3\"\n\nkubeflow_tools:\n  pipelines:\n    mysql:\n      host: \"mysql_NEW.example.com\"\n</code></pre> <p>How you pass these files to deployKF will depend on the mode of operation you are using.</p> ArgoCD Plugin ModeManifests Repo Mode <p>In ArgoCD plugin mode, if you pass these files under <code>values_files</code> in the following order:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: deploykf-app-of-apps\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: deploykf-app-of-apps\n    app.kubernetes.io/part-of: deploykf\nspec:\n  project: \"default\"\n  source:\n\n    ## source git repo configuration\n    ##\n    repoURL: \"https://github.com/&lt;EXAMPLE_ORG&gt;/&lt;EXAMPLE_REPO&gt;.git\"\n    targetRevision: \"main\"\n    path: \".\"\n\n    ## plugin configuration\n    ##\n    plugin:\n      name: \"deploykf\"\n      parameters:\n\n        ## the deployKF generator version\n        ##\n        - name: \"source_version\"\n          string: \"0.1.5\"\n\n        ## paths to values files within the `repoURL` repository\n        ##\n        - name: \"values_files\"\n          array:\n            - \"./sample-values-0.1.5.yaml\"\n            - \"./values-1.yaml\"\n            - \"./values-2.yaml\"\n\n        ## a string containing the contents of a values file\n        ##  - we are not using this in this example\n        ##  - values defined here have the highest precedence\n        ##\n        #- name: \"values\"\n        #  string: |\n        #    ...\n        #    values file contents\n        #    ...\n\n  destination:\n    server: \"https://kubernetes.default.svc\"\n    namespace: \"argocd\"\n</code></pre> <p>In manifests repo mode, if you pass these files to the <code>deploykf</code> command in the following order:</p> <pre><code>deploykf generate \\\n  --source-version \"0.1.5\" \\\n  --values ./values-1.yaml \\\n  --values ./values-2.yaml \\\n  --output-dir ./GENERATOR_OUTPUT\n</code></pre> <p>The resulting \"merged\" values will be as follows (with the default values omitted for brevity):</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      ## NOTE: list values are NOT merged, they are replaced in full\n      staticPasswords:\n        - email: \"user3@example.com\"\n          password:\n            value: \"password3\"\n\nkubeflow_tools:\n  pipelines:\n    mysql:\n      ## NOTE: for map values, the last one wins\n      host: \"mysql_NEW.example.com\"\n</code></pre>"},{"location":"guides/dependencies/argocd/","title":"Argo CD","text":"<p>Learn how and why deployKF uses Argo CD. Learn how to use your existing Argo CD with deployKF and Kubeflow.</p>"},{"location":"guides/dependencies/argocd/#what-is-argo-cd","title":"What is Argo CD?","text":"<p> Argo CD is an extremely widely-used tool that helps you programmatically manage the applications deployed on a Kubernetes cluster.</p> <p>Please note that Argo CD is a completely different tool from Argo Workflows, they just have similar names.</p> <p> Argo CD Manages the state of Kubernetes resources. Argo Workflows Runs DAG workflows in Pods on Kubernetes.(Used by Kubeflow Pipelines) </p>"},{"location":"guides/dependencies/argocd/#argo-cd-applications","title":"Argo CD Applications","text":"<p>The main config for Argo CD is the <code>Application</code>, a Kubernetes custom resource that specifies Kubernetes manifests for Argo CD to deploy and manage (typically from a git repository).</p> <p>An \"app of apps\" is a pattern where a single Argo CD <code>Application</code> contains other <code>Application</code> definitions, this is typically done to make bootstrapping large applications easier.</p>"},{"location":"guides/dependencies/argocd/#argo-cd-interfaces","title":"Argo CD Interfaces","text":"<p>The Argo CD Web Interface lets you visually manage your cluster, allowing you to view and make changes to Kubernetes resources (including <code>Applications</code>). While the CLI and REST API allow you to manage everything programmatically.</p> <p> </p> <p> The ArgoCD Web UI allows you to view and manage your cluster. </p>"},{"location":"guides/dependencies/argocd/#how-does-deploykf-use-argo-cd","title":"How does deployKF use Argo CD?","text":"<p>Argo CD is a core part of deployKF, it helps us manage the lifecycle and state of all components in the platform. For example, we use Argo CD for:</p> <ul> <li>Applying manifests to the cluster, in a defined order</li> <li>Detecting when applications are out-of-sync</li> <li>Syncing applications to their desired state</li> <li>Pruning old manifests which are no longer needed</li> <li>Programmatically managing all of the above</li> </ul>"},{"location":"guides/dependencies/argocd/#what-is-the-deploykf-argocd-plugin","title":"What is the deployKF ArgoCD Plugin?","text":"<p>The deployKF ArgoCD Plugin is an optional part of deployKF which removes the need to commit manifests to a Git repository. The plugin adds a special kind of Argo CD <code>Application</code> that produces deployKF manifests internally, similar to how Helm charts are used in Argo CD. </p> <p>With the plugin, you manage the whole platform from a single \"app of apps\" <code>Application</code> whose specification only needs your values, and a specified source version of deployKF. For an example of this, see this section of the local quickstart.</p>"},{"location":"guides/dependencies/argocd/#can-i-use-other-tool-instead-of-argo-cd","title":"Can I use &lt;other tool&gt; instead of Argo CD?","text":"<p>Not yet.</p> <p>While we believe that Argo CD is currently the best in its category, we recognize that it's not the only option. In the future, we may support other Kubernetes GitOps tools (like Flux CD), or even build a deployKF-specific solution.</p> <p>deployKF will make your MLOps life so much easier, that it's still worth using, even if you don't already love Argo CD. If you want, you can largely treat Argo CD as a \"black box\" and just use the provided sync scripts to manage the platform.</p> <p>Info</p> <p>To learn more about this decision, and participate in the discussion, see <code>deployKF/deployKF#110</code>.</p>"},{"location":"guides/dependencies/argocd/#can-i-use-my-existing-argo-cd","title":"Can I use my existing Argo CD?","text":"<p>Yes, you must. </p> <p>See our version matrix for a list of supported Argo CD versions, then follow the Getting Started guide to install deployKF with your existing Argo CD.</p>"},{"location":"guides/dependencies/argocd/#can-i-use-an-off-cluster-argocd","title":"Can I use an off-cluster ArgoCD?","text":"<p>Yes. deployKF supports the Argo CD \"management cluster\" pattern, where multiple target clusters are managed by a single Argo CD.</p> Step 1 - Configure <code>destination</code> and <code>appNamePrefix</code> <p>When using an off-cluster ArgoCD, you must set the <code>argocd.destination</code> value to target the correct cluster.</p> <p>You must also set the <code>argocd.appNamePrefix</code> value to avoid conflicting ArgoCD application names (which is needed because multiple sets of them may exist in the management cluster).</p> <p>For example, say you have defined a remote cluster named <code>\"my-cluster1\"</code> on your Argo CD management cluster. The following values will prefix all application names with <code>\"cluster1-\"</code> and target them to the named destination <code>\"my-cluster1\"</code>:</p> <pre><code>argocd:\n  ## a prefix to use for argocd application names\n  appNamePrefix: \"cluster1-\"\n\n  ## the destination used for deployKF argocd applications\n  destination:\n    name: \"my-cluster1\"\n</code></pre> <p>Destination MUST be remote</p> <p>When the <code>argocd.appNamePrefix</code> value is non-empty, the <code>argocd.destination</code> MUST be a remote cluster (that is, you should not run deployKF on your management cluster).</p> Step 2 - Update App-of-Apps <p>Your app-of-apps <code>Application</code> MUST target the management cluster, NOT the remote cluster, only the internal <code>Applications</code> will target the remote cluster.</p> <p>Also, you must set the <code>app.kubernetes.io/part-of</code> label to <code>{argocd.appNamePrefix}deploykf</code>, so the sync script works correctly.</p> <p>For example, your app-of-apps <code>Application</code> might look like this:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: {argocd.appNamePrefix}deploykf-app-of-apps\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: deploykf-app-of-apps\n    app.kubernetes.io/part-of: {argocd.appNamePrefix}deploykf\nspec:\n  ## NOTE: This project ONLY applies to the app-of-apps itself, not the internal Applications.\n  ##       It needs to create Applications in the management cluster and Namespaces in the target.\n  ##       The project used by internal Applications is set by the `argocd.project` value.\n  project: default\n\n  source:\n    ...\n    ...\n    ...\n\n  destination:\n    ## OPTION 1: target the management cluster with `server`\n    server: \"https://kubernetes.default.svc\"\n\n    ## OPTION 2: target the management cluster with `name`\n    #name: \"in-cluster\"\n</code></pre> Step 3 - Update Sync Script <p>By default, the <code>sync_argocd_apps.sh</code> script assumes that <code>argocd.appNamePrefix</code> is not set.</p> <p>Update the <code>ARGOCD_APP_NAME_PREFIX</code> variable at the top of the script to match your <code>argocd.appNamePrefix</code> value.</p> <pre><code>ARGOCD_APP_NAME_PREFIX=\"cluster1-\"\n</code></pre> <p>TIP: make sure you have your <code>kubectl</code> context set to the management cluster (NOT your target cluster), before running the sync script.</p>"},{"location":"guides/dependencies/cert-manager/","title":"Cert Manager","text":"<p>Learn how and why deployKF uses cert-manager. Learn how to integrate your existing cert-manager with deployKF and Kubeflow.</p>"},{"location":"guides/dependencies/cert-manager/#what-is-cert-manager","title":"What is cert-manager?","text":"<p> Cert-Manager is a widely-used Kubernetes operator that declaratively manages TLS certificates using Kubernetes resources.</p> <p>The core resource of cert-manager is the <code>Certificate</code>, which is a Kubernetes custom resource that specifies the details of a TLS certificate (e.g. domain name). Each <code>Certificate</code> references an <code>Issuer</code> (or <code>ClusterIssuer</code>) which tells cert-manager how to provision the certificate (e.g. using Let's Encrypt or self-signing). Cert-Manager can store provisioned certificates in Kubernetes <code>Secrets</code> so they can be used by Pods, and will automatically renew the certificate when it is about to expire.</p>"},{"location":"guides/dependencies/cert-manager/#what-is-trust-manager","title":"What is trust-manager?","text":"<p>Trust-Manager is a Kubernetes operator that declaratively manages trust bundles using Kubernetes resources. deployKF uses trust-manager when self-signed certificates are configured (the default) because it allows us to distribute the root CA certificate (via our root CA <code>Bundle</code>) to all services in the platform.</p>"},{"location":"guides/dependencies/cert-manager/#how-does-deploykf-use-cert-manager","title":"How does deployKF use cert-manager?","text":"<p>deployKF uses cert-manager to provision TLS certificates for the Istio Ingress Gateway. Furthermore, many tools in the platform use cert-manager to provision TLS certificates for internal webhooks and APIs.</p> <p>See the Configure TLS Certificates guide for more details.</p>"},{"location":"guides/dependencies/cert-manager/#can-i-use-my-existing-cert-manager","title":"Can I use my existing cert-manager?","text":"<p>Yes.</p> <p>If you already have cert-manager deployed in your cluster, you may configure deployKF to use it instead of the embedded one.</p> <p>Valid Certificates Required</p> <p>If you disable the embedded cert-manager, the <code>ClusterIssuer</code> you configure MUST be able to provision valid certificates (not self-signed). Otherwise, deployKF will fail to start due to certificate validation errors.</p> <p>This is not a problem when using the embedded cert-manager, as all components are automatically configured to trust the default self-signed root CA.</p> Step 1 - Disable Embedded Cert-Manager <p>Disable the embedded cert-manager by setting the <code>deploykf_dependencies.cert_manager.enabled</code> value to <code>false</code>:</p> <pre><code>deploykf_dependencies:\n  cert_manager:\n    enabled: false\n</code></pre> Step 2 - Configure ClusterIssuer <p>When the embedded cert-manager is disabled, the <code>deploykf_dependencies.cert_manager.clusterIssuer</code> value still selects the <code>ClusterIssuer</code> to use (which must be provisioned by you).</p> <p>For example, to use a <code>ClusterIssuer</code> named <code>my-cluster-issuer</code>, you would set the following values:</p> <pre><code>deploykf_dependencies:\n  cert_manager:\n    enabled: false\n\n    clusterIssuer:\n      ## NOTE: when `cert_manager.enabled` is false, \n      ##       all other `cert_manager` values have NO effect\n      issuerName: my-cluster-issuer\n</code></pre> <p>If you don't already have a <code>ClusterIssuer</code>, see Use Let's Encrypt with Cert-Manager for an example of how to configure one.</p>"},{"location":"guides/dependencies/istio/","title":"Istio","text":"<p>Learn how and why deployKF uses Istio. Learn how to integrate your existing Istio with deployKF and Kubeflow.</p>"},{"location":"guides/dependencies/istio/#what-is-istio","title":"What is Istio?","text":"<p> Istio is a service mesh for Kubernetes which is based around the  Envoy proxy. A service mesh is a dedicated infrastructure layer for managing service-to-service network communication.</p> <p>Istio changes Kubernetes Pod definitions (dynamically at runtime) so they have a sidecar container (Envoy proxy) which is configured to intercept all network traffic to and from the Pod. Together, these sidecars form a mesh network that can implement advanced networking features like Traffic Management, Security, and Observability with minimal changes to the application code.</p>"},{"location":"guides/dependencies/istio/#how-is-istio-configured","title":"How is Istio configured?","text":"<p>The Istio mesh is configured declaratively using Kubernetes Custom Resources (CRDs), so you don't need to configure the Envoy proxies directly. Some of the most important Istio CRDs are: <code>Gateway</code>, <code>VirtualService</code>, <code>DestinationRule</code>, <code>ServiceEntry</code>, <code>PeerAuthentication</code>, <code>AuthorizationPolicy</code> and <code>EnvoyFilter</code>.</p>"},{"location":"guides/dependencies/istio/#how-can-external-traffic-access-the-mesh","title":"How can external traffic access the mesh?","text":""},{"location":"guides/dependencies/istio/#mutual-tls","title":"Mutual TLS","text":"<p>The Envoy sidecar uses Mutual TLS (mTLS) to verify if network traffic destined for the Pod is coming from within the mesh. Based on the <code>PeerAuthentication</code> policy for the Pod, the Envoy sidecar will either allow or deny external traffic (not from within the mesh).</p> <p>Istio <code>PeerAuthentication</code> Policies</p> <p>If external traffic is allowed to reach the Pod (like when <code>PeerAuthentication</code> has an <code>mtls.mode</code> of <code>PERMISSIVE</code>), it will be accessing the Pod directly, effectively bypassing the mesh. This means that <code>AuthorizationPolicy</code> and <code>EnvoyFilter</code> policies would not be applied to that traffic.</p>"},{"location":"guides/dependencies/istio/#gateways","title":"Gateways","text":"<p>To expose services in the mesh to external traffic (e.g. from the internet), Istio provides the concept of a \"Gateway\", which sits at the edge of the mesh and can route external traffic to virtual services defined in the mesh.</p> <p>The idea of \"Gateways\" is a common source of confusion for new Istio users because it refers to two different things.</p> Gateway Deployments Gateway Resources A Kubernetes <code>Deployment</code> of special Envoy proxy <code>Pods</code> which act as an \"entry point\" to the mesh. The <code>Gateway</code> is the CRD which configures the Envoy proxies of a \"Gateway Deployment\", and can be selected by <code>VirtualServices</code> to define routes to Pods in the mesh. <p>Here are examples of the two different types of \"Gateway\" in Istio:</p> Example - Gateway Deployment <p>The following <code>Deployment</code> will be automatically mutated by Istio to include an Envoy proxy sidecar container:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-gateway-deployment\n  namespace: gateway-namespace\nspec:\n  selector:\n    matchLabels:\n      istio: my-gateway-deployment\n  template:\n    metadata:\n      annotations:\n        ## this tells istio to inject using the \"gateway\" template,\n        ## rather than the \"sidecar\" template (which is the default)\n        inject.istio.io/templates: \"gateway\"\n      labels:\n        ## this ensures that the istio-proxy container is injected\n        sidecar.istio.io/inject: \"true\"\n\n        ## the pod label (same as any normal kubernetes deployment)\n        ## but which is also used by Gateway resources to select these pods\n        istio: my-gateway-deployment\n    spec:\n      ## allow binding to all ports (such as 80 and 443)\n      securityContext:\n        sysctls:\n          - name: net.ipv4.ip_unprivileged_port_start\n            value: \"0\"\n      containers:\n        - name: istio-proxy\n\n          ## the image is automatically replaced by istio\n          image: auto\n\n          ## drop all privileges, allowing running as non-root\n          securityContext:\n            capabilities:\n              drop:\n                - ALL\n            runAsUser: 1337\n            runAsGroup: 1337\n</code></pre> <p>The following <code>Service</code> exposes the \"Gateway Deployment\" from above with a <code>LoadBalancer</code> type so it can be accessed from outside the cluster:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-gateway-service\n  namespace: gateway-namespace\nspec:\n  type: LoadBalancer\n  selector:\n    istio: my-gateway-deployment\n  ports:\n    - port: 80\n      name: http\n    - port: 443\n      name: https\n</code></pre> Example - Gateway Resource <p>The following <code>Gateway</code> resource configures the \"Gateway Deployment\" from above:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: Gateway\nmetadata:\n  name: my-gateway\n  namespace: gateway-namespace\nspec:\n  ## a selector for Pod labels, which selects the \"Gateway Deployment\"\n  selector:\n    istio: my-gateway-deployment\n  servers:\n    - port:\n        number: 80\n        name: http\n        protocol: HTTP\n      hosts:\n        - \"*\"\n    - port:\n        number: 443\n        name: https\n        protocol: HTTPS\n      hosts:\n        - \"*\"\n      tls:\n        mode: SIMPLE\n        ## the name of the Kubernetes Secret with a TLS certificate\n        credentialName: my-gateway-certificate\n</code></pre> <p>The following <code>VirtualService</code> selects the <code>Gateway</code> defined above, and routes traffic to an application <code>Service</code> named <code>my-service</code>:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: my-virtual-service\n  ## virtual services can be in any namespace, not only the same as the gateway\n  namespace: my-service-namespace\nspec:\n  hosts:\n    ## you could replace this with a specific hostname if you want\n    ## to do Host-based routing, so multiple services can share the same gateway/port\n    - \"*\"\n  gateways:\n    ## this selects the gateway defined above\n    - some-namespace/my-gateway\n  http:\n    - route:\n        ## this assumes there is a `Service` named `my-service` in `my-service-namespace`\n        - destination:\n            host: my-service.my-service-namespace.svc.cluster.local\n            port:\n              number: 80\n</code></pre> <p>TLS Termination</p> <p>In this example, the backend service listens for HTTP traffic (port 80). However, because the gateway is doing TLS termination, end-clients can access the service over HTTPS (port 443).</p>"},{"location":"guides/dependencies/istio/#how-does-deploykf-use-istio","title":"How does deployKF use Istio?","text":"<p>deployKF uses Istio as a service mesh to provide advanced networking features.</p> <p>Here are some of the ways deployKF itself uses Istio:</p> Feature Implementation External Traffic Routing Services are exposed to non-mesh traffic via <code>Gateways</code> and <code>VirtualServices</code>.(Learn More: Expose Gateway) Authentication &amp; Authorization External traffic is authenticated using <code>EnvoyFilters</code>, then authorized with <code>AuthorizationPolicies</code>.(Learn More: User Authentication) Internal Service Communication Internal services talk through the mesh, and service-to-service access controls are enforced with <code>AuthorizationPolicies</code> to restrict which services can talk to each other. <p>Additionally, some tools in deployKF make direct use of Istio:</p> Tool How it uses Istio Kubeflow Notebooks Manages <code>VirtualServices</code> for each <code>Notebook</code> Pod to make it accessible on the main Istio gateway."},{"location":"guides/dependencies/istio/#can-i-use-my-existing-istio","title":"Can I use my existing Istio?","text":"<p>Yes.</p> <p>By default, deployKF will install Istio and create an ingress gateway deployment. However, you may use your existing Istio installation and/or gateway deployment instead.</p> <p>As the gateway deployment is separate from Istio itself, there are 3 common combinations of who manages what:</p> Configuration Istio Installation Gateway Deployment Gateway Resources Default deployKF deployKF Always by deployKF Custom Istio, Managed Gateway You deployKF Always by deployKF Fully Custom You You Always by deployKF"},{"location":"guides/dependencies/istio/#use-an-existing-istio-installation","title":"Use an existing istio installation","text":"<p>If you already have an Istio installation, you may use it instead of the deployKF-managed one by following these steps. See the version matrix for which versions of Istio are supported by deployKF.</p> Gateway Version Alignment <p>If you are NOT also bringing your own gateway deployment, you MUST ensure that the deployKF-managed gateway matches your Istio version. The <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.version</code> value sets the version of the embedded gateway deployment.</p> <p>For example, the following deployKF values will deploy a gateway for Istio <code>1.19.6</code>:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n    charts:\n      istioGateway:\n        name: gateway\n        version: 1.19.6\n        repository: https://istio-release.storage.googleapis.com/charts\n</code></pre> Step 1 - Disable embedded Istio <p>Disable the embedded Istio installation by setting the <code>deploykf_dependencies.istio.enabled</code> value to <code>false</code>:</p> <pre><code>deploykf_dependencies:\n  istio:\n    enabled: false\n</code></pre> Step 2 - Configure your Istio <p>deployKF requires some non-default mesh configs which you MUST set in your Istio installation:</p> Mesh Config Value Purpose <code>defaultConfig.holdApplicationUntilProxyStarts</code> <code>true</code> Ensures the Istio sidecar is fully initialized before application containers start. Prevents race-conditions where application containers start before the sidecar is ready. <code>defaultConfig.proxyMetadata</code> <code>{ \"ISTIO_META_DNS_AUTO_ALLOCATE\": \"true\", \"ISTIO_META_DNS_CAPTURE\": \"true\" }</code> Enable DNS Proxying, which deployKF requires. <p>Default Namespace Injection</p> <p>Ensure you do NOT have <code>sidecarInjectorWebhook.enableNamespacesByDefault</code> set to <code>true</code>.  (In the Istio Helm Chart this defaults to <code>false</code>, but you should check to be sure).</p> <p>For example, if you are using the Istio Helm Chart to install Istio, you may set these Helm values:</p> <pre><code>meshConfig:\n  defaultConfig:\n    holdApplicationUntilProxyStarts: true\n    proxyMetadata:\n      ISTIO_META_DNS_AUTO_ALLOCATE: \"true\"\n      ISTIO_META_DNS_CAPTURE: \"true\"\n\nsidecarInjectorWebhook:\n  enableNamespacesByDefault: false\n</code></pre>"},{"location":"guides/dependencies/istio/#use-an-existing-gateway-deployment","title":"Use an existing gateway deployment","text":"<p>If you have an existing Istio gateway deployment, you can use it instead of the deployKF-managed one. You may do this even when using the deployKF-managed Istio installation.</p> Step 1 - Disable embedded Gateway Deployment <p>Disable the embedded gateway deployment by setting the <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.enabled</code> value to <code>false</code>:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## disable the embedded gateway deployment\n    charts:\n      istioGateway:\n        enabled: false\n</code></pre> Step 2 - Configure deployKF <p>You must set the following deployKF values to match your existing gateway deployment:</p> <ul> <li><code>deploykf_core.deploykf_istio_gateway.namespace</code></li> <li><code>deploykf_core.deploykf_istio_gateway.gateway.ports</code></li> <li><code>deploykf_core.deploykf_istio_gateway.gateway.selectorLabels</code></li> <li><code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.serviceAccount.name</code></li> <li><code>deploykf_core.deploykf_istio_gateway.gatewayService.ports</code> (depending on your setup)</li> </ul> <p>For example, you might set the following values:    </p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## the namespace where your gateway deployment is running\n    namespace: my-gateway-namespace\n\n    gateway:\n      ## the label selector for your gateway deployment pods\n      selectorLabels:\n        app: my-gateway-deployment\n        istio: my-gateway-deployment\n\n      ## the ports on your gateway deployment which deployKF should use\n      ##  - the \"internal\" ports which deployKF will use on your gateway deployment\n      ##  - they must be different from any existing services on this gateway deployment\n      ##  - they may be different to the user-facing ports, as users might connect\n      ##    to the gateway through a Service or Ingress (see `gatewayService.ports`)\n      ports:\n        http: 80\n        https: 443\n\n    gatewayDeployment:\n      serviceAccount:\n        ## the name of the SERVICE ACCOUNT used by the gateway deployment pods\n        ##  - deployKF needs to know this so it can trust traffic from the gateway\n        ##    check the `serviceAccountName` field in your gateway Pods\n        name: my-gateway-service-account\n\n    #gatewayService:\n    #\n    #  ## the ports which clients are actually using to connect to the gateway\n    #  ##  - the \"public\" ports which clients are expected to connect to\n    #  ##  - they can be different to the \"internal\" ports defined in `gateway.ports`\n    #  ##  - these values affect the ports presented in user-facing HTTP links\n    #  ##  - if unset, they default to the corresponding value of `gateway.ports`\n    #  ports:\n    #    http: 80\n    #    https: 443\n</code></pre> Step 3 - Expose your Gateway Deployment <p>If you havent already, you will need to create a <code>Service</code> (and possibly <code>Ingress</code>) that selects your gateway deployment to expose it to external traffic.</p> <p>Service Health Checks</p> <p>Many LoadBalancer Service implementations require a \"health check\" to pass before allowing traffic to flow (e.g. AWS NLB/ALB), and will send health-check requests to one or more ports on the Service.</p> <p>Istio gateway Pods will always return a <code>200 OK</code> response on port <code>15021</code>, under the <code>/healthz/ready</code> HTTP path for this purpose. Therefore, you can expose the <code>15021</code> port on the Service, and configure the health-check path to <code>/healthz/ready</code>.</p> <p>TLS Termination and SNI</p> <p>If you put the Gateway behind a proxy which terminates TLS (like AWS ALB), you will probably need to disable SNI Matching. This is because most proxies don't forward the original request's Server Name Indication (SNI) to the backend service after TLS termination.</p> <p>To disable SNI Matching, set <code>deploykf_core.deploykf_istio_gateway.gateway.tls.matchSNI</code> to <code>false</code>:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    gateway:\n      tls:\n        matchSNI: false\n</code></pre> <p>Read more about this in the Expose Gateway and configure HTTPS guide.</p> Can I have other services on the deployKF Gateway? <p>Yes. You may expose your non-deployKF <code>Gateway</code> and <code>VirtualService</code> resources on the same Gateway Deployment as deployKF, as long as the ports/hostnames are not incompatible with deployKF's configuration.</p> Limitations in deployKF <code>0.1.3</code> and earlier <p>In deployKF <code>0.1.3</code> and earlier, you MUST use a DEDICATED gateway deployment for deployKF. That is, you can't expose non-deployKF services on the same gateway deployment as deployKF.</p> <p>This limitation was removed in deployKF <code>0.1.4</code>.</p> Using non-standard ports <p>If you already have Istio <code>VirtualServices</code> on your gateway deployment using ports <code>80</code> and <code>443</code>, you will need to use non-standard ports (like <code>18080</code> and <code>18443</code>) for deployKF.</p> <p>For example, you might set the following values to use non-standard ports:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## the ports on your gateway deployment which deployKF should use\n    gateway:\n      ports:\n        http: 18080\n        https: 18443\n\n    ## the ports which clients are actually using to connect to the gateway\n    gatewayService:\n      ports:\n        http: 80\n        https: 443\n</code></pre> <p>You will probably also want to use an Ingress which listens on standard ports, and routes traffic to the correct gateway port based on the hostname. This will prevent users from seeing the non-standard ports in their URLs like <code>https://deploykf.example.com:18443</code>.</p> <p>For example, your Ingress could route traffic like this:</p> <ul> <li><code>other-service.example.com</code> \u2192 gateway port <code>443</code></li> <li><code>deploykf.example.com</code> \u2192 gateway port <code>18443</code></li> <li><code>*.deploykf.example.com</code> \u2192 gateway port <code>18443</code></li> </ul>"},{"location":"guides/dependencies/istio/#use-custom-gateway-resources","title":"Use custom gateway resources","text":"<p>You are NOT able to use your own <code>Gateway</code> and <code>VirtualService</code> resources for deployKF.</p> <p>While you may attach deployKF to an existing Gateway Deployment (Pods + Service), ALL virtual <code>Gateway</code> and <code>VirtualService</code> resources are managed by deployKF, this is a result of how deployKF implements features like authentication.</p> <p>For reference, here are some gateway resources that deployKF creates:</p> Resources Purpose <code>Gateway/deploykf-istio-gateway</code> The main gateway that exposes the platform to external traffic. <code>Gateway/deploykf-istio-gateway-https-redirect</code> A special gateway for HTTP to HTTPS redirects. <code>VirtualService/https-redirect</code> Redirects HTTP traffic to HTTPS, connected to <code>Gateway/deploykf-istio-gateway-https-redirect</code>. <code>VirtualService/deploykf-istio-gateway</code> Routes for the central dashboard."},{"location":"guides/dependencies/kyverno/","title":"Kyverno","text":"<p>Learn how and why deployKF uses Kyverno. Learn how to integrate your existing Kyverno with deployKF and Kubeflow.</p>"},{"location":"guides/dependencies/kyverno/#what-is-kyverno","title":"What is Kyverno?","text":"<p>Coming soon</p>"},{"location":"guides/dependencies/kyverno/#how-does-deploykf-use-kyverno","title":"How does deployKF use Kyverno?","text":"<p>Coming soon</p>"},{"location":"guides/dependencies/kyverno/#can-i-use-my-existing-kyverno","title":"Can I use my existing Kyverno?","text":"<p>Coming soon</p>"},{"location":"guides/external/mysql/","title":"MySQL","text":"<p>Learn how and why deployKF needs MySQL. Learn how to use an external MySQL database to improve the performance and reliability of Kubeflow Pipelines and Katib.</p>"},{"location":"guides/external/mysql/#what-is-mysql","title":"What is MySQL?","text":"<p> MySQL is an extremely popular and open-source relational database management system. Many of the world's largest applications use MySQL to store and manage their data.</p>"},{"location":"guides/external/mysql/#why-does-deploykf-use-mysql","title":"Why does deployKF use MySQL?","text":"<p>MySQL is a dependency of the following ML &amp; Data tools, which are part of deployKF:</p> <ul> <li>Kubeflow Pipelines: stores metadata about pipelines, experiments, and runs</li> <li>Katib: stores metadata about hyperparameter tuning experiments</li> </ul>"},{"location":"guides/external/mysql/#connect-an-external-mysql","title":"Connect an External MySQL","text":"<p>By default, deployKF includes an embedded MySQL instance. However, to improve the performance and reliability of Kubeflow Pipelines and Katib, we recommend using an external MySQL database.</p> <p>Embedded MySQL</p> <p>You should ALWAYS use an external MySQL database. The embedded MySQL is a single-instance server running in a Kubernetes Pod, with no backups or high-availability.</p>"},{"location":"guides/external/mysql/#1-prepare-mysql","title":"1. Prepare MySQL","text":"<p>You may use any MySQL database service, as long as it is accessible from the Kubernetes cluster where deployKF is running.</p> <p>You may consider using one of the following services:</p> Platform MySQL Service Amazon Web Services Amazon Relational Database Service (RDS) Microsoft Azure Azure Database for MySQL Google Cloud Cloud SQL Alibaba Cloud ApsaraDB RDS for MySQL IBM Cloud IBM Cloud Databases for MySQL Self-Hosted MySQL Community Edition <p>You must create some databases (schemas) and a user with the appropriate permissions to access them.</p> <p>MySQL User Authentication</p> <p>You MUST set the user's authentication plugin to <code>mysql_native_password</code>, NOT <code>caching_sha2_password</code>, which is the default in MySQL 8.0.4+. Kubeflow Pipelines does not support <code>caching_sha2_password</code> (<code>kubeflow/pipelines#9549</code>).</p> <p>The following SQL command will show the authentication plugin for each user:</p> <pre><code>SELECT user, host, plugin FROM mysql.user;\n</code></pre> <p>For example, you might run the following SQL commands to create the databases and users:</p> <pre><code>-- create the databases\nCREATE DATABASE IF NOT EXISTS `katib`;\nCREATE DATABASE IF NOT EXISTS `kfp_cache`;\nCREATE DATABASE IF NOT EXISTS `kfp_metadata`;\nCREATE DATABASE IF NOT EXISTS `kfp_pipelines`;\n\n-- create the 'kubeflow' user (allowing access from any host)\nCREATE USER 'kubeflow'@'%' IDENTIFIED WITH mysql_native_password BY 'MY_PASSWORD';\n\n-- grant access to the databases\nGRANT ALL PRIVILEGES ON `katib`.* TO 'kubeflow'@'%';\nGRANT ALL PRIVILEGES ON `kfp_cache`.* TO 'kubeflow'@'%';\nGRANT ALL PRIVILEGES ON `kfp_metadata`.* TO 'kubeflow'@'%';\nGRANT ALL PRIVILEGES ON `kfp_pipelines`.* TO 'kubeflow'@'%';\n</code></pre>"},{"location":"guides/external/mysql/#2-disable-the-embedded-mysql","title":"2. Disable the Embedded MySQL","text":"<p>The <code>deploykf_opt.deploykf_mysql.enabled</code> value controls if the embedded MySQL instance is deployed.</p> <p>The following values will disable the embedded MySQL instance:</p> <pre><code>deploykf_opt:\n  deploykf_mysql:\n    enabled: false\n</code></pre>"},{"location":"guides/external/mysql/#3-connect-katib","title":"3. Connect Katib","text":"<p>To connect Katib to your external MySQL database, you will need to configure the following values:</p> Value Purpose <code>kubeflow_tools.katib.mysqlDatabase</code> name of database/schema <code>kubeflow_tools.katib.mysql</code> connection details &amp; credentials <p>The following values will connect Katib to an external MySQL database at <code>mysql.example.com</code> on port <code>3306</code>, using the <code>katib</code> database, reading the username and password from a Kubernetes secret called <code>my-secret-name</code> (from the <code>kubeflow</code> namespace):</p> <pre><code>kubeflow_tools:\n  katib:\n    mysqlDatabase: \"katib\"\n\n    mysql:\n      useExternal: true\n      host: \"mysql.example.com\"\n      port: 3306\n      auth:\n        ## (OPTION 1):\n        ##  - set username/password with values (NOT RECOMMENDED)\n        #username: kubeflow\n        #password: password\n\n        ## (OPTION 2):\n        ##  - read a kubernetes secret from the 'kubeflow' namespace\n        ##  - note, `existingSecret*Key` specifies the KEY NAMES in the \n        ##    secret itself, which contain the secret values\n        existingSecret: \"my-secret-name\"\n        existingSecretUsernameKey: \"username\"\n        existingSecretPasswordKey: \"password\"\n</code></pre>"},{"location":"guides/external/mysql/#4-connect-kubeflow-pipelines","title":"4. Connect Kubeflow Pipelines","text":"<p>To connect Kubeflow Pipelines to your external MySQL database, you will need to configure the following values:</p> Value Purpose <code>kubeflow_tools.pipelines.mysqlDatabases</code> names of databases/schemas <code>kubeflow_tools.pipelines.mysql</code> connection details &amp; credentials <p>The following values will connect Kubeflow Pipelines to an external MySQL database at <code>mysql.example.com</code> on port <code>3306</code>, using the <code>kfp_cache</code>, <code>kfp_metadata</code>, and <code>kfp_pipelines</code> databases, reading the username and password from a Kubernetes secret called <code>my-secret-name</code> (from the <code>kubeflow</code> namespace):</p> <pre><code>kubeflow_tools:\n  pipelines:\n    mysqlDatabases:\n      cacheDatabase: kfp_cache\n      metadataDatabase: kfp_metadata\n      pipelinesDatabase: kfp_pipelines\n\n    mysql:\n      useExternal: true\n      host: \"mysql.example.com\"\n      port: 3306\n      auth:\n        ## (OPTION 1):\n        ##  - set username/password with values (NOT RECOMMENDED)\n        #username: kubeflow\n        #password: password\n\n        ## (OPTION 2):\n        ##  - read a kubernetes secret from the 'kubeflow' namespace\n        ##  - note, `existingSecret*Key` specifies the KEY NAMES in the \n        ##    secret itself, which contain the secret values\n        existingSecret: \"my-secret-name\"\n        existingSecretUsernameKey: \"username\"\n        existingSecretPasswordKey: \"password\"\n</code></pre>"},{"location":"guides/external/object-store/","title":"Object Store","text":"<p>Learn how and why deployKF needs an object store. Learn how to use any S3-compatible object store with Kubeflow Pipelines.</p>"},{"location":"guides/external/object-store/#what-is-an-object-store","title":"What is an Object Store?","text":"<p>An object store is a type of storage system that manages data as objects, as opposed to traditional file systems which manage data as files. Each object typically includes the data itself, a variable amount of metadata, and a globally unique identifier.</p>"},{"location":"guides/external/object-store/#what-is-an-s3-compatible-object-store","title":"What is an S3-compatible Object Store?","text":"<p>The most well-known object store is  Amazon S3. Given its popularity, many other object stores have implemented S3-compatible APIs, which allows them to be used with tools that are designed to work with S3.</p>"},{"location":"guides/external/object-store/#why-does-deploykf-use-an-object-store","title":"Why does deployKF use an Object Store?","text":"<p>An S3-compatible object store is a dependency of  Kubeflow Pipelines, which uses it to store pipeline definitions and artifacts from pipeline runs.</p>"},{"location":"guides/external/object-store/#connect-an-external-object-store","title":"Connect an External Object Store","text":"<p>By default, deployKF includes an embedded MinIO instance. However, to improve the performance and reliability of Kubeflow Pipelines, we recommend using an external S3-compatible object store.</p> <p>Embedded MinIO</p> <p>You should ALWAYS use an external S3-compatible object store. The embedded MinIO is only intended for testing purposes as it only supports a single replica, and has no backups.</p> <p>Please ensure you are familiar with MinIO's licence, at the time of writing it was AGPLv3. deployKF is licensed under Apache 2.0 and does NOT contain any code from MinIO, instead, we provide links so that you may download MinIO directly from official sources, at your own discretion.</p> <p>You may use any S3-compatible object store, as long as it is accessible from the Kubernetes cluster where deployKF is running.</p> <p>You might consider using one of the following services:</p> Platform Object Store S3-compatible Endpoint Amazon Web Services Amazon S3 <code>s3.{region}.amazonaws.com</code> Google Cloud Google Cloud Storage <code>storage.googleapis.com</code> you must use HMAC Keys for authentication  Microsoft Azure Azure Blob Storage No first-party API.Third-party translation layers like S3Proxy can be used. Alibaba Cloud Alibaba Cloud Object Storage Service (OSS) <code>s3.oss-{region}.aliyuncs.com</code> IBM Cloud IBM Cloud Object Storage <code>s3.{region}.cloud-object-storage.appdomain.cloud</code> Other Cloudflare R2 <code>{account_id}.r2.cloudflarestorage.com</code> Self-Hosted MinIO, Ceph, Wasabi See provider documentation. <p>S3-compatible APIs Only</p> <p>Currently, Kubeflow Pipelines only supports object stores which have an S3-compatible XML API. This means that while you can use services like Google Cloud Storage, you will need to use their XML API, and features like GKE Workload Identity will NOT work.</p> <p>If you would like Kubeflow Pipelines to implement support for the native APIs of your object store, please raise this with the upstream Kubeflow Pipelines community.</p>"},{"location":"guides/external/object-store/#1-create-a-bucket","title":"1. Create a Bucket","text":"<p>You must create a single bucket for Kubeflow Pipelines. Refer to the documentation for your object store to learn how to create a bucket.</p> <p>For example, if you are using AWS S3, you may use the following methods:</p> <ul> <li>Create S3 bucket (AWS Console)</li> <li>Create S3 bucket (AWS CLI)</li> </ul>"},{"location":"guides/external/object-store/#2-create-iam-policies","title":"2. Create IAM Policies","text":"<p>You must create IAM Policies to allow Kubeflow Pipelines to access your bucket. Refer to the documentation for your object store to learn how to create IAM Policies.</p> <p>For example, if you are using AWS S3, you may use the following methods:</p> <ul> <li>Create IAM Policies (AWS Console)</li> <li>Create IAM Policies (AWS CLI)</li> </ul>"},{"location":"guides/external/object-store/#bucket-iam-policies","title":"Bucket IAM Policies","text":"<p>It is recommended to create separate IAM Roles for each component and user. The following are example IAM Policies for the Kubeflow Pipelines BACKEND and PROFILE namespaces.</p> IAM Policy - Backend <p>The following IAM Policy can be used by the Kubeflow Pipelines BACKEND, replace <code>&lt;BUCKET_NAME&gt;</code> with the name of your bucket.</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetBucketLocation\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:PutObject\",\n        \"s3:DeleteObject\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;/artifacts/*\",\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;/pipelines/*\",\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;/v2/artifacts/*\"\n      ]\n    }\n  ]\n}\n</code></pre> IAM Policy - Profile <p>The following IAM Policy can be used by each PROFILE namespace, replace <code>&lt;BUCKET_NAME&gt;</code> with the name of your bucket, and <code>&lt;PROFILE_NAME&gt;</code> with the name of the profile.</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetBucketLocation\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:PutObject\",\n        \"s3:DeleteObject\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;/artifacts/&lt;PROFILE_NAME&gt;/*\",\n        \"arn:aws:s3:::&lt;BUCKET_NAME&gt;/v2/artifacts/&lt;PROFILE_NAME&gt;/*\"\n      ]\n    }\n  ]\n}\n</code></pre> <p>To learn more about how objects are stored in the bucket, see the following section:</p> Object Store Structure <p>All Kubeflow Pipelines artifacts are stored in the same bucket, but are separated by object key prefixes.</p> <p>The following table shows the prefixes used by Kubeflow Pipelines:</p> Key Prefix Purpose <code>/pipelines/</code> pipeline definitions <code>/artifacts/{profile_name}/</code> pipeline run artifacts (KFP v1) <code>/v2/artifacts/{profile_name}/</code> pipeline run artifacts (KFP v2) <p>Key Format</p> <p>Notice that the key prefixes include <code>{profile_name}</code>, this allows prefix-based IAM Policies to ensure each profile only has access to its own artifacts.</p>"},{"location":"guides/external/object-store/#3-disable-embedded-minio","title":"3. Disable Embedded MinIO","text":"<p>The <code>deploykf_opt.deploykf_minio.enabled</code> value controls if the embedded MinIO instance is deployed.</p> <p>The following values will disable the embedded MinIO instance:</p> <pre><code>deploykf_opt:\n  deploykf_minio:\n    enabled: false\n</code></pre>"},{"location":"guides/external/object-store/#4-connect-kubeflow-pipelines","title":"4. Connect Kubeflow Pipelines","text":"<p>How you connect Kubeflow Pipelines to your external object store depends on the authentication method you choose.</p> <p>The following sections show how to configure each method:</p>  Key-Based Authentication IRSA-Based Authentication <p>All S3-compatible object stores support key-based authentication.</p> <p>In this method, deployKF will use HMAC Keys (that is, an <code>access_key</code> and <code>secret_key</code>) to authenticate with your object store.</p> Step 1 - Create Secrets (Backend) <p>First, create a secret for the Kubeflow Pipelines backend:</p> <pre><code>## create a secret for the KFP backend\nkubectl create secret generic \\\n  \"kubeflow-pipelines--backend-object-store-auth\" \\\n  --namespace \"kubeflow\" \\\n  --from-literal AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE \\\n  --from-literal AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n</code></pre> <p>Info</p> <ul> <li>The backend secret MUST be in the <code>kubeflow</code> namespace, as this is where the KFP backend is deployed.</li> <li>The backend secret should have access to all KFP artifacts in the bucket.</li> <li>See the Example IAM Policies.</li> </ul> Step 2 - Create Secrets (User Profiles) <p>Next, create a secret for each profile that will use Kubeflow Pipelines:</p> <pre><code>## create a secret for the \"team-1\" profile\nkubectl create secret generic \\\n  \"kubeflow-pipelines--profile-object-store-auth--team-1\" \\\n  --namespace \"my-namespace\" \\\n  --from-literal AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE \\\n  --from-literal AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n\n## create a secret for the \"team-2\" profile\nkubectl create secret generic \\\n  \"kubeflow-pipelines--profile-object-store-auth--team-2\" \\\n  --namespace \"my-namespace\" \\\n  --from-literal AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE \\\n  --from-literal AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n</code></pre> <p>Info</p> <ul> <li>The profile secrets can be in any namespace, deployKF will automatically clone the correct secret into the profile namespace and configure KFP to use it.</li> <li>It is common to store all the profile secrets in a single namespace, as this makes them easier to manage.</li> <li>Each profile secret should only have the minimum permissions required for that profile.</li> <li>See the Example IAM Policies.</li> </ul> Step 3 - Configure deployKF <p>Finally, configure deployKF to use the secrets you created using the following values:</p> Value Purpose <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth</code> Default bucket authentication used in profiles that do NOT have <code>tools.kubeflowPipelines.objectStoreAuth</code> defined in their <code>deploykf_core.deploykf_profiles_generator.profiles</code> list entry. <code>kubeflow_tools.pipelines.objectStore</code> Connection details &amp; bucket authentication used by the KFP backend (not profiles). <code>kubeflow_tools.pipelines.bucket</code> Bucket name and region configs. <p>The following values will connect Kubeflow Pipelines to an external object store using key-based authentication:</p> <pre><code>deploykf_core:\n  deploykf_profiles_generator:\n\n    ## NOTE: each profile can override the defaults \n    ##       see under `profiles` for an example of a profile \n    ##       which overrides the default auth pattern\n    ##\n    profileDefaults:\n      tools:\n        kubeflowPipelines:\n          objectStoreAuth:\n            ## (OPTION 1):\n            ##  - all profiles share the same access key (NOT RECOMMENDED)\n            ##  - the `existingSecretAccessKeyKey` and `existingSecretSecretKeyKey`\n            ##    reference the KEY NAMES in the Kubernetes Secret you create\n            ##\n            #existingSecret: \"my-secret-name\"\n            #existingSecretNamespace: \"my-namespace\"\n            #existingSecretAccessKeyKey: \"AWS_ACCESS_KEY_ID\"\n            #existingSecretSecretKeyKey: \"AWS_SECRET_ACCESS_KEY\"\n\n            ## (OPTION 2):\n            ##  - each profile has its own access key\n            ##  - instances of '{profile_name}' in `existingSecret` \n            ##    are replaced with the profile name\n            ##  - the `existingSecretAccessKeyKey` and `existingSecretSecretKeyKey`\n            ##    reference the KEY NAMES in the Kubernetes Secret you create\n            ##\n            existingSecret: \"kubeflow-pipelines--profile-object-store-auth--{profile_name}\"\n            existingSecretNamespace: \"my-namespace\"\n            existingSecretAccessKeyKey: \"AWS_ACCESS_KEY_ID\"\n            existingSecretSecretKeyKey: \"AWS_SECRET_ACCESS_KEY\"\n\n    ## example of a profile which overrides the default auth\n    #profiles:\n    #  - name: \"my-profile\"\n    #    members: []\n    #    tools:\n    #      kubeflowPipelines:\n    #        objectStoreAuth:\n    #          existingSecret: \"my-secret-name\"\n    #          existingSecretNamespace: \"\" # defaults to the profile's namespace\n    #          existingSecretAccessKeyKey: \"AWS_ACCESS_KEY_ID\"\n    #          existingSecretSecretKeyKey: \"AWS_SECRET_ACCESS_KEY\"\n\nkubeflow_tools:\n  pipelines:\n    bucket:\n      ## this specifies the name of your bucket (and region, if applicable)\n      name: kubeflow-pipelines\n      region: \"\"\n\n    objectStore:\n      useExternal: true\n\n      ## this specifies the S3-compatible endpoint of your object store\n      ##  - for S3 itself, you may need to use the region-specific endpoint\n      ##  - don't set a port unless it is non-standard\n      host: \"s3.amazonaws.com\"\n      port: \"\"\n      useSSL: true\n\n      ## these credentials are used by the KFP backend (not profiles)\n      auth:\n        ## (OPTION 1):\n        ##  - set keys with values (NOT RECOMMENDED)\n        #accessKey: \"AKIAIOSFODNN7EXAMPLE\"\n        #secretKey: \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"\n\n        ## (OPTION 2):\n        ##  - read a kubernetes secret from the 'kubeflow' namespace\n        ##  - note, `existingSecretKey` specifies the KEY NAMES in the \n        ##    secret itself, which contain the secret values\n        existingSecret: \"kubeflow-pipelines--backend-object-store-auth\"\n        existingSecretAccessKeyKey: \"AWS_ACCESS_KEY_ID\"\n        existingSecretSecretKeyKey: \"AWS_SECRET_ACCESS_KEY\"\n</code></pre> <p>If you are using EKS and S3, you may use IAM roles for service accounts (IRSA).</p> <p>In this method, EKS will inject access keys automatically based on Kubernetes ServiceAccount annotations, so no keys are required.</p> <p>IRSA is only supported on EKS</p> <p>IRSA is only supported when connecting to S3 from an EKS cluster.</p> <p>If you are using a different platform, you will need to use key-based authentication.</p> Step 1 - Enable IRSA <p>First, you must enable IRSA on your EKS cluster.</p> <p>Refer to the AWS Documentation for detailed instructions.</p> Step 2 - Associate IAM Roles <p>You will need to associate the Kubernetes ServiceAccounts to the roles you created in the previous step.</p> <p>The following ServiceAccounts are used by Kubeflow Pipelines:</p> Component Namespace ServiceAccount Name Kubeflow Pipelines Backend <code>kubeflow</code> <code>ml-pipeline</code> Kubeflow Pipelines Backend <code>kubeflow</code> <code>ml-pipeline-ui</code> Kubeflow Pipelines Backend <code>kubeflow-argo-workflows</code> <code>argo-server</code> Kubeflow Pipelines Backend <code>kubeflow-argo-workflows</code> <code>argo-workflow-controller</code> User Profiles <code>{profile_name}</code> <code>default-editor</code> <p>For example, the following command will associate the <code>arn:aws:iam::MY_ACCOUNT_ID:policy/MY_POLICY_NAME</code> IAM Policy with the <code>ml-pipeline</code> ServiceAccount in the <code>kubeflow</code> namespace, and create an IAM Role named <code>kubeflow-pipelines-backend</code>:</p> <pre><code>eksctl create iamserviceaccount \\\n  --cluster \"my-cluster\" \\\n  --namespace \"kubeflow\" \\\n  --name \"ml-pipeline\" \\\n  --role-name \"kubeflow-pipelines-backend\" \\\n  --attach-policy-arn \"arn:aws:iam::MY_ACCOUNT_ID:policy/MY_POLICY_NAME\" \\\n  --approve\n</code></pre> Step 3 - Configure deployKF <p>The following values are needed to configure IRSA-based auth:</p> Value Purpose <code>deploykf_core.deploykf_profiles_generator.profileDefaults.plugins</code> Default profile-plugins, used by profiles which do NOT have <code>plugins</code> defined in their <code>deploykf_core.deploykf_profiles_generator.profiles</code> list entry.Note, the <code>AwsIamForServiceAccount</code> plugin is used to configure AWS IRSA-based auth by annotating the <code>default-editor</code> and <code>default-viewer</code> ServiceAccounts in each profile. <code>kubeflow_dependencies.kubeflow_argo_workflows.controller.serviceAccount</code> Kubernetes ServiceAccount used by the Argo Workflows Controller <code>kubeflow_dependencies.kubeflow_argo_workflows.server.serviceAccount</code> Kubernetes ServiceAccount used by the Argo Server UI <code>kubeflow_tools.pipelines.serviceAccounts.apiServer</code> Kubernetes ServiceAccount used by the Kubeflow Pipelines API Server <code>kubeflow_tools.pipelines.serviceAccounts.frontend</code> Kubernetes ServiceAccount used by the Kubeflow Pipelines Frontend <code>kubeflow_tools.pipelines.objectStore.auth.fromEnv</code> If <code>true</code>, disables all other auth methods, so the AWS Credential Provider Chain will try to use IRSA-based auth. <p>The following values will connect Kubeflow Pipelines to an external object store using IRSA-based authentication:</p> <pre><code>deploykf_core:\n  deploykf_profiles_generator:\n\n    ## NOTE: if you want to have a different set of plugins for each profile,\n    ##       for example, to have some profiles use a different IAM role,\n    ##       you can define the `plugins` list explicitly in a profile \n    ##       to override the default plugins\n    profileDefaults:\n      plugins:\n        - kind: AwsIamForServiceAccount\n          spec:\n            awsIamRole: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n            AnnotateOnly: true\n\n    ## example of a profile which overrides the default plugins\n    #profiles:\n    #  - name: \"my-profile\"\n    #    members: []\n    #    plugins:\n    #      - kind: AwsIamForServiceAccount\n    #        spec:\n    #          awsIamRole: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n    #          AnnotateOnly: true\n\nkubeflow_dependencies:\n  kubeflow_argo_workflows:\n    controller:\n      serviceAccount:\n        annotations:\n          eks.amazonaws.com/role-arn: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n    server:\n      serviceAccount:\n        annotations:\n          eks.amazonaws.com/role-arn: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n\nkubeflow_tools:\n  pipelines:\n    serviceAccounts:\n      apiServer:\n        annotations:\n          eks.amazonaws.com/role-arn: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n      frontend:\n        annotations:\n          eks.amazonaws.com/role-arn: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n\n    bucket:\n      name: kubeflow-pipelines\n      region: \"us-west-2\"\n\n    objectStore:\n      useExternal: true\n\n      ## for IRSA, this should always be \"s3.{region}.amazonaws.com\" or similar\n      host: \"s3.us-west-2.amazonaws.com\"\n      useSSL: true\n\n      auth:\n        ## setting `fromEnv` to `true` disables all other auth methods\n        ## so the AWS Credential Provider Chain will try to use IRSA-based auth\n        fromEnv: true\n</code></pre> deployKF <code>0.1.4</code> and earlier <p>If you are using deployKF <code>0.1.4</code> or earlier, you will need to explicitly set <code>kubeflow_tools.pipelines.kfpV2.minioFix</code> to <code>false</code>. Note that newer versions of deployKF do not have this value, as the MinIO issue has been resolved.</p> <p>For example:</p> <pre><code>kubeflow_tools:\n  pipelines:\n    kfpV2:\n      ## NOTE: only required if you are using 'sample-values.yaml' as a base\n      ##       as `minioFix` can only be 'true' when using the embedded MinIO\n      minioFix: false\n</code></pre>"},{"location":"guides/platform/deploykf-authentication/","title":"User Authentication and External Identity Providers","text":"<p>Learn about user authentication and connecting with external identity providers in deployKF.</p> <p>Related Guides</p> <p>In addition to configuring how users are authenticated, you will likely want to authorize them by assigning to profiles. Note, the level of access a user has is directly determined by which profiles they are a member of.</p>"},{"location":"guides/platform/deploykf-authentication/#introduction","title":"Introduction","text":"<p>deployKF provides a very flexible approach to user authentication.</p> <p>All user-facing components that require authentication are connected with the embedded Dex instance. Most components connect to Dex via OAuth2 Proxy with Istio <code>EnvoyFilters</code> (e.g. Kubeflow), but some components connect with Dex directly (e.g. MinIO, Argo Server). </p> <p>When a user needs to be authenticated, they will be redirected to Dex, which then authenticates them using one (or more) of the following methods:</p> Authentication Method(Click for Details) Description External Identity Providers Connect with external identity providers like Active Directory, Okta, GitHub, Google. Static User/Password Combinations Define a list of static user/password combinations that are local to deployKF.These credentials are commonly used as \"service accounts\" for things like Accessing the Kubeflow Pipelines API, but may also be used for regular users if you don't have an external identity provider."},{"location":"guides/platform/deploykf-authentication/#external-identity-providers","title":"External Identity Providers","text":"<p>Typically, organizations will have an existing identity provider like Okta, GitHub, or Google.</p> <p>Dex provides connectors for many external identity providers. The following table lists some common identity providers and the Dex connector you should use to connect with them:</p> Provider Name(Click for Example) Dex Connector Type Active Directory (LDAP) <code>ldap</code> AWS Cognito <code>oidc</code> GitHub <code>github</code> Google Workspace <code>google</code> Microsoft Identity Platform <code>microsoft</code> Okta <code>oidc</code> OneLogin <code>oidc</code> Keycloak <code>oidc</code> Generic (OpenID Connect) <code>oidc</code> <p>SAML 2.0</p> <p>You should NOT use the <code>saml</code> connector, as it does not support refresh tokens, so users would be forced to re-login every 60 minutes. Most identity providers with SAML 2.0 also have OpenID Connect (OIDC), which supports refresh tokens.</p> <p>Groups</p> <p>Currently, deployKF does not use the <code>groups</code> claim from providers. Within deployKF, groups are virtual constructs which are defined with the profile values.</p>"},{"location":"guides/platform/deploykf-authentication/#connector-values","title":"Connector Values","text":"<p>The <code>deploykf_core.deploykf_auth.dex.connectors</code> value configures the list of Dex connectors which are available for user authentication. You may define multiple connectors, users will be prompted to choose one when they login.</p> <p>The generic structure of a <code>connector</code> list element is as follows:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - ## the connector type (ldap, github, oidc, etc.)\n          type: &lt;connector-type&gt;\n\n          ## identifier for the connector (any string)\n          id: &lt;connector-id&gt;\n\n          ## human-readable name for the connector (any string)\n          name: &lt;connector-name&gt;\n\n          ## (OPTION 1):\n          ##  - set the config with values (NOT RECOMMENDED)\n          ##  - see provider guides for examples\n          config:\n            config-key-1: config-value-1\n            config-key-2: config-value-2\n            config-key-3: config-value-3\n\n          ## (OPTION 2):\n          ##  - read a kubernetes secret from the 'deploykf-auth' namespace\n          ##  - using this completely overrides the `config` map above\n          #configExistingSecret: \"my-secret-name\"\n          #configExistingSecretKey: \"key-in-secret-with-config-yaml-string\"\n</code></pre> How do I use <code>configExistingSecret</code>? <p>To use the <code>configExistingSecret</code> option, you must create a Kubernetes secret with the <code>config</code> values.</p> <p>The secret must be created in the <code>deploykf-auth</code> namespace, and the <code>configExistingSecretKey</code> key in the secret must contain a string of YAML which is formatted the same as the <code>config</code> map key above.</p> <p>Note, the <code>type</code>, <code>id</code>, and <code>name</code> fields are defined in the <code>connector</code> list element, NOT in the secret.</p> <p>For example, you may create a secret like this:</p> <pre><code>kind: Secret\napiVersion: v1\nmetadata:\n  name: my-secret-name\n  namespace: deploykf-auth\n## NOTE: you may also use `data` if you base64 encode the string\nstringData:\n  key-in-secret-with-config-yaml-string: |\n    config-key-1: config-value-1\n    config-key-2: config-value-2\n    config-key-3: config-value-3\n</code></pre> <p>The following values will then make use of the secret:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - type: &lt;connector-type&gt;\n          id: &lt;connector-id&gt;\n          name: &lt;connector-name&gt;\n          configExistingSecret: \"my-secret-name\"\n          configExistingSecretKey: \"key-in-secret-with-config-yaml-string\"\n</code></pre> Can I use External Secrets Operator? <p>If you are using External Secrets Operator, you can easily include the <code>ExternalSecret</code> manifest in your deployKF values. The <code>deploykf_core.deploykf_auth.extraManifests</code> value will include additional manifests in the <code>deploykf-auth</code> namespace.</p> <p>For example, the following values will create an <code>ExternalSecret</code> named <code>my-secret-name</code>:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    extraManifests:\n      - |\n        apiVersion: external-secrets.io/v1beta1\n        kind: ExternalSecret\n        metadata:\n          name: my-secret-name\n          namespace: deploykf-auth\n        spec:\n          refreshInterval: \"60s\"\n\n          ## the secret store to read from\n          secretStoreRef:\n            name: my-secret-store\n            kind: SecretStore\n\n          ## the secret to be created\n          target:\n            ## the `configExistingSecret` would be this secret\n            name: my-secret-name\n\n            ## NOTE: we wrap templates in {{ `...` }} to stop helm from parsing them\n            template:\n              data:\n                ## the `configExistingSecretKey` would be this key\n                google-config: |\n                  clientID: {{ `{{ .clientID | quote }}` }}\n                  clientSecret: {{ `{{ .clientSecret | quote }}` }}\n                  redirectURI: \"https://deploykf.example.com/dex/callback\"\n\n          ## data to read from the secret store\n          ##  - key: the secret to read from the secret store\n          ##  - property: usually a GJSON expression to extract the value from the secret\n          data:\n            - secretKey: clientID\n              remoteRef:\n                key: /deploykf/auth/google-oidc\n                property: clientID\n\n            - secretKey: clientSecret\n              remoteRef:\n                key: /deploykf/auth/google-oidc\n                property: clientSecret\n</code></pre>"},{"location":"guides/platform/deploykf-authentication/#provider-examples","title":"Provider Examples","text":"<p>The following guides show provider-specific instructions for configuring Dex connectors:</p> Active Directory (LDAP) AWS Cognito GitHub Google Workspace Microsoft Identity Platform Okta OneLogin Keycloak Generic (OpenID Connect)"},{"location":"guides/platform/deploykf-authentication/#active-directory-ldap","title":"Active Directory (LDAP)","text":"<p>How to connect deployKF with Active Directory will depend on the structure of your Active Directory:</p> <ul> <li>Dex: Docs for <code>ldap</code> connector</li> </ul> <p>The following values act as a good starting point for connecting deployKF with LDAP:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - type: ldap\n          id: ldap\n          name: LDAP\n          config:\n            ## the LDAP server URL and port\n            host: ldap.example.com:636\n\n            ## if we should skip TLS certificate verification\n            ## WARNING: this is insecure, prefer to use `rootCAData`\n            insecureSkipVerify: false\n\n            ## a base64 encoded PEM file with your root CA certificate\n            #rootCAData: \"\"\n\n            ## the credentials to use for searching the directory\n            ## NOTE: not required if anonymous bind is allowed\n            #bindDN: uid=Administrator,cn=Users,dc=example,dc=com\n            #bindPW: password\n\n            ## text used in password-prompt box\n            usernamePrompt: \"Username\"\n\n            ## how users are searched for, based on the provided username\n            userSearch:\n\n              ## base search from\n              baseDN: cn=Users,dc=example,dc=com\n\n              ## an additional search filter to apply\n              filter: \"(objectClass=person)\"\n\n              ## how to map user attributes\n              username: uid\n              idAttr: uid\n              emailAttr: mail\n              nameAttr: name\n\n            ## how groups are searched for, based on the found user\n            groupSearch:\n              ## base search from\n              baseDN: cn=Groups,dc=example,dc=com\n\n              ## an additional search filter to apply\n              ## WARNING: if too many groups are returned, you will exceed the HTTP header size limit.\n              ##          you may need to apply a filter like: \"(&amp;(objectClass=group)(cn=*deployKF*))\" \n              ##          which will only return groups with \"deployKF\" in the name. However, note that\n              ##          deployKF does not currently use these groups, so you are mostly preparing \n              ##          for the future.\n              filter: \"(objectClass=group)\"\n\n              ## list of user-attribute to group-attribute pairs\n              ## the value of the found user's `userAttr` must be one of the group's `groupAttr`\n              userMatchers:\n                - userAttr: uid\n                  groupAttr: member\n\n              ## how to map group attributes\n              nameAttr: cn\n</code></pre> <p>Restricting Access to Members of Specific Group</p> <p>deployKF does not currently use <code>groups</code> from providers. If you need to restrict deployKF to members of specific group, you must extend the <code>userSearch.filter</code> to include a group membership check.</p> <p>For example, if users are in the <code>cn=Users,dc=example,dc=com</code> OU, and you want to restrict access to members of the <code>cn=deploykf,ou=Groups,dc=example,dc=com</code> group, you could use the following:</p> <pre><code>userSearch:\n  baseDN: cn=Users,dc=example,dc=com\n  filter: \"(&amp;(objectClass=person)(memberOf=cn=deploykf,ou=Groups,dc=example,dc=com))\"\n</code></pre> <p>This pattern could be extended to support multiple groups by using <code>(|(memberOf=...)(memberOf=...))</code>.</p> <p>Use Kubernetes Secrets</p> <p>Consider using <code>configExistingSecret</code> instead of <code>config</code> to avoid storing secrets in your values, see the Connector Values section for more details.</p>"},{"location":"guides/platform/deploykf-authentication/#aws-cognito","title":"AWS Cognito","text":"<p>To connect deployKF with AWS Cognito, you must first create an \"App Client\" in AWS Cognito:</p> <ul> <li>AWS: Create user pool app clients </li> <li>Dex: Docs for <code>oidc</code> connector</li> </ul> <p>The following values will connect deployKF with your AWS Cognito application:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - type: oidc\n          id: aws-cognito\n          name: AWS Cognito\n          config:\n            issuer: https://cognito-idp.&lt;AWS_REGION&gt;.amazonaws.com/&lt;USER_POOL_ID&gt;\n\n            clientID: \"XXXXXXXXXXXXXXXXXXXX\"\n            clientSecret: \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n\n            ## replace with your deploykf domain\n            ## NOTE: this must be an allowed redirect URI in the AWS Cognito app\n            redirectURI: https://deploykf.example.com/dex/callback\n\n            ## openid scopes to request\n            scopes:\n              - openid\n              - email\n              - profile\n\n            ## cognito does not send the `name` claim\n            userNameKey: cognito:username\n\n            ## cognito does not always send the `email_verified` claim\n            insecureSkipEmailVerified: true\n</code></pre> <p>Use Kubernetes Secrets</p> <p>Consider using <code>configExistingSecret</code> instead of <code>config</code> to avoid storing secrets in your values, see the Connector Values section for more details.</p>"},{"location":"guides/platform/deploykf-authentication/#github","title":"GitHub","text":"<p>To connect deployKF with GitHub, you must create an OAuth application in GitHub:</p> <ul> <li>GitHub: Creating an OAuth app</li> <li>Dex: Docs for <code>github</code> connector</li> </ul> <p>The following values will connect deployKF with your GitHub application:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - type: github\n          id: github\n          name: GitHub\n          config:\n            clientID: \"XXXXXXXXXXXXXXXXXXXX\"\n            clientSecret: \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n\n            ## replace with your deploykf domain\n            ## NOTE: this must be an allowed redirect URI in the GitHub app\n            redirectURI: https://deploykf.example.com/dex/callback\n\n            ## a list of GitHub organizations and teams to allow users from\n            orgs:\n              ## allow ALL users from \"my-organization\"\n              - name: \"my-organization\"\n\n              ## allow users from \"my-organization\" who are in the listed teams\n              #- name: \"my-organization\"\n              #  teams:\n              #    - \"red-team\"\n              #    - \"blue-team\"\n\n            ## how the team names are formatted\n            ##  - If \"name\", the full team name is used (default)\n            ##    EXAMPLE: \"Site Reliability Engineers\"\n            ##  - If \"slug\", the slug of the team name is used\n            ##    EXAMPLE: \"site-reliability-engineers\"\n            teamNameField: slug\n\n            ## how to determine the user's email\n            ##  - WARNING: tell users to REMOVE any PUBLIC emails from their \n            ##    GitHub profiles, currently, public emails override this setting.\n            ##  - When 'preferredEmailDomain' is set, the first email matching this \n            ##    domain is returned, falling back to the primary email if no match is found.\n            ##  - To allow multiple subdomains, you may specify a wildcard like \"*.example.com\"\n            ##    which will match \"aaaa.example.com\" and \"bbbb.example.com\", but NOT \"example.com\".\n            #preferredEmailDomain: \"example.com\"\n\n            ## only required for GitHub Enterprise\n            #hostName: github.example.com\n</code></pre> <p>Use Kubernetes Secrets</p> <p>Consider using <code>configExistingSecret</code> instead of <code>config</code> to avoid storing secrets in your values, see the Connector Values section for more details.</p>"},{"location":"guides/platform/deploykf-authentication/#google-workspace","title":"Google Workspace","text":"<p>To connect deployKF with Google Workspace, you must register an application in the Google API Console:</p> <ul> <li>Google: Setting up OAuth 2.0</li> <li>Dex: Docs for <code>google</code> connector</li> </ul> <p>The following values will connect deployKF with your Google Workspace:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - type: google\n          id: google\n          name: Google\n          config:\n            clientID: \"XXXXXXXXXXXXXXXXXXXX\"\n            clientSecret: \"XXXXXXXXXXXXXXXXXXXXXXXXX\"\n\n            ## replace with your deploykf domain\n            ## NOTE: this must be an allowed redirect URI in the Google app\n            redirectURI: https://deploykf.example.com/dex/callback\n</code></pre> <p>Use Kubernetes Secrets</p> <p>Consider using <code>configExistingSecret</code> instead of <code>config</code> to avoid storing secrets in your values, see the Connector Values section for more details.</p>"},{"location":"guides/platform/deploykf-authentication/#microsoft-identity-platform","title":"Microsoft Identity Platform","text":"<p>To connect deployKF with Microsoft Identity Platform, register an application in Azure:</p> <ul> <li>Azure: Register app with Microsoft identity platform</li> <li>Dex: Docs for <code>microsoft</code> connector</li> </ul> <p>The following values will connect deployKF with your Microsoft Identity Platform application:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - type: microsoft\n          id: microsoft\n          name: Microsoft\n          config:\n            clientID: \"XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\"\n            clientSecret: \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n\n            ## replace with your deploykf domain\n            ## NOTE: this must be an allowed redirect URI in the Okta app\n            redirectURI: \"https://deploykf.example.com/dex/callback\"\n</code></pre> <p>Use Kubernetes Secrets</p> <p>Consider using <code>configExistingSecret</code> instead of <code>config</code> to avoid storing secrets in your values, see the Connector Values section for more details.</p>"},{"location":"guides/platform/deploykf-authentication/#okta","title":"Okta","text":"<p>To connect deployKF with Okta, you must first create a \"OIDC - Web Application\" application in Okta:</p> <ul> <li>Okta: Create OIDC app integrations</li> <li>Dex: Docs for <code>oidc</code> connector</li> </ul> <p>The following values will connect deployKF with your Okta application:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - type: oidc\n          id: okta\n          name: Okta\n          config:\n            issuer: https://MY_COMPANY.okta.com\n\n            clientID: \"XXXXXXXXXXXXXXXXXXXX\"\n            clientSecret: \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n\n            ## replace with your deploykf domain\n            ## NOTE: this must be an allowed redirect URI in the Okta app\n            redirectURI: https://deploykf.example.com/dex/callback\n\n            ## openid scopes to request\n            scopes:\n              - openid\n              - email\n              - profile\n              ## NOTE: offline_access is required for refresh tokens\n              ##  - ensure the Okta app has \"Refresh Token\" grant type enabled\n              ##  - set the \"Refresh Token Behavior\" to \"Rotate token after every use\"\n              - offline_access\n\n            ## okta does not always send the `email_verified` claim\n            insecureSkipEmailVerified: true\n</code></pre> <p>Use Kubernetes Secrets</p> <p>Consider using <code>configExistingSecret</code> instead of <code>config</code> to avoid storing secrets in your values, see the Connector Values section for more details.</p>"},{"location":"guides/platform/deploykf-authentication/#onelogin","title":"OneLogin","text":"<p>To connect deployKF with OneLogin, you must first create an \"OpenID Connect\" application in OneLogin:</p> <ul> <li>OneLogin: Create OpenID Connect app</li> <li>Dex: Docs for <code>oidc</code> connector</li> </ul> <p>The following values will connect deployKF with your OneLogin application:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - type: oidc\n          id: onelogin\n          name: OneLogin\n          config:\n            issuer: https://openid-connect.onelogin.com/oidc\n\n            clientID: \"XXXXXXXXXXXXXXXXXXXX\"\n            clientSecret: \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n\n            ## replace with your deploykf domain\n            ## NOTE: this must be an allowed redirect URI in the OneLogin app\n            redirectURI: https://deploykf.example.com/dex/callback\n\n            ## openid scopes to request\n            scopes:\n              - openid\n              - email\n              - profile\n              ## NOTE: offline_access is required for refresh tokens\n              - offline_access\n\n            ## onelogin does not always send the `email_verified` claim\n            insecureSkipEmailVerified: true\n</code></pre>"},{"location":"guides/platform/deploykf-authentication/#keycloak","title":"Keycloak","text":"<p>To connect deployKF with Keycloak, you must first create an \"OpenID Connect\" client in Keycloak:</p> <ul> <li>Keycloak: Managing OpenID Connect clients</li> <li>Keycloak: Using OpenID Connect to secure apps</li> <li>Dex: Docs for <code>oidc</code> connector</li> </ul> <p>The following values will connect deployKF with your Keycloak application:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - type: oidc\n          id: keycloak\n          name: Keycloak\n          config:\n            issuer: https://keycloak.example.com/realms/&lt;REALM_NAME&gt;\n\n            clientID: \"XXXXXXXXXXXXXXXXXXXX\"\n            clientSecret: \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n\n            ## replace with your deploykf domain\n            ## NOTE: this must be an allowed redirect URI in the Keycloak app\n            redirectURI: https://deploykf.example.com/dex/callback\n\n            ## openid scopes to request\n            scopes:\n              - openid\n              - email\n              - profile\n              ## NOTE: offline_access is required for refresh tokens\n              - offline_access\n\n            ## keycloak does not always send the `email_verified` claim\n            insecureSkipEmailVerified: true\n\n            ## if your Keycloak uses a self-signed certificate\n            #insecureSkipVerify: true\n</code></pre>"},{"location":"guides/platform/deploykf-authentication/#generic-openid-connect","title":"Generic (OpenID Connect)","text":"<p>Many identity providers support the OpenID Connect (OIDC) protocol, which is an extension of OAuth2.</p> <p>Dex provides an <code>oidc</code> connector which can be used to connect with any OIDC provider.</p> <p>For example, here are generic values for connecting with an OIDC provider:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      connectors:\n        - type: oidc\n          id: oidc\n          name: Generic OIDC\n          config:\n            ## replace with your OIDC provider's issuer URL\n            ## NOTE: the URL must expose the `.well-known/openid-configuration` endpoint \n            issuer: https://oidc.example.com\n\n            ## credentials for the OIDC client\n            clientID: \"XXXXXXXXXXXXXXXXXXXX\"\n            clientSecret: \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n\n            ## replace with your deploykf domain\n            ## NOTE: this must be an allowed redirect URI in the OIDC app\n            redirectURI: https://deploykf.example.com/dex/callback\n\n            ## openid scopes to request\n            scopes:\n              - openid\n              - email\n              - profile\n              ## NOTE: offline_access is typically required for refresh tokens\n              ##       if possible, configure your provider to only allow each\n              ##       refresh token to be used once\n              - offline_access\n\n            ## set to true, if provider does not always send `email_verified` claim\n            insecureSkipEmailVerified: true\n</code></pre>"},{"location":"guides/platform/deploykf-authentication/#static-userpassword-combinations","title":"Static User/Password Combinations","text":"<p>deployKF supports defining static user/password combinations which are local to itself.</p> <p>These static credentials are commonly used as \"service accounts\" for things like Accessing the Kubeflow Pipelines API, but may also be used for regular users if you don't have an external identity provider.</p> <p>Password Secret Rotation</p> <p>If a user's password is defined from a Kubernetes Secret (with <code>existingSecret</code>), the password will be automatically rotated when the Secret is updated.</p> <p>The <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> value defines the list of credentials which are available for user authentication.</p> <p>The following values show three different ways to define static credentials:</p> <pre><code>deploykf_core:\n  deploykf_auth:\n    dex:\n      staticPasswords:\n        ## (OPTION 1):\n        ##  - a user with password defined as a plaintext value\n        - email: \"plaintext@example.com\"\n          password:\n            value: \"password\"\n\n        ## (OPTION 2):\n        ##  - a user with password defined as a bcrypt hash\n        ##  - a bcrypt hash for \"password\" can be generated with one of the following:\n        ##     - echo \"password\" | htpasswd -BinC 10 NULL | cut -d: -f2\n        ##     - python -c 'import bcrypt; print(bcrypt.hashpw(b\"password\", bcrypt.gensalt(10)).decode())'\n        - email: \"bcrypt@example.com\"\n          password:\n            ## the bcrypt hash of the password \"password\"\n            value: \"$2y$10$z22lKMtSyC65VhMfTROkGesiS2ofrVQQdkGu.vjhIH2HM5Epmhil2\"\n            type: \"hash\"\n\n        ## (OPTION 3):\n        ##  - a user with password defined from a kubernetes secret\n        - email: \"kubernetes-secret@example.com\"\n          password:\n            existingSecret: \"my-secret\"\n            existingSecretKey: \"password-key\"\n</code></pre>"},{"location":"guides/platform/deploykf-dashboard/","title":"Customize the Dashboard","text":"<p>Learn how to customize the deployKF Dashboard.</p>"},{"location":"guides/platform/deploykf-dashboard/#overview","title":"Overview","text":"<p>The deployKF Dashboard is the web-based interface for deployKF, and is the primary way that users interact with the platform.</p> <p>The dashboard includes navigation menus with links to various tools and documentation which can be customized.</p> <p> </p>"},{"location":"guides/platform/deploykf-dashboard/#sidebar-links","title":"Sidebar Links","text":"<p>Extra links may be added to the sidebar navigation menu with the <code>deploykf_core.deploykf_dashboard.navigation.externalLinks</code> value.</p> <p>For example, you may use the following values to add a link to the deployKF website:</p> <pre><code>deploykf_core:\n  deploykf_dashboard:\n    navigation:\n      externalLinks:\n        - text: \"deployKF Website\"\n          url: \"https://deployKF.org\"\n          icon: \"launch\"\n</code></pre>"},{"location":"guides/platform/deploykf-dashboard/#documentation-links","title":"Documentation Links","text":"<p>Extra links may be added to the \"documentation\" section of the home page with the <code>deploykf_core.deploykf_dashboard.navigation.documentationItems</code> value.</p> <p>For example, you may use the following values to add a link to the deployKF website:</p> <pre><code>deploykf_core:\n  deploykf_dashboard:\n    navigation:\n      documentationItems:\n        - text: \"deployKF Website\"\n          desc: \"The tool that deployed your ML platform!\"\n          link: \"https://github.com/deployKF/deployKF\"\n</code></pre>"},{"location":"guides/platform/deploykf-gateway/","title":"Expose Gateway and configure HTTPS","text":"<p>Learn how to make deployKF accessible to your users, and how to configure HTTPS/TLS.</p> <p>Help Us Improve</p> <p>This guide covers an incredibly broad topic with near limitless possible implementations. If you see anything incorrect or missing, please help us by raising an issue!</p>"},{"location":"guides/platform/deploykf-gateway/#expose-the-gateway-service","title":"Expose the Gateway Service","text":"<p>deployKF uses  Istio for networking. Clients access deployKF through the Pods of an Istio Gateway Deployment via a Kubernetes <code>Service</code> named <code>deploykf-gateway</code>. This Service needs to be accessible from outside the cluster to allow users to access the deployKF dashboard and other tools.</p> <p>Public Internet</p> <p>The default Service type is <code>LoadBalancer</code>, this may expose your deployKF Gateway to the public internet (depending on how your Kubernetes cluster is configured).</p> <p>You should seriously consider the security implications of exposing the deployKF Gateway to the public internet. Most organizations choose to expose the gateway on a private network, and then use a VPN or other secure connection to access it.</p> <p>You can expose the <code>deploykf-gateway</code> Service in a few different ways, depending on your platform and requirements:</p>"},{"location":"guides/platform/deploykf-gateway/#use-kubectl-port-forward","title":"Use kubectl port-forward","text":"<p>If you are just testing the platform, you may use <code>kubectl port-forward</code> to access the Service from your local machine.</p> Step 1 - Modify Hosts <p>You can't access deployKF using <code>localhost</code>, <code>127.0.0.1</code>, or any other IP address.</p> <p>Without an HTTP Host header, deployKF won't know which service you are trying to access. You must update your hosts file to resolve <code>deploykf.example.com</code> and its subdomains to <code>127.0.0.1</code>.</p> <p>Edit the hosts file on your local machine (where you run your web browser), NOT the Kubernetes cluster itself.</p> macOSLinuxWindows <p>The <code>/etc/hosts</code> can ONLY be edited by a user with root privileges.</p> <p>Run the following command to open the hosts file in a text editor:</p> <pre><code>sudo nano /etc/hosts \n# OR: sudo vim /etc/hosts\n</code></pre> <p>Add the following lines to the END of your <code>/etc/hosts</code> file:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> <p>If you have configured a custom domain, replace <code>deploykf.example.com</code> with your custom domain.</p> <p>The <code>/etc/hosts</code> can ONLY be edited by a user with root privileges.</p> <p>Run the following command to open the hosts file in a text editor:</p> <pre><code>sudo nano /etc/hosts \n# OR: sudo vim /etc/hosts\n</code></pre> <p>Add the following lines to the END of your <code>/etc/hosts</code> file:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> <p>If you have configured a custom domain, replace <code>deploykf.example.com</code> with your custom domain.</p> <p>The hosts file can ONLY be edited by the Windows Administrator user.</p> <p>Run this PowerShell command to start an Administrator Notepad:</p> <pre><code>Start-Process notepad.exe -ArgumentList \"C:\\Windows\\System32\\drivers\\etc\\hosts\" -Verb RunAs\n</code></pre> <p>Add the following lines to the END of your <code>C:\\Windows\\System32\\drivers\\etc\\hosts</code> file:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> <p>If you have configured a custom domain, replace <code>deploykf.example.com</code> with your custom domain.</p> Step 2 - Port-Forward the Gateway <p>The <code>kubectl port-forward</code> command creates a private tunnel to the Kubernetes cluster. Run the following command on your local machine to expose the <code>deploykf-gateway</code> Service on <code>127.0.0.1</code>:</p> <pre><code>kubectl port-forward \\\n  --namespace \"deploykf-istio-gateway\" \\\n  svc/deploykf-gateway 8080:http 8443:https\n</code></pre> <p>If your browser suddenly stops working, press <code>CTRL+C</code> to stop the port-forward, and then run the command again (<code>kubernetes/kubernetes#74551</code>).</p> <p>The deployKF dashboard should now be available on your local machine at:</p> <p> https://deploykf.example.com:8443/</p> <p>Remember that you can NOT access deployKF using <code>localhost</code> or <code>127.0.0.1</code>!</p>"},{"location":"guides/platform/deploykf-gateway/#use-a-loadbalancer-service","title":"Use a LoadBalancer Service","text":"<p>Most Kubernetes platforms provide a LoadBalancer-type Service that can be used to expose Pods on a private or public IP address. How you configure a LoadBalancer Service will depend on the platform you are using, for example:</p> AWS - Network Load Balancer <p>The AWS Load Balancer Controller is commonly used to configure LoadBalancer services on EKS.</p> <p>Tip</p> <p>AWS EKS does NOT have the AWS Load Balancer Controller installed by default.  Follow the official instructions to install the controller.</p> <p>For example, you might set the following values to use a Network Load Balancer (NLB):</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## these values configure the deployKF Gateway Service\n    ##\n    gatewayService:\n      name: \"deploykf-gateway\"\n      type: \"LoadBalancer\"\n      annotations:\n        service.beta.kubernetes.io/aws-load-balancer-type: \"external\"\n        service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: \"ip\"\n        service.beta.kubernetes.io/aws-load-balancer-scheme: \"internal\"\n\n        ## for external-dns integration (if not `--source=istio-gateway` config)\n        #external-dns.alpha.kubernetes.io/hostname: \"deploykf.example.com, *.deploykf.example.com\"\n\n        ## for static private IP addresses\n        #service.beta.kubernetes.io/aws-load-balancer-private-ipv4-addresses: \"192.168.XXX.XXX, 192.168.YYY.YYY\"\n        #service.beta.kubernetes.io/aws-load-balancer-subnets: \"subnet-XXX, subnet-YYY\"\n\n        ## for static public IP addresses\n        #service.beta.kubernetes.io/aws-load-balancer-eip-allocations: \"eipalloc-XXX, eipalloc-YYY\"\n        #service.beta.kubernetes.io/aws-load-balancer-subnets: \"subnet-XXX, subnet-YYY\"\n\n      ## the ports the gateway Service listens on\n      ##  - defaults to the corresponding port under `gateway.ports`\n      ##  - these are the \"public\" ports which clients will connect to\n      ##    (they impact the user-facing HTTP links)\n      ##\n      ports:\n        http: 80\n        https: 443\n</code></pre> Google Cloud - Network Load Balancer <p>GKE, has a LoadBalancer Service type, which is configured with annotations like <code>networking.gke.io/load-balancer-type</code>. </p> <p>For example, you might set the following values to use an INTERNAL Passthrough Network Load Balancer:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## these values configure the deployKF Gateway Service\n    ##\n    gatewayService:\n      name: \"deploykf-gateway\"\n      type: \"LoadBalancer\"\n      annotations:\n        networking.gke.io/load-balancer-type: \"Internal\"\n\n        ## for external-dns integration (if not `--source=istio-gateway` config)\n        #external-dns.alpha.kubernetes.io/hostname: \"deploykf.example.com, *.deploykf.example.com\"\n\n      ## for static IP addresses\n      #loadBalancerIP: \"192.168.XXX.XXX\"\n      #loadBalancerSourceRanges: [\"192.168.XXX.XXX/32\"]\n\n      ## the ports the gateway Service listens on\n      ##  - defaults to the corresponding port under `gateway.ports`\n      ##  - these are the \"public\" ports which clients will connect to\n      ##    (they impact the user-facing HTTP links)\n      ##\n      ports:\n        http: 80\n        https: 443\n</code></pre> MetalLB <p>MetalLB is a popular LoadBalancer implementation for bare-metal Kubernetes clusters.</p> <p>For example, you might set the following values to use MetalLB:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## these values configure the deployKF Gateway Service\n    ##\n    gatewayService:\n      name: \"deploykf-gateway\"\n      type: \"LoadBalancer\"\n      annotations:\n        ## for static IP addresses (specific IP)\n        metallb.universe.tf/loadBalancerIPs: 192.168.XXX.XXX\n\n        ## for static IP addresses (from IP pool)\n        #metallb.universe.tf/address-pool: my-pool-XXX\n\n        ## for external-dns integration (if not `--source=istio-gateway` config)\n        #external-dns.alpha.kubernetes.io/hostname: \"deploykf.example.com, *.deploykf.example.com\"\n\n      ## the ports the gateway Service listens on\n      ##  - defaults to the corresponding port under `gateway.ports`\n      ##  - these are the \"public\" ports which clients will connect to\n      ##    (they impact the user-facing HTTP links)\n      ##\n      ports:\n        http: 80\n        https: 443\n</code></pre>"},{"location":"guides/platform/deploykf-gateway/#use-a-kubernetes-ingress","title":"Use a Kubernetes Ingress","text":"<p>Most Kubernetes platforms provide an Ingress class that can expose cluster services behind an application-layer load balancer. How you configure an Ingress will depend on the platform you are using, for example:</p> AWS - Application Load Balancer <p>The AWS Load Balancer Controller is commonly used to configure Ingress resources on EKS.</p> <p>Tip</p> <p>AWS EKS does NOT have the AWS Load Balancer Controller installed by default.  Follow the official instructions to install the controller.</p> <p>Because ALB does NOT support TLS-passthrough, you must manually create an AWS Certificate Manager (ACM) wildcard certificate for your domain. The <code>alb.ingress.kubernetes.io/certificate-arn</code> Ingress annotation will be used to select the certificate and allow the Ingress to terminate TLS before forwarding to the Gateway Service.</p> Hostname Certificate Field <code>*.deploykf.example.com</code> CN, SAN <code>deploykf.example.com</code> SAN <p>For example, you might set the following values to use an Application Load Balancer (ALB):</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## this value adds arbitrary manifests to the generated output\n    ##\n    extraManifests:\n      - |\n        apiVersion: networking.k8s.io/v1\n        kind: Ingress\n        metadata:\n          name: deploykf-gateway\n          annotations:\n            alb.ingress.kubernetes.io/scheme: internal\n            alb.ingress.kubernetes.io/target-type: ip\n            alb.ingress.kubernetes.io/backend-protocol: HTTPS\n\n            ## the 'deploykf-gateway' service has a named \"status-port\" pointing to Istio's 15021 health port\n            ## see: https://istio.io/latest/docs/ops/deployment/requirements/#ports-used-by-istio\n            alb.ingress.kubernetes.io/healthcheck-port: \"status-port\"\n            alb.ingress.kubernetes.io/healthcheck-protocol: HTTP\n            alb.ingress.kubernetes.io/healthcheck-path: \"/healthz/ready\"\n\n            alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n            alb.ingress.kubernetes.io/ssl-redirect: \"443\"\n            alb.ingress.kubernetes.io/certificate-arn: |\n              arn:aws:acm:REGION_NAME:ACCOUNT_ID:certificate/CERTIFICATE_ID\n        spec:\n          ingressClassName: alb                  \n          rules:\n            - host: \"deploykf.example.com\"\n              http:\n                paths:\n                  - path: \"/\"\n                    pathType: Prefix\n                    backend:\n                      service:\n                        name: \"deploykf-gateway\"\n                        port:\n                          name: https\n            - host: \"*.deploykf.example.com\"\n              http:\n                paths:\n                  - path: \"/\"\n                    pathType: Prefix\n                    backend:\n                      service:\n                        name: \"deploykf-gateway\"\n                        port:\n                          name: https\n\n    ## these values configure the deployKF Istio Gateway\n    ##\n    gateway:\n\n      ## the \"base domain\" for deployKF\n      ##  - this domain MUST align with your Ingress hostnames\n      ##  - this domain and its subdomains MUST be dedicated to deployKF\n      ##\n      hostname: deploykf.example.com\n\n      ## the ports that gateway Pods listen on\n      ##  - for an Ingress, these MUST be the standard 80/443\n      ##  - note, defaults from 'sample-values.yaml' are 8080/8443\n      ##\n      ports:\n        http: 80\n        https: 443\n\n      ## these values configure TLS\n      ##\n      tls:\n        ## ALB does NOT forward the SNI after TLS termination, \n        ## so we must disable SNI matching in the gateway\n        matchSNI: false\n\n    ## these values configure the deployKF Gateway Service\n    ##\n    gatewayService:\n      name: \"deploykf-gateway\"\n      ## WARNING: must be \"NodePort\" if \"alb.ingress.kubernetes.io/target-type\" is \"instance\"\n      type: \"ClusterIP\"\n      annotations: {}\n</code></pre> Google Cloud - Application Load Balancer <p>GKE, has an Ingress class that can be used to configure Ingress resources for external or internal access. </p> <p>In the following example, we are configuring the GKE Ingress to use the same TLS certificate as the deployKF Gateway Service (found in <code>Secret/deploykf-istio-gateway-cert</code>). Later in this guide you will learn how to make this certificate valid, and not self-signed.</p> <p>Warning</p> <p>Google Managed Certificates are only supported by EXTERNAL Application Load Balancers (ALB). Because using an EXTERNAL ALB would expose deployKF to the public internet, we instead strongly recommend configuring cert-manager to generate a valid certificate.</p> <p>For example, you might set the following values to use an INTERNAL Application Load Balancer:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## this value adds arbitrary manifests to the generated output\n    ##\n    extraManifests:\n      - |\n        apiVersion: networking.k8s.io/v1\n        kind: Ingress\n        metadata:\n          name: deploykf-gateway\n          annotations:\n            kubernetes.io/ingress.class: \"gce-internal\"\n            kubernetes.io/ingress.allow-http: \"false\"\n        spec:\n          tls:\n            ## NOTE: this secret is created as part of the deployKF installation\n            - secretName: \"deploykf-istio-gateway-cert\"\n          rules:\n            - host: \"deploykf.example.com\"\n              http:\n                paths:\n                  - path: \"/*\"\n                    pathType: ImplementationSpecific\n                    backend:\n                      service:\n                        name: \"deploykf-gateway\"\n                        port:\n                          name: https\n            - host: \"*.deploykf.example.com\"\n              http:\n                paths:\n                  - path: \"/*\"\n                    pathType: ImplementationSpecific\n                    backend:\n                      service:\n                        name: \"deploykf-gateway\"\n                        port:\n                          name: https\n\n    ## these values configure the deployKF Istio Gateway\n    ##\n    gateway:\n\n      ## the \"base domain\" for deployKF\n      ##  - this domain MUST align with your Ingress hostnames\n      ##  - this domain and its subdomains MUST be dedicated to deployKF\n      ##\n      hostname: deploykf.example.com\n\n      ## the ports that gateway Pods listen on\n      ##  - for an Ingress, these MUST be the standard 80/443\n      ##  - note, defaults from 'sample-values.yaml' are 8080/8443\n      ##\n      ports:\n        http: 80\n        https: 443\n\n    ## these values configure the deployKF Gateway Service\n    ##\n    gatewayService:\n      name: \"deploykf-gateway\"\n      type: \"NodePort\"\n      annotations:\n        cloud.google.com/app-protocols: '{\"https\":\"HTTPS\",\"http\":\"HTTP\"}'\n\n        ## this annotation may be required if you are using a Shared VPC\n        ##  https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balance-ingress#shared_vpc\n        #cloud.google.com/neg: '{\"ingress\": true}'\n</code></pre> Nginx - Kubernetes Community <p>Many clusters are configured with the Nginx Ingress Controller made by the Kubernetes community.</p> <p>Warning</p> <p>There are two independant Nginx Ingress Controller projects, each with their own configuration options. We have guides for both, so make sure you are using the correct one.</p> <ul> <li><code>kubernetes/ingress-nginx</code> - made by the Kubernetes community</li> <li><code>nginxinc/kubernetes-ingress</code> - made by NGINX, Inc.</li> </ul> <p>In the following example, we are configuring the Nginx Ingress to use the same TLS certificate as the deployKF Gateway Service (found in <code>Secret/deploykf-istio-gateway-cert</code>). Later in this guide you will learn how to make this certificate valid, and not self-signed.</p> <p>For example, you might set the following values:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## this value adds arbitrary manifests to the generated output\n    ##\n    extraManifests:\n      - |\n        apiVersion: networking.k8s.io/v1\n        kind: Ingress\n        metadata:\n          name: deploykf-gateway\n          annotations:\n            nginx.ingress.kubernetes.io/backend-protocol: HTTPS\n\n            ## nginx wil NOT proxy the SNI by default\n            ## see: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#backend-certificate-authentication\n            nginx.ingress.kubernetes.io/proxy-ssl-name: \"deploykf.example.com\"\n            nginx.ingress.kubernetes.io/proxy-ssl-server-name: \"on\"\n\n            ## this config is needed due to a bug in ingress-nginx\n            ## see: https://github.com/kubernetes/ingress-nginx/issues/6728\n            nginx.ingress.kubernetes.io/proxy-ssl-secret: \"deploykf-istio-gateway/deploykf-istio-gateway-cert\"\n        spec:\n          ingressClassName: nginx\n          tls:\n            ## NOTE: this secret is created as part of the deployKF installation\n            - secretName: \"deploykf-istio-gateway-cert\"\n          rules:\n            - host: \"deploykf.example.com\"\n              http:\n                paths:\n                  - path: \"/\"\n                    pathType: Prefix\n                    backend:\n                      service:\n                        name: \"deploykf-gateway\"\n                        port:\n                          name: https\n            - host: \"*.deploykf.example.com\"\n              http:\n                paths:\n                  - path: \"/\"\n                    pathType: Prefix\n                    backend:\n                      service:\n                        name: \"deploykf-gateway\"\n                        port:\n                          name: https\n\n    ## these values configure the deployKF Istio Gateway\n    ##\n    gateway:\n\n      ## the \"base domain\" for deployKF\n      ##  - this domain MUST align with your Ingress hostnames\n      ##  - this domain and its subdomains MUST be dedicated to deployKF\n      ##\n      hostname: deploykf.example.com\n\n      ## the ports that gateway Pods listen on\n      ##  - for an Ingress, these MUST be the standard 80/443\n      ##  - note, defaults from 'sample-values.yaml' are 8080/8443\n      ##\n      ports:\n        http: 80\n        https: 443\n\n    ## these values configure the deployKF Gateway Service\n    ##\n    gatewayService:\n      name: \"deploykf-gateway\"\n      type: \"ClusterIP\"\n      annotations: {}\n</code></pre> Nginx - NGINX, Inc. <p>You may be using the Nginx Ingress Controller made by NGINX, Inc.</p> <p>Warning</p> <p>There are two independant Nginx Ingress Controller projects, each with their own configuration options. We have guides for both, so make sure you are using the correct one.</p> <ul> <li><code>kubernetes/ingress-nginx</code> - made by the Kubernetes community</li> <li><code>nginxinc/kubernetes-ingress</code> - made by NGINX, Inc.</li> </ul> <p>In the following example, we are configuring the Nginx Ingress to use the same TLS certificate as the deployKF Gateway Service (found in <code>Secret/deploykf-istio-gateway-cert</code>). Later in this guide you will learn how to make this certificate valid, and not self-signed.</p> <p>For example, you might set the following values:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n\n    ## this value adds arbitrary manifests to the generated output\n    ##\n    extraManifests:\n      - |\n        apiVersion: networking.k8s.io/v1\n        kind: Ingress\n        metadata:\n          name: deploykf-gateway\n          annotations:\n            ## this annoataion must be set to the name of the Service\n            ## it tells Nginx to talk to the Service over HTTPS\n            nginx.org/ssl-services: \"deploykf-gateway\"\n        spec:\n          ingressClassName: nginx\n          tls:\n            ## NOTE: this secret is created as part of the deployKF installation\n            - secretName: \"deploykf-istio-gateway-cert\"\n          rules:\n            - host: \"deploykf.example.com\"\n              http:\n                paths:\n                  - path: \"/\"\n                    pathType: Prefix\n                    backend:\n                      service:\n                        name: \"deploykf-gateway\"\n                        port:\n                          name: https\n            - host: \"*.deploykf.example.com\"\n              http:\n                paths:\n                  - path: \"/\"\n                    pathType: Prefix\n                    backend:\n                      service:\n                        name: \"deploykf-gateway\"\n                        port:\n                          name: https\n\n    ## these values configure the deployKF Istio Gateway\n    ##\n    gateway:\n\n      ## the \"base domain\" for deployKF\n      ##  - this domain MUST align with your Ingress hostnames\n      ##  - this domain and its subdomains MUST be dedicated to deployKF\n      ##\n      hostname: deploykf.example.com\n\n      ## the ports that gateway Pods listen on\n      ##  - for an Ingress, these MUST be the standard 80/443\n      ##  - note, defaults from 'sample-values.yaml' are 8080/8443\n      ##\n      ports:\n        http: 80\n        https: 443\n\n      ## these values configure TLS\n      ##\n      tls:\n        ## nginx does NOT forward the SNI after TLS termination, \n        ## so we must disable SNI matching in the gateway\n        matchSNI: false\n\n    ## these values configure the deployKF Gateway Service\n    ##\n    gatewayService:\n      name: \"deploykf-gateway\"\n      type: \"ClusterIP\"\n      annotations: {}\n</code></pre> <p>There are a few important things to note when using an Ingress:</p> Considerations when terminating TLS at the Ingress <p>If you put the deployKF Gateway behind a proxy which terminates TLS (like AWS ALB), you will probably need to disable SNI Matching. This is because most proxies don't forward the original request's Server Name Indication (SNI) to the backend service after TLS termination.</p> <p>To disable SNI Matching, set <code>deploykf_core.deploykf_istio_gateway.gateway.tls.matchSNI</code> to <code>false</code>:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n    gateway:\n      tls:\n        matchSNI: false\n</code></pre> Ingress must talk to the Gateway over HTTPS <p>By default, the deployKF Gateway redirects all HTTP requests to HTTPS. This means any proxy you place in front of the gateway will need to talk to the gateway over HTTPS.</p> <p>By default, the deployKF Istio Gateway uses a self-signed certificate, to make your proxy trust this certificate you will probably need to do ONE of the following:</p> <ol> <li>Configure a valid certificate for the gateway</li> <li>Trust the certificate in <code>Secret/deploykf-istio-gateway-cert</code> (Namespace: <code>deploykf-istio-gateway</code>)</li> <li>Trust the CA found in <code>Secret/selfsigned-ca-issuer-root-cert</code> (Namespace: <code>cert-manager</code>)</li> <li>Disable backend certificate validation in your proxy</li> </ol> <p>If your proxy is simply unable to use HTTPS backends, and you don't require end-to-end encryption, you may disable the automatic redirection by setting <code>deploykf_core.deploykf_istio_gateway.gateway.tls.redirect</code> to <code>false</code>:</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n    gateway:\n      tls:\n        redirect: false\n</code></pre>"},{"location":"guides/platform/deploykf-gateway/#configure-dns-records","title":"Configure DNS Records","text":"<p>Now that the deployKF Gateway Service has an IP address, you must configure DNS records which point to it.</p> <p>You can't use the Gateway's IP address</p> <p>You can't access deployKF using the Gateway's IP address. This is because deployKF hosts multiple services on the same IP address using virtual hostname routing.</p>"},{"location":"guides/platform/deploykf-gateway/#base-domain-and-ports","title":"Base Domain and Ports","text":"<p>You will need to tell deployKF which hostnames to use, and which ports to listen on.</p> <p>The following values set the base domain to <code>deploykf.example.com</code> (default), and the ports to <code>80</code> and <code>443</code> (not default):</p> <pre><code>deploykf_core:\n  deploykf_istio_gateway:\n    gateway:\n      ## the \"base domain\" for deployKF\n      ##  - this domain and its subdomains MUST be dedicated to deployKF\n      ##\n      hostname: deploykf.example.com\n\n      ## the ports that gateway Pods listen on\n      ##  - 80/443 are the defaults, but if you are using 'sample-values.yaml' \n      ##    as a base, the defaults are 8080/8443, so you will need to \n      ##    override them to use the standard ports\n      ##\n      ports:\n        http: 80\n        https: 443\n\n    #gatewayService:\n\n      ## the ports the gateway Service listens on\n      ##  - defaults to the corresponding port under `gateway.ports`\n      ##  - these are the \"public\" ports which clients will connect to\n      ##    (they impact the user-facing HTTP links)\n      ##\n      #ports:\n      #  http: ~\n      #  https: ~\n</code></pre> <p>Depending on which tools you have enabled, the gateway may serve the following hostnames:</p> Hostname Description <code>deploykf.example.com</code> Base Domain (dashboard and other apps) <code>argo-server.deploykf.example.com</code> Argo Server <code>minio-api.deploykf.example.com</code> MinIO API <code>minio-console.deploykf.example.com</code> MinIO Console"},{"location":"guides/platform/deploykf-gateway/#use-external-dns","title":"Use External-DNS Option 1 - Istio Gateway Source: Option 2 - Ingress Source:Option 3 - Manual Annotation:","text":"<p>External-DNS is a Kubernetes controller that automatically configures DNS records for Kubernetes resources. The following steps explain how to install and configure External-DNS to set DNS records for the deployKF Gateway Service.</p> Step 1 - Install External-DNS <p>The External-DNS documentation provides instructions for installing External-DNS on various platforms.</p> <p>The following table links to the documentation for some popular DNS providers:</p> Cloud Platform DNS Provider Documentation Amazon Web Services Route53 Google Cloud Cloud DNS Microsoft Azure Azure DNS, Azure Private DNS Any Cloudflare, Akamai Edge DNS <p>Deletion of DNS Records</p> <p>Unless the <code>--policy=upsert-only</code> argument is used, external-dns will delete DNS records when a resource is deleted (or changed in a way that would affect the records). Records take time to propagate, so you may experience downtime if you delete resources and then recreate them.</p> Step 2 - Configure External-DNS <p>There are a few ways to configure External-DNS so that it sets DNS records for the deployKF Gateway Service.</p> <p></p> <p>You may configure External-DNS to extract hostnames names from Istio <code>Gateway</code> resources. If you do this, a separate DNS record is created for each domain selected by our Istio <code>Gateway</code>.</p> <p>To connect External-DNS with Istio, you will need to:</p> <ol> <li>Update your <code>Deployment/external-dns</code> to include the <code>--source=istio-gateway</code> start argument</li> <li>Update your <code>ClusterRole/external-dns</code> to allow access to Istio <code>Gateway</code> and <code>VirtualService</code> resources</li> </ol> <p></p> <p>You may configure External-DNS to automatically extract the domain names from Kubernetes <code>Ingress</code> resources. If you do this, a separate DNS record is created for each hostname in the Ingress.</p> <p>To connect External-DNS with Ingress, you will need to:</p> <ol> <li>Update your <code>Deployment/external-dns</code> to include the <code>--source=ingress</code> start argument</li> <li>Update your <code>ClusterRole/external-dns</code> to allow access to Kubernetes <code>Ingress</code> resources</li> </ol> <p></p> <p>You can manually configure External-DNS by annotating the <code>Service</code> or <code>Ingress</code> resource with the <code>external-dns.alpha.kubernetes.io/hostname</code> annotation. Multiple hostnames can be specified in a single annotation using a comma-separated list.</p> <p>The annotation can be set in one of the following ways:</p> <ul> <li>Service: setting the <code>deploykf_core.deploykf_istio_gateway.gatewayService.annotations</code> value</li> <li>Ingress: manually annotating your Ingress resource</li> </ul> <p>See the manually create DNS records section for information about which records to create.</p>"},{"location":"guides/platform/deploykf-gateway/#manually-create-dns-records","title":"Manually Create DNS Records","text":"<p>Alternatively, you may manually configure DNS records with your DNS provider. The following steps explain how to manually create DNS records for the deployKF Gateway Service.</p> Step 1 - Get Service IP <p>You will need to find the IP address of the deployKF Gateway Service, this can be done by running the following command:</p> <pre><code>kubectl get service deploykf-gateway --namespace deploykf-istio-gateway\n</code></pre> <p>The <code>EXTERNAL-IP</code> field will contain the IP address of the deployKF Gateway Service.</p> <pre><code>NAME               TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)                                         AGE\ndeploykf-gateway   LoadBalancer   10.43.24.148   172.23.0.2    15021:30XXXX/TCP,80:30XXXX/TCP,443:30XXXX/TCP   1d\n</code></pre> Step 2 - Configure DNS Records <p>You can now configure DNS records with your DNS provider that target the IP address of the deployKF Gateway Service.</p> <p>You need to create records for BOTH the base domain AND subdomains. You can avoid the need to specify each subdomain by using a wildcard DNS record, but you will still need to specify the base domain.</p> <p>For example, you might set the following DNS records:</p> Type Name Value A <code>*.deploykf.example.com</code> IP Address of the deployKF Gateway Service A <code>deploykf.example.com</code> IP Address of the deployKF Gateway Service <p>Propagation Time</p> <p>DNS records can take time to propagate, so you may experience downtime if you delete records and then recreate them.</p>"},{"location":"guides/platform/deploykf-gateway/#configure-tls-certificates","title":"Configure TLS Certificates","text":"<p>deployKF uses  cert-manager to manage TLS certificates.</p> <p>Existing cert-manager Installation</p> <p>If your cluster already has a cert-manager installation, you should follow these instructions to disable the deployKF cert-manager installation and use your own.</p>"},{"location":"guides/platform/deploykf-gateway/#use-lets-encrypt-with-cert-manager","title":"Use Let's Encrypt with Cert-Manager","text":"<p>By default, the deployKF Gateway will use a self-signed certificate. Therefore, if you are not using an external proxy to terminate TLS, you will likely want to configure a valid TLS certificate for the gateway itself.</p> <p>For almost everyone, the best Certificate Authority (CA) is Let's Encrypt. The following steps show how to use Let's Encrypt to generate valid TLS certificates for the Gateway.</p> Step 1 - Connect Cert-Manager to DNS Provider <p>Because deployKF uses a wildcard <code>Certificate</code>, you MUST use the <code>DNS-01</code> challenge to verify domain ownership (rather than <code>HTTP-01</code>). This requires you to configure cert-manager so that it is able to create DNS records.</p> <p>The cert-manager documentation provides instructions for configuring <code>DNS-01</code> challenges for various DNS providers. The following table links to the documentation for some popular DNS providers:</p> Cloud Platform DNS Provider Documentation Amazon Web Services Route53 Google Cloud Cloud DNS Microsoft Azure Azure DNS Any Cloudflare, Akamai Edge DNS <p>ServiceAccount Annotations</p> <p>To use Pod-based authentication with your DNS Provider (for example, to use IRSA on EKS), you may need to annotate the cert-manager ServiceAccount.</p> <p>Custom ServiceAccount annotations may be applied to the embedded cert-manager with the <code>deploykf_dependencies.cert_manager.controller.serviceAccount.annotations</code> value:</p> <pre><code>deploykf_dependencies:\n  cert_manager:\n    controller:\n\n      ## EXAMPLE: for Azure AD Workload Identity\n      #podLabels:\n      #  azure.workload.identity/use: \"true\"\n\n      serviceAccount:\n        annotations: \n          ## EXAMPLE: for AWS IRSA\n          #eks.amazonaws.com/role-arn: \"arn:aws:iam::MY_ACCOUNT_ID:role/MY_ROLE_NAME\"\n\n          ## EXAMPLE: for GCP Workload Identity\n          #iam.gke.io/gcp-service-account=GSA_NAME@GSA_PROJECT.iam.gserviceaccount.com\n\n          ## EXAMPLE: for Azure AD Workload Identity\n          #azure.workload.identity/client-id: \"00000000-0000-0000-0000-000000000000\"\n          #azure.workload.identity/tenant-id: \"00000000-0000-0000-0000-000000000000\"\n</code></pre> Step 2 - Create a ClusterIssuer <p>Once cert-manager is connected to your DNS provider, you must create a <code>ClusterIssuer</code> resource that can generate certificates for your domain from Let's Encrypt.</p> <p>For example, you may create a <code>ClusterIssuer</code> resource like this when using Google Cloud DNS:</p> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: my-cluster-issuer\nspec:\n  acme:\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    email: user@example.com\n    privateKeySecretRef:\n      name: letsencrypt-staging\n      key: tls.key\n    solvers:\n      - dns01:\n          cloudDNS:\n            project: my-project-id\n            serviceAccountSecretRef:\n              name: my-service-account-secret\n              key: service-account.json\n        selector:\n          dnsNames:\n            - \"*.deploykf.example.com\"\n            - \"deploykf.example.com\"\n</code></pre> <p>Issuer Kind</p> <p>Most cert-manager examples show an <code>Issuer</code> resource.  Note that any issuer may be converted to its equivalent cluster version by changing the <code>kind</code> field from <code>\"Issuer\"</code> to <code>\"ClusterIssuer\"</code> and removing the <code>metadata.namespace</code> field.</p> Step 3 - Configure the Istio Gateway <p>Once you have a <code>ClusterIssuer</code> resource that can generate certificates for your domain, you must configure the deployKF Istio Gateway to use it. This is done by using the <code>deploykf_dependencies.cert_manager.clusterIssuer</code> values.</p> <p>For example, if you created a <code>ClusterIssuer</code> named <code>my-cluster-issuer</code>, you would set the following values:</p> <pre><code>deploykf_dependencies:\n  cert_manager:\n    clusterIssuer:\n      ## this tells deployKF that you have created a ClusterIssuer\n      enabled: false\n\n      ## this value should match the name of your ClusterIssuer\n      issuerName: \"my-cluster-issuer\"\n</code></pre>"},{"location":"guides/platform/deploykf-gateway/#use-a-custom-certificate","title":"Use a Custom Certificate","text":"<p>If you already have a valid TLS certificate for your domain, and don't want to configure cert-manager, you will need to use an Ingress to terminate TLS before the Gateway using your certificate.</p> <p>Please note, not all Ingress controllers support reading a Kubernetes Secret for TLS termination, so this process may vary depending on your platform.</p> Step 1 - Get your TLS Certificate <p>Create a wildcard certificate with the following fields, replacing <code>deploykf.example.com</code> with the base domain you have configured.</p> Field Value Common Name (CN) <code>*.deploykf.example.com</code> Subject Alternative Name (SAN) DNS Name: <code>*.deploykf.example.com</code>DNS Name: <code>deploykf.example.com</code> <p>You will need the <code>.crt</code> and <code>.key</code> files for your TLS certificate.</p> <p>The <code>.crt</code> file should contain the public certificate in PEM format, it should look something like this:</p> <pre><code>-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----\n</code></pre> <p>The <code>.key</code> file should contain the private signing key in PEM format, it should look something like this:</p> <pre><code>-----BEGIN RSA PRIVATE KEY-----\n...\n-----END RSA PRIVATE KEY-----\n</code></pre> Step 2 - Create Kubernetes Secret <p>First, you will need to create a Kubernetes Secret containing your TLS certificate and key.</p> <p>The following command will create a Secret named <code>my-tls-secret</code> in the <code>deploykf-istio-gateway</code> Namespace:</p> <pre><code>kubectl create secret tls \"my-tls-secret\" \\\n  --cert /path/to/tls.crt \\\n  --key /path/to/tls.key \\\n  --namespace \"deploykf-istio-gateway\"\n</code></pre> Step 3 - Configure the Ingress <p>Next, you will need to configure an Ingress resource to use the <code>my-tls-secret</code> Secret for TLS termination. You may start from one of the above examples and update the <code>tls</code> field to use your Secret.</p> <p>For example, your updated Ingress resource will probably look something like this:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: deploykf-gateway\n  namespace: deploykf-istio-gateway\n  annotations:\n    ...\n    ...\nspec:\n  ingressClassName: XXXXXX\n\n  tls:\n    ## this tells the Ingress to use `my-tls-secret` for TLS termination\n    - secretName: \"my-tls-secret\"\n\n    ## NOTE: some Ingress controllers allow multiple certificates to be specified\n    ##       for different hostnames\n    #- secretName: \"other-tls-secret\"\n    #  hosts:\n    #    - \"*.deploykf.example.com\"\n    #    - \"deploykf.example.com\"\n\n  rules:\n    ...\n    ...\n</code></pre>"},{"location":"guides/platform/deploykf-gateway/#terminate-tls-before-the-gateway","title":"Terminate TLS before the Gateway","text":"<p>It is common to terminate TLS at a proxy in front of the deployKF Gateway. For example, you might be using an Ingress to expose the deployKF Gateway Service (like AWS ALB), or have a proxy like Cloudflare in front of your cluster.</p> <p>In both of these cases it may be unnecessary to configure a valid TLS certificate for the deployKF Gateway. Because, off-cluster clients will see the certificate of the proxy, not the Gateway itself.</p> <p>In-Mesh Traffic to Gateway</p> <p>When Pods inside the Istio mesh make requests to the gateway hostname/ports, this traffic bypasses your public LoadBalancer/Ingress and goes directly to the Gateway Deployment Pods (through the mesh).</p> <p>Therefore, even if your Ingress has its own valid TLS termination (e.g. from AWS ALB), in-mesh Pods will see the certificate of the Istio Gateway itself (which by default is self-signed).</p> Why does this happen? <p>Traffic from in-mesh Pods gets intercepted by the Istio sidecar because of this <code>ServiceEntry</code>, and because we enable Istio's DNS Proxying feature by setting <code>ISTIO_META_DNS_CAPTURE</code> and <code>ISTIO_META_DNS_AUTO_ALLOCATE</code> to <code>true</code>.</p> How can I prevent these TLS errors? <p>All core deployKF apps are configured to trust the default self-signed certificate (e.g. oauth2-proxy). However, your own in-mesh apps will need to do ONE of the following (unless you use a valid certificate):</p> <ol> <li>Disable Istio DNS Proxying on your app's Pods:<ul> <li>Set the <code>proxy.istio.io/config</code> Pod annotation to <code>{\"proxyMetadata\": {\"ISTIO_META_DNS_CAPTURE\": \"false\", \"ISTIO_META_DNS_AUTO_ALLOCATE\": \"false\"}}</code></li> </ul> </li> <li>Disable certificate validation in your app:<ul> <li>See your app's documentation for information on how to do this.</li> </ul> </li> <li>Trust the CA found in <code>Secret/selfsigned-ca-issuer-root-cert</code> (Namespace: <code>cert-manager</code>):<ul> <li>See your app's documentation for information on how to do this.</li> <li>Note, we create a trust-manager <code>Bundle</code> for this CA by default;   All Namespaces with the label <code>deploykf.github.io/inject-root-ca-cert: \"enabled\"</code> will have a <code>ConfigMap</code> named <code>deploykf-gateway-issuer-root-ca-cert</code> with a key named <code>root-cert.pem</code> containing the CA certificate.</li> </ul> </li> </ol>"},{"location":"guides/platform/deploykf-profiles/","title":"User Authorization and Profile Management","text":"<p>Learn how to manage profiles and assign users to them in deployKF.</p> <p>Related Guides</p> <p>Users are identified and selected into profiles by an email-like string which is verified by the authentication system. Before reading this guide, you may want to define static user credentials or connect with an external identity provider.</p>"},{"location":"guides/platform/deploykf-profiles/#introduction","title":"Introduction","text":"<p>A deployKF profile has a 1:1 relationship with a Kubernetes namespace. The profiles which users are members of determine their level of access to resources/tools in the cluster.</p> <p>The core entities of the profile system are:</p> Entity(Click for Details) Description User User entities are identified by email address, and may be assigned to groups or profiles. Group Group entities are logical collections of users, and may be assigned to profiles. Profile Profiles define the access level for the users/groups assigned to them. <p>No Profile = No Access</p> <p>If a user is not a member of any profiles, they will NOT have any access, even though they may be able to log in.</p>"},{"location":"guides/platform/deploykf-profiles/#user-entities","title":"User Entities","text":"<p>The <code>deploykf_core.deploykf_profiles_generator.users</code> value defines \"user\" entities.</p> <p>Email Address</p> <p>Users are identified by the email address which is provided by the identity provider or static account.</p> <p>This means that each <code>email</code> must be unique and only associated to a single <code>id</code>.</p> <p>For example, you might use the following values to define three users:</p> <pre><code>deploykf_core:\n  deploykf_profiles_generator:\n    users:\n      - id: user-1\n        email: \"user1@example.com\"\n\n      - id: user-2\n        email: \"user2@example.com\"\n\n      - id: user-3\n        email: \"user3@example.com\"\n</code></pre>"},{"location":"guides/platform/deploykf-profiles/#group-entities","title":"Group Entities","text":"<p>The <code>deploykf_core.deploykf_profiles_generator.groups</code> value defines \"group\" entities, which are logical collections of \"user\" entities.</p> <p>Groups from Identity Providers</p> <p>Currently, deployKF can NOT use any groups sent by your external identity provider. You must manually define the groups and their members in the <code>deploykf_profiles_generator</code> values.</p> <p>For example, you might use the following values to define two groups:</p> <pre><code>deploykf_core:\n  deploykf_profiles_generator:\n    groups:\n      - id: team-1--admins\n        users:\n          - user-1\n\n      - id: team-1--users\n        users:\n          - user-1\n          - user-2\n          - user-3\n</code></pre>"},{"location":"guides/platform/deploykf-profiles/#profile-definitions","title":"Profile Definitions","text":"<p>The <code>deploykf_core.deploykf_profiles_generator.profiles</code> value defines the profiles (namespaces) to create, and the groups/users to assign to them.</p> <p>Highest Level of Access</p> <p>If a user has multiple memberships in the same profile, the highest level of access will be used.</p> <p>Use Profile Generator Only</p> <p>You must ONLY use the <code>deploykf_core.deploykf_profiles_generator</code> values to manage profile definitions or user assignments. Any manual changes using the UI or other manifests will result in undefined behaviour.</p> <p>For example, you might use the following values to define two profiles:</p> <pre><code>deploykf_core:\n  deploykf_profiles_generator:\n    profiles:\n      - name: team-1\n        members:\n          - group: team-1--users\n            access:\n              role: edit\n              notebooksAccess: true\n\n      - name: team-1-prod\n        members:\n          - group: team-1--admins\n            access:\n              role: edit\n              notebooksAccess: true\n\n          - group: team-1--users\n            access:\n              role: view\n              notebooksAccess: false\n</code></pre> <p>Profile Owners</p> <p>DO NOT set or change the owner of any profile:</p> <ul> <li>It is NEVER nessasary to be an owner of a profile, being an owner grants no useful permissions and actually prevents you from accessing the MinIO and Argo Server UIs.</li> <li>It is NOT possible to change the owner of a profile once it is created (<code>kubeflow/kubeflow#6576</code>).</li> <li>By default, <code>\"admin@example.com\"</code> is the \"owner\" of all profiles, we recommend that you leave the default owner as <code>admin@example.com</code>.</li> </ul> <p>In a future release, any email which is the owner of a profile will be blocked from logging in.  Until then, we reccomend you remove the <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> entry for <code>\"admin@example.com\"</code>, so it can never be used to log in.</p>"},{"location":"guides/platform/image-pull-secrets/","title":"Image Pull Secrets","text":"<p>Learn how to configure image pull secrets in deployKF.</p>"},{"location":"guides/platform/image-pull-secrets/#overview","title":"Overview","text":"<p>You may need to configure image pull secrets in deployKF. Image pull secrets tell Kubernetes how to authenticate with a container registry when pulling images.</p> <p>For example, you may want to avoid Docker Hub rate limits on public images, or use a private container registry that requires authentication.</p>"},{"location":"guides/platform/image-pull-secrets/#configure-image-pull-secrets","title":"Configure Image Pull Secrets","text":"<p>deployKF provides a built-in  Kyverno policy to clone image-pull-secrets into every namespace, and automatically add them to the <code>spec.imagePullSecrets</code> field of every Pod in the cluster. See the <code>ClusterPolicy</code> for more details.</p> <p>These steps will guide you through creating and using an image pull secret in deployKF.</p> Step 1 - Authenticate with Container Registry <p>You will need to use <code>docker login</code> to authenticate with your container registry.</p> <p>For example, to authenticate with Docker Hub:</p> <pre><code># login to your container registry\ndocker login\n\n# review the docker config file\ncat ~/.docker/config.json\n</code></pre> <p>Other Container Registries</p> <p>For information on using <code>docker login</code> with other container registries, see the following documentation:</p> <ul> <li>Google Container Registry</li> <li>GitHub Container Registry </li> <li>Quay</li> </ul> Step 2 - Create Kubernetes Secret <p>Next, you will need to create a Kubernetes secret from your <code>~/.docker/config.json</code> file.</p> <p>For example, to create a secret called <code>my-docker-config</code> in the <code>argocd</code> namespace:</p> <pre><code>kubectl create secret generic \"my-docker-config\" \\\n  --namespace \"argocd\" \\\n  --type=kubernetes.io/dockerconfigjson \\\n  --from-file=.dockerconfigjson=~/.docker/config.json\n</code></pre> <p>Credentials Store</p> <p>If <code>~/.docker/config.json</code> contains a <code>credsStore</code> field, you won't be able to create the secret from the file directly, see the upstream Kubernetes documentation for more details.</p> <p>For example, to create a secret for <code>docker.io</code> with an Access Token:</p> <pre><code>kubectl create secret docker-registry \"my-docker-config\" \\\n  --namespace \"argocd\" \\\n  --docker-server=\"https://index.docker.io/v1/\" \\\n  --docker-username=\"MY_DOCKER_USERNAME\" \\\n  --docker-password=\"MY_DOCKER_ACCESS_TOKEN\"\n</code></pre> <p>For example, to create a secret for <code>ghcr.io</code> with a Personal Access Token (PAT):</p> <pre><code>kubectl create secret docker-registry \"my-ghcr-config\" \\\n  --namespace \"argocd\" \\\n  --docker-server=\"https://ghcr.io/v2/\" \\\n  --docker-username=\"MY_GITHUB_USERNAME\" \\\n  --docker-password=\"MY_GITHUB_PAT\"\n</code></pre> <p>For example, to create a secret for <code>&lt;region&gt;-docker.pkg.dev</code> (GCP) with a Service Account Key:</p> <pre><code>kubectl create secret docker-registry \"my-gcr-config\" \\\n  --namespace \"argocd\" \\\n  --docker-server=\"https://&lt;region&gt;-docker.pkg.dev\" \\\n  --docker-username=\"_json_key\" \\\n  --docker-password=\"$(cat ~/path/to/service-account-key.json)\"\n</code></pre> Step 3 - Configure deployKF <p>Finally, you will need to configure deployKF to use the new secret.</p> <p>The <code>deploykf_dependencies.kyverno.clusterPolicies.imagePullSecrets</code> values are used to configure our Kyverno ClusterPolicy.</p> <p>The following values will enable the policy and use the <code>my-docker-config</code> secret (from the <code>argocd</code> namespace):</p> <pre><code>deploykf_dependencies:\n  kyverno:\n    clusterPolicies:\n\n      imagePullSecrets:\n        ## if the policy is enabled\n        enabled: true\n\n        ## a list of namespaces to exclude from this policy\n        #excludeNamespaces:\n        #  - \"argocd\"\n        #  - \"kube-system\"\n\n        ## a list of registry credentials\n        registryCredentials:\n          - existingSecret: \"my-docker-config\"\n            existingSecretNamespace: \"argocd\"\n</code></pre> <p>Exclude Namespaces</p> <p>The <code>imagePullSecrets.excludeNamespaces</code> value will exclude namespaces from the policy.</p> <p>By default, the <code>argocd</code> and <code>kube-system</code> namespaces are excluded  (WARNING: if you set this key, make sure you list them, as the default values will be overridden). The <code>kyverno</code> namespace is always excluded, so you don't need to list it.</p> <p>This value supports the following wildcards:</p> <ul> <li><code>*</code> - matches zero or many characters</li> <li><code>?</code> - matches at least one character</li> </ul>"},{"location":"guides/platform/offline/","title":"Air-Gapped Clusters and Private Registries","text":"<p>Learn how to use deployKF in offline and air-gapped clusters. Use private container registries and Helm repositories.</p>"},{"location":"guides/platform/offline/#overview","title":"Overview","text":"<p>In some situations, you may need to use deployKF in an offline or air-gapped cluster. This guide will help you understand how to use deployKF in these scenarios.</p> <p>The main topics covered in this guide are:</p> <ul> <li>ArgoCD Plugin Mode</li> <li>Private Container Registries</li> <li>Private Helm Repositories</li> </ul>"},{"location":"guides/platform/offline/#argocd-plugin-mode","title":"ArgoCD Plugin Mode","text":"<p>If you are using ArgoCD Plugin Mode in an offline or air-gapped cluster, the plugin will be unable to download the generator package from the <code>deployKF/deployKF</code> GitHub releases page.</p> <p>If you still want the convenience of using the plugin (as opposed to Manifests Repo Mode), you can download the generator package manually and host it on an internal git repo.</p> Step 1 - Install the Plugin <p>When you install the plugin, you will likely need to mirror the container images used by the plugin to a private registry.</p> <p>See the manifests of the plugin for the list of images to update and mirror.</p> Step 2 - Download the Generator Package <p>For the version of deployKF that you want to use, download the <code>deploykf-&lt;version&gt;-generator.zip</code> generator package from the <code>deployKF/deployKF</code> GitHub releases page.</p> <p>For example, to download the generator package for version <code>0.1.5</code>, you might run the following command:</p> <pre><code>curl -fL -o \"deploykf-0.1.5-generator.zip\" \\\n  \"https://github.com/deployKF/deployKF/releases/download/v0.1.5/deploykf-0.1.5-generator.zip\"\n</code></pre> Step 3 - Update App-of-Apps <p>After pushing the <code>deploykf-0.1.5-generator.zip</code> file to your internal git repository, replace the <code>source_version</code> parameter with <code>source_path</code> in your app-of-apps <code>Application</code>.</p> <p>For example, your app-of-apps <code>Application</code> might look like this:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: deploykf-app-of-apps\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: deploykf-app-of-apps\n    app.kubernetes.io/part-of: deploykf\nspec:\n  project: ...\n\n  source:\n\n    ## the git repository containing the generator package\n    ##\n    repoURL: \"https://git.example.com/deploykf.git\"\n    targetRevision: \"main\"\n    path: \".\"\n\n    ## plugin configuration\n    ##\n    plugin:\n      name: \"deploykf\"\n      parameters:\n\n        ## the path to the generator package within the `repoURL` repository\n        - name: \"source_path\"\n          string: \"./deploykf-0.1.5-generator.zip\"\n\n        ## paths to values files within the `repoURL` repository\n        - name: \"values_files\"\n          array:\n            - ...\n\n        ## a string containing the contents of a values file\n        - name: \"values\"\n          string: |\n            ...\n\n  destination:\n    ...\n</code></pre>"},{"location":"guides/platform/offline/#private-container-registries","title":"Private Container Registries","text":"<p>In some situations, like when your cluster is not connected to the internet, you may need to use a private container registry for all container images.</p> <p>Advanced Topic</p> <p>Using a private container registry is an advanced scenario, and is NOT recommended for most users (because of the number of images in deployKF). If at all possible, we recommend using the default image locations.</p> <p>For your reference, the default image locations are spread across multiple container registries:</p> <ul> <li>Docker Hub (<code>docker.io</code>)</li> <li>Google Container Registry (<code>gcr.io</code>)</li> <li>GitHub Container Registry (<code>ghcr.io</code>)</li> <li>Quay (<code>quay.io</code>)</li> </ul> Step 1 - Get list of Images <p>The first step is to determine which images and tags need to be mirrored to your private registry. Currently, we don't have an out-of-the-box solution for this.</p> <p>However, we have created values to override all images in deployKF. Almost all image values are under the <code>&lt;path_to_tool&gt;.images</code> key of each component, but some are in a different location (these end in an <code>image</code> suffix, to make them easier to find). For example, the images for Kubeflow Pipelines are under <code>kubeflow_tools.pipelines.images</code> and <code>kubeflow_tools.pipelines.kfpV2.xxxxImage</code>.</p> <p>Tip</p> <p>Search for <code>images:</code> and <code>image:</code> in the <code>default_values.yaml</code> to find all current image values.</p> <p>You will notice that the <code>tag</code> is not specified for some images. This is because Helm/Kustomize will automatically set this at deploy time based on the version of the component. This makes determining the correct tag to mirror a bit more difficult. The only way to determine the correct tag is to render the manifests for each component and extract the images which are actually used.</p> <p>For example, to print the images for Kubeflow Pipelines (which is a Kustomize app), you might run the following commands:</p> <pre><code># Render the manifests\ndeploykf generate ... --output-dir ./GENERATOR_OUTPUT\n\n# Go to the component directory\ncd ./GENERATOR_OUTPUT/manifests/kubeflow-tools/pipelines\n\n# Print the images\nkustomize build . \\\n  | perl -nle $'print $1 if /image: [\"\\']?([^ {\"\\']+)[\"\\']?/'\n</code></pre> <p>For example, to print the images for Istio (which is a Helm chart), you might run the following commands:</p> <pre><code># Render the manifests\ndeploykf generate ... --output-dir ./GENERATOR_OUTPUT\n\n# Go to the component directory\ncd ./GENERATOR_OUTPUT/manifests/deploykf-dependencies/istio\n\n# Update the Helm dependencies\nhelm dependency update .\n\n# Print the images\n# NOTE: the istio chart needs the namespace to be set\nhelm template . --namespace istio-system \\\n  | perl -nle $'print $1 if /image: [\"\\']?([^ {\"\\']+)[\"\\']?/'\n</code></pre> <p>Not all Images are in the Manifests</p> <p>Some images are not technically \"part of the manifests\", that is, not used in the <code>image</code> field of a PodSpec. This means they will NOT show up with the above commands. However, all such images should have an associated deployKF value, so you can find them in the <code>default_values.yaml</code>.</p> <p>For example, Istio injects sidecar containers into Pod definitions at runtime (and the image used is configured by a ConfigMap). Its associated image value is <code>deploykf_dependencies.istio.images.istioProxy</code>.</p> <p>Regex</p> <p>The above commands are using the regex <code>/image: [\"']?([^ {\"']+)[\"']?/</code> to extract parts of the manifest which look like <code>image: \"xxxx\"</code>, <code>image: 'xxxx'</code>, or <code>image: xxxx</code>.</p> <p>We are not sure if this regex is sufficient for all cases, please let us know if you find a better one!</p> Step 2 - Mirror the Images <p>Once you have the list of images and tags, you will need to mirror them to your private container registry. You may use the <code>docker</code> command to pull and push the images.</p> <p>For example, you might create a script which loops through each image and does the following:</p> <pre><code># set the source image\nSOURCE_REGISTRY=\"ghcr.io\" # depending on image: \"docker.io\", \"grc.io\", \"ghcr.io\", \"quay.io\"\nSOURCE_IMAGE=\"deploykf/kubeflow-pipelines/cache-server:X.Y.Z\"\n\n# set the destination image\nDEST_REGISTRY=\"docker.example.com\"\nDEST_IMAGE=\"${SOURCE_IMAGE}\"\n\n# pull the images\ndocker pull \"${SOURCE_REGISTRY}/${SOURCE_IMAGE}\"\n\n# tag the images\ndocker tag \"${SOURCE_REGISTRY}/${SOURCE_IMAGE}\" \"${DEST_REGISTRY}/${DEST_IMAGE}\"\n\n# push the images\n# NOTE: you may need to login first with `docker login ...`\ndocker push \"${DEST_REGISTRY}/${DEST_IMAGE}\"\n</code></pre> <p>Image Names</p> <p>We recommend using the same image name as the source image, as this will make it easier to update the deployKF values.</p> Step 3 - Set Image Values <p>Finally, you will need to update all the deployKF image values to use the mirrored images.</p> <p>Almost all image values are under the <code>&lt;path_to_tool&gt;.images</code> key of each component, but some are in a different location (these end in an <code>image</code> suffix, to make them easier to find).</p> <p>Tip</p> <p>Search for <code>images:</code> and <code>image:</code> in the <code>default_values.yaml</code> to find all current image values.</p> <p>For example, the images for Kubeflow Pipelines are under <code>kubeflow_tools.pipelines.images</code> and <code>kubeflow_tools.pipelines.kfpV2.xxxxImage</code>:</p> <pre><code>kubeflow_tools:\n  pipelines:\n    images:\n      kfpCacheServer:\n        repository: docker.example.com/deploykf/kubeflow-pipelines/cache-server\n        tag: X.Y.Z\n\n      kfpMetadataEnvoy:\n        repository: docker.example.com/deploykf/kubeflow-pipelines/metadata-envoy\n        tag: X.Y.Z\n\n      kfpMetadataWriter:\n        repository: docker.example.com/deploykf/kubeflow-pipelines/metadata-writer\n        tag: X.Y.Z\n\n      kfpApiServer:\n        repository: docker.example.com/deploykf/kubeflow-pipelines/api-server\n        tag: X.Y.Z\n\n      kfpPersistenceagent:\n        repository: docker.example.com/deploykf/kubeflow-pipelines/persistenceagent\n        tag: X.Y.Z\n\n      kfpScheduledworkflow:\n        repository: docker.example.com/deploykf/kubeflow-pipelines/scheduledworkflow\n        tag: X.Y.Z\n\n      kfpFrontend:\n        repository: docker.example.com/deploykf/kubeflow-pipelines/frontend\n        tag: X.Y.Z\n\n      kfpViewerCrdController:\n        repository: docker.example.com/deploykf/kubeflow-pipelines/viewer-crd-controller\n        tag: X.Y.Z\n\n      kfpVisualizationServer:\n        repository: docker.example.com/deploykf/kubeflow-pipelines/visualization-server\n        tag: X.Y.Z\n\n      tfxMlMetadataStoreServer:\n        repository: docker.example.com/deploykf/ml_metadata_store_server\n        ## NOTE: this tag is not aligned to the other KFP images\n        tag: X.Y.Z\n\n    kfpV2:\n      driverImage: \"docker.example.com/deploykf/kubeflow-pipelines/kfp-driver:X.Y.Z\"\n      launcherImage: \"docker.example.com/deploykf/kubeflow-pipelines/kfp-launcher:X.Y.Z\"\n\n      ## NOTE: this tag is not aligned to the other KFP images\n      v2CompatibleLauncherImage: \"docker.example.com/deploykf/kubeflow-pipelines/kfp-launcher:1.8.22-deploykf.0\"\n</code></pre> <p>Help Us Improve</p> <p>If you have a better idea, or have created a script to automate this process, please let us know!</p>"},{"location":"guides/platform/offline/#private-helm-repositories","title":"Private Helm Repositories","text":"<p>A small number of deployKF components use an upstream Helm repository. If your cluster does not have internet access, you may need to mirror these Helm charts to a private repository, or install these components manually.</p>  Mirror the Helm Charts Disable the Helm Charts <p>If you are able to mirror Helm charts to a private repository, you can tell deployKF to use this repository instead of the default ones.</p> Step 1 - Get list of Helm Charts <p>The first step is to determine which Helm charts need to be mirrored to your private repository. Currently, we don't have an out-of-the-box solution for this.</p> <p>However, we have created values to override all Helm charts in deployKF. All Helm repository URLs can be overridden with the <code>&lt;path_to_tool&gt;.charts.&lt;chart_name&gt;.repository</code> values.</p> <p>Tip</p> <p>Search for <code>charts:</code> in the <code>default_values.yaml</code> to find all current chart values.</p> Step 2 - Mirror the Helm Charts <p>Once you have the list of Helm charts, you will need to mirror them to a private repository.</p> <p>Unless you already have a traditional Helm repository, you will likely want to use the new OCI-based registries to push the charts to a container registry that you already have.</p> <p>For example, you might create a script which loops through each chart and does the following:</p> <pre><code># set the source chart\nSOURCE_REPO=\"https://charts.jetstack.io\"\nSOURCE_CHART=\"cert-manager\"\nSOURCE_VERSION=\"X.Y.Z\"\n\n# set the destination repository\nDEST_REPO=\"oci://ghcr.io/MY_GITHUB_USER/helm-charts\" # or another OCI registry\n\n# we untar the chart because some charts have a \"v\" in their version (cert-manager)\n# but OCI registries don't ignore the \"v\" like traditional Helm registries, \n# so we need to remove it\nUNTAR_DIR=\"./${SOURCE_CHART}-${SOURCE_VERSION}\"\nrm -rf \"${UNTAR_DIR}\"\n\n# pull the chart\nhelm pull \\\n  --repo \"${SOURCE_REPO}\" \\\n  --version \"${SOURCE_VERSION}\" \\\n  --untar \\\n  --untardir \"${UNTAR_DIR}\" \\\n  \"${SOURCE_CHART}\"\n\n# repackage the chart\nhelm package \\\n  \"${SOURCE_CHART}-${SOURCE_VERSION}/${SOURCE_CHART}\" \\\n  --version \"${SOURCE_VERSION}\"\n\n# push the chart\n# NOTE: you may need to login first with `docker login ...`\nhelm push \\\n  \"${SOURCE_CHART}-${SOURCE_VERSION}.tgz\" \\\n  \"${DEST_REPO}\"\n\n# cleanup\nrm -rf \"${UNTAR_DIR}\"\n</code></pre> Step 3 - Repository Credentials (if needed) <p>If your registry requires authentication, you will need to configure ArgoCD with credentials to access the repository.</p> <p>How you do this will depend on which mode of operation you are using:</p> ArgoCD Plugin Mode <p>Due to upstream limitations for ArgoCD plugins, it is not currently possible for the plugin to read from ArgoCD's credential store (<code>argoproj/argo-cd#8820</code>)</p> <p>You will need to create a <code>kubernetes.io/dockerconfigjson</code> type secret in the <code>argocd</code> namespace, and then update the deployKF ArgoCD Plugin to use this secret.</p> <p>For example, to use the GitHub Container Registry (<code>ghcr.io/MY_GITHUB_USERNAME/helm-charts</code>) with a Personal Access Token (PAT) you might run the following commands:</p> <pre><code>kubectl create secret docker-registry \"my-ghcr-config\" \\\n  --namespace \"argocd\" \\\n  --docker-server=\"https://ghcr.io/v2/\" \\\n  --docker-username=\"MY_GITHUB_USERNAME\" \\\n  --docker-password=\"MY_GITHUB_PAT\"\n</code></pre> <p>Then you will need to apply the following patch to the <code>argocd-repo-server</code> Deployment:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: argocd-repo-server\n  namespace: argocd\nspec:\n  template:\n    spec:\n      containers:\n        - name: deploykf-plugin\n          env:\n            - name: HELM_REGISTRY_CONFIG\n              value: \"/helm-working-dir/registry/.dockerconfigjson\"\n          volumeMounts:\n            - name: registry\n              mountPath: /helm-working-dir/registry\n      volumes:\n        - name: registry\n          secret:\n            secretName: my-ghcr-config\n</code></pre> <p>Either add it as an additional <code>patchesStrategicMerge</code> in the plugin <code>kustomization.yaml</code>, or apply it directly to the cluster with <code>kubectl</code>:</p> <pre><code>kubectl patch deployment \"argocd-repo-server\" \\\n  --namespace \"argocd\" \\\n  --patch-file=./my-patch.yaml\n</code></pre> Manifests Repo Mode <p>In manifests repo mode, you may configure ArgoCD itself with the required OCI registry credentials.  </p> <p>For example, to use GitHub Container Registry (<code>ghcr.io/MY_GITHUB_USERNAME/helm-charts</code>) with a Personal Access Token (PAT):</p> <pre><code># create a secret with your GitHub credentials\n# NOTE: kubectl can't create and label a secret in one command, so we use a pipe\nkubectl create secret generic --dry-run=client -o yaml \\\n    \"argocd-repository--ghcr-oci\" \\\n    --namespace \"argocd\" \\\n    --from-literal=type=\"helm\" \\\n    --from-literal=name=\"ghcr-oci\" \\\n    --from-literal=enableOCI=\"true\" \\\n    --from-literal=url=\"ghcr.io/MY_GITHUB_USERNAME/helm-charts\" \\\n    --from-literal=username=\"MY_GITHUB_USERNAME\" \\\n    --from-literal=password=\"MY_GITHUB_PAT\" \\\n  | kubectl label --local --dry-run=client -o yaml -f - \\\n    \"argocd.argoproj.io/secret-type\"=\"repository\" \\\n  | kubectl apply -f -\n</code></pre> Step 4 - Set Helm Chart Values <p>Finally, you will need to update all the deployKF Helm chart values to use the mirrored charts.</p> <p>For example, you might override the <code>cert-manager</code>, <code>istio</code>, and <code>kyverno</code> charts with the following values:</p> <pre><code>deploykf_dependencies:\n\n  cert_manager:\n    charts:\n      certManager:\n        name: cert-manager\n        version: X.Y.Z\n        repository: \"oci://ghcr.io/MY_GITHUB_USERNAME/helm-charts\"\n        #repository: https://charts.jetstack.io\n\n  istio:\n    charts:\n      istioBase:\n        name: base\n        version: X.Y.Z\n        repository: \"oci://ghcr.io/MY_GITHUB_USERNAME/helm-charts\"\n        #repository: https://istio-release.storage.googleapis.com/charts\n\n      istioDaemon:\n        name: istiod\n        version: X.Y.Z\n        repository: \"oci://ghcr.io/MY_GITHUB_USERNAME/helm-charts\"\n        #repository: https://istio-release.storage.googleapis.com/charts\n\n  kyverno:\n    name: kyverno\n    version: X.Y.Z\n    repository: \"oci://ghcr.io/MY_GITHUB_USERNAME/helm-charts\"\n    #repository: https://kyverno.github.io/kyverno\n\ndeploykf_core:\n\n  deploykf_istio_gateway:\n    charts:\n      istioGateway:\n        name: gateway\n        version: X.Y.Z\n        repository: \"oci://ghcr.io/MY_GITHUB_USERNAME/helm-charts\"\n        #repository: https://istio-release.storage.googleapis.com/charts\n</code></pre> <p>Alternatively, you may disable the components which use these upstream Helm charts.</p> Step - Disable Components <p>Right now, the only components which use upstream Helm charts are ones which can be replaced with an existing deployment on your cluster.</p> <ul> <li>Use Existing Istio</li> <li>Use Existing cert-manager</li> <li>Use Existing Kyverno (coming soon)</li> </ul>"},{"location":"guides/tools/kubeflow-notebooks/","title":"Configure Kubeflow Notebooks","text":"<p>Learn how to configure Kubeflow Notebooks in deployKF. Use custom environments, GPU acceleration, faster storage, and more!</p>"},{"location":"guides/tools/kubeflow-notebooks/#overview","title":"Overview","text":"<p>Kubeflow Notebooks allows users to spawn Pods running instances of JupyterLab, Visual Studio Code (code-server), and RStudio in profile namespaces.</p> <p>As the cluster administrator, you may configure which options are available to users when spawning a Notebook Pod:</p> <ul> <li>Container Images</li> <li>Container Resources (CPU, Memory, GPU)</li> <li>Storage Volumes</li> <li>Advanced Pod Options (Affinity, Tolerations, PodDefaults)</li> <li>Idle Notebook Culling</li> </ul> <p>Kubeflow Notebooks Limitations</p> <p>The current version of Kubeflow Notebooks exposes many Kubernetes-specific concepts to users, which may be confusing for non-technical users. There is an upstream proposal to abstract away these concepts in a more user-friendly way, see <code>kubeflow/kubeflow#7156</code> for more information.</p> <p>When the <code>kubeflow_tools.notebooks.spawnerFormDefaults</code> values are updated, this has no effect on existing Notebook Pods, only new Pods will use the updated values.</p>"},{"location":"guides/tools/kubeflow-notebooks/#container-images","title":"Container Images","text":"<p>Container images are the \"environment\" which users will be working in when using a Notebook Pod, and can be configured to provide different tools and packages to users.</p> <p>The following values configure which container images are available to users when spawning a Notebook Pod:</p> <ul> <li>Jupyter-Like: <code>kubeflow_tools.notebooks.spawnerFormDefaults.image</code></li> <li>VSCode-like: <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupOne</code></li> <li>RStudio-like: <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupTwo</code></li> </ul>"},{"location":"guides/tools/kubeflow-notebooks/#container-resources","title":"Container Resources","text":"<p>Container resources directly correspond to Kubernetes Container Resources which are requested by the Notebook Pod.</p> <p>The following values configure the resource requests/limits for containers in Notebook Pods:</p> <ul> <li>CPU: <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu</code></li> <li>Memory: <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory</code></li> <li>GPU: <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpu</code></li> </ul> <p>Resource Requests</p> <p>Kubernetes uses resource requests when scheduling Pods, and does not strictly enforce them at runtime. User Notebooks are not well-behaved applications (from a resource perspective), so will likely impact other Pods running on the same node.</p> <p>However, setting resource limits will have unintended consequences for users, as the Notebook Pod will be terminated if it exceeds certain limits (like memory), which may result in lost work.</p> <p>A common alternative is to use a dedicated node for each Notebook Pod, see Advanced Pod Options for information on how to do this with Affinity and Tolerations.</p>"},{"location":"guides/tools/kubeflow-notebooks/#storage-volumes","title":"Storage Volumes","text":"<p>Storage volumes are used to provide persistent storage to Notebook Pods between restarts, and are implemented using Kubernetes Persistent Volumes.</p> <p>The following values configure the storage volumes for Notebook Pods:</p> <ul> <li>Home Volume: <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume</code></li> <li>Data Volume: <code>kubeflow_tools.notebooks.spawnerFormDefaults.dataVolumes</code></li> </ul> <p>StorageClass and Performance</p> <p>The <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.spec.storageClassName</code> value defines which Kubernetes StorageClass is used to provision the workspace volume. If a <code>storageClassName</code> is not specified, the cluster's default StorageClass is used.</p> <p>As ML workloads are often IO-intensive, it is recommended to use a StorageClass which provides high-performance, typically this is only possible with drives which are attached to the node, rather than network-attached storage.</p>"},{"location":"guides/tools/kubeflow-notebooks/#advanced-pod-options","title":"Advanced Pod Options","text":"<p>Advanced Pod Options are additional configurations for Notebook Pods which manage things like Pod Affinity, Node Tolerations, and Kubeflow's PodDefaults.</p> <p>The following values configure the advanced options for Notebook Pods:</p> <ul> <li>Pod Affinity: <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig</code></li> <li>Node Tolerations: <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup</code></li> <li>PodDefaults: <code>kubeflow_tools.notebooks.spawnerFormDefaults.configurations</code></li> </ul> Dedicated Node for each Notebook Pod <p>Because Notebook Pods are not well-behaved applications (from a resource perspective), it is common to want a dedicated node for each Notebook Pod. With a combination of Pod Affinity and Node Tolerations, this can be achieved.</p> <p>Note, this will require your cluster to have node-autoscaling configured (e.g. Cluster Autoscaler or Karpenter), as the cluster will need to provision a new node for each Notebook Pod.</p> <p>First, you will need to make one or more groups of nodes that are tainted to prevent other Pods from being scheduled on them. In the following example, we have four groups of nodes with different CPU/Memory configurations, that are each tainted with a different value of the <code>dedicated</code> key with effect <code>NoSchedule</code>:</p> <ul> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-c5.xlarge</code>, Effect: <code>NoSchedule</code></li> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-c5.2xlarge</code>, Effect: <code>NoSchedule</code></li> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-c5.4xlarge</code>, Effect: <code>NoSchedule</code></li> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-r5.8xlarge</code>, Effect: <code>NoSchedule</code> </li> </ul> <p>Next, you will need to configure Pod Affinity configs that do not allow two Notebook Pods to be scheduled on the same node. In the following example, we do this by:</p> <ul> <li>Using <code>nodeAffinity</code> to require a Node with label <code>lifecycle=kubeflow-notebook</code></li> <li>Using <code>podAntiAffinity</code> to require a Node WITHOUT an existing Pod having <code>notebook-name</code> label</li> </ul> <p>Finally, you may use the following values to expose these options to users:</p> <pre><code>kubeflow_tools:\n  notebooks:\n    spawnerFormDefaults:\n      ## Affinity\n      ##  - note, setting `readOnly` to `true` to ensures that this affinity is always applied\n      ##  - note, `namespaceSelector` was added in Kubernetes 1.22, \n      ##    so this will NOT work on older clusters\n      ##\n      affinityConfig:\n        readOnly: true\n        value: \"dedicated_node_per_notebook\"\n        options:\n          - configKey: \"dedicated_node_per_notebook\"\n            displayName: \"Dedicated Node Per Notebook\"\n            affinity:\n              ## Require a Node with label `lifecycle=kubeflow-notebook`\n              nodeAffinity:\n                requiredDuringSchedulingIgnoredDuringExecution:\n                  nodeSelectorTerms:\n                    - matchExpressions:\n                        - key: \"lifecycle\"\n                          operator: \"In\"\n                          values:\n                            - \"kubeflow-notebook\"\n\n              ## Require a Node WITHOUT an existing Pod having `notebook-name` label\n              podAntiAffinity:\n                requiredDuringSchedulingIgnoredDuringExecution:\n                  - labelSelector:\n                      matchExpressions:\n                        - key: \"notebook-name\"\n                          operator: \"Exists\"\n                    topologyKey: \"kubernetes.io/hostname\"\n                    namespaceSelector: {}\n\n      ## Tolerations\n      ##\n      tolerationGroup:\n        readOnly: false\n        value: \"group_1\"\n        options:\n          - groupKey: \"group_1\"\n            displayName: \"4 CPU 8Gb Mem at ~$X.XXX USD per day\"\n            tolerations:\n              - key: \"dedicated\"\n                operator: \"Equal\"\n                value: \"kubeflow-c5.xlarge\"\n                effect: \"NoSchedule\"\n\n          - groupKey: \"group_2\"\n            displayName: \"8 CPU 16Gb Mem at ~$X.XXX USD per day\"\n            tolerations:\n              - key: \"dedicated\"\n                operator: \"Equal\"\n                value: \"kubeflow-c5.2xlarge\"\n                effect: \"NoSchedule\"\n\n          - groupKey: \"group_3\"\n            displayName: \"16 CPU 32Gb Mem at ~$X.XXX USD per day\"\n            tolerations:\n              - key: \"dedicated\"\n                operator: \"Equal\"\n                value: \"kubeflow-c5.4xlarge\"\n                effect: \"NoSchedule\"\n\n          - groupKey: \"group_4\"\n            displayName: \"32 CPU 256Gb Mem at ~$X.XXX USD per day\"\n            tolerations:\n              - key: \"dedicated\"\n                operator: \"Equal\"\n                value: \"kubeflow-r5.8xlarge\"\n                effect: \"NoSchedule\"\n</code></pre> <p>Users will then be able to select which group of nodes they want to use by choosing the corresponding \"Toleration\" group when spawning their Notebook.</p> PodDefault for Kubeflow Pipelines Authentication <p>The <code>kubeflow_tools.pipelines.profileResourceGeneration.kfpApiTokenPodDefault</code> value  configures if a <code>PodDefault</code> named <code>\"kubeflow-pipelines-api-token\"</code> is automatically generated in each profile namespace.</p> <p>If the user selects this \"configuration\" when spawning their Notebook, they will be able to use the Kubeflow Pipelines Python SDK from the Notebook without needing to manually authenticate.</p> <p>To have this \"configuration\" selected by default in the spawner, you may use the following values:</p> <pre><code>kubeflow_tools:\n  notebooks:\n    spawnerFormDefaults:\n      configurations:\n        value:\n          - \"kubeflow-pipelines-api-token\"\n</code></pre> <p>For more information, see the Access Kubeflow Pipelines API user guide.</p>"},{"location":"guides/tools/kubeflow-notebooks/#idle-notebook-culling","title":"Idle Notebook Culling","text":"<p>Kubeflow Notebooks supports automatically culling idle Notebook Pods, which is configured by the <code>kubeflow_tools.notebooks.notebookCulling</code> values.</p> <p>For example, the following values will enable idle culling after 1 day of inactivity:</p> <pre><code>kubeflow_tools:\n  notebooks:\n    notebookCulling:\n      enabled: true\n      idleTime: 1440 # 1 day in minutes\n</code></pre> <p>Jupyter Notebooks Only</p> <p>Currently, only Jupyter Notebooks are supported for idle culling, see the upstream design proposal for more information.</p>"},{"location":"guides/tools/kubeflow-notebooks/#override-notebook-template","title":"Override Notebook Template","text":"<p>Sometimes, you may need to make additional changes that are not possible with the <code>spawnerFormDefaults</code> values.  To achieve this, you may override the <code>Notebook</code> YAML template with the <code>kubeflow_tools.notebooks.notebookTemplate</code> value.</p> <p>Default Notebook Template</p> <p>You must include a FULL <code>Notebook</code> YAML template, this is because setting <code>notebookTemplate</code> completely replaces the default.</p> <p>Find the default <code>Notebook</code> template by checking which version of Kubeflow Notebooks is included with your version of deployKF. Next, retrieve the default template from the <code>kubeflow/kubeflow</code> repository under <code>./components/crud-web-apps/jupyter/backend/apps/common/yaml/notebook_template.yaml</code> (select the appropriate git tag).</p> <p>For example, the following values set a container <code>securityContext</code> on all Notebook Pods:</p> <pre><code>kubeflow_tools:\n  notebooks:\n    notebookTemplate: |\n      apiVersion: kubeflow.org/v1beta1\n      kind: Notebook\n      metadata:\n        name: {name}\n        namespace: \"{namespace}\"\n        labels:\n          app: {name}\n        annotations:\n          notebooks.kubeflow.org/server-type: \"\"\n      spec:\n        template:\n          spec:\n            serviceAccountName: {serviceAccount}\n            containers:\n              - name: {name}\n                image: \"\"\n                ## ============= BEGIN: Changes =============\n                securityContext:\n                  ## WARNING: these settings will NOT work until Kubeflow 1.9.0 / deployKF 0.2.0\n                  ##          https://github.com/kubeflow/kubeflow/pull/7622\n                  allowPrivilegeEscalation: false\n                  capabilities:\n                    drop:\n                      - ALL\n                  runAsNonRoot: true\n\n                  ## WARNING: setting `readOnlyRootFilesystem` to `true` will NOT work,\n                  ##          there are currently no plans to support this feature\n                  #readOnlyRootFilesystem: true\n                ## ============= END: Changes ===============\n                volumeMounts: []\n                env: []\n                resources:\n                  requests:\n                    cpu: \"0.1\"\n                    memory: \"0.1Gi\"\n            volumes: []\n            tolerations: []\n</code></pre>"},{"location":"guides/tools/kubeflow-poddefaults/","title":"Use Kubeflow PodDefaults","text":"<p>Learn how to use Kubeflow PodDefaults to mutate Pods as they are created. Make changes like adding sidecars, volumes, environment variables, and more.</p>"},{"location":"guides/tools/kubeflow-poddefaults/#overview","title":"Overview","text":"<p>Kubeflow PodDefaults allow you to change (mutate) the definition of Pods as they are created. The central config is the <code>PodDefault</code> CRD that defines how to select Pods, and what changes to make.</p> <p>Some common use cases for PodDefaults include:</p> <ul> <li>Adding extra <code>sidecars</code> or <code>init-containers</code> to Pods.</li> <li>Setting <code>imagePullSecrets</code> of Pods.</li> <li>Mounting extra volumes to Pods.</li> <li>Adding extra environment variables to Pods.</li> </ul> <p>Similarity to Kyverno</p> <p> Kyverno is a general-purpose policy engine for Kubernetes which also allows mutating resources as they are created. However, Kyverno is more general-purpose and can be used to mutate any resource, not just Pods, and includes the ability to mutate existing resources.</p> <p>Because deployKF depends on Kyverno, you will have access to both tools.</p>"},{"location":"guides/tools/kubeflow-poddefaults/#create-a-poddefault","title":"Create a PodDefault","text":"<p>To use PodDefaults, you need to create a <code>PodDefault</code> resource in the namespace where you want to mutate Pods.</p> <p>Warning</p> <p>PodDefaults only affect Pods as they are created, and only in the namespace where the CRD is defined, existing Pods which match the selector are NOT affected.</p> <p>Info</p> <p>To learn  more about all the options in the <code>PodDefault</code> CRD, review the <code>admission-webhook</code> code from the <code>kubeflow/kubeflow</code> repository under the <code>admission-webhook/pkg/apis/settings/v1alpha1/poddefault_types.go</code> file.</p> <p>Here is the full spec of a <code>PodDefault</code> resource, with all the possible options set:</p> <pre><code>apiVersion: kubeflow.org/v1alpha1\nkind: PodDefault\nmetadata:\n  name: kubeflow-pipelines-api-token\n  namespace: MY_NAMESPACE\nspec:\n  ## a human-readable description of what this PodDefault does\n  ##\n  desc: \"...\"\n\n  ## a selector to match Pods\n  ##  - spec for LabelSelector:\n  ##    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#labelselector-v1-meta\n  ##\n  selector:\n\n    ## match Pods with these labels\n    ##\n    matchLabels:\n      my-label: \"my-value\"\n\n    ## match Pods with these expressions\n    ##  - WARNING: Kubeflow Notebooks has issues with `matchExpressions`\n    ##             https://github.com/kubeflow/kubeflow/issues/7552\n    ##\n    #matchExpressions:\n    #  - key: kubeflow-pipelines-api-token\n    #    operator: In\n    #    values:\n    #      - \"true\"\n\n  ## extra annotations for the Pod metadata\n  ##\n  annotations: {}\n\n  ## extra labels for the Pod metadata\n  ##\n  labels: {}\n\n  ## extra `initContainers` for the PodSpec\n  ##  - spec for Container:\n  ##    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#container-v1-core\n  ##\n  initContainers: []\n\n  ## extra `containers` for the PodSpec\n  ##  - spec for Container:\n  ##    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#container-v1-core\n  ##\n  sidecars: []\n\n  ## extra `imagePullSecrets` for the PodSpec\n  ##  - spec for LocalObjectReference:\n  ##    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#localobjectreference-v1-core\n  ##\n  imagePullSecrets: []\n\n  ## override the `serviceAccountName` of the PodSpec\n  ##\n  serviceAccountName: \"\"\n\n  ## override the `automountServiceAccountToken` of the PodSpec\n  ##\n  automountServiceAccountToken: true\n\n  ## extra `env` for the containers in the PodSpec\n  ##  - spec for EnvVar:\n  ##    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#envvar-v1-core\n  ##\n  env: []\n\n  ## extra `envFrom` for the containers in the PodSpec\n  ##  - spec for EnvFromSource:\n  ##    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#envfromsource-v1-core\n  ##\n  envFrom: []\n\n  ## extra `volumes` for the PodSpec\n  ##  - spec for Volume:\n  ##    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#volume-v1-core\n  ##\n  volumes: []\n\n  ## extra `volumeMounts` for the containers in the PodSpec\n  ##  - spec for VolumeMount:\n  ##    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#volumemount-v1-core\n  ##\n  volumeMounts: []\n\n  ## extra `tolerations` for the PodSpec\n  ##\n  tolerations: []\n\n  ## set the `command` of containers in the PodSpec\n  ##  - note, this will NOT affect containers that already have `command` set\n  ##\n  command: []\n\n  ## set the `args` of containers in the PodSpec\n  ##  - note, this will NOT affect containers that already have `args` set\n  ##\n  args: []\n</code></pre>"},{"location":"guides/tools/kubeflow-poddefaults/#examples","title":"Examples","text":"<p>While the full spec for a <code>PodDefault</code> is quite complex, here are some examples of common changes you might want to make.</p>"},{"location":"guides/tools/kubeflow-poddefaults/#add-a-sidecar","title":"Add a Sidecar","text":"<p>When this <code>PodDefault</code> is applied to a cluster, Pods in the <code>MY_NAMESPACE</code> namespace with the label <code>add-sidecar: \"true\"</code> will have a sidecar container added to them.</p> <pre><code>apiVersion: kubeflow.org/v1alpha1\nkind: PodDefault\nmetadata:\n  name: add-sidecar\n  namespace: MY_NAMESPACE\nspec:\n  desc: \"Add a sidecar to the Pod\"\n\n  selector:\n    matchLabels:\n      add-sidecar: \"true\"\n\n  sidecars:\n    - name: my-sidecar\n      image: ubuntu:22.04\n      imagePullPolicy: IfNotPresent\n      command:\n        - \"/bin/sh\"\n        - \"-c\"\n      args:\n        - |\n          ## to break the infinite loop when we receive SIGTERM\n          trap \"exit 0\" TERM;\n\n          ## keep the container running (so people can `kubectl exec -it` into it)\n          while true; do\n            echo \"I am alive...\";\n            sleep 30;\n          done\n</code></pre>"},{"location":"guides/tools/kubeflow-poddefaults/#kubeflow-pipelines-api-token","title":"Kubeflow Pipelines API Token","text":"<p>When this <code>PodDefault</code> is applied to a cluster, Pods in the <code>MY_NAMESPACE</code> namespace with the label <code>kubeflow-pipelines-api-token: \"true\"</code> will have a service account token mounted at <code>/var/run/secrets/ml-pipeline/token</code> which allows authentication with the Kubeflow Pipelines API.</p> <p>Info</p> <p>This example is actually the <code>PodDefault</code> which deployKF creates in each profile namespace when the <code>kubeflow_tools.pipelines.profileResourceGeneration.kfpApiTokenPodDefault</code> value is enabled.</p> <pre><code>apiVersion: kubeflow.org/v1alpha1\nkind: PodDefault\nmetadata:\n  name: kubeflow-pipelines-api-token\n  namespace: MY_NAMESPACE\nspec:\n  desc: \"Mount a serviceAccountToken to authenticate with Kubeflow Pipelines API\"\n\n  selector:\n    matchLabels:\n      kubeflow-pipelines-api-token: \"true\"\n\n  ## set the `KF_PIPELINES_SA_TOKEN_PATH` environment variable\n  env:\n    - name: KF_PIPELINES_SA_TOKEN_PATH\n      value: \"/var/run/secrets/ml-pipeline/token\"\n\n  ## mount the serviceAccountToken at `/var/run/secrets/ml-pipeline/token`\n  volumeMounts:\n    - mountPath: \"/var/run/secrets/ml-pipeline\"\n      name: volume-ml-pipeline-token\n      readOnly: true\n\n  ## define a projected volume to mount the serviceAccountToken\n  volumes:\n    - name: volume-ml-pipeline-token\n      projected:\n        sources:\n          - serviceAccountToken:\n              audience: pipelines.kubeflow.org\n              expirationSeconds: 7200\n              path: token\n</code></pre>"},{"location":"reference/deploykf-values/","title":"Generator Values","text":"<p>The following is a summary of the generator values (configs) available in deployKF.</p> <p>What are Generator Values?</p> <p>The generator values configure all aspects of deployKF, including which tools are deployed, how they are configured, and what versions are used.</p> <p>These values are conceptually similar to Helm Chart values, but they are all \"global\". This means you only need to configure them once, even though they control multiple internal Helm Charts and Kustomize apps.</p> <p>For more information, see the values page.</p>"},{"location":"reference/deploykf-values/#argo-cd","title":"Argo CD","text":"<p>Values related to Argo CD.</p> <code>argocd</code>"},{"location":"reference/deploykf-values/#argocd","title":"<code>argocd</code>","text":"Value Default <code>argocd.appNamePrefix</code> <code>\"\"</code> <code>argocd.namespace</code> <code>\"argocd\"</code> <code>argocd.project</code> <code>\"default\"</code> <code>argocd.source.plugin.enabled</code> <code>false</code> <code>argocd.source.repo.url</code> <code>\"\"</code> <code>argocd.source.repo.revision</code> <code>\"\"</code> <code>argocd.source.repo.path</code> <code>\"\"</code> <code>argocd.destination.server</code> <code>\"https://kubernetes.default.svc\"</code> <code>argocd.destination.name</code> <code>\"\"</code>"},{"location":"reference/deploykf-values/#kubernetes","title":"Kubernetes","text":"<p>Values related to the Kubernetes cluster.</p> <code>kubernetes.azure</code>"},{"location":"reference/deploykf-values/#kubernetesazure","title":"<code>kubernetes.azure</code>","text":"Value Default <code>kubernetes.azure.admissionsEnforcerFix</code> <code>false</code>"},{"location":"reference/deploykf-values/#deploykf-dependencies","title":"deployKF Dependencies","text":"<p>Values for configuring dependencies of deployKF.</p> <code>deploykf_dependencies.kyverno</code> <code>deploykf_dependencies.cert_manager</code> <code>deploykf_dependencies.istio</code>"},{"location":"reference/deploykf-values/#deploykf_dependencieskyverno","title":"<code>deploykf_dependencies.kyverno</code>","text":"Value Default <code>deploykf_dependencies.kyverno.enabled</code> <code>true</code> <code>deploykf_dependencies.kyverno.namespace</code> <code>\"kyverno\"</code> <code>deploykf_dependencies.kyverno.extraManifests</code> <code>[]</code> <code>deploykf_dependencies.kyverno.charts.kyverno.name</code> <code>\"kyverno\"</code> <code>deploykf_dependencies.kyverno.charts.kyverno.version</code> <code>\"3.0.1\"</code> <code>deploykf_dependencies.kyverno.charts.kyverno.repository</code> <code>\"https://kyverno.github.io/kyverno\"</code> <code>deploykf_dependencies.kyverno.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_dependencies.kyverno.images.kubectl.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyverno.repository</code> <code>\"ghcr.io/kyverno/kyverno\"</code> <code>deploykf_dependencies.kyverno.images.kyverno.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyverno.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoInit.repository</code> <code>\"ghcr.io/kyverno/kyvernopre\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoInit.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoInit.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoBackgroundController.repository</code> <code>\"ghcr.io/kyverno/background-controller\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoBackgroundController.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoBackgroundController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoCleanupController.repository</code> <code>\"ghcr.io/kyverno/cleanup-controller\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoCleanupController.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoCleanupController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoReportsController.repository</code> <code>\"ghcr.io/kyverno/reports-controller\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoReportsController.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoReportsController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.extraResourceRules</code> <code>[]</code> <code>deploykf_dependencies.kyverno.admissionController.replicas</code> <code>3</code> <code>deploykf_dependencies.kyverno.admissionController.resources.limits.memory</code> <code>\"384Mi\"</code> <code>deploykf_dependencies.kyverno.admissionController.resources.requests.cpu</code> <code>\"100m\"</code> <code>deploykf_dependencies.kyverno.admissionController.resources.requests.memory</code> <code>\"128Mi\"</code> <code>deploykf_dependencies.kyverno.backgroundController.replicas</code> <code>1</code> <code>deploykf_dependencies.kyverno.backgroundController.resources.limits.memory</code> <code>\"512Mi\"</code> <code>deploykf_dependencies.kyverno.backgroundController.resources.requests.cpu</code> <code>\"100m\"</code> <code>deploykf_dependencies.kyverno.backgroundController.resources.requests.memory</code> <code>\"128Mi\"</code> <code>deploykf_dependencies.kyverno.cleanupController.replicas</code> <code>1</code> <code>deploykf_dependencies.kyverno.cleanupController.resources.limits.memory</code> <code>\"128Mi\"</code> <code>deploykf_dependencies.kyverno.cleanupController.resources.requests.cpu</code> <code>\"100m\"</code> <code>deploykf_dependencies.kyverno.cleanupController.resources.requests.memory</code> <code>\"64Mi\"</code> <code>deploykf_dependencies.kyverno.reportsController.replicas</code> <code>1</code> <code>deploykf_dependencies.kyverno.reportsController.resources.limits.memory</code> <code>\"128Mi\"</code> <code>deploykf_dependencies.kyverno.reportsController.resources.requests.cpu</code> <code>\"100m\"</code> <code>deploykf_dependencies.kyverno.reportsController.resources.requests.memory</code> <code>\"64Mi\"</code> <code>deploykf_dependencies.kyverno.clusterPolicies.imagePullSecrets.enabled</code> <code>false</code> <code>deploykf_dependencies.kyverno.clusterPolicies.imagePullSecrets.excludeNamespaces</code> <code>[\"argocd\", \"kube-system\"]</code> <code>deploykf_dependencies.kyverno.clusterPolicies.imagePullSecrets.registryCredentials</code> <code>[]</code>"},{"location":"reference/deploykf-values/#deploykf_dependenciescert_manager","title":"<code>deploykf_dependencies.cert_manager</code>","text":"Value Default <code>deploykf_dependencies.cert_manager.enabled</code> <code>true</code> <code>deploykf_dependencies.cert_manager.namespace</code> <code>\"cert-manager\"</code> <code>deploykf_dependencies.cert_manager.extraManifests</code> <code>[]</code> <code>deploykf_dependencies.cert_manager.charts.certManager.name</code> <code>\"cert-manager\"</code> <code>deploykf_dependencies.cert_manager.charts.certManager.version</code> <code>\"1.12.10\"</code> <code>deploykf_dependencies.cert_manager.charts.certManager.repository</code> <code>\"https://charts.jetstack.io\"</code> <code>deploykf_dependencies.cert_manager.charts.trustManager.name</code> <code>\"trust-manager\"</code> <code>deploykf_dependencies.cert_manager.charts.trustManager.version</code> <code>\"0.9.2-deploykf\"</code> <code>deploykf_dependencies.cert_manager.charts.trustManager.repository</code> <code>\"file://forks/trust-manager\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerController.repository</code> <code>\"quay.io/jetstack/cert-manager-controller\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerController.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerWebhook.repository</code> <code>\"quay.io/jetstack/cert-manager-webhook\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerWebhook.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerWebhook.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerCainjector.repository</code> <code>\"quay.io/jetstack/cert-manager-cainjector\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerCainjector.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerCainjector.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerAcmesolver.repository</code> <code>\"quay.io/jetstack/cert-manager-acmesolver\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerAcmesolver.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerCtl.repository</code> <code>\"quay.io/jetstack/cert-manager-ctl\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerCtl.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerCtl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.trustManager.repository</code> <code>\"quay.io/jetstack/trust-manager\"</code> <code>deploykf_dependencies.cert_manager.images.trustManager.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.trustManager.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.trustManagerDefaultPackage.repository</code> <code>\"quay.io/jetstack/cert-manager-package-debian\"</code> <code>deploykf_dependencies.cert_manager.images.trustManagerDefaultPackage.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.trustManagerDefaultPackage.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.controller.securityContext.fsGroup</code> <code>1001</code> <code>deploykf_dependencies.cert_manager.controller.serviceAccount.create</code> <code>true</code> <code>deploykf_dependencies.cert_manager.controller.serviceAccount.name</code> <code>\"cert-manager\"</code> <code>deploykf_dependencies.cert_manager.controller.extraArgs</code> <code>[\"--enable-certificate-owner-ref=true\"]</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.enabled</code> <code>true</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.issuerName</code> <code>\"deploykf-gateway-issuer\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.type</code> <code>\"SELF_SIGNED\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.selfSigned.caIssuerName</code> <code>\"selfsigned-ca-issuer\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.selfSigned.caSecretName</code> <code>\"selfsigned-ca-issuer-root-cert\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.selfSigned.injectedConfigMapName</code> <code>\"deploykf-gateway-issuer-root-ca-cert\"</code>"},{"location":"reference/deploykf-values/#deploykf_dependenciesistio","title":"<code>deploykf_dependencies.istio</code>","text":"Value Default <code>deploykf_dependencies.istio.enabled</code> <code>true</code> <code>deploykf_dependencies.istio.namespace</code> <code>\"istio-system\"</code> <code>deploykf_dependencies.istio.extraManifests</code> <code>[]</code> <code>deploykf_dependencies.istio.charts.istioBase.name</code> <code>\"base\"</code> <code>deploykf_dependencies.istio.charts.istioBase.version</code> <code>\"1.17.8\"</code> <code>deploykf_dependencies.istio.charts.istioBase.repository</code> <code>\"https://istio-release.storage.googleapis.com/charts\"</code> <code>deploykf_dependencies.istio.charts.istioDaemon.name</code> <code>\"istiod\"</code> <code>deploykf_dependencies.istio.charts.istioDaemon.version</code> <code>\"1.17.8\"</code> <code>deploykf_dependencies.istio.charts.istioDaemon.repository</code> <code>\"https://istio-release.storage.googleapis.com/charts\"</code> <code>deploykf_dependencies.istio.images.istioProxy.repository</code> <code>\"docker.io/istio/proxyv2\"</code> <code>deploykf_dependencies.istio.images.istioProxy.tag</code> <code>nil</code> <code>deploykf_dependencies.istio.images.istioPilot.repository</code> <code>\"docker.io/istio/pilot\"</code> <code>deploykf_dependencies.istio.images.istioPilot.tag</code> <code>nil</code> <code>deploykf_dependencies.istio.defaultImageVariant</code> <code>\"distroless\"</code>"},{"location":"reference/deploykf-values/#deploykf-core","title":"deployKF Core","text":"<p>Values for configuring core deployKF components.</p> <code>deploykf_core.deploykf_istio_gateway</code> <code>deploykf_core.deploykf_profiles_generator</code> <code>deploykf_core.deploykf_auth</code> <code>deploykf_core.deploykf_dashboard</code>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_istio_gateway","title":"<code>deploykf_core.deploykf_istio_gateway</code>","text":"Value Default <code>deploykf_core.deploykf_istio_gateway.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.namespace</code> <code>\"deploykf-istio-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.name</code> <code>\"gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.version</code> <code>\"1.17.8\"</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.repository</code> <code>\"https://istio-release.storage.googleapis.com/charts\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.name</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.hostname</code> <code>\"deploykf.example.com\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.ports.http</code> <code>80</code> <code>deploykf_core.deploykf_istio_gateway.gateway.ports.https</code> <code>443</code> <code>deploykf_core.deploykf_istio_gateway.gateway.tls.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.gateway.tls.clientsUseHttps</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.gateway.tls.matchSNI</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.gateway.tls.redirect</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.gateway.selectorLabels.app</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.selectorLabels.istio</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.enableProxyProtocol</code> <code>false</code> <code>deploykf_core.deploykf_istio_gateway.gateway.xffNumTrustedHops</code> <code>0</code> <code>deploykf_core.deploykf_istio_gateway.gateway.emailToLowercase</code> <code>false</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.replicaCount</code> <code>1</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.serviceAccount.name</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.minReplicas</code> <code>1</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.maxReplicas</code> <code>5</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.targetCPUUtilizationPercentage</code> <code>80</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.name</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.type</code> <code>\"LoadBalancer\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.loadBalancerIP</code> <code>\"\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.loadBalancerSourceRanges</code> <code>[]</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.ports.http</code> <code>nil</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.ports.https</code> <code>nil</code>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_profiles_generator","title":"<code>deploykf_core.deploykf_profiles_generator</code>","text":"Value Default <code>deploykf_core.deploykf_profiles_generator.enabled</code> <code>true</code> <code>deploykf_core.deploykf_profiles_generator.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.profileNamePrefix</code> <code>\"\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.ownerEmail</code> <code>\"admin@example.com\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.memberAccess.role</code> <code>\"view\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.memberAccess.notebooksAccess</code> <code>false</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.plugins</code> <code>[]</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecret</code> <code>\"kubeflow-pipelines--profile-object-store-auth--{profile_name}\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecretNamespace</code> <code>\"\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecretAccessKeyKey</code> <code>\"access_key\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecretSecretKeyKey</code> <code>\"secret_key\"</code> <code>deploykf_core.deploykf_profiles_generator.users</code> <code>[{\"id\": \"user-1\", \"email\": \"user1@example.com\"}, {\"id\": \"user-2\", \"email\": \"user2@example.com\"}]</code> <code>deploykf_core.deploykf_profiles_generator.groups</code> <code>[{\"id\": \"team-1\", \"users\": [\"user-1\", \"user-2\"]}]</code> <code>deploykf_core.deploykf_profiles_generator.profiles</code> <code>[{\"name\": \"team-1\", \"members\": [{\"group\": \"team-1\", \"access\": {\"role\": \"edit\", \"notebooksAccess\": true}}]}, {\"name\": \"team-1-prod\", \"members\": [{\"group\": \"team-1\", \"access\": {\"role\": \"view\", \"notebooksAccess\": false}}]}]</code>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_auth","title":"<code>deploykf_core.deploykf_auth</code>","text":"Value Default <code>deploykf_core.deploykf_auth.enabled</code> <code>true</code> <code>deploykf_core.deploykf_auth.namespace</code> <code>\"deploykf-auth\"</code> <code>deploykf_core.deploykf_auth.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_auth.images.dex.repository</code> <code>\"ghcr.io/dexidp/dex\"</code> <code>deploykf_core.deploykf_auth.images.dex.tag</code> <code>\"v2.39.1\"</code> <code>deploykf_core.deploykf_auth.images.dex.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_auth.images.oauth2Proxy.repository</code> <code>\"quay.io/oauth2-proxy/oauth2-proxy\"</code> <code>deploykf_core.deploykf_auth.images.oauth2Proxy.tag</code> <code>\"v7.6.0\"</code> <code>deploykf_core.deploykf_auth.images.oauth2Proxy.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_auth.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_core.deploykf_auth.images.kubectl.tag</code> <code>\"1.26.15-debian-12-r4\"</code> <code>deploykf_core.deploykf_auth.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> <code>[{\"email\": \"admin@example.com\", \"password\": {\"value\": \"admin\"}}, {\"email\": \"user1@example.com\", \"password\": {\"value\": \"user1\"}}, {\"email\": \"user2@example.com\", \"password\": {\"value\": \"user2\"}}]</code> <code>deploykf_core.deploykf_auth.dex.connectors</code> <code>[]</code> <code>deploykf_core.deploykf_auth.dex.expiry.idToken</code> <code>\"60m\"</code> <code>deploykf_core.deploykf_auth.dex.expiry.refreshToken.idle</code> <code>\"168h\"</code> <code>deploykf_core.deploykf_auth.dex.expiry.refreshToken.total</code> <code>\"2160h\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientId</code> <code>\"oauth2-proxy\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.value</code> <code>\"bbbbbbbbbbbbbbbb\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.existingSecretKey</code> <code>\"client_secret\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.generateSecret</code> <code>false</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientId</code> <code>\"minio-console\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.value</code> <code>\"bbbbbbbbbbbbbbbb\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.existingSecretKey</code> <code>\"client_secret\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.generateSecret</code> <code>false</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientId</code> <code>\"argo-server\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.value</code> <code>\"bbbbbbbbbbbbbbbb\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.existingSecretKey</code> <code>\"client_secret\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.generateSecret</code> <code>false</code> <code>deploykf_core.deploykf_auth.dex.clients.kubeflowPipelinesSDK.enabled</code> <code>true</code> <code>deploykf_core.deploykf_auth.dex.clients.kubeflowPipelinesSDK.clientId</code> <code>\"kubeflow-pipelines-sdk\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.enableSignInPage</code> <code>false</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.name</code> <code>\"_deploykf_token\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.expire</code> <code>\"168h\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.refresh</code> <code>\"60m\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.value</code> <code>\"cccccccccccccccc\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.existingSecretKey</code> <code>\"cookie_secret\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.generateSecret</code> <code>false</code>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_dashboard","title":"<code>deploykf_core.deploykf_dashboard</code>","text":"Value Default <code>deploykf_core.deploykf_dashboard.enabled</code> <code>true</code> <code>deploykf_core.deploykf_dashboard.namespace</code> <code>\"deploykf-dashboard\"</code> <code>deploykf_core.deploykf_dashboard.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_dashboard.images.dashboard.repository</code> <code>\"ghcr.io/deploykf/dashboard\"</code> <code>deploykf_core.deploykf_dashboard.images.dashboard.tag</code> <code>\"0.1.1\"</code> <code>deploykf_core.deploykf_dashboard.images.dashboard.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_dashboard.images.profileController.repository</code> <code>\"kubeflownotebookswg/profile-controller\"</code> <code>deploykf_core.deploykf_dashboard.images.profileController.tag</code> <code>\"v1.8.0\"</code> <code>deploykf_core.deploykf_dashboard.images.profileController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_dashboard.images.kfamApi.repository</code> <code>\"kubeflownotebookswg/kfam\"</code> <code>deploykf_core.deploykf_dashboard.images.kfamApi.tag</code> <code>\"v1.8.0\"</code> <code>deploykf_core.deploykf_dashboard.images.kfamApi.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_dashboard.navigation.externalLinks</code> <code>[]</code> <code>deploykf_core.deploykf_dashboard.navigation.documentationItems</code> <code>[{\"text\": \"deployKF Website\", \"desc\": \"The tool that deployed your ML platform!\", \"link\": \"https://github.com/deployKF/deployKF\"}]</code>"},{"location":"reference/deploykf-values/#deploykf-opt","title":"deployKF Opt","text":"<p>Values for configuring optional embedded applications, which are used when external alternatives are not configured.</p> <code>deploykf_opt.deploykf_mysql</code> <code>deploykf_opt.deploykf_minio</code>"},{"location":"reference/deploykf-values/#deploykf_optdeploykf_mysql","title":"<code>deploykf_opt.deploykf_mysql</code>","text":"Value Default <code>deploykf_opt.deploykf_mysql.enabled</code> <code>false</code> <code>deploykf_opt.deploykf_mysql.namespace</code> <code>\"deploykf-mysql\"</code> <code>deploykf_opt.deploykf_mysql.extraManifests</code> <code>[]</code> <code>deploykf_opt.deploykf_mysql.images.mysql.repository</code> <code>\"docker.io/mysql\"</code> <code>deploykf_opt.deploykf_mysql.images.mysql.tag</code> <code>\"8.0.37\"</code> <code>deploykf_opt.deploykf_mysql.images.mysql.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_mysql.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_opt.deploykf_mysql.images.kubectl.tag</code> <code>\"1.26.15-debian-12-r4\"</code> <code>deploykf_opt.deploykf_mysql.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_mysql.persistence.enabled</code> <code>true</code> <code>deploykf_opt.deploykf_mysql.persistence.existingClaim</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.persistence.subPath</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.persistence.storageClass</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.persistence.accessMode</code> <code>\"ReadWriteOnce\"</code> <code>deploykf_opt.deploykf_mysql.persistence.size</code> <code>\"5Gi\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.password</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.existingSecret</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.existingSecretPasswordKey</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.generateSecret</code> <code>false</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.username</code> <code>\"kubeflow\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.password</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.existingSecret</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.existingSecretUsernameKey</code> <code>\"username\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.existingSecretPasswordKey</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.generateSecret</code> <code>false</code> <code>deploykf_opt.deploykf_mysql.customUsers</code> <code>[]</code> <code>deploykf_opt.deploykf_mysql.customDatabases</code> <code>[]</code> <code>deploykf_opt.deploykf_mysql.configuration</code> [mysqld]disable_log_bindefault_authentication_plugin=mysql_native_passwordlog_error_suppression_list='MY-013360'"},{"location":"reference/deploykf-values/#deploykf_optdeploykf_minio","title":"<code>deploykf_opt.deploykf_minio</code>","text":"Value Default <code>deploykf_opt.deploykf_minio.enabled</code> <code>false</code> <code>deploykf_opt.deploykf_minio.namespace</code> <code>\"deploykf-minio\"</code> <code>deploykf_opt.deploykf_minio.extraManifests</code> <code>[]</code> <code>deploykf_opt.deploykf_minio.images.minio.repository</code> <code>\"docker.io/bitnami/minio\"</code> <code>deploykf_opt.deploykf_minio.images.minio.tag</code> <code>\"2024.5.10-debian-12-r2\"</code> <code>deploykf_opt.deploykf_minio.images.minio.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_minio.images.minioMc.repository</code> <code>\"docker.io/bitnami/minio-client\"</code> <code>deploykf_opt.deploykf_minio.images.minioMc.tag</code> <code>\"2024.5.9-debian-12-r0\"</code> <code>deploykf_opt.deploykf_minio.images.minioMc.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_minio.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_opt.deploykf_minio.images.kubectl.tag</code> <code>\"1.26.15-debian-12-r4\"</code> <code>deploykf_opt.deploykf_minio.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_minio.images.shell.repository</code> <code>\"docker.io/bitnami/os-shell\"</code> <code>deploykf_opt.deploykf_minio.images.shell.tag</code> <code>\"12-debian-12-r20\"</code> <code>deploykf_opt.deploykf_minio.images.shell.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_minio.persistence.enabled</code> <code>true</code> <code>deploykf_opt.deploykf_minio.persistence.existingClaim</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.persistence.subPath</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.persistence.storageClass</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.persistence.accessMode</code> <code>\"ReadWriteOnce\"</code> <code>deploykf_opt.deploykf_minio.persistence.size</code> <code>\"5Gi\"</code> <code>deploykf_opt.deploykf_minio.rootUser.username</code> <code>\"minioadmin\"</code> <code>deploykf_opt.deploykf_minio.rootUser.password</code> <code>\"minioadmin\"</code> <code>deploykf_opt.deploykf_minio.rootUser.existingSecret</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.rootUser.existingSecretUsernameKey</code> <code>\"username\"</code> <code>deploykf_opt.deploykf_minio.rootUser.existingSecretPasswordKey</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_minio.rootUser.generateSecret</code> <code>false</code> <code>deploykf_opt.deploykf_minio.rootUser.serviceAccounts</code> <code>[]</code> <code>deploykf_opt.deploykf_minio.identity.openid.policyClaim</code> <code>\"email\"</code> <code>deploykf_opt.deploykf_minio.identity.openid.scopes</code> <code>\"openid,email,groups,profile,offline_access\"</code> <code>deploykf_opt.deploykf_minio.buckets</code> <code>[]</code> <code>deploykf_opt.deploykf_minio.policies</code> <code>[]</code>"},{"location":"reference/deploykf-values/#deploykf-tools","title":"deployKF Tools","text":"<p>Values for configuring tools from the deployKF ecosystem.</p>"},{"location":"reference/deploykf-values/#kubeflow-dependencies","title":"Kubeflow Dependencies","text":"<p>Values for configuring the dependencies of tools in the Kubeflow ecosystem.</p> <code>kubeflow_dependencies.kubeflow_argo_workflows</code>"},{"location":"reference/deploykf-values/#kubeflow_dependencieskubeflow_argo_workflows","title":"<code>kubeflow_dependencies.kubeflow_argo_workflows</code>","text":"Value Default <code>kubeflow_dependencies.kubeflow_argo_workflows.enabled</code> <code>false</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.namespace</code> <code>\"kubeflow-argo-workflows\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.extraManifests</code> <code>[]</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoCli.repository</code> <code>\"quay.io/argoproj/argocli\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoCli.tag</code> <code>\"v3.4.8\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoCli.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoExecutor.repository</code> <code>\"quay.io/argoproj/argoexec\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoExecutor.tag</code> <code>\"v3.3.10\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoExecutor.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoWorkflowController.repository</code> <code>\"quay.io/argoproj/workflow-controller\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoWorkflowController.tag</code> <code>\"v3.3.10\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoWorkflowController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.artifactRepository.keyFormat</code> <code>\"artifacts/{{ workflow.namespace }}/{{ workflow.name }}/{{ workflow.creationTimestamp.Y }}/{{ workflow.creationTimestamp.m }}/{{ workflow.creationTimestamp.d }}/{{ pod.name }}\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.controller.serviceAccount.create</code> <code>true</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.controller.serviceAccount.name</code> <code>\"argo-workflow-controller\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.server.serviceAccount.create</code> <code>true</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.server.serviceAccount.name</code> <code>\"argo-server\"</code>"},{"location":"reference/deploykf-values/#kubeflow-tools","title":"Kubeflow Tools","text":"<p>Values for configuring tools from the Kubeflow ecosystem.</p> <code>kubeflow_tools.notebooks</code> <code>kubeflow_tools.tensorboards</code> <code>kubeflow_tools.katib</code> <code>kubeflow_tools.poddefaults_webhook</code> <code>kubeflow_tools.volumes</code> <code>kubeflow_tools.pipelines</code> <code>kubeflow_tools.training_operator</code>"},{"location":"reference/deploykf-values/#kubeflow_toolsnotebooks","title":"<code>kubeflow_tools.notebooks</code>","text":"Value Default <code>kubeflow_tools.notebooks.enabled</code> <code>false</code> <code>kubeflow_tools.notebooks.extraManifests</code> <code>[]</code> <code>kubeflow_tools.notebooks.images.jupyterWebApp.repository</code> <code>\"docker.io/kubeflownotebookswg/jupyter-web-app\"</code> <code>kubeflow_tools.notebooks.images.jupyterWebApp.tag</code> <code>nil</code> <code>kubeflow_tools.notebooks.images.notebookController.repository</code> <code>\"docker.io/kubeflownotebookswg/notebook-controller\"</code> <code>kubeflow_tools.notebooks.images.notebookController.tag</code> <code>nil</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.allowCustomImage</code> <code>true</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.hideRegistry</code> <code>true</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.hideTag</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imagePullPolicy.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imagePullPolicy.value</code> <code>\"IfNotPresent\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.image.value</code> <code>\"kubeflownotebookswg/jupyter-scipy:v1.8.0\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.image.options</code> <code>[\"kubeflownotebookswg/jupyter-scipy:v1.8.0\", \"kubeflownotebookswg/jupyter-pytorch-full:v1.8.0\", \"kubeflownotebookswg/jupyter-pytorch-cuda-full:v1.8.0\", \"kubeflownotebookswg/jupyter-tensorflow-full:v1.8.0\", \"kubeflownotebookswg/jupyter-tensorflow-cuda-full:v1.8.0\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupOne.value</code> <code>\"kubeflownotebookswg/codeserver-python:v1.8.0\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupOne.options</code> <code>[\"kubeflownotebookswg/codeserver-python:v1.8.0\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupTwo.value</code> <code>\"kubeflownotebookswg/rstudio-tidyverse:v1.8.0\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupTwo.options</code> <code>[\"kubeflownotebookswg/rstudio-tidyverse:v1.8.0\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu.value</code> <code>\"0.5\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu.limitFactor</code> <code>\"1.2\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory.value</code> <code>\"1.0Gi\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory.limitFactor</code> <code>\"1.2\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.value.vendor</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.value.vendors</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.value.num</code> <code>\"none\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.mount</code> <code>\"/home/jovyan\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.metadata.name</code> <code>\"{notebook-name}-workspace\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.spec.resources.requests.storage</code> <code>\"5Gi\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.spec.accessModes</code> <code>[\"ReadWriteOnce\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.dataVolumes.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.dataVolumes.value</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig.value</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig.options</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup.value</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup.options</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.shm.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.shm.value</code> <code>true</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.configurations.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.configurations.value</code> <code>[]</code> <code>kubeflow_tools.notebooks.notebookTemplate</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupOne.icon</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupOne.logo</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupTwo.icon</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupTwo.logo</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.notebookCulling.enabled</code> <code>false</code> <code>kubeflow_tools.notebooks.notebookCulling.idleTime</code> <code>1440</code> <code>kubeflow_tools.notebooks.notebookCulling.idlenessCheckPeriod</code> <code>1</code>"},{"location":"reference/deploykf-values/#kubeflow_toolstensorboards","title":"<code>kubeflow_tools.tensorboards</code>","text":"Value Default <code>kubeflow_tools.tensorboards.enabled</code> <code>false</code> <code>kubeflow_tools.tensorboards.extraManifests</code> <code>[]</code> <code>kubeflow_tools.tensorboards.images.tensorboardController.repository</code> <code>\"docker.io/kubeflownotebookswg/tensorboard-controller\"</code> <code>kubeflow_tools.tensorboards.images.tensorboardController.tag</code> <code>nil</code> <code>kubeflow_tools.tensorboards.images.tensorboardsWebApp.repository</code> <code>\"docker.io/kubeflownotebookswg/tensorboards-web-app\"</code> <code>kubeflow_tools.tensorboards.images.tensorboardsWebApp.tag</code> <code>nil</code> <code>kubeflow_tools.tensorboards.images.kubeRbacProxy.repository</code> <code>\"gcr.io/kubebuilder/kube-rbac-proxy\"</code> <code>kubeflow_tools.tensorboards.images.kubeRbacProxy.tag</code> <code>nil</code> <code>kubeflow_tools.tensorboards.tensorboardImage</code> <code>\"docker.io/tensorflow/tensorflow:2.5.1\"</code>"},{"location":"reference/deploykf-values/#kubeflow_toolskatib","title":"<code>kubeflow_tools.katib</code>","text":"Value Default <code>kubeflow_tools.katib.enabled</code> <code>false</code> <code>kubeflow_tools.katib.extraManifests</code> <code>[]</code> <code>kubeflow_tools.katib.images.katibController.repository</code> <code>\"docker.io/kubeflowkatib/katib-controller\"</code> <code>kubeflow_tools.katib.images.katibController.tag</code> <code>nil</code> <code>kubeflow_tools.katib.images.katibDbManager.repository</code> <code>\"docker.io/kubeflowkatib/katib-db-manager\"</code> <code>kubeflow_tools.katib.images.katibDbManager.tag</code> <code>nil</code> <code>kubeflow_tools.katib.images.katibUi.repository</code> <code>\"docker.io/kubeflowkatib/katib-ui\"</code> <code>kubeflow_tools.katib.images.katibUi.tag</code> <code>nil</code> <code>kubeflow_tools.katib.mysql.useExternal</code> <code>false</code> <code>kubeflow_tools.katib.mysql.host</code> <code>\"mysql.example.com\"</code> <code>kubeflow_tools.katib.mysql.port</code> <code>3306</code> <code>kubeflow_tools.katib.mysql.auth.username</code> <code>\"kubeflow\"</code> <code>kubeflow_tools.katib.mysql.auth.password</code> <code>\"password\"</code> <code>kubeflow_tools.katib.mysql.auth.existingSecret</code> <code>\"\"</code> <code>kubeflow_tools.katib.mysql.auth.existingSecretUsernameKey</code> <code>\"username\"</code> <code>kubeflow_tools.katib.mysql.auth.existingSecretPasswordKey</code> <code>\"password\"</code> <code>kubeflow_tools.katib.mysqlDatabase</code> <code>\"katib\"</code>"},{"location":"reference/deploykf-values/#kubeflow_toolspoddefaults_webhook","title":"<code>kubeflow_tools.poddefaults_webhook</code>","text":"Value Default <code>kubeflow_tools.poddefaults_webhook.enabled</code> <code>false</code> <code>kubeflow_tools.poddefaults_webhook.extraManifests</code> <code>[]</code> <code>kubeflow_tools.poddefaults_webhook.images.poddefaultsWebhook.repository</code> <code>\"docker.io/kubeflownotebookswg/poddefaults-webhook\"</code> <code>kubeflow_tools.poddefaults_webhook.images.poddefaultsWebhook.tag</code> <code>nil</code>"},{"location":"reference/deploykf-values/#kubeflow_toolsvolumes","title":"<code>kubeflow_tools.volumes</code>","text":"Value Default <code>kubeflow_tools.volumes.enabled</code> <code>false</code> <code>kubeflow_tools.volumes.extraManifests</code> <code>[]</code> <code>kubeflow_tools.volumes.images.volumesWebApp.repository</code> <code>\"docker.io/kubeflownotebookswg/volumes-web-app\"</code> <code>kubeflow_tools.volumes.images.volumesWebApp.tag</code> <code>nil</code>"},{"location":"reference/deploykf-values/#kubeflow_toolspipelines","title":"<code>kubeflow_tools.pipelines</code>","text":"Value Default <code>kubeflow_tools.pipelines.enabled</code> <code>false</code> <code>kubeflow_tools.pipelines.extraManifests</code> <code>[]</code> <code>kubeflow_tools.pipelines.images.kfpCacheServer.repository</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/cache-server\"</code> <code>kubeflow_tools.pipelines.images.kfpCacheServer.tag</code> <code>\"2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.images.kfpMetadataEnvoy.repository</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/metadata-envoy\"</code> <code>kubeflow_tools.pipelines.images.kfpMetadataEnvoy.tag</code> <code>\"2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.images.kfpMetadataWriter.repository</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/metadata-writer\"</code> <code>kubeflow_tools.pipelines.images.kfpMetadataWriter.tag</code> <code>\"2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.images.kfpApiServer.repository</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/api-server\"</code> <code>kubeflow_tools.pipelines.images.kfpApiServer.tag</code> <code>\"2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.images.kfpPersistenceagent.repository</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/persistenceagent\"</code> <code>kubeflow_tools.pipelines.images.kfpPersistenceagent.tag</code> <code>\"2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.images.kfpScheduledworkflow.repository</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/scheduledworkflow\"</code> <code>kubeflow_tools.pipelines.images.kfpScheduledworkflow.tag</code> <code>\"2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.images.kfpFrontend.repository</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/frontend\"</code> <code>kubeflow_tools.pipelines.images.kfpFrontend.tag</code> <code>\"2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.images.kfpViewerCrdController.repository</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/viewer-crd-controller\"</code> <code>kubeflow_tools.pipelines.images.kfpViewerCrdController.tag</code> <code>\"2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.images.kfpVisualizationServer.repository</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/visualization-server\"</code> <code>kubeflow_tools.pipelines.images.kfpVisualizationServer.tag</code> <code>\"2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.images.tfxMlMetadataStoreServer.repository</code> <code>\"ghcr.io/deploykf/ml_metadata_store_server\"</code> <code>kubeflow_tools.pipelines.images.tfxMlMetadataStoreServer.tag</code> <code>\"1.14.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.bucket.name</code> <code>\"kubeflow-pipelines\"</code> <code>kubeflow_tools.pipelines.bucket.region</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.objectStore.useExternal</code> <code>false</code> <code>kubeflow_tools.pipelines.objectStore.host</code> <code>\"s3.amazonaws.com\"</code> <code>kubeflow_tools.pipelines.objectStore.port</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.objectStore.useSSL</code> <code>true</code> <code>kubeflow_tools.pipelines.objectStore.auth.fromEnv</code> <code>false</code> <code>kubeflow_tools.pipelines.objectStore.auth.accessKey</code> <code>\"my-access-key\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.secretKey</code> <code>\"my-secret-key\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.existingSecret</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.existingSecretAccessKeyKey</code> <code>\"AWS_ACCESS_KEY_ID\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.existingSecretSecretKeyKey</code> <code>\"AWS_SECRET_ACCESS_KEY\"</code> <code>kubeflow_tools.pipelines.mysql.useExternal</code> <code>false</code> <code>kubeflow_tools.pipelines.mysql.host</code> <code>\"mysql.example.com\"</code> <code>kubeflow_tools.pipelines.mysql.port</code> <code>3306</code> <code>kubeflow_tools.pipelines.mysql.auth.username</code> <code>\"kubeflow\"</code> <code>kubeflow_tools.pipelines.mysql.auth.password</code> <code>\"password\"</code> <code>kubeflow_tools.pipelines.mysql.auth.existingSecret</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.mysql.auth.existingSecretUsernameKey</code> <code>\"username\"</code> <code>kubeflow_tools.pipelines.mysql.auth.existingSecretPasswordKey</code> <code>\"password\"</code> <code>kubeflow_tools.pipelines.mysqlDatabases.cacheDatabase</code> <code>\"kfp_cache\"</code> <code>kubeflow_tools.pipelines.mysqlDatabases.metadataDatabase</code> <code>\"kfp_metadata\"</code> <code>kubeflow_tools.pipelines.mysqlDatabases.pipelinesDatabase</code> <code>\"kfp_pipelines\"</code> <code>kubeflow_tools.pipelines.kfpV2.defaultPipelineRoot</code> <code>\"{scheme}://{bucket_name}/v2/artifacts/{profile_name}?region={bucket_region}&amp;endpoint={endpoint}&amp;disableSSL={not_use_ssl}&amp;s3ForcePathStyle=true\"</code> <code>kubeflow_tools.pipelines.kfpV2.driverImage</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/kfp-driver:2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.kfpV2.launcherImage</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/kfp-launcher:2.1.0-deploykf.0\"</code> <code>kubeflow_tools.pipelines.kfpV2.v2CompatibleLauncherImage</code> <code>\"ghcr.io/deploykf/kubeflow-pipelines/kfp-launcher:1.8.22-deploykf.0\"</code> <code>kubeflow_tools.pipelines.cache.image</code> <code>\"gcr.io/google-containers/busybox:1.27\"</code> <code>kubeflow_tools.pipelines.cache.maximumMaxCacheStaleness</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.cache.defaultMaxCacheStaleness</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.cache.namespaceRedirect</code> <code>true</code> <code>kubeflow_tools.pipelines.profileResourceGeneration.kfpApiTokenPodDefault</code> <code>false</code>"},{"location":"reference/deploykf-values/#kubeflow_toolstraining_operator","title":"<code>kubeflow_tools.training_operator</code>","text":"Value Default <code>kubeflow_tools.training_operator.enabled</code> <code>false</code> <code>kubeflow_tools.training_operator.extraManifests</code> <code>[]</code> <code>kubeflow_tools.training_operator.images.trainingOperator.repository</code> <code>\"docker.io/kubeflow/training-operator\"</code> <code>kubeflow_tools.training_operator.images.trainingOperator.tag</code> <code>nil</code>"},{"location":"reference/future-tools/","title":"Future Tools","text":"<p>A list of ML &amp; Data tools which may be part of future versions of deployKF.</p> <p>How do I request or contribute a tool?</p> <p>If you would like to request or contribute support for a tool, please raise an issue on GitHub, or join the discussion on an existing issue.</p>"},{"location":"reference/future-tools/#tool-roadmap","title":"Tool Roadmap","text":"<p>The following is a roadmap of ML &amp; Data tools which are planned for future versions of deployKF, grouped by priority.</p>"},{"location":"reference/future-tools/#higher-priority","title":"Higher Priority","text":"Name(Click for Details) Purpose MLflow Model Registry Model Registry KServe Model Serving"},{"location":"reference/future-tools/#medium-priority","title":"Medium Priority","text":"Name(Click for Details) Purpose Feast Feature Store Apache Airflow Workflow Orchestration"},{"location":"reference/future-tools/#lower-priority","title":"Lower Priority","text":"Name(Click for Details) Purpose DataHub Data Catalog Airbyte Data Integration Label Studio Data Labeling BentoML Yatai Model Serving Seldon Core Model Serving"},{"location":"reference/future-tools/#tool-details","title":"Tool Details","text":"<p>The following sections provide details and descriptions of each tool which is planned for future versions of deployKF.</p> Details - MLflow Model Registry Details - KServe Details - Feast Details - Apache Airflow Details - DataHub Details - Airbyte Details - Label Studio Details - BentoML Yatai Details - Seldon Core"},{"location":"reference/future-tools/#mlflow-model-registry","title":"MLflow Model Registry","text":"<p> PurposeModel Registry MaintainerDatabricks DocumentationDocumentation Source Code<code>mlflow/mlflow</code> Roadmap PriorityHigher MLflow Model Registry is an open source machine learning model registry.</p> <p>A model registry decouples model training from model deployment, allowing you to break the model lifecycle down into three separate concerns. This separation enables you to have well-scoped pipelines, rather than trying to go from training to deployment all at once.</p> <ol> <li>Model Training: Training new versions of models and logging them into the registry.</li> <li>Model Evaluation: Evaluating versions of models and logging the results into the registry.</li> <li>Model Deployment: Making informed decisions about which models to deploy and then deploying them.</li> </ol> <p>The key features of MLflow Model Registry are:</p> <ul> <li>Model Versioning: Version your model artifacts and attach metadata to each version.</li> <li>Model Stage Transitions: Transition models between stages (e.g. staging to production).</li> <li>Web UI: A graphical web interface for managing models.</li> <li>Python API: A Python API for managing models.</li> <li>REST API: A REST API for managing models.</li> </ul>"},{"location":"reference/future-tools/#kserve","title":"KServe","text":"<p> PurposeModel Serving MaintainerLinux Foundation DocumentationDocumentation Source Code<code>kserve/kserve</code> Roadmap PriorityHigher KServe provides comprehensive interfaces for deploying, managing, and monitoring ML models on Kubernetes.</p> <p>The core features of KServe are:</p> <ul> <li>Support for Many Frameworks: KServe natively supports many ML frameworks (e.g. PyTorch, TensorFlow, scikit-learn, XGBoost).</li> <li>Autoscaling, Even to Zero: KServe can autoscale model replicas to meet demand, even scaling to zero when there are no requests.</li> <li>Model Monitoring: KServe integrates tools like Alibi Detect to provide model monitoring for drift and outlier detection.</li> <li>Model Explainability: KServe integrates tools like Alibi Explain to provide model explainability.</li> <li>Request Batching: KServe can batch requests to your model, improving throughput and reducing cost.</li> <li>Canary Deployments: KServe can deploy new versions of your model alongside old versions, and route requests to the new version based on a percentage.</li> <li>Feature Transformers: KServe can do feature pre/post processing alongside model inference (e.g. using Feast).</li> <li>Inference Graphs: KServe can chain multiple models together to form an inference graph.</li> </ul>"},{"location":"reference/future-tools/#feast","title":"Feast","text":"<p> PurposeFeature Store MaintainerTecton DocumentationDocumentation Source Code<code>feast-dev/feast</code> Roadmap PriorityMedium Feast is an open-source feature store for machine learning.</p> <p>A good way to understand the purpose of a feature store is to think about the data access patterns encountered during the model lifecycle. A feature store should somehow make these data access patterns easier.</p> <ul> <li>Feature Engineering: Accesses and transforms historical data to create features.</li> <li>Target Engineering: Accesses and transforms historical data to create targets.</li> <li>Model Training: Accesses features and targets to train and evaluate the model.</li> <li>Model Inference: Accesses features of new data to predict the target.</li> </ul> <p>The key features of Feast are:</p> <ul> <li>Feature Registry: Where Feast persists feature definitions (not data) that are registered with with it (e.g. Local-Files, S3, GCS).</li> <li>Python SDK: The primary interface for managing feature definitions, and retrieving feature values from Feast.</li> <li>Offline Data Stores: A store which Feast can read feature values from, for historical data retrieval (e.g. Snowflake, BigQuery, Redshift).</li> <li>Online Data Stores: A store which Feast can materialize (write) feature values into, for online model inference (e.g. Snowflake, Redis, DynamoDB, Bigtable).</li> <li>Batch Materialization Engine: A data processing engine which Feast can use to materialize feature values from an Offline Store into an Online Store (e.g. Snowflake, Spark, Bytewax).</li> </ul> <p>A good feature store is NOT a database, but rather a data access layer between your data sources and your ML models. Be very wary of any feature store that requires you to load your data into it directly.</p>"},{"location":"reference/future-tools/#apache-airflow","title":"Apache Airflow","text":"<p> PurposeWorkflow Orchestration MaintainerApache Software Foundation DocumentationDocumentation Source Code<code>apache/airflow</code> Roadmap PriorityMedium Apache Airflow is by far the most popular open-source workflow orchestration tool in the world.</p> <p>The versatility and extensibility of Apache Airflow make it a great fit for many different use cases, including machine learning.</p> <p>The key features of Apache Airflow are:</p> <ul> <li>Python Centered: Airflow is written in Python and uses a Python DSL to define workflows.</li> <li>Dynamic Workflows: Airflow's code-driven workflow definitions enable powerful patterns like dynamically generating workflows.</li> <li>Extensive Plugins: Airflow has a rich ecosystem of plugins and integrations with other tools.</li> <li>User Interface: Airflow is known for its powerful user interface which allows users to monitor and manage workflows.</li> </ul>"},{"location":"reference/future-tools/#datahub","title":"DataHub","text":"<p> PurposeData Catalog MaintainerAcryl Data DocumentationDocumentation Source Code<code>datahub-project/datahub</code> Roadmap PriorityLower DataHub is an open-source metadata platform for discovering, managing, and understanding data.</p> <p>The core features of DataHub are:</p> <ul> <li>Support for Many Data Sources: DataHub supports ingestion of metadata from many sources.</li> <li>Search &amp; Discovery: DataHub provides a search interface for discovering data.</li> <li>Data Lineage: DataHub can capture and visualize complex data lineage.</li> </ul>"},{"location":"reference/future-tools/#airbyte","title":"Airbyte","text":"<p> PurposeData Integration MaintainerAirbyte DocumentationDocumentation Source Code<code>airbytehq/airbyte</code> Roadmap PriorityLower Airbyte is a data integration platform which aims to make it easy to move data from any source to any destination.</p> <p>The core features of Airbyte are:</p> <ul> <li>Comprehensive Connector Catalog: Airbyte has an extremely large catalog of connectors for data sources and destinations.</li> <li>Airbyte Web UI: Airbyte provides a graphical web interface for managing data connectors and orchestrating data syncs.</li> </ul>"},{"location":"reference/future-tools/#label-studio","title":"Label Studio","text":"<p> PurposeData Labeling MaintainerHeartex DocumentationDocumentation Source Code<code>heartexlabs/label-studio</code> Roadmap PriorityLower Label Studio is an open-source data labeling platform which supports a variety of data types and labeling tasks.</p> <p>The core features of Label Studio are:</p> <ul> <li>Data Types: Label Studio supports a variety of data types, including text, images, audio, video, and time series.</li> <li>Task Templates: Label Studio provides many templates for common labeling tasks, including text classification, named entity recognition, and object detection.</li> <li>Label Studio Web UI: Label Studio provides a graphical web interface for labeling data and managing labeling projects.</li> </ul>"},{"location":"reference/future-tools/#bentoml-yatai","title":"BentoML Yatai","text":"<p> PurposeModel Serving MaintainerBentoML DocumentationDocumentation Source Code<code>bentoml/Yatai</code> Roadmap PriorityLower BentoML Yatai is a platform for managing the lifecycle of BentoML models on Kubernetes.</p> <p>The core features of BentoML Yatai are:</p> <ul> <li>Model Registry: A central registry for packaged Bentos.</li> <li>Model Deployment: Managing the deployment of BentoML models to Kubernetes, including building model container images.</li> <li>Web UI: A graphical web interface for viewing, deploying, and monitoring models.</li> <li>REST APIs: A REST API for viewing, deploying, and monitoring models.</li> <li>Kubernetes CRDs: Manage the deployment of models in a DevOps-friendly way.</li> </ul>"},{"location":"reference/future-tools/#seldon-core","title":"Seldon Core","text":"<p> PurposeModel Serving MaintainerSeldon DocumentationDocumentation Source Code<code>SeldonIO/seldon-core</code> Roadmap PriorityLower Seldon Core provides interfaces for converting ML models into REST/gRPC microservices on Kubernetes.</p> <p>The core features of Seldon Core are:</p> <ul> <li>Support for Many Frameworks: Seldon Core natively supports many ML frameworks (e.g. TensorFlow, scikit-learn, XGBoost, HuggingFace, NVIDIA Triton).</li> <li>Reusable Model Servers: Seldon Core removes the need to build a container image for each model, by providing a system to download model artifacts at runtime.</li> <li>Model Deployment CRD Seldon Core provides a simple, yet powerful, Kubernetes CRD for deploying models.</li> </ul>"},{"location":"reference/tools/","title":"Current Tools","text":"<p>A list of ML &amp; Data tools which are currently available in deployKF.</p> <p>Versions of tools</p> <p>The tool versions page lists which versions of these tools are included with each version of deployKF.</p> <p>Future tools</p> <p>The future tools page gives information about tools which are planned for future releases.</p>"},{"location":"reference/tools/#tool-index","title":"Tool Index","text":"<p>The following is an index of ML &amp; Data tools which are currently supported by deployKF, grouped by ecosystem.</p>"},{"location":"reference/tools/#kubeflow-ecosystem","title":"Kubeflow Ecosystem","text":"<p>Kubeflow is an \"MLOps on Kubernetes\" ecosystem which is owned by the CNCF, and provides various tools for building and deploying ML applications on Kubernetes.</p> Name(Click for Details) Purpose Since deployKF Kubeflow Pipelines Workflow Orchestration <code>0.1.0</code> Kubeflow Notebooks Hosting Developer Environments <code>0.1.0</code> Kubeflow Katib Automated Machine Learning <code>0.1.0</code> Kubeflow Training Operator Managing Training Jobs <code>0.1.0</code> Kubeflow Volumes Managing Kubernetes Volumes <code>0.1.0</code> Kubeflow TensorBoards Managing TensorBoards <code>0.1.0</code>"},{"location":"reference/tools/#deploykf-ecosystem","title":"deployKF Ecosystem","text":"<p>Coming soon... See future tools for more information.</p>"},{"location":"reference/tools/#tool-details","title":"Tool Details","text":"<p>The following sections provide details and descriptions of each tool which is currently available in deployKF.</p> Details - Kubeflow Pipelines Details - Kubeflow Notebooks Details - Kubeflow Katib Details - Kubeflow Training Operator Details - Kubeflow Volumes Details - Kubeflow TensorBoards"},{"location":"reference/tools/#kubeflow-pipelines","title":"Kubeflow Pipelines","text":"<p> PurposeWorkflow Orchestration MaintainerKubeflow Project DocumentationDocumentation Source Code<code>kubeflow/pipelines</code> deployKF Configs<code>kubeflow_tools.pipelines</code> Since deployKF<code>0.1.0</code> Kubeflow Pipelines (KFP) is a platform for building and running machine learning workflows on Kubernetes.</p> <p>KFP provides higher-level abstractions for Argo Workflows to reduce repetition when defining machine learning tasks.  KFP has abstractions for defining pipelines and reusable components which it can compile and execute as Argo <code>Workflows</code>.</p> <p>The primary interface of KFP is the Python SDK, which allows you to define pipelines and reusable components with Python. KFP also provides a Web UI for managing and tracking experiments, pipeline definitions, and pipeline runs. Finally, KFP provides a REST API that allows programmatic access to the platform.</p>"},{"location":"reference/tools/#kubeflow-notebooks","title":"Kubeflow Notebooks","text":"<p> PurposeHosting Developer Environments MaintainerKubeflow Project DocumentationDocumentation Source Code<code>kubeflow/kubeflow</code> deployKF Configs<code>kubeflow_tools.notebooks</code> Since deployKF<code>0.1.0</code> Kubeflow Notebooks lets you run web-based development environments inside a Kubernetes cluster.</p> <p>Kubeflow Notebooks can run any web-based tool, but comes with pre-built images for JupyterLab, RStudio, and Visual Studio Code.</p> <p>Running development environments inside a Kubernetes cluster has several advantages:</p> <ul> <li>Remote Resources: Users can work directly on the cluster, rather than locally on their workstations.</li> <li>Standard Environments: Cluster admins can provide standard environment images for their organization, with required and approved packages pre-installed.</li> <li>Sharing &amp; Access Control: Access is managed via role-based-access-control (RBAC), enabling easier notebook sharing and collaboration across the organization.</li> </ul>"},{"location":"reference/tools/#kubeflow-katib","title":"Kubeflow Katib","text":"<p> PurposeAutomated Machine Learning MaintainerKubeflow Project DocumentationDocumentation Source Code<code>kubeflow/katib</code> deployKF Configs<code>kubeflow_tools.katib</code> Since deployKF<code>0.1.0</code> Kubeflow Katib is an Automated Machine Learning (AutoML) platform for Kubernetes.</p> <p>The key features of Katib are:</p> <ul> <li>Support for Multiple Techniques: Katib supports techniques like Hyperparameter Tuning, Early Stopping, and Neural Architecture Search.</li> <li>Support for ML Frameworks: Katib natively supports many ML frameworks like TensorFlow, PyTorch, XGBoost, and more.</li> <li>Kubernetes Native: Katib can manage training jobs on any Kubernetes Resource, and has out-of-the-box support for Kubeflow Training Operator, Argo Workflows, Tekton Pipelines, and more.</li> </ul>"},{"location":"reference/tools/#kubeflow-training-operator","title":"Kubeflow Training Operator","text":"<p> PurposeManaging Training Jobs MaintainerKubeflow Project DocumentationDocumentation Source Code<code>kubeflow/training-operator</code> deployKF Configs<code>kubeflow_tools.training_operator</code> Since deployKF<code>0.1.0</code> Kubeflow Training Operator helps you run machine learning training jobs on Kubernetes.</p> <p>The core function of the  Kubeflow Training Operator is to provide Kubernetes Custom Resources (CRDs) that define and monitor training jobs on Kubernetes.</p> <p>Many popular ML frameworks have been integrated with the Training Operator, including:</p> <ul> <li>PyTorch</li> <li>TensorFlow</li> <li>XGBoost</li> <li>MPI</li> </ul>"},{"location":"reference/tools/#kubeflow-volumes","title":"Kubeflow Volumes","text":"<p> PurposeManaging Kubernetes Volumes MaintainerKubeflow Project DocumentationN/A Source Code<code>kubeflow/kubeflow</code> deployKF Configs<code>kubeflow_tools.volumes</code> Since deployKF<code>0.1.0</code> Kubeflow Volumes is a web-based UI for creating and managing Kubernetes Persistent Volumes.</p>"},{"location":"reference/tools/#kubeflow-tensorboards","title":"Kubeflow TensorBoards","text":"<p> PurposeManaging TensorBoards MaintainerKubeflow Project DocumentationN/A Source Code<code>kubeflow/kubeflow</code> deployKF Configs<code>kubeflow_tools.tensorboards</code> Since deployKF<code>0.1.0</code> Kubeflow TensorBoards is a web-based UI for creating and managing TensorBoard instances on Kubernetes.</p>"},{"location":"releases/changelog-deploykf-cli/","title":"Changelog - deployKF CLI","text":"<p>This changelog lists releases of the deployKF CLI that are found in the <code>deployKF/cli</code> repository.</p> What about pre-releases? <p>For a changelog that includes pre-releases, see the full-changelog.</p>"},{"location":"releases/changelog-deploykf-cli/#0.1.2","title":"0.1.2 (2023-08-09)","text":"What's Changed <p>Bug Fixes</p> <ul> <li>fix: nil pointer on download error by @thesuperzapper in #12</li> </ul>"},{"location":"releases/changelog-deploykf-cli/#0.1.1","title":"0.1.1 (2023-08-07)","text":"What's Changed <p>New Features</p> <ul> <li>feat: publish container image for cli by @thesuperzapper in #11</li> </ul>"},{"location":"releases/changelog-deploykf-cli/#0.1.0","title":"0.1.0 (2023-07-09)","text":"What's Changed <p>Significant Changes</p> <ul> <li>initial release \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 </li> </ul>"},{"location":"releases/changelog-deploykf/","title":"Changelog - deployKF","text":"<p>This changelog lists releases of deployKF that are found in the <code>deployKF/deployKF</code> repository.</p> <p>Danger</p> <p>Carefully review the \"Upgrade Notes\" and \"Important Notes\" before upgrading deployKF to a new version.Also review the tool versions and version matrix pages.</p> Can I be notified of new releases? <p>Yes. Watch the <code>deployKF/deployKF</code> repo on GitHub.At the top right, click <code>Watch</code> \u2192 <code>Custom</code> \u2192 <code>Releases</code> then confirm by selecting <code>Apply</code>.</p> What about pre-releases? <p>For a changelog that includes pre-releases, see the full-changelog.</p>"},{"location":"releases/changelog-deploykf/#0.1.5","title":"0.1.5 (2024-05-28)","text":"Upgrade Notes <ul> <li>We strongly recommend updating to this version for security reasons.</li> <li>As always, if your deployKF platform is critical to your organization, you should test this upgrade in a non-production cluster. We have done extensive testing, but you could encounter unexpected issues.</li> <li>Please update your <code>sync_argocd_apps.sh</code> script version BEFORE SYNCING 0.1.5.</li> <li>The sample values for 0.1.4 had some values that will conflict with 0.1.5, YOU MUST REMOVE THEM from your custom values when upgrading:<ul> <li><code>kubeflow_tools.pipelines.kfpV2.defaultPipelineRoot</code></li> <li><code>kubeflow_tools.pipelines.kfpV2.minioFix</code></li> <li><code>kubeflow_tools.pipelines.kfpV2.launcherImage</code></li> </ul> </li> <li>We have updated the default embedded Istio version to 1.17.8. To make the process of updating the sidecar images easier, we now provide the <code>update_istio_sidecars.sh</code> script to restart pods with incorrect istio sidecar container versions. Warning, running this script will cause DISRUPTION, especially to Notebooks, so ensure your users have saved their work!</li> <li>If you have followed the Air-Gapped Clusters guide, you must mirror the new images/charts used in 0.1.5, and update the corresponding values. For an overview of which images have changed, see the diff of <code>default_values.yaml</code> from 0.1.4 to 0.1.5. Warning, DO NOT continue using the old images/charts with 0.1.5, as this will not work.</li> </ul> Important Notes <ul> <li>deployKF Dashboard:<ul> <li>We have grouped the sidebar links from Kubeflow Pipelines into their own section.</li> <li>Users can now see their profiles with \"view\" and \"edit\" access on the \"Manage Contributors\" page.</li> </ul> </li> <li>Kubeflow Pipelines:<ul> <li>This release includes a patched version of Kubeflow Pipelines 2.1.0 which is specially designed to be backward compatible with all V1 and V2-compatible pipelines.</li> <li>When doing an in-place upgrade, you will not automatically have the V2 tutorial pipelines added to your cluster. You may want to upload them manually as \"shared\" pipeline definitions (find the YAML files attached to the GitHub release).</li> </ul> </li> <li>Kubeflow Notebooks:<ul> <li>We have updated the default Kubeflow Notebooks images to the ones shipped with upstream 1.8.0, these provide significant version bumps for all packages, including TensorFlow 2.13.0 and PyTorch 2.1.0. These images will be updated further in the next release.</li> <li>Please note, we have only updated the DEFAULT IMAGES, which will not affect any existing notebooks. To update existing Notebooks, you must delete and recreate them (data stored in the home directory PVC will be persisted, and you can re-attach it to the new notebooks).</li> </ul> </li> <li>ARM Support:<ul> <li>For those waiting on full ARM64 support, there are now only two remaining components preventing this. The Kubeflow Notebooks backend (which will be updated in the next release), and Kubeflow Pipelines (which needs some help upstream, see #10309 to help).</li> </ul> </li> <li>Istio:<ul> <li>While the default version of Istio (<code>1.17.8</code>) is very old, you can easily update to a newer version that is supported by deployKF by updating the <code>deploykf_dependencies.istio.charts</code> and <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway</code> values.</li> <li>We provide the <code>update_istio_sidecars.sh</code> script to restart pods with incorrect Istio sidecar container versions. Warning, running this script will cause DISRUPTION, especially to Notebooks, so ensure your users have saved their work!</li> <li>In the next minor release, we will do a significant update to the default Istio version, and drop out-of-the-box support for very old Kubernetes versions.</li> </ul> </li> <li>Kyverno:<ul> <li>We still have a hard dependency on Kyverno 1.10.0 due to issues upstream. Hopefully, this will change in the next deployKF version as we test and implement support for the recently released Kyverno 1.12 (which is NOT supported in deployKF 0.1.5).</li> <li>This means that you are still unable to bring your own Kyverno deployment (unless it happens to be the 1.10.0 version). Once this is not the case, we will release a proper \"use existing Kyverno\" guide like we have for Istio.</li> </ul> </li> </ul> What's Changed <p>Significant Changes</p> <ul> <li>docs: add <code>update_istio_sidecars.sh</code> script by @thesuperzapper in #132</li> <li>feat: update to Kubeflow Pipelines 2.1.0 by @thesuperzapper in #122</li> <li>feat: update dashboard to 0.1.1 + update sidebar links by @thesuperzapper in #163</li> <li>feat: update default notebook images to 1.8.0 by @thesuperzapper in #164</li> </ul> <p>New Features</p> <ul> <li>feat: update oauth2-proxy to 7.6.0 by @thesuperzapper in #152</li> <li>feat: update cert-manager to 1.12.10 by @thesuperzapper in #153</li> <li>feat: update dex to 2.39.1 by @thesuperzapper in #155</li> <li>feat: update kubectl container to 1.26.15 by @thesuperzapper in #156</li> <li>feat: update default istio to 1.17.8 by @thesuperzapper in #157</li> <li>feat: update default minio to <code>RELEASE.2024-05-10T01-41-38Z</code> by @thesuperzapper in #158</li> <li>feat: update default mysql to 8.0.37 by @thesuperzapper in #159</li> <li>feat: update profile-controller and kfam to 1.8.0 by @thesuperzapper in #162</li> <li>feat: update trust-manager to 0.9.2 by @thesuperzapper in #154</li> </ul> <p>Improvements</p> <ul> <li>improve: support <code>argocd.appNamePrefix</code> in argocd sync script by @thesuperzapper in #108</li> <li>improve: add robots.txt to deny all user-agents by @thesuperzapper in #106</li> </ul> <p>Bug Fixes</p> <ul> <li>fix: argocd sync script only seeing first app in each group by @thesuperzapper in #109</li> <li>fix: require pruning in sync script by @thesuperzapper in #123</li> <li>fix: require bash 4.4+ for sync script by @thesuperzapper in #126</li> <li>fix: script should sync apps that failed their last sync by @thesuperzapper in #151</li> <li>fix: minio not starting, upstream removed curl by @thesuperzapper in #165</li> <li>fix: stop embedded mysql log spam about <code>mysql_native_password</code> by @thesuperzapper in #167</li> </ul> <p>Documentation</p> <ul> <li>docs: update default argocd to 2.10.4 by @thesuperzapper in #114</li> <li>docs: add argocd helm example for plugin by @thesuperzapper in #121</li> <li>docs: remove confusing sample values by @thesuperzapper in #160</li> <li>docs: update default argocd to 2.10.11 by @thesuperzapper in #166</li> </ul>"},{"location":"releases/changelog-deploykf/#0.1.4","title":"0.1.4 (2024-02-16)","text":"Upgrade Notes <ul> <li>There will be some downtime for Kubeflow Pipelines and users will be forced to re-authenticate.</li> <li>You MUST sync with pruning enabled, as we have changed a number of resources.</li> <li>If you are using our automated ArgoCD Sync Script:<ul> <li>Update to the latest script version, found in the <code>main</code> branch.</li> <li>Ensure you respond \"yes\" to all \"Do you want to sync with PRUNING enabled?\" prompts.</li> <li>To prevent the need to sync twice, please manually delete this <code>ClusterPolicy</code> using the following command BEFORE syncing: <code>kubectl delete clusterpolicy \"kubeflow-pipelines--generate-profile-resources\"</code></li> <li>(otherwise, the first sync will time-out waiting for <code>kf-tools--pipelines</code> to be healthy)</li> </ul> </li> </ul> Important Notes <ul> <li>We no longer use Kyverno to generate resources in each profile for Kubeflow Pipelines, we now include these resources directly based on your profile values, this is due to Kyverno not scaling well for large numbers of profiles. However, we still use Kyverno for cloning Secrets across namespaces, triggering restarts of Deployments, and a few other things.</li> <li>We have resolved the compatibility issues with Azure AKS. To enable the Azure-specific fixes, please set the <code>kubernetes.azure.admissionsEnforcerFix</code> value to <code>true</code>.</li> <li>There have been significant changes to how authentication is implemented. These changes should allow you to bring your own Istio Gateway Deployment (Pods) without having other services end up behind deployKF's authentication system. However, please note that deployKF still manages its own Gateway Resource (CRD).</li> <li>For those experiencing \"route not found\" issues when using an external proxy to terminate TLS, you can now disable \"SNI Matching\" on the Istio Gateway by setting the <code>deploykf_core.deploykf_istio_gateway.gateway.tls.matchSNI</code> value to <code>false</code>.</li> </ul> What's Changed <p>Significant Changes</p> <ul> <li>feat: allow other istio gateways on ingress deployment by @thesuperzapper in #66</li> <li>feat: allow disabling SNI matching on gateway by @thesuperzapper in #83</li> <li>fix: issues preventing deployment on Azure AKS by @thesuperzapper in #85</li> <li>improve: stop using kyverno to provision kfp profile resources by @thesuperzapper in #102</li> </ul> <p>New Features</p> <ul> <li>feat: disable default plugins and resource-quotas in specific profiles by @thesuperzapper in #67</li> <li>feat: allow custom external service ports by @thesuperzapper in #82</li> <li>feat: allow disabling HTTPS redirect by @thesuperzapper in #86</li> <li>feat: add pod-labels value for cert-manager controller by @thesuperzapper in #88</li> <li>feat: optional sign-in page to stop background request CSRF accumulation by @thesuperzapper in #100</li> </ul> <p>Improvements</p> <ul> <li>improve: use <code>__Secure-</code> cookie prefix and remove domains config by @thesuperzapper in #87</li> <li>improve: increase kyverno resource limits and add values by @thesuperzapper in #93</li> <li>improve: use CRD-level \"replace\" for kyverno ArgoCD app by @thesuperzapper in #94</li> <li>improve: argocd sync script should only wait for app health once by @thesuperzapper in #104</li> </ul> <p>Bug Fixes</p> <ul> <li>fix: prevent kyverno log spam on missing generate context by @thesuperzapper in #54</li> <li>fix: rstudio logo format for non-chrome browsers by @thesuperzapper in #56</li> <li>fix: using AWS IRSA with Kubeflow Pipelines by @thesuperzapper in #79</li> <li>fix: use 307 status for HTTP redirects by @thesuperzapper in #81</li> <li>fix: proxy protocol envoyfilter for istio gateway by @thesuperzapper in #80</li> <li>fix: disallow out-of-band KFP audience when disabled by @thesuperzapper in #89</li> <li>fix: support kyverno chart changes (but keep kyverno version) by @thesuperzapper in #92</li> <li>fix: annotate cloned imagePullSecrets to be ignored by ArgoCD by @dkhachyan in #90</li> <li>fix: add background filter to restart trigger policies by @thesuperzapper in #95</li> <li>fix: prevent CSRF cookie accumulation on auth expiry by @thesuperzapper in #99</li> </ul> <p>Documentation</p> <ul> <li>docs: update example ArgoCD to 2.9.6 by @thesuperzapper in #91</li> </ul>"},{"location":"releases/changelog-deploykf/#0.1.3","title":"0.1.3 (2023-10-31)","text":"Important Notes <ul> <li>For more information about using the new \"browser login flow\" with Kubeflow Pipelines SDK, please see the updated Access Kubeflow Pipelines API guide.</li> </ul> What's Changed <p>Significant Changes</p> <ul> <li>feat: browser-based KFP SDK auth by @thesuperzapper in #45</li> </ul> <p>New Features</p> <ul> <li>feat: update oauth2-proxy to 7.5.1 by @thesuperzapper in #44</li> <li>feat: kyverno policy for image-pull-secrets by @thesuperzapper in #47</li> <li>feat: add values for kyverno replicas by @thesuperzapper in #50</li> </ul> <p>Improvements</p> <ul> <li>improve: limit trigger operations for kyverno policies by @thesuperzapper in #49</li> </ul> <p>Bug Fixes</p> <ul> <li>fix: don't mount trust bundles with own cert-manager by @thesuperzapper in #46</li> <li>fix: ensure kyverno has permission to manage PodDefaults by @thesuperzapper in #51</li> </ul> <p>Documentation</p> <ul> <li>docs: update sync script to force update kyverno policies by @thesuperzapper in #40</li> <li>docs: add requirement checks to argocd sync script by @thesuperzapper in #42</li> <li>docs: update reference argocd version to 2.8.5 by @thesuperzapper in #52</li> </ul> <p>Miscellaneous</p> <ul> <li>refactor: always use <code>v1</code> kyverno resources by @thesuperzapper in #48</li> </ul>"},{"location":"releases/changelog-deploykf/#0.1.2","title":"0.1.2 (2023-09-22)","text":"Important Notes <ul> <li>If you are using the <code>deployKF ArgoCD Plugin</code>, you MUST update to the latest version of the plugin BEFORE upgrading to this version (see: #29).</li> </ul> What's Changed <p>Significant Changes</p> <ul> <li>docs: add reference <code>sync_argocd_apps.sh</code> script by @thesuperzapper in #38</li> </ul> <p>Bug Fixes</p> <ul> <li>fix: set kyverno webhook failure policy to ignore (fix uninstall deadlock) by @thesuperzapper in #26</li> <li>fix: resolve cert-manager race conditions by @thesuperzapper in #28</li> <li>fix: argocd plugin with \"file://\" dependencies (needed for helm forks) by @thesuperzapper in #29</li> <li>fix: create separate namespaces app, if destination is remote by @thesuperzapper in #30</li> <li>fix: ensure namespaces are never deleted or pruned by @thesuperzapper in #31</li> <li>fix: add sync waves to argocd apps (fix deletion) by @thesuperzapper in #32</li> <li>fix: resolve profile generator race condition by @thesuperzapper in #33</li> <li>fix: resolve race conditions with cloned secrets by @thesuperzapper in #34</li> <li>fix: app-of-apps should always target argocd cluster by @thesuperzapper in #35</li> </ul> <p>Documentation</p> <ul> <li>docs: move guides to website by @thesuperzapper in #20</li> <li>docs: improve example app-of-apps for plugin by @thesuperzapper in #37</li> <li>docs: improve sample values, add reference overrides by @thesuperzapper in #36</li> </ul>"},{"location":"releases/changelog-deploykf/#0.1.1","title":"0.1.1 (2023-08-08)","text":"What's Changed <p>Significant Changes</p> <ul> <li>feat: create argocd plugin by @thesuperzapper in #16</li> </ul> <p>New Features</p> <ul> <li>feat: allow custom documentation links in dashboard by @yankcrime in #12</li> <li>feat: allow a single ArgoCD to manage deployKF across multiple clusters by @thesuperzapper in #17</li> </ul> <p>Bug Fixes</p> <ul> <li>fix: set <code>securityContext.fsGroup</code> on minio pods by @thesuperzapper in #14</li> <li>fix: minio-console user permissions (update minio) by @thesuperzapper in #18</li> </ul> <p>Documentation</p> <ul> <li>docs: improve getting started formatting by @thesuperzapper in #8</li> <li>docs: add links to important values in readme by @thesuperzapper in #9</li> <li>docs: improve getting started guide by @thesuperzapper in #11</li> <li>docs: add link to youtube demo by @thesuperzapper in #13</li> </ul>"},{"location":"releases/changelog-deploykf/#0.1.0","title":"0.1.0 (2023-07-10)","text":"What's Changed <p>Significant Changes</p> <ul> <li>initial release \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 </li> </ul>"},{"location":"releases/tool-versions/","title":"Tool Version Matrix","text":"<p>The versions of ML &amp; Data tools included with each version of deployKF.</p>"},{"location":"releases/tool-versions/#kubeflow-ecosystem","title":"Kubeflow Ecosystem","text":"<p>This section lists the versions of tools in the Kubeflow Ecosystem which are included in each version of deployKF.</p>"},{"location":"releases/tool-versions/#kubeflow-pipelines","title":"Kubeflow Pipelines","text":"<p>The Kubeflow Pipelines component versions:</p> deployKF <code>0.1.0</code> - <code>0.1.4</code> <code>0.1.5+</code> Kubeflow Pipelines <code>2.0.0-alpha.7</code> <code>2.1.0-deploykf.0</code> Argo Workflows <code>3.3</code>, <code>3.4</code><sup>[1]</sup> <sup>[2]</sup> <code>3.3</code>, <code>3.4</code><sup>[1]</sup> <sup>[2]</sup> Which versions of the <code>kfp</code> Python SDK are supported? <p>You MUST use the correct version of the Kubeflow Pipelines Python SDK, using the wrong version of the SDK will result in errors. This table shows which SDK version can be used with each version of deployKF:</p> deployKF Version <code>pip install kfp==1.18.22</code> <code>pip install kfp&gt;=2.0.0,&lt;3</code> <code>0.1.4</code> and earlier <code>0.1.5</code> and later <p>To check the version of the <code>kfp</code> SDK, run the following Python code:</p> <pre><code>import kfp\nprint(kfp.__version__)\n</code></pre> What does the <code>-deploykf.X</code> version suffix mean? <p>Due to upstream issues with Kubeflow Pipelines, we maintain a fork in the <code>deployKF/kubeflow-pipelines</code> repository. From an end-user perspective, the fork is functionally identical to upstream, and works with the official <code>kfp</code> Python SDK.</p> Can I bring my own version of Argo Workflows? <p>By default, deployKF will install the correct version of Argo Workflows for the version of Kubeflow Pipelines you are using. Right now, its a little complex to bring your own Argo Workflows version. </p> <p>See <code>deployKF/deployKF#116</code> to join the discussion.</p>"},{"location":"releases/tool-versions/#kubeflow-notebooks","title":"Kubeflow Notebooks","text":"<p>The Kubeflow Notebooks component versions:</p> deployKF <code>0.1.0+</code> Notebooks Web App <code>1.7.0</code> Notebooks Controller <code>1.7.0</code> PodDefaults Webhook <code>1.7.0</code>"},{"location":"releases/tool-versions/#kubeflow-katib","title":"Kubeflow Katib","text":"<p>The Kubeflow Katib component versions:</p> deployKF <code>0.1.0+</code> Kubeflow Katib <code>0.15.0</code>"},{"location":"releases/tool-versions/#kubeflow-training-operator","title":"Kubeflow Training Operator","text":"<p>The Kubeflow Training Operator component versions:</p> deployKF <code>0.1.0+</code> Kubeflow Training Operator <code>1.6.0</code>"},{"location":"releases/tool-versions/#kubeflow-volumes","title":"Kubeflow Volumes","text":"<p>The Kubeflow Volumes component versions:</p> deployKF <code>0.1.0+</code> Volumes Web App <code>1.7.0</code>"},{"location":"releases/tool-versions/#kubeflow-tensorboards","title":"Kubeflow TensorBoards","text":"<p>The Kubeflow TensorBoards component versions:</p> deployKF <code>0.1.0+</code> TensorBoards Web App <code>1.7.0</code> TensorBoards Controller <code>1.7.0</code>"},{"location":"releases/version-matrix/","title":"Dependency Version Matrix","text":"<p>The versions of dependencies supported by each version of deployKF.</p> <p>Table Key</p> <ul> <li> Supported</li> <li> Not Supported</li> <li> Default Included Version</li> </ul>"},{"location":"releases/version-matrix/#kubernetes","title":"Kubernetes","text":"deployKF Version \u2192 Kubernetes Version \u2193 <code>0.1</code> <code>1.21</code> <code>1.22</code> <code>1.23</code> <code>1.24</code> <code>1.25</code> <code>1.26</code> <code>1.27</code> <code>1.28</code> <code>1.29</code> <code>1.30</code>"},{"location":"releases/version-matrix/#argo-cd","title":"Argo CD","text":"<p>Existing Argo CD</p> <p>To use deployKF with your existing Argo CD installation, please see this guide.</p> deployKF Version \u2192 Argo CD Version \u2193 <code>0.1</code> <code>2.2</code> <code>2.3+</code>"},{"location":"releases/version-matrix/#cert-manager","title":"Cert-Manager","text":"<p>Existing Cert-Manager</p> <p>To use deployKF with your existing Cert-Manager installation, please see this guide.</p> deployKF Version \u2192 Cert-Manager Version \u2193 <code>0.1</code> <code>1.11</code> <code>1.12 LTS</code> <code>1.13</code> <code>1.14</code>"},{"location":"releases/version-matrix/#istio","title":"Istio","text":"<p>Existing Istio</p> <p>To use deployKF with your existing Istio installation, please see this guide.</p> deployKF Version \u2192 Istio Version \u2193 <code>0.1</code> <code>1.14</code> <sup>[1]</sup> <code>1.15</code> <code>1.16</code> <code>1.17</code> <code>1.18</code> <code>1.19</code> <code>1.20</code> <code>1.21</code> <code>1.22</code>"},{"location":"releases/version-matrix/#kyverno","title":"Kyverno","text":"<p>Existing Kyverno</p> <p>To use deployKF with your existing Kyverno installation, please see this guide.</p> deployKF Version \u2192 Kyverno Version \u2193 <code>0.1</code> <code>1.9.*</code> <sup>[1]</sup> <code>1.10.0</code>  WARNING: this is the ONLY working version  <code>1.10.1</code> - <code>1.10.3</code> <sup>[2]</sup> <code>1.11.*</code> <sup>[3]</sup>"},{"location":"user-guides/access-kubeflow-pipelines-api/","title":"Access Kubeflow Pipelines API","text":"<p>Learn how to access the Kubeflow Pipelines API with the Kubeflow Pipelines Python SDK and authenticate with deployKF.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#overview","title":"Overview","text":"<p>The Kubeflow Pipelines SDK is the Python client for Kubeflow Pipelines. This SDK is used to author, compile, and then submit workflows to the Kubeflow Pipelines API.</p> <p>This table outlines the SDK authentication methods available in deployKF:</p> Authentication Method(Click for Details) In Cluster Outside Cluster No User Interaction Browser Login Flow Dex Static Credentials Kubernetes ServiceAccount Token <p>Python SDK Versions</p> <p>You MUST use the correct version of the Kubeflow Pipelines Python SDK, using the wrong version of the SDK will result in errors. This table shows which SDK version can be used with each version of deployKF:</p> deployKF Version <code>pip install kfp==1.18.22</code> <code>pip install kfp&gt;=2.0.0,&lt;3</code> <code>0.1.4</code> and earlier <code>0.1.5</code> and later <p>To check the version of the <code>kfp</code> SDK, run the following Python code:</p> <pre><code>import kfp\nprint(kfp.__version__)\n</code></pre>"},{"location":"user-guides/access-kubeflow-pipelines-api/#browser-login-flow","title":"Browser Login Flow","text":"<p>The browser login flow (also known as \"out-of-band\" OIDC login) allows users to authenticate their local SDK using a web browser. This flow is suitable for interactive workflows, such as Jupyter Notebooks, or other situations that have access to a web browser.</p> <p>A significant benefit of this flow is that it allows users to act as themselves, rather than a service account, and supports all external identity providers that may be configured in deployKF.</p> <p>Minimum deployKF Version</p> <p>The \"out-of-band\" OIDC login flow requires deployKF v0.1.3, or later.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#authentication-flow","title":"Authentication Flow","text":"<p>The flow to authenticate the SDK using an \"out-of-band\" OIDC login is:</p> <ol> <li>The credential provider attempts to read a cached token, from the user's home directory:<ul> <li>If an unexpired token is found, it is returned to the SDK.</li> <li>If an expired token is found, the credential provider attempts to refresh the token.</li> </ul> </li> <li>Otherwise, the credential provider starts a new \"out-of-band\" OIDC login flow:<ul> <li>The user is prompted to open a URL in their browser.</li> <li>Once the user has authenticated, a code is provided to the user.</li> <li>The user copies the code from the browser and pastes it into the terminal.</li> <li>The token is persisted to the user's home directory, and returned to the SDK.</li> </ul> </li> </ol>"},{"location":"user-guides/access-kubeflow-pipelines-api/#reference-implementation","title":"Reference Implementation","text":"<p>The following reference implementation shows how to authenticate the Kubeflow Pipelines SDK using an \"out-of-band\" OIDC login flow.</p> <p>The <code>DeployKFCredentialsOutOfBand()</code> class extends <code>TokenCredentialsBase()</code> to create a custom credential provider that implements the \"out-of-band\" OIDC login flow.</p> Python Code - Define Credentials Provider <pre><code>import base64\nimport hashlib\nimport json\nimport logging\nimport os\nimport sys\nimport time\nfrom typing import Optional\n\nimport requests\nimport urllib3\nfrom kubernetes.client import configuration\nfrom requests_oauthlib import OAuth2Session\n\ntry:\n    # for kubeflow pipelines v2\n    from kfp.client.token_credentials_base import TokenCredentialsBase\nexcept ImportError:\n    # for kubeflow pipelines v1\n    from kfp.auth import TokenCredentialsBase\n\n\nclass DeployKFCredentialsOutOfBand(TokenCredentialsBase):\n    \"\"\"\n    A Kubeflow Pipelines credential provider which uses an \"out-of-band\" OIDC login flow.\n\n    WARNING: intended for deployKF clusters only, unlikely to work with other Kubeflow clusters.\n\n    Key features:\n     - uses the OIDC client named 'kubeflow-pipelines-sdk', which is pre-configured in deployKF\n     - stores tokens in the user's home directory '~/.config/kfp/dkf_credentials.json'\n       (this file is indexed by issuer URL, so multiple clusters can be used concurrently)\n     - attempts to use the \"refresh_token\" grant before prompting the user to login again\n       (in deployKF, refresh tokens are valid if used at least once every 7 days, and not longer than 90 days in total)\n    \"\"\"\n\n    def __init__(self, issuer_url: str, skip_tls_verify: bool = False):\n        \"\"\"\n        Initialize a DeployKFTokenCredentials instance.\n\n        :param issuer_url: the OIDC issuer URL (e.g. 'https://deploykf.example.com:8443/dex')\n        :param skip_tls_verify: if True, skip TLS verification\n        \"\"\"\n        # oidc configuration\n        self.oidc_issuer_url = issuer_url\n        self.oidc_client_id = \"kubeflow-pipelines-sdk\"\n        self.oidc_redirect_uri = \"urn:ietf:wg:oauth:2.0:oob\"\n        self.oidc_scope = [\"openid\", \"email\", \"groups\", \"profile\", \"offline_access\"]\n\n        # other configuration\n        self.http_timeout = 15\n        self.local_credentials_path = os.path.join(\n            os.path.expanduser(\"~\"), \".config\", \"kfp\", \"dkf_credentials.json\"\n        )\n\n        # setup logging\n        self.log = logging.getLogger(__name__)\n        self._setup_logging()\n\n        # disable SSL verification, if requested\n        self.skip_tls_verify = skip_tls_verify\n        if self.skip_tls_verify:\n            self.log.warning(\"TLS verification is disabled\")\n            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n            os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n\n        # discover the OIDC issuer configuration\n        self._discover_oidc()\n\n        # perform the initial login, if necessary\n        self.get_token()\n\n    def _setup_logging(self):\n        self.log.propagate = False\n        self.log.setLevel(logging.INFO)\n        if not self.log.hasHandlers():\n            handler = logging.StreamHandler()\n            formatter = logging.Formatter(\n                fmt=\"%(asctime)s %(levelname)-8s %(message)s\",\n                datefmt=\"%Y-%m-%d %H:%M:%S\",\n            )\n            handler.setFormatter(formatter)\n            self.log.addHandler(handler)\n\n    def _discover_oidc(self):\n        \"\"\"\n        Discover the OIDC issuer configuration.\n        https://openid.net/specs/openid-connect-discovery-1_0.html\n        \"\"\"\n        oidc_discovery_url = f\"{self.oidc_issuer_url}/.well-known/openid-configuration\"\n        self.log.info(\"Discovering OIDC configuration from: %s\", oidc_discovery_url)\n        response = requests.get(\n            url=oidc_discovery_url,\n            timeout=self.http_timeout,\n            verify=not self.skip_tls_verify,\n        )\n        response.raise_for_status()\n        oidc_issuer_config = response.json()\n        self.oidc_issuer = oidc_issuer_config[\"issuer\"]\n        self.oidc_auth_endpoint = oidc_issuer_config[\"authorization_endpoint\"]\n        self.oidc_token_endpoint = oidc_issuer_config[\"token_endpoint\"]\n\n    def _read_credentials(self) -&gt; dict:\n        \"\"\"\n        Read credentials from the JSON file for the current issuer.\n        \"\"\"\n        self.log.debug(\n            \"Checking for existing credentials in: %s\", self.local_credentials_path\n        )\n        if os.path.exists(self.local_credentials_path):\n            with open(self.local_credentials_path, \"r\") as file:\n                data = json.load(file)\n                return data.get(self.oidc_issuer, {})\n        return {}\n\n    def _write_credentials(self, token: str):\n        \"\"\"\n        Write the provided token to the local credentials file (under the current issuer).\n        \"\"\"\n        # Create the directory, if it doesn't exist\n        credential_dir = os.path.dirname(self.local_credentials_path)\n        if not os.path.exists(credential_dir):\n            os.makedirs(credential_dir, exist_ok=True)\n\n        # Read all existing credentials from the JSON file\n        credentials_data = {}\n        if os.path.exists(self.local_credentials_path):\n            with open(self.local_credentials_path, \"r\") as f:\n                data = json.load(f)\n\n        # Update the credentials for the given issuer\n        credentials_data[self.oidc_issuer] = token\n        self.log.info(\"Writing credentials to: %s\", self.local_credentials_path)\n        with open(self.local_credentials_path, \"w\") as f:\n            json.dump(credentials_data, f)\n\n    def _generate_pkce_verifier(self) -&gt; (str, str):\n        \"\"\"\n        Generate a PKCE code verifier and its derived challenge.\n        https://tools.ietf.org/html/rfc7636#section-4.1\n        \"\"\"\n        # Generate a code_verifier of length between 43 and 128 characters\n        code_verifier = base64.urlsafe_b64encode(os.urandom(96)).decode(\"utf-8\")\n        code_verifier = code_verifier.rstrip(\"=\")\n        code_verifier = code_verifier[:128]\n\n        # Generate the code_challenge using the S256 method\n        sha256_digest = hashlib.sha256(code_verifier.encode(\"utf-8\")).digest()\n        code_challenge = (\n            base64.urlsafe_b64encode(sha256_digest).decode(\"utf-8\").rstrip(\"=\")\n        )\n\n        return code_verifier, code_challenge\n\n    def _refresh_token(self, oauth_session: OAuth2Session) -&gt; Optional[dict]:\n        \"\"\"\n        Attempt to refresh the provided token.\n        https://requests-oauthlib.readthedocs.io/en/latest/oauth2_workflow.html#refreshing-tokens\n        \"\"\"\n        if not oauth_session.token.get(\"refresh_token\", None):\n            return None\n\n        self.log.warning(\"Attempting to refresh token...\")\n        try:\n            new_token = oauth_session.refresh_token(\n                self.oidc_token_endpoint,\n                client_id=self.oidc_client_id,\n                timeout=self.http_timeout,\n                verify=not self.skip_tls_verify,\n            )\n            self.log.info(\"Successfully refreshed token!\")\n            self._write_credentials(new_token)\n            return new_token\n        except Exception as ex:\n            self.log.error(\"Failed to refresh token!\", exc_info=ex)\n\n    def _login(self, oauth_session: OAuth2Session) -&gt; dict:\n        \"\"\"\n        Start a new \"out-of-band\" login flow.\n        \"\"\"\n        self.log.info(\"Starting new 'out-of-band' login flow...\")\n\n        verifier, challenge = self._generate_pkce_verifier()\n        authorization_url, state = oauth_session.authorization_url(\n            self.oidc_auth_endpoint,\n            code_challenge_method=\"S256\",\n            code_challenge=challenge,\n        )\n\n        # ensure everything is printed to the console before continuing\n        sys.stderr.flush()\n        time.sleep(0.5)\n\n        # Get the authorization code from the user\n        print(\n            f\"\\nPlease open this URL in a browser to continue:\\n &gt; {authorization_url}\\n\",\n            flush=True,\n        )\n        user_input = input(\"Enter the authorization code:\\n &gt; \")\n        authorization_code = user_input.strip()\n\n        # Exchange the authorization code for a token\n        new_token = oauth_session.fetch_token(\n            self.oidc_token_endpoint,\n            code=authorization_code,\n            code_verifier=verifier,\n            include_client_id=True,\n            state=state,\n            timeout=self.http_timeout,\n            verify=not self.skip_tls_verify,\n        )\n        self.log.info(\"Successfully fetched new token!\")\n        self._write_credentials(new_token)\n        return new_token\n\n    def get_token(self) -&gt; str:\n        \"\"\"\n        Get the current auth token.\n        Will attempt to use \"refresh_token\" before prompting the user to login again.\n        \"\"\"\n        # return the existing token, if it's valid for at least 5 minutes\n        stored_token = self._read_credentials()\n        if stored_token:\n            expires_at = stored_token.get(\"expires_at\", 0)\n            expires_in = expires_at - time.time()\n            if expires_in &gt; 300:\n                self.log.info(\n                    \"Using cached auth token (expires in %d seconds)\", expires_in\n                )\n                return stored_token[\"id_token\"]\n            elif expires_in &gt; 0:\n                self.log.warning(\n                    \"Existing auth token expires in %d seconds\",\n                    expires_in,\n                )\n            else:\n                self.log.warning(\"Existing auth token has expired!\")\n\n        oauth_session = OAuth2Session(\n            self.oidc_client_id,\n            redirect_uri=self.oidc_redirect_uri,\n            scope=self.oidc_scope,\n            token=stored_token,\n        )\n\n        # try to refresh the token, or start a new login flow\n        new_token = self._refresh_token(oauth_session)\n        if not new_token:\n            new_token = self._login(oauth_session)\n\n        return new_token[\"id_token\"]\n\n    def refresh_api_key_hook(self, config: configuration.Configuration):\n        config.verify_ssl = not self.skip_tls_verify\n        config.api_key[\"authorization\"] = self.get_token()\n</code></pre> <p>The following examples demonstrate using the <code>DeployKFCredentialsOutOfBand()</code> class to create an authenticated <code>kfp.Client()</code>:</p> Python Code - Use Credentials Provider - KFP v1 <pre><code>import kfp\n\n# initialize a credentials instance \ncredentials = DeployKFCredentialsOutOfBand(\n    issuer_url=\"https://deploykf.example.com:8443/dex\", \n    skip_tls_verify=True,\n)\n\n# creates a patched client that supports disabling SSL verification\n# required before kfp v2: https://github.com/kubeflow/pipelines/pull/7174\ndef patched_kfp_client(verify_ssl=True):\n    _original_load_config = kfp.Client._load_config\n\n    def _patched_load_config(client_self, *args, **kwargs):\n        config = _original_load_config(client_self, *args, **kwargs)\n        config.verify_ssl = verify_ssl\n        return config\n\n    _patched_client = kfp.Client\n    _patched_client._load_config = _patched_load_config\n\n    return _patched_client\n\n# initialize a client instance\nkfp_client = patched_kfp_client(verify_ssl=not credentials.skip_tls_verify)(\n    host=\"https://deploykf.example.com:8443/pipeline\",\n    credentials=credentials,\n)\n\n# test the client by listing experiments\nexperiments = kfp_client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre> Python Code - Use Credentials Provider - KFP v2 <pre><code>import kfp\n\n# initialize a credentials instance \ncredentials = DeployKFCredentialsOutOfBand(\n    issuer_url=\"https://deploykf.example.com:8443/dex\", \n    skip_tls_verify=True,\n)\n\n# initialize a client instance\nkfp_client = kfp.Client(\n    host=\"https://deploykf.example.com:8443/pipeline\",\n    verify_ssl=not credentials.skip_tls_verify,\n    credentials=credentials,\n)\n\n# test the client by listing experiments\nexperiments = kfp_client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre> <p>Refresh Token Expiry</p> <p>By default, deployKF allows refresh tokens to be used for 90 days in total, as long as they are used at least once every 7 days. While these defaults are usually sufficient, the following values control the refresh token expiry:</p> <ul> <li><code>deploykf_core.deploykf_auth.dex.expiry.refreshToken.idle</code></li> <li><code>deploykf_core.deploykf_auth.dex.expiry.refreshToken.total</code></li> </ul>"},{"location":"user-guides/access-kubeflow-pipelines-api/#dex-static-credentials","title":"Dex Static Credentials","text":"<p>Dex static credentials work from both inside and outside the cluster without needing user interaction during authentication. This makes them suitable for use in CI/CD pipelines, or other privileged automated workflows that need to access Kubeflow Pipelines.</p> <p>Provision Static Credentials</p> <p>Dex static credentials are managed by config values and are provisioned by the cluster administrator. The user authentication guide provides information about managing static credentials in deployKF.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#authentication-flow_1","title":"Authentication Flow","text":"<p>The flow to authenticate the SDK using Dex static credentials is:</p> <ol> <li>The client sends an unauthenticated request to the Kubeflow Pipelines API.</li> <li>The request is redirected to Dex for authentication.</li> <li>The client authenticates with Dex using the static credentials.</li> <li>The client is issued a session cookie by OAuth2 Proxy.</li> <li>The client uses the session cookie with all subsequent requests.</li> </ol>"},{"location":"user-guides/access-kubeflow-pipelines-api/#reference-implementation_1","title":"Reference Implementation","text":"<p>The following reference implementation shows how to authenticate the Kubeflow Pipelines SDK using Dex static credentials.</p> <p>The <code>KFPClientManager()</code> class creates authenticated <code>kfp.Client()</code> instances that use Dex static credentials for authentication.</p> Python Code - Define Client Manager <pre><code>import re\nfrom urllib.parse import urlsplit, urlencode\n\nimport kfp\nimport requests\nimport urllib3\n\n\nclass KFPClientManager:\n    \"\"\"\n    A class that creates `kfp.Client` instances with Dex authentication.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_url: str,\n        dex_username: str,\n        dex_password: str,\n        dex_auth_type: str = \"local\",\n        skip_tls_verify: bool = False,\n    ):\n        \"\"\"\n        Initialize the KfpClient\n\n        :param api_url: the Kubeflow Pipelines API URL\n        :param skip_tls_verify: if True, skip TLS verification\n        :param dex_username: the Dex username\n        :param dex_password: the Dex password\n        :param dex_auth_type: the auth type to use if Dex has multiple enabled, one of: ['ldap', 'local']\n        \"\"\"\n        self._api_url = api_url\n        self._skip_tls_verify = skip_tls_verify\n        self._dex_username = dex_username\n        self._dex_password = dex_password\n        self._dex_auth_type = dex_auth_type\n        self._client = None\n\n        # disable SSL verification, if requested\n        if self._skip_tls_verify:\n            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\n        # ensure `dex_default_auth_type` is valid\n        if self._dex_auth_type not in [\"ldap\", \"local\"]:\n            raise ValueError(\n                f\"Invalid `dex_auth_type` '{self._dex_auth_type}', must be one of: ['ldap', 'local']\"\n            )\n\n    def _get_session_cookies(self) -&gt; str:\n        \"\"\"\n        Get the session cookies by authenticating against Dex\n        :return: a string of session cookies in the form \"key1=value1; key2=value2\"\n        \"\"\"\n\n        # use a persistent session (for cookies)\n        s = requests.Session()\n\n        # GET the api_url, which should redirect to Dex\n        resp = s.get(\n            self._api_url, allow_redirects=True, verify=not self._skip_tls_verify\n        )\n        if resp.status_code == 200:\n            pass\n        elif resp.status_code == 403:\n            # if we get 403, we might be at the oauth2-proxy sign-in page\n            # the default path to start the sign-in flow is `/oauth2/start?rd=&lt;url&gt;`\n            url_obj = urlsplit(resp.url)\n            url_obj = url_obj._replace(\n                path=\"/oauth2/start\", query=urlencode({\"rd\": url_obj.path})\n            )\n            resp = s.get(\n                url_obj.geturl(), allow_redirects=True, verify=not self._skip_tls_verify\n            )\n        else:\n            raise RuntimeError(\n                f\"HTTP status code '{resp.status_code}' for GET against: {self._api_url}\"\n            )\n\n        # if we were NOT redirected, then the endpoint is unsecured\n        if len(resp.history) == 0:\n            # no cookies are needed\n            return \"\"\n\n        # if we are at `../auth` path, we need to select an auth type\n        url_obj = urlsplit(resp.url)\n        if re.search(r\"/auth$\", url_obj.path):\n            url_obj = url_obj._replace(\n                path=re.sub(r\"/auth$\", f\"/auth/{self._dex_auth_type}\", url_obj.path)\n            )\n\n        # if we are at `../auth/xxxx/login` path, then we are at the login page\n        if re.search(r\"/auth/.*/login$\", url_obj.path):\n            dex_login_url = url_obj.geturl()\n        else:\n            # otherwise, we need to follow a redirect to the login page\n            resp = s.get(\n                url_obj.geturl(), allow_redirects=True, verify=not self._skip_tls_verify\n            )\n            if resp.status_code != 200:\n                raise RuntimeError(\n                    f\"HTTP status code '{resp.status_code}' for GET against: {url_obj.geturl()}\"\n                )\n            dex_login_url = resp.url\n\n        # attempt Dex login\n        resp = s.post(\n            dex_login_url,\n            data={\"login\": self._dex_username, \"password\": self._dex_password},\n            allow_redirects=True,\n            verify=not self._skip_tls_verify,\n        )\n        if resp.status_code != 200:\n            raise RuntimeError(\n                f\"HTTP status code '{resp.status_code}' for POST against: {dex_login_url}\"\n            )\n\n        # if we were NOT redirected, then the login credentials were probably invalid\n        if len(resp.history) == 0:\n            raise RuntimeError(\n                f\"Login credentials are probably invalid - \"\n                f\"No redirect after POST to: {dex_login_url}\"\n            )\n\n        # if we are at `../approval` path, we need to approve the login\n        url_obj = urlsplit(resp.url)\n        if re.search(r\"/approval$\", url_obj.path):\n            dex_approval_url = url_obj.geturl()\n\n            # approve the login\n            resp = s.post(\n                dex_approval_url,\n                data={\"approval\": \"approve\"},\n                allow_redirects=True,\n                verify=not self._skip_tls_verify,\n            )\n            if resp.status_code != 200:\n                raise RuntimeError(\n                    f\"HTTP status code '{resp.status_code}' for POST against: {url_obj.geturl()}\"\n                )\n\n        return \"; \".join([f\"{c.name}={c.value}\" for c in s.cookies])\n\n    def _create_kfp_client(self) -&gt; kfp.Client:\n        try:\n            session_cookies = self._get_session_cookies()\n        except Exception as ex:\n            raise RuntimeError(f\"Failed to get Dex session cookies\") from ex\n\n        # monkey patch the kfp.Client to support disabling SSL verification\n        # kfp only added support in v2: https://github.com/kubeflow/pipelines/pull/7174\n        original_load_config = kfp.Client._load_config\n\n        def patched_load_config(client_self, *args, **kwargs):\n            config = original_load_config(client_self, *args, **kwargs)\n            config.verify_ssl = not self._skip_tls_verify\n            return config\n\n        patched_kfp_client = kfp.Client\n        patched_kfp_client._load_config = patched_load_config\n\n        return patched_kfp_client(\n            host=self._api_url,\n            cookies=session_cookies,\n        )\n\n    def create_kfp_client(self) -&gt; kfp.Client:\n        \"\"\"Get a newly authenticated Kubeflow Pipelines client.\"\"\"\n        return self._create_kfp_client()\n</code></pre> <p>The following example demonstrates using the <code>KFPClientManager()</code> class to create an authenticated <code>kfp.Client()</code>:</p> Python Code - Use Client Manager <pre><code># initialize a KFPClientManager\nkfp_client_manager = KFPClientManager(\n    api_url=\"https://deploykf.example.com:8443/pipeline\",\n    skip_tls_verify=True,\n\n    dex_username=\"user1@example.com\",\n    dex_password=\"user1\",\n\n    dex_auth_type=\"local\",\n)\n\n# get a newly authenticated KFP client\n# TIP: long-lived sessions might need to get a new client when their session expires\nkfp_client = kfp_client_manager.create_kfp_client()\n\n# test the client by listing experiments\nexperiments = kfp_client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre> <p>Supported Authentication Methods</p> <p>The <code>KFPClientManager</code> class ONLY supports authentication with static (<code>local</code>) or LDAP (<code>ldap</code>) credentials, as determined by the <code>dex_auth_type</code> class parameter. Due to the nature of other authentication methods, it is not likely that they could be supported by this class in the future.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#kubernetes-serviceaccount-token","title":"Kubernetes ServiceAccount Token","text":"<p>The Kubeflow Pipelines backend has a trust relationship with the Kubernetes ServiceAccount system. This means that if a request is made to the Kubeflow Pipelines API (internal service) that presents a Kubernetes ServiceAccount bearer token, the request will be authenticated as that ServiceAccount.</p> <p>This authentication method provides a reliable way to authenticate with the Kubeflow Pipelines API from inside the cluster, without needing user interaction during authentication.</p> <p>RBAC Access</p> <p>The level of Kubeflow Pipelines access which a Kubernetes ServiceAccount has, is defined by Kubernetes RBAC, rather than deployKF profile definitions.</p> <p>By default, the ServiceAccount used by Kubeflow Pipelines and Kubeflow Notebooks (called <code>default-editor</code>), will have read/write access to all Kubeflow Pipelines resources in the same namespace as the Pod.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#authentication-flow_2","title":"Authentication Flow","text":"<p>The flow to authenticate the SDK using a Kubernetes ServiceAccount token is:</p> <ol> <li>The Pod where the client is running, has a ServiceAccount token volume mounted.</li> <li>The client uses the bearer token to authenticate with the Kubeflow Pipelines API.</li> <li>Kubernetes itself manages the token's expiry and rotation.</li> </ol>"},{"location":"user-guides/access-kubeflow-pipelines-api/#reference-implementation_2","title":"Reference Implementation","text":"<p>Kubernetes has a feature called ServiceAccount token volume projection which mounts and automatically manages ServiceAccount tokens for Pods. The following reference implementations show how to authenticate the Kubeflow Pipelines SDK using these Kubernetes ServiceAccount tokens.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#manually-mount-a-token-volume","title":"Manually Mount a Token Volume","text":"<p>You may adjust the definition of any Pod to mount a ServiceAccount token volume that can be used to authenticate with the Kubeflow Pipelines API.</p> <p>For example, the following Pod has a ServiceAccount token volume mounted at the <code>/var/run/secrets/kubeflow/pipelines/token</code> path:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: access-kfp-example\nspec:\n  ## NOTE: the token will be for the service account of the Pod\n  serviceAccountName: default-editor\n  containers:\n    - image: hello-world:latest\n      name: hello-world\n      env:\n        - name: KF_PIPELINES_SA_TOKEN_PATH\n          value: /var/run/secrets/kubeflow/pipelines/token\n      volumeMounts:\n        - mountPath: /var/run/secrets/kubeflow/pipelines\n          name: volume-kf-pipeline-token\n          readOnly: true\n  volumes:\n    - name: volume-kf-pipeline-token\n      projected:\n        sources:\n          - serviceAccountToken:\n              path: token\n              expirationSeconds: 7200\n              audience: pipelines.kubeflow.org\n</code></pre>"},{"location":"user-guides/access-kubeflow-pipelines-api/#automatically-mount-a-token-volume-with-poddefaults","title":"Automatically Mount a Token Volume with PodDefaults","text":"<p>Kubeflow includes a special CRD called PodDefault which will mutate Pods at admission time based on the presence of certain labels. You may use a PodDefault to automatically inject a token volume into a Pod when it is created.</p> Example - PodDefault for ServiceAccount Token Volume <p>If you wish to define your own PodDefault, you may do so by creating one in a Profile Namespace.</p> <p>For example, the following PodDefault will inject a ServiceAccount token volume into any Pod with the label <code>my-kfp-api-token=true</code>:</p> <pre><code>apiVersion: kubeflow.org/v1alpha1\nkind: PodDefault\nmetadata:\n  name: my-kfp-api-token\n  namespace: \"&lt;YOUR_USER_PROFILE_NAMESPACE&gt;\"\nspec:\n  desc: \"Mount a serviceAccountToken to authenticate with Kubeflow Pipelines API\"\n  selector:\n    matchLabels:\n      my-kfp-api-token: \"true\"\n  env:\n    - name: KF_PIPELINES_SA_TOKEN_PATH\n      value: /var/run/secrets/kubeflow/pipelines/token\n  volumes:\n    - name: volume-kf-pipeline-token\n      projected:\n        sources:\n          - serviceAccountToken:\n              path: token\n              expirationSeconds: 7200\n              audience: pipelines.kubeflow.org\n  volumeMounts:\n    - mountPath: /var/run/secrets/kubeflow/pipelines\n      name: volume-kf-pipeline-token\n      readOnly: true\n</code></pre> <p>When the <code>kubeflow_tools.pipelines.profileResourceGeneration.kfpApiTokenPodDefault</code> value is <code>true</code>, such a PodDefault is automatically provisioned in each Profile Namespace:</p> <pre><code>kubeflow_tools:\n  pipelines:\n    profileResourceGeneration:\n      kfpApiTokenPodDefault: true\n</code></pre> <p>The PodDefault is called <code>\"kubeflow-pipelines-api-token\"</code>, selects Pods with the <code>kubeflow-pipelines-api-token=true</code> label, and injects KFP ServiceAccount token volumes into them.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: access-kfp-example\n  labels:\n    kubeflow-pipelines-api-token: \"true\"\nspec:\n  ## NOTE: the token will be for the service account of the Pod\n  serviceAccountName: default-editor\n  containers:\n    - image: hello-world:latest\n      name: hello-world\n</code></pre> <p>Kubeflow Notebooks Integration</p> <p>Kubeflow Notebooks detects any PodDefaults which are in a Profile Namespace. Users may tick a checkbox under <code>\"Advanced Options\"</code> \u2192 <code>\"Configurations\"</code> to apply a PodDefault when spawning a new Notebook.</p> <p>If you wish to apply a PodDefault to ALL new Notebooks, see the \"advanced pod options\" section of Configure Kubeflow Notebooks.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#example-python-code","title":"Example Python Code","text":"<p>When run inside a Pod that has a ServiceAccount token volume mounted, the following Python code creates a <code>kfp.Client()</code> using the token for authentication:</p> <pre><code>import kfp\n\n# by default, when run from inside a Kubernetes cluster:\n#  - the token is read from the `KF_PIPELINES_SA_TOKEN_PATH` path\n#  - the host is set to `http://ml-pipeline-ui.kubeflow.svc.cluster.local`\nkfp_client = kfp.Client()\n\n# test the client by listing experiments\nexperiments = kfp_client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre> Can I specify a different token path or host? <p>By default, when <code>kfp.Client()</code> is run from inside a Kubernetes Pod, the token is read from <code>/var/run/secrets/kubeflow/pipelines/token</code> (or the value of the <code>KF_PIPELINES_SA_TOKEN_PATH</code> environment variable), and <code>http://ml-pipeline-ui.kubeflow.svc.cluster.local</code> is used for the host.</p> <p>You may also explicitly initialize a <code>ServiceAccountTokenVolumeCredentials</code> instance and pass it to the <code>kfp.Client()</code> constructor as the <code>credentials</code> parameter.</p> <p>For example to read the token from <code>/var/run/secrets/kubeflow/pipelines/token2</code>:</p> <pre><code>import kfp\n\ntry:\n    # for kubeflow pipelines v2\n    from kfp.client.set_volume_credentials import ServiceAccountTokenVolumeCredentials\nexcept ImportError:\n    # for kubeflow pipelines v1\n    from kfp.auth import ServiceAccountTokenVolumeCredentials\n\n# initialize a credentials instance\ncredentials = ServiceAccountTokenVolumeCredentials(\n    path=\"/var/run/secrets/kubeflow/pipelines/token2\"\n)\n\n# initialize a client instance\n# NOTE: we must use the `Service/ml-pipeline-ui` service, NOT the public gateway\nkfp_client = kfp.Client(\n    host=\"http://ml-pipeline-ui.kubeflow.svc.cluster.local\",\n    credentials=credentials,\n)\n\n# test the client by listing experiments\nexperiments = kfp_client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre>"},{"location":"user-guides/gitops-for-kubeflow-pipelines/","title":"GitOps for Kubeflow Pipelines Schedules","text":"<p>Learn how to use GitOps to manage Kubeflow Pipelines, including pipeline definitions and pipeline schedules.</p>"},{"location":"user-guides/gitops-for-kubeflow-pipelines/#overview","title":"Overview","text":"<p>Initially, most users of Kubeflow Pipelines manually create and run workflows with the UI or Python SDK as this is the fastest way to get started. When the number of pipelines grows, it becomes increasingly difficult and error-prone to manage them manually; this is where GitOps comes in.</p>"},{"location":"user-guides/gitops-for-kubeflow-pipelines/#reference-implementation","title":"Reference Implementation","text":"<p>We provide a reference implementation for managing pipeline definitions and their schedules using GitOps in the <code>deployKF/kubeflow-pipelines-gitops</code> GitHub repo.</p> <p> Check out the Reference Repository</p> <p>The reference architecture is logically grouped into four steps:</p> Step Description Step 1: Render Pipelines Render pipeline definitions into their static YAML representation. Step 2: Run Pipelines Run the rendered pipelines ad-hoc. Step 3: Schedule Pipelines Schedule the rendered pipelines. Step 4: Automatic Reconciliation Automatically reconcile the schedule configs."}]}