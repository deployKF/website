{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"faq/","title":"Frequently Asked Questions","text":"What is deployKF? What AI/ML tools are in deployKF? Is commercial support available for deployKF? Who uses deployKF? Who created deployKF? What is the difference between Kubeflow and deployKF? How can I get involved with deployKF? How is deployKF licensed?"},{"location":"faq/#what-is-deploykf","title":"What is deployKF?","text":"<p>deployKF is the best way to build reliable ML Platforms on Kubernetes.</p> <ul> <li>deployKF supports leading MLOps &amp; Data tools from both Kubeflow, and other projects</li> <li>deployKF has a Helm-like interface, with values for configuring all aspects of the deployment (no need to edit Kubernetes YAML)</li> <li>deployKF does NOT install resources directly in your cluster, instead it generates ArgoCD Applications to provide native GitOps support</li> </ul>"},{"location":"faq/#what-aiml-tools-are-in-deploykf","title":"What AI/ML tools are in deployKF?","text":"<p>Currently, deployKF supports MLOps tools from the Kubeflow ecosystem like Kubeflow Pipelines and Kubeflow Notebooks. We are actively adding support for other popular tools such as MLFlow (Model Registry), Apache Airflow, and Feast. </p> <p>For more information, please see supported tools and future tools!</p>"},{"location":"faq/#is-commercial-support-available-for-deploykf","title":"Is commercial support available for deployKF?","text":"<p>The creator of deployKF (Mathew Wicks), operates a US-based MLOps company called Aranui Solutions that provides commercial support and consulting for deployKF.</p> <p>Connect on LinkedIn or email <code>sales@aranui.solutions</code> to learn more!</p>"},{"location":"faq/#who-uses-deploykf","title":"Who uses deployKF?","text":"<p>deployKF is a new project, and we are still building our community.</p> <p>Please consider adding your organization to our list of adopters.</p>"},{"location":"faq/#who-created-deploykf","title":"Who created deployKF?","text":"<p>deployKF was originally created by Mathew Wicks (GitHub: @thesuperzapper), a Kubeflow lead and maintainer of the popular Apache Airflow Helm Chart. However, deployKF is now a community-led project that welcomes contributions from anyone who wants to help.</p>"},{"location":"faq/#what-is-the-difference-between-kubeflow-and-deploykf","title":"What is the difference between Kubeflow and deployKF?","text":"<p>Kubeflow and deployKF are two different but related projects:</p> <ul> <li>deployKF is a tool for deploying Kubeflow and other MLOps tools on Kubernetes as a cohesive platform.</li> <li>Kubeflow is a project that develops MLOps tools, including Kubeflow Pipelines, Kubeflow Notebooks, Katib, and more.</li> </ul> <p>For more details, see our detailed deployKF vs  Kubeflow comparison.</p>"},{"location":"faq/#how-can-i-get-involved-with-deploykf","title":"How can I get involved with deployKF?","text":"<p>The deployKF project is a welcoming community of contributors and users.  We encourage participation from anyone who shares our mission of making it easy to build open ML Platforms on Kubernetes.</p> <p>For more details, see our community page.</p>"},{"location":"faq/#how-is-deploykf-licensed","title":"How is deployKF licensed?","text":"<p>deployKF is licensed under the Apache License 2.0. However, some of the tools that deployKF can help deploy are licensed differently. Please ensure you are aware of how the tools you deploy are licenced.</p>"},{"location":"about/architecture/","title":"Architecture of deployKF","text":"<p>This document takes a detailed look at the architecture of deployKF and its components.</p>"},{"location":"about/architecture/#overview","title":"Overview","text":"<p>deployKF has two user-facing components:</p> <ul> <li>deployKF CLI: a command line program who's primary purpose is to generate a set of folders containing GitOps-ready Kubernetes manifests, from configs provided in one or more values files</li> <li>deployKF Generator: a versioned <code>.zip</code> package which contains all the templates and helpers needed to generate the output folders</li> </ul>"},{"location":"about/architecture/#deploykf-cli","title":"deployKF CLI","text":"<p>The deployKF CLI is a command line program written in Go, it is developed in the <code>deployKF/cli</code> GitHub repo.</p>"},{"location":"about/architecture/#steps-of-the-deploykf-generate-command","title":"Steps of the <code>deploykf generate</code> command","text":"<ol> <li>Locate the deployKF Generator to use, depending on which arguments were provided:<ul> <li><code>--source-version</code>: download a generator ZIP from the releases of <code>deploykf/deploykf</code> GitHub repo</li> <li><code>--source-path</code>: use a local generator ZIP or folder with unzipped generator files</li> </ul> </li> <li>Unzip or copy the generator into a temporary folder:<ul> <li>The folder is automatically deleted after the command is run, or if the command fails</li> </ul> </li> <li>Read the <code>.deploykf_generator</code> marker file from the root of the generator:<ul> <li>The <code>.deploykf_generator</code> file contains JSON data with information like the <code>generator_schema</code> version</li> <li>If the CLI does not support the encountered <code>generator_schema</code> version, the CLI will exit with an error</li> </ul> </li> <li>Clean the folder currently at the <code>--outut-dir</code> target:<ul> <li>The CLI will only remove the contents of a non-empty target if there is a <code>.deploykf_output</code> marker file at its root</li> </ul> </li> <li>Render the manifests into <code>--outut-dir</code> in two phases, using the provided <code>--values</code> files:<ol> <li>PHASE 1: render the <code>.gomplateignore_template</code> files into <code>.gomplateignore</code> files (still in the temporary folder)<ul> <li>Note, these files behave like <code>.gitignore</code> files, and are used to exclude files from the output in the second phase</li> </ul> </li> <li>PHASE 2: render the templates from the <code>templates</code> folder into the <code>--output-dir</code><ul> <li>Note, the resulting output folder will be structured identically to the <code>templates</code> folder (subject to the <code>.gomplateignore</code> files)</li> </ul> </li> </ol> </li> </ol>"},{"location":"about/architecture/#notes-about-the-deploykf-generate-command","title":"Notes about the <code>deploykf generate</code> command","text":"<ul> <li>The generator templates are rendered using a version of gomplate that is embedded in the deployKF CLI:<ul> <li>The template delimiters are set to <code>{{&lt;</code> and <code>&gt;}}</code> as to avoid conflicts with Helm and other Go-like templates</li> </ul> </li> <li>The output folder will contain a <code>.deploykf_output</code> marker file which contains the following information in JSON format:<ul> <li><code>generated_at</code>: the time the generator was run</li> <li><code>source_version</code>: the source version that was used (if <code>--source-version</code> was provided)</li> <li><code>source_path</code>: the path of the source artifact that was used </li> <li><code>source_hash</code>: the SHA256 hash of the source artifact that was used</li> <li><code>cli_version</code>: the version of the deployKF CLI that was used</li> </ul> </li> </ul>"},{"location":"about/architecture/#deploykf-generator","title":"deployKF Generator","text":"<p>The deployKF Generator is a versioned ZIP package which contains all the templates and helpers needed to generate the output folders, it is developed in the <code>deployKF/deployKF</code> GitHub repo.</p>"},{"location":"about/architecture/#structure-of-generator-zip","title":"Structure of generator ZIP","text":"<pre><code>.\n\u251c\u2500\u2500 .deploykf_generator\n\u251c\u2500\u2500 default_values.yaml\n\u251c\u2500\u2500 helpers/\n\u2514\u2500\u2500 templates/\n    \u251c\u2500\u2500 .gomplateignore_template\n    \u251c\u2500\u2500 app-of-apps.yaml\n    \u251c\u2500\u2500 argocd/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 kustomization.yaml\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-core/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-dependencies/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-opt/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 deploykf-tools/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 kubeflow-dependencies/\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 kubeflow-tools/\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 namespaces/\n    \u2514\u2500\u2500 manifests/\n        \u251c\u2500\u2500 deploykf-core/\n        \u251c\u2500\u2500 deploykf-dependencies/\n        \u251c\u2500\u2500 deploykf-opt/\n        \u251c\u2500\u2500 deploykf-tools/\n        \u251c\u2500\u2500 kubeflow-dependencies/\n        \u2514\u2500\u2500 kubeflow-tools/\n</code></pre>"},{"location":"about/architecture/#purpose-of-each-item-under","title":"Purpose of each item under <code>.</code>","text":"<ul> <li><code>.deploykf_generator</code> a file with metadata about the generator, in JSON format, including the <code>generator_schema</code> version</li> <li><code>default_values.yaml</code> a file with the default values for this generator version</li> <li><code>helpers/</code> a folder with helpers that are used in the <code>templates/</code></li> <li><code>templates/</code> a folder with templates that are used to generate the output</li> </ul>"},{"location":"about/architecture/#purpose-of-each-item-under-templates","title":"Purpose of each item under <code>templates/</code>","text":"<ul> <li><code>.gomplateignore_template</code> is used to generate the <code>.gomplateignore</code> files in the first phase of the <code>deploykf generate</code> command</li> <li><code>app-of-apps.yaml</code> a template for an Argo CD app of apps, which points to <code>./argocd/kustomization.yaml</code> (this is the only manifest which is manually applied by the user)</li> <li><code>argocd/</code> a folder with templates of Argo CD applications</li> <li><code>manifests/</code> a folder with templates of Kubernetes manifests</li> </ul>"},{"location":"about/architecture/#purpose-of-each-item-under-templatesargocd","title":"Purpose of each item under <code>templates/argocd/</code>","text":"<ul> <li><code>kustomization.yaml</code> a Kustomize file pointing to the other Argo CD applications and namespaces (this is the target of the <code>app-of-apps.yaml</code>)</li> <li><code>deploykf-core/</code> a folder with templates of Argo CD applications for \"core components of deployKF\"</li> <li><code>deploykf-dependencies/</code> a folder with templates of Argo CD applications for \"dependencies of deployKF\"</li> <li><code>deploykf-opt/</code> a folder with templates of Argo CD applications for \"optional embedded applications that are used when external alternatives are not configured\"</li> <li><code>deploykf-tools/</code> a folder with templates of Argo CD applications for \"MLOps tools from the deployKF ecosystem\"</li> <li><code>kubeflow-dependencies/</code> a folder with templates of Argo CD applications for \"dependencies of Kubeflow's MLOps tools\"</li> <li><code>kubeflow-tools/</code> a folder with templates of Argo CD applications for \"MLOps tools from the Kubeflow ecosystem\"</li> <li><code>namespaces/</code> a folder with the templates for Kubernetes Namespaces</li> </ul>"},{"location":"about/architecture/#purpose-of-each-item-under-templatesmanifests","title":"Purpose of each item under <code>templates/manifests/</code>","text":"<ul> <li><code>deploykf-core/</code> a folder with templates of Kubernetes manifests for \"core components of deployKF\"</li> <li><code>deploykf-dependencies/</code> a folder with templates of Kubernetes manifests for \"dependencies of deployKF\"</li> <li><code>deploykf-opt/</code> a folder with templates of Kubernetes manifests for \"optional embedded applications that are used when external alternatives are not configured\"</li> <li><code>deploykf-tools/</code> a folder with templates of Kubernetes manifests for \"MLOps tools from the deployKF ecosystem\"</li> <li><code>kubeflow-dependencies/</code> a folder with templates of Kubernetes manifests for \"dependencies of Kubeflow's MLOps tools\"</li> <li><code>kubeflow-tools/</code> a folder with templates of Kubernetes manifests for \"MLOps tools from the Kubeflow ecosystem\"</li> </ul>"},{"location":"about/community/","title":"Community","text":"<p>The deployKF project is a welcoming community of contributors and users. We encourage participation from anyone who shares our mission of making it easy to build open ML Platforms on Kubernetes.</p>"},{"location":"about/community/#slack","title":"Slack","text":"<p>The deployKF community uses the Kubeflow Slack for informal discussions among users and contributors.</p> <p> Join the Kubeflow Slack</p> <p>Tip</p> <p>After you join, connect with us on the <code>#deploykf</code> channel!</p>"},{"location":"about/community/#mailing-lists","title":"Mailing Lists","text":"<p>The deployKF community has two mailing lists which are hosted on Google Groups.</p>"},{"location":"about/community/#users-mailing-list","title":"Users Mailing List","text":"<p>The deploykf-users mailing list is for users of deployKF to ask questions and share ideas.</p> <p> Join the User Mailing List</p>"},{"location":"about/community/#dev-mailing-list","title":"Dev Mailing List","text":"<p>The deploykf-dev mailing list is for contributors to deployKF to discuss development and design.</p> <p> Join the Contributor Mailing List</p>"},{"location":"about/kubeflow-vs-deploykf/","title":"Kubeflow vs deployKF","text":"<p>This page aims to unpack the differences between deployKF and Kubeflow.</p> <p>Packaged distributions of Kubeflow</p> <p>Most other distributions of Kubeflow, are using mostly unmodified versions of the Kubeflow Manifests, so the comparison is still relevant for them.</p>"},{"location":"about/kubeflow-vs-deploykf/#introduction","title":"Introduction","text":"<p>Kubeflow and deployKF are two different but related projects:</p> <ul> <li>deployKF is a tool for deploying Kubeflow and other MLOps tools on Kubernetes as a cohesive platform.</li> <li>Kubeflow is a project that develops MLOps tools, including Kubeflow Pipelines, Kubeflow Notebooks, Katib, and more.</li> </ul>"},{"location":"about/kubeflow-vs-deploykf/#kubeflow-vs-kubeflow-manifests","title":"Kubeflow vs Kubeflow Manifests","text":"<p>Before a more detailed comparison can be made, it is important to understand the distinction between Kubeflow and Kubeflow Manifests.</p> Kubeflow Kubeflow Manifests A project that develops many MLOps tools, including Kubeflow Pipelines, Kubeflow Notebooks, Katib, and more. A set of Kubernetes manifests that can be used to deploy Kubeflow's MLOps tools on Kubernetes, found in the <code>kubeflow/manifests</code> repo."},{"location":"about/kubeflow-vs-deploykf/#deploykf-vs-kubeflow-manifests","title":"deployKF vs Kubeflow Manifests","text":"<p>Hopefully, it is now clear the most useful comparison is between deployKF and Kubeflow Manifests (not the Kubeflow project as a whole).</p> <p>The following table compares the two projects across a number of different aspects:</p> Aspect deployKF Kubeflow Manifests Ease of Use <ul><li>Has a Helm-like interface, with values for configuring all aspects of the deployment (no need to edit Kubernetes YAML)</li><li>Upgrades are easy because config values only have minimal changes between versions.</li></ul> <ul><li>Manual patching of YAML manifests required for any changes.</li><li>Upgrades are difficult because new versions require starting from scratch with the new manifests.</li></ul> Capabilities <ul><li>Supports leading MLOps &amp; Data tools from both Kubeflow, and other projects.</li><li>When a config or secret is changed, any affected components are automatically restarted.</li><li>Includes Argo Server UI with integrated single sign-on where access is aligned to profile membership.</li><li>Optionally includes MinIO Console UI with integrated single sign-on where access is aligned to profile membership.</li></ul> <ul><li>Limited to Kubeflow's tools.</li></ul> Customization <ul><li>Allows selective deployment of MLOps tools through simple config values.</li><li>Allows brining custom versions of dependencies like Istio, cert-manager, MySQL, S3, and more.</li><li>Simplifies multi-cluster configurations with support for shared common values and environment-specific overlays.</li></ul> <ul><li>Less customizable, and requires difficult patching of YAML manifests.</li></ul> GitOps <ul><li>GitOps-native application with built-in support for Argo CD.</li></ul> <ul><li>Lacks native support for Argo CD or other GitOps tools.</li></ul> Security <ul><li>All secrets are randomly generated at install time, rather than being hardcoded in manifests.</li><li>Reduced attack vectors compared to Kubeflow Manifests, particularly in Istio configurations.</li><li>Utilizes standard auth tools (<code>oauth2-proxy</code>) over unknown tools (<code>arrikto/oidc-authservice</code>).</li><li>Automatically refreshes session cookies for active users in most cases.</li><li>Uses Istio with distroless images by default.</li><li>MinIO (or S3) access keys are isolated to each profile, not shared, and scoped to the minimum required permissions.</li><li>Supports using AWS IRSA instead of S3 access keys.</li></ul> <ul><li>Potentially more security vulnerabilities than deployKF.</li><li>Lacks session cookie refresh for active users in most cases.</li></ul>"},{"location":"about/kubeflow-vs-deploykf/#next-steps","title":"Next Steps","text":"<ul> <li>If you're ready to start migrating from Kubeflow to deployKF, check out the Migrate from Kubeflow Manifests guide.</li> </ul>"},{"location":"about/support/","title":"Get Support","text":"<p>While we aim to make deployKF as self-service as possible, sometimes things go wrong, or your use case is a little different to the norm.  In these cases, you have a few options.</p>"},{"location":"about/support/#join-the-community","title":"Join the Community","text":"<p>If you have a question, or just want to chat, you can:</p> <ol> <li>Post a message on the Slack</li> <li>Start a thread on the Users Mailing List</li> </ol>"},{"location":"about/support/#raise-an-issue","title":"Raise an Issue","text":"<p>If you have found a bug, or have a feature request, you can raise an issue on the relevant GitHub repository:</p> Component Repository deployKF Generator <code>deployKF/deployKF</code> deployKF CLI <code>deployKF/cli</code> deployKF Website <code>deployKF/website</code>"},{"location":"about/support/#commercial-support","title":"Commercial Support","text":"<p>For US-based commercial support, the creator of deployKF (Mathew Wicks), operates an MLOps company called Aranui Solutions.</p> <p>Connect on LinkedIn or email <code>sales@aranui.solutions</code> to learn more!</p>"},{"location":"about/support/#vendor-partnerships","title":"Vendor Partnerships","text":"<p>Are you a vendor who wants to support deployKF or use it in your product?</p> <p>Let's work together! Email <code>mathew@aranui.solutions</code> to discuss more.</p>"},{"location":"guides/deploykf-cli/","title":"Install deployKF CLI","text":"<p>This guide explains how to install the <code>deploykf</code> command line interface (CLI) on your local machine.</p>"},{"location":"guides/deploykf-cli/#about-the-cli","title":"About the CLI","text":"<p>The deployKF CLI is used to generate GitOps-ready Kubernetes manifests from one or more values files. This example generates manifests under the <code>./GENERATOR_OUTPUT</code> directory from the <code>0.1.1</code> source version with the values specified in the <code>./custom-values.yaml</code> file.</p> <pre><code>deploykf \\\n--source-version \"0.1.1\" \\\n--values ./custom-values.yaml \\\n--output-dir ./GENERATOR_OUTPUT\n</code></pre> <p>Source Version</p> <p>The <code>--source-version</code> is a tagged release of the deployKF generator, without the \"v\" prefix.</p> <p>The version of the CLI does NOT need to match the <code>--source-version</code>.  If a breaking change is ever needed, the CLI will fail to generate with newer source versions, and will print message telling you to upgrade the CLI.</p> <p>deployKF ArgoCD Plugin</p> <p>If you are using the deployKF ArgoCD Plugin, it is NOT necessary to install the deployKF CLI, this is because the manifests generation will happen inside the ArgoCD plugin, rather than on your local machine.</p>"},{"location":"guides/deploykf-cli/#install-the-cli","title":"Install the CLI","text":"<p>You can install the CLI on your local machine by following the instructions below that are appropriate for your operating system.</p> <p>Latest Version</p> <p>You can find the latest version of the CLI on the GitHub releases page, which is currently <code>v0.1.2</code>.</p> macOSLinuxWindows <p>macOS Security</p> <p>MacOS has security features that will prevent you running the CLI if you downloaded it via a web browser. However, if you download it from the command line (for example, using <code>curl</code> or <code>wget</code>) it should be allowed to run.</p> <p>Either way, if you encounter a \"this app is from an unidentified developer\" error you can go to <code>System Preferences &gt; Privacy &amp; Security</code> and click <code>Open Anyway</code> to allow the CLI to run.</p> <p>The following commands will download the CLI for macOS and place it in <code>/usr/local/bin</code>:</p> <pre><code>DKF_CLI_VERSION=\"0.1.2\"\nDKF_CLI_ARCH=$(uname -m | sed -e 's/x86_64/amd64/')\nDFK_CLI_DEST=/usr/local/bin/deploykf\n\n# download the binary\nsudo curl -fL \"https://github.com/deploykf/cli/releases/download/v${DKF_CLI_VERSION}/deploykf-darwin-${DKF_CLI_ARCH}\" -o \"${DFK_CLI_DEST}\"\n\n# make the binary executable\nsudo chmod +x \"${DFK_CLI_DEST}\"\n\n# test the binary\ndeploykf version\n</code></pre> <p>Alternatively, you can manually download the latest <code>deploykf-darwin-{ARCH}</code> binary from the <code>v0.1.2</code> GitHub Release and place it in a directory on your <code>PATH</code> environment variable.</p> <p>Apple Silicon</p> <p>If you have a Mac with an Apple Silicon processor (M1, M2, etc), you will need to download the <code>deploykf-darwin-arm64</code> binary. If you have a Mac with an Intel processor, you will need to download the <code>deploykf-darwin-amd64</code> binary.</p> <p>The following commands will download the CLI for Linux and place it in <code>/usr/local/bin</code>:</p> <pre><code>DKF_CLI_VERSION=\"0.1.2\"\nDKF_CLI_ARCH=$(uname -m | sed -e 's/x86_64/amd64/' -e 's/aarch64/arm64/')\nDFK_CLI_DEST=/usr/local/bin/deploykf\n\n# download the binary\nsudo curl -fL \"https://github.com/deploykf/cli/releases/download/v${DKF_CLI_VERSION}/deploykf-linux-${DKF_CLI_ARCH}\" -o \"${DFK_CLI_DEST}\"\n\n# make the binary executable\nsudo chmod +x \"${DFK_CLI_DEST}\"\n\n# test the binary\ndeploykf version\n</code></pre> <p>Alternatively, you can manually download the latest <code>deploykf-linux-{ARCH}</code> binary from the <code>v0.1.2</code> GitHub Release and place it in a directory on your <code>PATH</code> environment variable.</p> <p>Processor Architecture</p> <p>If you are using a Linux machine with an ARM64 processor, you will need to download the <code>deploykf-linux-arm64</code> binary. If you are using a Linux machine with an X86/AMD64 processor, you will need to download the <code>deploykf-linux-amd64</code> binary.</p> <p>Elevated PowerShell Prompt</p> <p>You will need to run the following commands in an elevated PowerShell prompt (right-click and select <code>Run as administrator</code>).</p> <p>Windows Security</p> <p>Windows has security features that may prevent you from running the CLI. If you encounter a \"Windows protected your PC\" error you can click <code>More info</code> and then <code>Run anyway</code> to allow the CLI to run.</p> <p>The following PowerShell commands will download the CLI for Windows and place it in <code>C:\\Windows\\System32</code>:</p> <pre><code>$DKF_CLI_VERSION=\"0.1.2\"\n$DFK_CLI_DEST=\"C:\\Windows\\System32\\deploykf.exe\"\n\n# download the binary\nInvoke-WebRequest -Uri \"https://github.com/deploykf/cli/releases/download/v${DKF_CLI_VERSION}/deploykf-windows-amd64.exe\" -OutFile \"${DFK_CLI_DEST}\"\n\n# test the binary\ndeploykf version\n</code></pre> <p>Alternatively, you can manually download the latest <code>deploykf-windows-amd64.exe</code> binary from the <code>v0.1.2</code> GitHub Release and place it in a directory on your <code>PATH</code> environment variable.</p>"},{"location":"guides/getting-started/","title":"Getting Started","text":"<p>This guide will explain how to get started with production usage of deployKF on any Kubernetes cluster.</p>"},{"location":"guides/getting-started/#about-deploykf","title":"About deployKF","text":"<p>Before starting, let us briefly introduce the deployKF project.</p>"},{"location":"guides/getting-started/#what-is-deploykf","title":"What is deployKF?","text":"<p>deployKF is the best way to build reliable ML Platforms on Kubernetes.</p> <ul> <li>deployKF supports leading MLOps &amp; Data tools from both Kubeflow, and other projects</li> <li>deployKF has a Helm-like interface, with values for configuring all aspects of the deployment (no need to edit Kubernetes YAML)</li> <li>deployKF does NOT install resources directly in your cluster, instead it generates ArgoCD Applications to provide native GitOps support</li> </ul>"},{"location":"guides/getting-started/#what-aiml-tools-are-in-deploykf","title":"What AI/ML tools are in deployKF?","text":"<p>Currently, deployKF supports MLOps tools from the Kubeflow ecosystem like Kubeflow Pipelines and Kubeflow Notebooks. We are actively adding support for other popular tools such as MLFlow (Model Registry), Apache Airflow, and Feast. </p> <p>For more information, please see supported tools and future tools!</p>"},{"location":"guides/getting-started/#media-coverage","title":"Media Coverage","text":"Intro / Demo - Kubeflow Community Call - July 2023"},{"location":"guides/getting-started/#other-questions","title":"Other Questions","text":"Is commercial support available for deployKF? <p>The creator of deployKF (Mathew Wicks), operates a US-based MLOps company called Aranui Solutions that provides commercial support and consulting for deployKF.</p> <p>Connect on LinkedIn or email <code>sales@aranui.solutions</code> to learn more!</p> Who uses deployKF? <p>deployKF is a new project, and we are still building our community.</p> <p>Please consider adding your organization to our list of adopters.</p> Do you have a Slack or Mailing List? <p>Slack:</p> <ul> <li>The deployKF community uses the Kubeflow Slack for informal discussions among users and contributors.</li> <li>Find us on the <code>#deploykf</code> channel!</li> </ul> <p> Join the Kubeflow Slack</p> <p>Mailing Lists:</p> <ul> <li>The deploykf-users mailing list is for users of deployKF to ask questions and share ideas.</li> <li>The deploykf-dev mailing list is for contributors to deployKF to discuss development and design.</li> </ul> <p> Join the User Mailing List</p> <p> Join the Contributor Mailing List</p> Why does deployKF use Argo CD? <p>ML Platforms are made up of many components and interconnected dependencies, and it can be difficult to manage the state of all these components.</p> <p>This is where GitOps comes in, it allows us to define the state (i.e. Kubernetes manifests) of all the components in a single place (Git), and then use a tool to reconcile the actual state of our cluster to match the defined state.</p> <p>Argo CD is a great tool for this job, it is widely used, part of the CNCF, and has a great Web UI for visualizing and managing the current state of your cluster.</p> <p>In the future, we plan to support other popular Kubernetes GitOps tools like Flux CD, but we have initially chosen to support Argo CD given its overwhelming popularity.</p> <p>It's important to note that Argo CD is NOT the same as Argo Workflows.</p> <ul> <li>Argo CD is a GitOps tool for Kubernetes, which means it uses Git as the source of truth for your cluster's state, rather than manually applying Kubernetes YAML with <code>kubectl apply</code> or <code>helm install</code>.</li> <li>Argo Workflows is a workflow engine for Kubernetes, which means it allows you to define and run DAG workflows in Pods on Kubernetes.</li> </ul>"},{"location":"guides/getting-started/#other-guides","title":"Other Guides","text":"<p>Migrate from Kubeflow to deployKF</p> <p>If you have an existing deployment of Kubeflow, there is a migration guide for you.</p>"},{"location":"guides/getting-started/#1-requirements","title":"1. Requirements","text":"<p>The requirements for deployKF vary depending on which \"mode of operation\" you use.</p> Mode Description \"Manifests Repo\" Mode In this mode, you use the deployKF CLI CLI to generate manifests and commit them to a \"manifests git repo\" before applying them with ArgoCD. \"ArgoCD Plugin\" Mode In this mode, you use the deployKF ArgoCD Plugin to generate and apply the manifests in a single step (no git repo required). <p>The following table outlines the requirements for each mode.</p> Requirement<sub>: required</sub><sub>: optional</sub> \"Manifests Repo\" Mode \"ArgoCD Plugin\" Mode a Kubernetes cluster (version compatibility) ArgoCD is installed on Kubernetes deployKF ArgoCD Plugin is installed - deployKF CLI is installed on local machine - a private git repo, for generated manifests - external MySQL database external S3-compatible object store Supported Kubernetes Distributions <p>deployKF should work on any Kubernetes distribution!</p> <p>Here are some popular distributions of Kubernetes that users have reported success with.</p> Platform Kubernetes Distribution Amazon Web Services Amazon Elastic Kubernetes Service (EKS) Microsoft Azure Azure Kubernetes Service (AKS) Google Cloud Google Kubernetes Engine (GKE) IBM Cloud IBM Cloud Kubernetes Service (IKS) Local Machine k3d, kind, minikube <p>Dedicated Kubernetes Cluster</p> <p>Only one deployKF platform can be deployed on a Kubernetes cluster at a time.</p> <p>Additionally, deployKF is not well suited to multi-tenant clusters. It uses cluster-wide components (e.g. Istio) and namespaces for user/team profiles. Therefore, we strongly recommend using a dedicated Kubernetes cluster for deployKF.</p> <p>If you are unable to create a new Kubernetes cluster, you may consider using vcluster to create a virtual Kubernetes cluster within an existing one.</p> <p>ARM Support</p> <p>deployKF does not currently support ARM clusters, this is because a small number of Kubeflow components do not support ARM just yet, we expect this to change after the release of Kubeflow 1.8 in October 2023.</p> <p>Default StorageClass</p> <p>The default values assume your Kubernetes cluster has a default StorageClass which has support for the <code>ReadWriteOnce</code> access mode.</p> <p>If you do not have a compatible default StorageClass, you can either:</p> <ol> <li>Configure a default StorageClass that has <code>ReadWriteOnce</code> support</li> <li>Explicitly set the <code>storageClass</code> value for the following components:<ul> <li><code>deploykf_opt.deploykf_minio.persistence.storageClass</code></li> <li><code>deploykf_opt.deploykf_mysql.persistence.storageClass</code></li> </ul> </li> <li>Disable components which require the StorageClass, and use external alternatives:<ul> <li><code>deploykf_opt.deploykf_minio.enabled</code></li> <li><code>deploykf_opt.deploykf_mysql.enabled</code></li> </ul> </li> </ol>"},{"location":"guides/getting-started/#2-values-configuration","title":"2. Values / Configuration","text":"<p>deployKF is configured using YAML files containing configs named \"values\" which behave similarly to those in Helm. There are a very large number of values (more than 1500), but you can start by defining a few important ones, and then grow your values file over time.</p> <p>We recommend that you start your values file by copying the <code>sample-values.yaml</code> file, which includes reasonable defaults that should work on any Kubernetes cluster.</p> <p>YAML Syntax</p> <p>For a refresher on YAML syntax, we recommend Learn YAML in Y minutes and YAML Multiline Strings</p> <p>Values Reference</p> <p>All the available values (and their defaults) are listed on the values reference page, and in the <code>generator/default_values.yaml</code> file.</p>"},{"location":"guides/getting-started/#required-values","title":"Required Values","text":"\"Manifests Repo\" Mode <p>When using the \"manifests repo\" mode, the following values are required:</p> <code>argocd.source.repo.url</code> <p>This value is the URL of the git repo where the generated manifests are stored.</p> <p>For example, if you are using a GitHub repo named <code>deployKF/examples</code>, you might set this value to <code>\"https://github.com/deployKF/examples\"</code> or <code>\"git@github.com:deployKF/examples.git\"</code></p> <code>argocd.source.repo.revision</code> <p>This value is the git branch/tag/commit that ArgoCD should use to sync the manifests from.        </p> <p>For example, if you are using the <code>main</code> branch of your repo, you might set this value to <code>\"main\"</code>.</p> <code>argocd.source.repo.path</code> <p>This value is the path within the git repo where the generated manifests are stored.        </p> <p>For example, if you are using a folder named <code>GENERATOR_OUTPUT</code> at the root of your repo, you might set this value to <code>\"./GENERATOR_OUTPUT/\"</code>.</p>"},{"location":"guides/getting-started/#configurations-platform","title":"Configurations (Platform)","text":"User Authentication and External Identity Providers <p>deployKF uses dex for user authentication.</p> <p>For more information about defining static user accounts, and connecting external identity providers, see the User Authentication and External Identity Providers guide.</p> Manage Profiles/Namespaces and Assigning Users <p>A deployKF profile has a 1:1 relationship with a Kubernetes namespace. The profiles which a user is a member of determines their level of access to resources/tools in the cluster.</p> <p>To learn about managing profiles and assigning users, see the Manage Profiles and Assigning Users guide.</p> Expose deployKF Gateway and configure HTTPS <p>By default, deployKF creates a LoadBalancer Service named <code>deploykf-gateway</code> in the <code>deploykf-istio-gateway</code> namespace.</p> <p>For more information about exposing the Gateway Service outside of the Kubernetes cluster, see the Expose deployKF Gateway and configure HTTPS guide.</p> Customize the deployKF Dashboard <p>The deployKF dashboard is the web-based interface for deployKF, and is the primary way that users interact with the platform. The dashboard includes navigation menus with links to various tools and documentation which can be customized.</p> <p>For more information about customizing the dashboard, see the Customize the deployKF Dashboard guide.</p>"},{"location":"guides/getting-started/#configurations-tools","title":"Configurations (Tools)","text":"Connect an external MySQL Database <p>deployKF includes an embedded MySQL instance. However, we recommend using an external MySQL database for production usage.</p> <p>For more information, see the Connect an external MySQL Database guide.</p> Connect an external S3-like Object Store <p>deployKF includes an embedded MinIO instance. However, you may wish to replace this with an external S3-compatible object store.</p> <p>For more information, see the Connect an external S3-like Object Store guide.</p> Configure Kubeflow Notebooks (Images, CPU, GPU, etc.) <p>Kubeflow Notebooks allows users to spawn Pods running instances of JupyterLab, Visual Studio Code (code-server), and RStudio in profile namespaces.</p> <p>For more information about configuring Kubeflow Notebooks, see the Configure Kubeflow Notebooks guide.</p>"},{"location":"guides/getting-started/#3-generate-apply-manifests","title":"3. Generate &amp; Apply Manifests","text":"<p>After creating your <code>custom-values.yaml</code> file(s), the method used to generate and apply the manifests to your Kubernetes cluster will depend on the deployKF \"mode of operation\" you have chosen.</p>"},{"location":"guides/getting-started/#manifests-repo-mode","title":"Manifests Repo Mode","text":"Steps for Manifests Repo Mode <p>When using the \"manifests repo\" mode, you will need to:</p> <ol> <li>generate the manifests</li> <li>commit the generated manifests to a git repo</li> <li>manually apply the app-of-apps manifest</li> </ol> <p>Step 1: Generate Manifests</p> <p>The <code>deploykf generate</code> command writes generated manifests into a folder, using one or more values files.</p> <p>The required arguments of the <code>deploykf generate</code> command are:</p> Argument Description <code>--source-version</code> the version of deployKF to use (see changelog for available versions) <code>--values</code> one or more values files to use for generating the manifests <code>--output-dir</code> the directory where the generated manifests will be written <p>For example, this command will use deployKF <code>0.1.1</code> to generate manifests under <code>GENERATOR_OUTPUT/</code>, from a values file named <code>custom-values.yaml</code>:</p> <pre><code>deploykf generate \\\n--source-version \"0.1.1\" \\\n--values ./custom-values.yaml \\\n--output-dir ./GENERATOR_OUTPUT\n</code></pre> <p>Avoid Manual Changes</p> <p>Manual changes in the <code>--output-dir</code> will be overwritten each time the <code>deploykf generate</code> command runs. If you find yourself needing to make manual changes, please raise an issue so we may consider adding a new value to support your use-case.</p> <p>Multiple Values Files</p> <p>If you specify <code>--values</code> multiple times, they will be merged with later ones taking precedence. Note, values which are YAML lists are NOT merged, they are replaced in full.</p> <p>Step 2: Commit Generated Manifests</p> <p>After running <code>deploykf generate</code>, you will likely want to commit the changes to your repo:</p> <pre><code># for example, to directly commit changes to the 'main' branch of your repo\ngit add GENERATOR_OUTPUT\ngit commit -m \"my commit message\"\ngit push origin main\n</code></pre> <p>Step 3: Apply App-of-Apps Manifest</p> <p>The only manifest you need to manually apply is the ArgoCD app-of-apps, which creates all the other ArgoCD applications.</p> <p>The <code>app-of-apps.yaml</code> manifest is generated at the root of your <code>--output-dir</code> folder, so you can apply it with:</p> <pre><code>kubectl apply --filename GENERATOR_OUTPUT/app-of-apps.yaml\n</code></pre>"},{"location":"guides/getting-started/#argocd-plugin-mode","title":"ArgoCD Plugin Mode","text":"Steps for ArgoCD Plugin Mode <p>When using the \"ArgoCD plugin\" mode, you will need to:</p> <ol> <li>install the deployKF ArgoCD plugin on your ArgoCD instance</li> <li>create an app-of-apps which uses the plugin</li> <li>apply your app-of-apps manifest</li> </ol> <p>Step 1: Install the ArgoCD Plugin</p> <p>We provide two options for installing the deployKF ArgoCD plugin:</p> New ArgoCD Installation <p>This method installs our pre-patched ArgoCD manifests with the plugin pre-installed. Use this method if you are installing ArgoCD for the first time.</p> <p>For specific information, see the Install Plugin (New ArgoCD) guide.</p> Patch an Existing ArgoCD Installation <p>This method explains how to patch an existing ArgoCD installation to include the plugin. Use this method if you already have an ArgoCD installation.</p> <p>For more information, see the Install Plugin (Existing ArgoCD) guide.</p> <p>Step 2: Create an App-of-Apps Manifest</p> <p>The \"deploykf\" plugin has the following parameters:</p> Parameter Type Description <code>source_version</code> String the version of deployKF to use (see changelog for available versions) <code>values_files</code> Array a list of paths to values files in your ArgoCD Application's <code>source</code> repo (relative to the <code>source.path</code>) <code>values</code> String a string containing the contents of a values file (these take precedence when being merged with values from <code>values_files</code>) <p>For example, this app-of-apps manifest will use deployKF <code>0.1.1</code> and read the <code>sample-values.yaml</code> from the <code>v0.1.1</code> tag of the <code>deploykf/deploykf</code> repo:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\nname: deploykf-app-of-apps\nnamespace: argocd\nlabels:\napp.kubernetes.io/name: deploykf-app-of-apps\napp.kubernetes.io/part-of: deploykf\nspec:\nproject: \"default\"\nsource:\n## source git repo configuration\n##  - we use the 'deploykf/deploykf' repo so we can read its 'sample-values.yaml' \n##    file, but you may use any repo (even one with no files)\n##\nrepoURL: \"https://github.com/deployKF/deployKF.git\"\ntargetRevision: \"v0.1.1\"\npath: \".\"\n\n## plugin configuration\n##\nplugin:\nname: \"deploykf\"\nparameters:\n\n## the deployKF generator version\n- name: \"source_version\"\nstring: \"0.1.1\"\n\n## paths to values files within the `repoURL` repository\n##  - values files are merged, with later ones taking precedence\n- name: \"values_files\"\narray:\n- \"./sample-values.yaml\"\n\n## a string containing the contents of a values file\n##  - this parameter allows defining values without needing to create a file\n##  - values defined here take precedence over any from `values_files`\n- name: \"values\"\nstring: |\n## --------------------------------------------------------------------------------\n##\n##                                  deploykf-core\n##\n## --------------------------------------------------------------------------------\ndeploykf_core:\n\n## --------------------------------------\n##        deploykf-istio-gateway\n## --------------------------------------\ndeploykf_istio_gateway:\n\n## istio gateway configs\ngateway:\nhostname: deploykf.example.com\n\ndestination:\nserver: \"https://kubernetes.default.svc\"\nnamespace: \"argocd\"\n</code></pre> <p>Step 3: Apply App-of-Apps Manifest</p> <p>After writing your app-of-apps manifest to a local file named <code>app-of-apps.yaml</code>, you may apply it with:</p> <pre><code>kubectl apply --filename ./app-of-apps.yaml --namespace \"argocd\"\n</code></pre>"},{"location":"guides/getting-started/#4-sync-argocd-applications","title":"4. Sync ArgoCD Applications","text":"<p>Now that the deployKF app-of-apps manifest has been applied, you must sync the ArgoCD applications that make up deployKF.</p> <p>ArgoCD supports syncing applications via both its Web UI and CLI. We recommend using the Web UI when you are first getting started.</p> <p>Private Git Repositories</p> <p>If your app-of-apps source repo is private, you will need to configure ArgoCD with git credentials.</p> <p>Sync Failures</p> <p>Some applications, specifically <code>dkf-dep--cert-manager</code> and <code>dkf-core--deploykf-profiles-generator</code> may fail to sync on the first attempt, simply wait a few seconds and try the sync again.</p> <p>Sync Order</p> <p>You MUST sync each \"group\" of applications in the order described below, as they depend on each other.</p>"},{"location":"guides/getting-started/#sync-with-argocd-web-ui","title":"Sync with ArgoCD Web UI","text":"Steps for ArgoCD Web UI <p>To sync the deployKF applications with the ArgoCD Web UI, you will need to:</p> <ol> <li>access the ArgoCD Web UI</li> <li>sync the applications</li> </ol> <p>Step 1: Access the ArgoCD Web UI</p> How do I access the ArgoCD Web UI? <p>If you have not publicly exposed the ArgoCD Web UI, you can access it by port-forwarding the <code>argocd-server</code> Service to your local machine.</p> <p>You can do this with the following <code>kubectl</code> command:</p> <pre><code>kubectl port-forward --namespace \"argocd\" svc/argocd-server 8090:https\n</code></pre> <p>You should now see the ArgoCD interface at https://localhost:8090.</p> <p>If this is the first time you are using ArgoCD, you will need to retrieve the initial password for the <code>admin</code> user.</p> <p>You can do this with the following <code>kubectl</code> command:</p> <pre><code>echo $(kubectl -n argocd get secret/argocd-initial-admin-secret \\\n-o jsonpath=\"{.data.password}\" | base64 -d)\n</code></pre> <p>You can now log in to ArgoCD with the <code>admin</code> user and the password you retrieved above.</p> <p>Step 2: Sync the Applications</p> <p>The deployKF applications are grouped into the following \"groups\", which must be synced in the order described.</p> <p>Group 0: \"app-of-apps\"</p> <p>First, you must sync the app-of-apps application:</p> <ul> <li><code>deploykf-app-of-apps</code></li> </ul> <p>Group 1: \"deploykf-dependencies\"</p> <p>Second, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-dependencies</code>:</p> <ul> <li><code>dkf-dep--cert-manager</code> (may fail on first attempt)</li> <li><code>dkf-dep--istio</code></li> <li><code>dkf-dep--kyverno</code></li> </ul> <p>Group 2: \"deploykf-core\"</p> <p>Third, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-core</code>:</p> <ul> <li><code>dkf-core--deploykf-auth</code></li> <li><code>dkf-core--deploykf-dashboard</code></li> <li><code>dkf-core--deploykf-istio-gateway</code></li> <li><code>dkf-core--deploykf-profiles-generator</code> (may fail on first attempt)</li> </ul> <p>Group 3: \"deploykf-opt\"</p> <p>Fourth, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-opt</code>:</p> <ul> <li><code>dkf-opt--deploykf-minio</code></li> <li><code>dkf-opt--deploykf-mysql</code></li> </ul> <p>Group 4: \"deploykf-tools\"</p> <p>Fifth, you must sync the applications with the label <code>app.kubernetes.io/component=deploykf-tools</code>:</p> <ul> <li>(none yet)</li> </ul> <p>Group 5: \"kubeflow-dependencies\"</p> <p>Sixth, you must sync the applications with the label <code>app.kubernetes.io/component=kubeflow-dependencies</code>:</p> <ul> <li><code>kf-dep--argo-workflows</code></li> </ul> <p>Group 6: \"kubeflow-tools\"</p> <p>Seventh, you must sync the applications with the label <code>app.kubernetes.io/component=kubeflow-tools</code>:</p> <ul> <li><code>kf-tools--katib</code></li> <li><code>kf-tools--notebooks--jupyter-web-app</code></li> <li><code>kf-tools--notebooks--notebook-controller</code></li> <li><code>kf-tools--pipelines</code></li> <li><code>kf-tools--poddefaults-webhook</code></li> <li><code>kf-tools--tensorboards--tensorboard-controller</code></li> <li><code>kf-tools--tensorboards--tensorboards-web-app</code></li> <li><code>kf-tools--training-operator</code></li> <li><code>kf-tools--volumes--volumes-web-app</code></li> </ul>"},{"location":"guides/getting-started/#sync-with-argocd-cli","title":"Sync with ArgoCD CLI","text":"Steps for ArgoCD CLI <p>To sync the deployKF applications with the ArgoCD CLI, you will need to:</p> <ol> <li>install the ArgoCD CLI</li> <li>expose the ArgoCD API server</li> <li>log in to ArgoCD</li> <li>sync the applications</li> </ol> <p>Step 1: Install the ArgoCD CLI</p> <p>You can install by following the ArgoCD CLI Installation instructions.</p> <p>Step 2: Expose the ArgoCD API Server</p> <p>You can expose the ArgoCD API server by port-forwarding the <code>argocd-server</code> Service to your local machine.</p> <p>You can do this with the following <code>kubectl</code> command:</p> <pre><code>kubectl port-forward svc/argocd-server --namespace \"argocd\" 8090:https\n</code></pre> <p>Step 3: Log in to ArgoCD</p> <p>If this is the first time you are using ArgoCD, you will need to retrieve the initial password for the <code>admin</code> user.</p> <p>You can do this with the following <code>kubectl</code> command:</p> <pre><code>echo $(kubectl -n argocd get secret/argocd-initial-admin-secret \\\n-o jsonpath=\"{.data.password}\" | base64 -d)\n</code></pre> <p>You can now log in to ArgoCD with the <code>admin</code> user and the password you retrieved above.</p> <pre><code>ARGOCD_PASSWORD=\"&lt;YOUR_PASSWORD_HERE&gt;\"\nargocd login localhost:8090 --username \"admin\" --password \"$ARGOCD_PASSWORD\" --insecure\n</code></pre> <p>Step 4: Sync the Applications</p> <p>The deployKF applications are grouped into the following \"groups\", which must be synced in the order described.</p> <pre><code># sync app-of-apps application\nargocd app sync \"deploykf-app-of-apps\"\n\n# sync applications with label \"app.kubernetes.io/component=deploykf-dependencies\"\nargocd app sync -l \"app.kubernetes.io/component=deploykf-dependencies\"\n\n# sync applications with label \"app.kubernetes.io/component=deploykf-core\"\nargocd app sync -l \"app.kubernetes.io/component=deploykf-core\"\n\n# sync applications with label \"app.kubernetes.io/component=deploykf-opt\"\nargocd app sync -l \"app.kubernetes.io/component=deploykf-opt\"\n\n# sync applications with label \"app.kubernetes.io/component=deploykf-tools\"\nargocd app sync -l \"app.kubernetes.io/component=deploykf-tools\"\n\n# sync applications with label \"app.kubernetes.io/component=kubeflow-dependencies\"\nargocd app sync -l \"app.kubernetes.io/component=kubeflow-dependencies\"\n\n# sync applications with label \"app.kubernetes.io/component=kubeflow-tools\"\nargocd app sync -l \"app.kubernetes.io/component=kubeflow-tools\"\n</code></pre>"},{"location":"guides/getting-started/#5-use-the-platform","title":"5. Use the Platform","text":"<p>Now that you have a working deployKF ML Platform, here are some things to try out!</p>"},{"location":"guides/getting-started/#access-the-dashboard","title":"Access the Dashboard","text":"<p>The deployKF dashboard is a web-based interface and is the primary way that users interact with the platform. You will need to expose its service (either publicly or privately) to access it.</p> Steps to Expose Gateway Service (with Port-Forwarding) <p>If you have not publicly exposed the deployKF Gateway Service, you may access it via port-forwarding by:</p> <ol> <li>adding some lines to your machine's <code>/etc/hosts</code> file</li> <li>port-forwarding the <code>deploykf-gateway</code> Service with <code>kubectl</code></li> </ol> <p>Step 1: Modify Hosts File</p> <p>You must add lines to your <code>/etc/hosts</code> file, this is because deployKF uses the \"Host\" header to route requests to the correct internal service, meaning that the IP address alone would NOT work.</p> <p>If the <code>deploykf_core.deploykf_istio_gateway.gateway.hostname</code> value is set as <code>\"deploykf.example.com\"</code>, you would add the following lines:</p> <pre><code>127.0.0.1 deploykf.example.com\n127.0.0.1 argo-server.deploykf.example.com\n127.0.0.1 minio-api.deploykf.example.com\n127.0.0.1 minio-console.deploykf.example.com\n</code></pre> <p>Step 2: Port-Forward the Gateway Service</p> <p>You can port-forward the <code>deploykf-gateway</code> Service with the following <code>kubectl</code> command:</p> <pre><code>kubectl port-forward \\\n--namespace \"deploykf-istio-gateway\" \\\nsvc/deploykf-gateway 8080:http 8443:https\n</code></pre> <p>You should now see the deployKF dashboard at: https://deploykf.example.com:8443/</p> Default Login Credentials <p>The following table lists the default login credentials for the deployKF dashboard.</p> Account Username Password Notes Admin <code>admin@example.com</code> <code>admin</code> not for normal use (owns all profiles) User 1 <code>user1@example.com</code> <code>user1</code> User 2 <code>user2@example.com</code> <code>user2</code> <p>Dex StaticPasswords</p> <p>These default login credentials are Dex StaticPasswords defined by the <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> value.</p> <p>Default Profile Owner</p> <p>By default, <code>\"admin@example.com\"</code> is the \"owner\" of all profiles, but is not a \"member\" of any. This means that it does NOT have access to the \"MinIO Console\" or \"Argo Workflows Server\" interfaces.</p>"},{"location":"guides/getting-started/#additional-topics","title":"Additional Topics","text":"<p>Note, the audience for these next topics is platform users rather than platform operators.</p> GitOps for Kubeflow Pipelines (Pipeline Definitions, Schedules) <p>We provide a reference implementation for managing Kubeflow Pipelines (pipeline definitions, schedules) using GitOps. For more information, see the GitOps for Kubeflow Pipelines user guide.</p> Access Kubeflow Pipelines API <p>We provide information on how to authenticate with the Kubeflow Pipelines API from both inside and outside the cluster. For more information, see the Access the Kubeflow Pipelines API user guide.</p>"},{"location":"guides/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Troubleshooting</li> <li>Join the deployKF community</li> <li>Get Support</li> </ul>"},{"location":"guides/migrate-from-kubeflow-manifests/","title":"Migrate from Kubeflow Manifests","text":"<p>This guide explains how to migrate from an existing deployment of Kubeflow to deployKF.</p>"},{"location":"guides/migrate-from-kubeflow-manifests/#1-understand-the-differences","title":"1. Understand the Differences","text":"<p>Before migrating, you may wish to review our detailed deployKF vs  Kubeflow comparison.</p> <p>Packaged distributions of Kubeflow</p> <p>Most other distributions of Kubeflow, are using mostly unmodified versions of the Kubeflow Manifests, so the comparison is still relevant for them.</p>"},{"location":"guides/migrate-from-kubeflow-manifests/#2-create-a-new-deployment","title":"2. Create a New Deployment","text":"<p>The best way to migrate from Kubeflow Manifests to deployKF is to spin up deployKF in a separate Kubernetes cluster, and then migrate your data manually.</p> <p>To create a new deployment of deployKF, follow the Getting Started guide.</p> <p>Warning</p> <p>Kubeflow Manifests and deployKF can NOT be deployed concurrently in the same Kubernetes cluster, doing so will result in unexpected behavior.</p>"},{"location":"guides/migrate-from-kubeflow-manifests/#3-migrate-your-data","title":"3. Migrate your data","text":"<p>Once you have a new deployment of deployKF, you can migrate the data from specific Kubeflow tools to their deployKF equivalents.</p> <p>For example, you will likely need to migrate your existing Kubeflow Pipelines (scheduled runs, pipeline definitions) and Kubeflow Notebooks (user volume data) to the new deployment.</p>"},{"location":"guides/troubleshooting/","title":"Troubleshooting","text":"<p>The following sections contain troubleshooting information for issues with deployKF.</p>"},{"location":"guides/troubleshooting/#deployment-issues","title":"Deployment Issues","text":"<p>Pods fail with \"too many open files\" error</p>"},{"location":"guides/troubleshooting/#pods-fail-with-too-many-open-files-error","title":"Pods fail with \"too many open files\" error:","text":"<p>This error has been discussed in the upstream Kubeflow repo (<code>kubeflow/manifests#2087</code>), to resolve it, you will need to increase your system's open/watched file limits.</p> <p>On linux, you may need to increase the <code>fs.inotify.max_user_*</code> sysctl values:</p> <ol> <li>Modify <code>/etc/sysctl.conf</code> to include the following lines:<ul> <li><code>fs.inotify.max_user_instances = 1280</code></li> <li><code>fs.inotify.max_user_watches = 655360</code></li> </ul> </li> <li>Reload sysctl configs by running <code>sudo sysctl -p</code></li> </ol>"},{"location":"guides/platform/deploykf-authentication/","title":"User Authentication and External Identity Providers","text":"<p>This guide explains how to configure deployKF user authentication, including connecting with external identity providers.</p>"},{"location":"guides/platform/deploykf-authentication/#overview","title":"Overview","text":"<p>deployKF uses Dex and Oauth2 Proxy via our Istio <code>EnvoyFilters</code> for user authentication.</p> <p>Dex allows multiple authentication methods to be used at the same time, including:</p> <ul> <li>Connecting External Identity Providers</li> <li>Defining Static User/Password Combinations</li> </ul>"},{"location":"guides/platform/deploykf-authentication/#external-identity-providers","title":"External Identity Providers","text":"<p>Dex provides connectors for many external identity providers including LDAP (Active Directory), GitHub, Google, Microsoft and OpenID Connect (Azure, Okta, Salesforce, etc).</p> <p>The <code>deploykf_core.deploykf_auth.dex.connectors</code> value configures the list of connectors which are available for user authentication.</p> <p>For example, to connect with Google, you might use the following values:</p> <pre><code>deploykf_core:\ndeploykf_auth:\ndex:\nconnectors:\n## NOTE:\n##  - this element is formatted the same as described in: \n##    https://dexidp.io/docs/connectors/google/\n##  - in addition to `type`, `id`, `name`, and `config`, \n##    which are the same as upstream dex, we provide the\n##    `configExistingSecret` and `configExistingSecretKey`\n##    fields, to set the `config` from a kubernetes secret\n- type: google\nid: google\nname: Google\n\n## NOTE: \n##  - the full `config` must come from a single source, \n##     you can NOT mix `config` and `configExistingSecret`\nconfig:\nclientID : \"kubeflow\"\nclientSecret : \"XXXXXXXXXXXXXXXXXXXXXXXXX\"\nredirectURI : \"https://XXXXXXXX/dex/callback\"\n\n## NOTE: \n##  - the `configExistingSecretKey` key in the secret must \n##    contain a string of YAML that is formatted the same \n##    as the CONTENTS of the `config` map key above\n#configExistingSecret: \"my-dex-connector-secret\"\n#configExistingSecretKey: \"google-config\"\n</code></pre> <p>SAML 2.0 Connector</p> <p>You should NOT use the SAML 2.0 connector, as it does not support refreshing tokens, so users would be forced to re-login every 60 minutes.</p>"},{"location":"guides/platform/deploykf-authentication/#static-userpassword-combinations","title":"Static User/Password Combinations","text":"<p>The <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> value defines a list of static user/password combinations.</p> <p>For example, you might use the following values to define three users:</p> <pre><code>deploykf_core:\ndeploykf_auth:\ndex:\nstaticPasswords:\n## a user with password defined as a plaintext value\n- email: \"plaintext@example.com\"\npassword:\nvalue: \"password\"\n\n## a user with password defined as a bcrypt hash\n##  - a bcrypt hash for \"PASSWORD_STRING\" can be generated with one of the following:\n##     - echo \"PASSWORD_STRING\" | htpasswd -BinC 10 NULL | cut -d: -f2\n##     - python -c 'import bcrypt; print(bcrypt.hashpw(b\"password\", bcrypt.gensalt(10)).decode())'\n- email: \"bcrypt@example.com\"\npassword:\n## the bcrypt hash of the password \"password\"\nvalue: \"$2y$10$z22lKMtSyC65VhMfTROkGesiS2ofrVQQdkGu.vjhIH2HM5Epmhil2\"\ntype: \"hash\"\n\n## a user with password defined from a kubernetes secret\n- email: \"kubernetes-secret@example.com\"\nexistingSecret: \"my-secret\"\nexistingSecretKey: \"password-key\"\n</code></pre> <p>Password Secret Rotation</p> <p>If a user's password is defined from a Kubernetes Secret, the password will be automatically rotated when the Secret is updated.</p> <p>Service Accounts</p> <p>The static accounts are commonly used as \"service accounts\" for things like Accessing the Kubeflow Pipelines API, but may also be used for regular users if you do not have an external identity provider.</p>"},{"location":"guides/platform/deploykf-dashboard/","title":"Customize the deployKF Dashboard","text":"<p>This guide explains how to customize the deployKF Dashboard.</p>"},{"location":"guides/platform/deploykf-dashboard/#overview","title":"Overview","text":"<p>The deployKF Dashboard is the web-based interface for deployKF, and is the primary way that users interact with the platform.</p> <p>The dashboard includes navigation menus with links to various tools and documentation which can be customized.</p>"},{"location":"guides/platform/deploykf-dashboard/#sidebar-links","title":"Sidebar Links","text":"<p>Extra links may be added to the sidebar navigation menu with the <code>deploykf_core.deploykf_dashboard.navigation.externalLinks</code> value.</p> <p>For example, you may use the following values to add a link to the deployKF website:</p> <pre><code>deploykf_core:\ndeploykf_dashboard:\nnavigation:\nexternalLinks:\n- name: \"deployKF Website\"\nurl: \"https://deployKF.org\"\nicon: \"launch\"\n</code></pre>"},{"location":"guides/platform/deploykf-dashboard/#documentation-links","title":"Documentation Links","text":"<p>Extra links may be added to the \"documentation\" section of the home page with the <code>deploykf_core.deploykf_dashboard.navigation.documentationItems</code> value.</p> <p>For example, you may use the following values to add a link to the deployKF website:</p> <pre><code>deploykf_core:\ndeploykf_dashboard:\nnavigation:\ndocumentationItems:\n- text: \"deployKF Website\"\ndesc: \"The tool that deployed your ML platform!\"\nlink: \"https://github.com/deployKF/deployKF\"\n</code></pre>"},{"location":"guides/platform/deploykf-gateway/","title":"Expose deployKF Gateway and configure HTTPS","text":"<p>This guide explains how to expose the deployKF Gateway Service and configure HTTPS.</p>"},{"location":"guides/platform/deploykf-gateway/#overview","title":"Overview","text":"<p>The \"deployKF Gateway Service\" is the main network entry point to deployKF.  By default, it is a Kubernetes Service named <code>deploykf-gateway</code> pointing to our Istio Ingress Gateway pods.</p> <p>Help Improve this Guide</p> <p>This guide covers an incredibly broad topic with near limitless possible implementations. As a result, it is likely to be missing some important details for your specific use case. If you see anything that is incorrect or missing, please help us by raising an issue!</p>"},{"location":"guides/platform/deploykf-gateway/#1-expose-the-gateway-service","title":"1. Expose the Gateway Service","text":"<p>The first step is to expose the deployKF Gateway Service on an IP address that is accessible from outside the cluster.</p> <p>There are two main options to expose the deployKF Gateway Service:</p> <ol> <li>Use a <code>LoadBalancer</code> type Service (recommended)</li> <li>Configure an <code>Ingress</code></li> </ol> <p>Public Internet</p> <p>You should seriously consider the security implications of exposing the deployKF Gateway to the public internet. Given the nature of ML Platforms, most companies choose to expose the gateway on their private network, and then use a VPN or other secure connection to access it.</p> <p>Include custom manifests in generated output</p> <p>deployKF provides an <code>extraManifests</code> value for each component which allows arbitrary YAML manifests to be added to the generated output. For example, <code>deploykf_core.deploykf_istio_gateway.extraManifests</code> may be used to add a custom Ingress or Secret resource to the generated output of the <code>deploykf-istio-gateway</code> component.</p>"},{"location":"guides/platform/deploykf-gateway/#expose-with-loadbalancer-service","title":"Expose with LoadBalancer Service","text":"Steps to Expose with LoadBalancer Service <p>Most Kubernetes platforms provide a LoadBalancer service that can expose on a public/private IP address.</p> <p>To use this option, you will generally need to do the following:</p> <ol> <li>Set the <code>deploykf_core.deploykf_istio_gateway.gatewayService.type</code> value to <code>\"LoadBalancer\"</code> (the default)</li> <li>Use the <code>deploykf_core.deploykf_istio_gateway.gatewayService.annotations</code> value to configure the Service</li> </ol> Amazon Web Services (EKS) <p>The AWS Load Balancer Controller is commonly used to configure LoadBalancer services on EKS.</p> <p>For example, you might set the following values to use a Network Load Balancer (NLB):</p> <pre><code>deploykf_core:\ndeploykf_istio_gateway:\n\n## these values are used to configure the deployKF Gateway Service\n##\ngatewayService:\nname: \"deploykf-gateway\"\ntype: \"LoadBalancer\"\nannotations:\nservice.beta.kubernetes.io/aws-load-balancer-type: \"external\"\nservice.beta.kubernetes.io/aws-load-balancer-nlb-target-type: \"ip\"\nservice.beta.kubernetes.io/aws-load-balancer-scheme: \"internal\"\n\n## for external-dns integration (if not `--source=istio-gateway` config)\n#external-dns.alpha.kubernetes.io/hostname: \"deploykf.example.com, *.deploykf.example.com\"\n\n## for static private IP addresses\n#service.beta.kubernetes.io/aws-load-balancer-private-ipv4-addresses: \"192.168.XXX.XXX, 192.168.YYY.YYY\"\n#service.beta.kubernetes.io/aws-load-balancer-subnets: \"subnet-XXX, subnet-YYY\"\n\n## for static public IP addresses\n#service.beta.kubernetes.io/aws-load-balancer-eip-allocations: \"eipalloc-XXX, eipalloc-YYY\"\n#service.beta.kubernetes.io/aws-load-balancer-subnets: \"subnet-XXX, subnet-YYY\"\n</code></pre> Google Cloud (GKE) <p>GKE, has a LoadBalancer Service type, which is configured with annotations like <code>networking.gke.io/load-balancer-type</code>. </p> <p>For example, you might set the following values to use an INTERNAL Passthrough Network Load Balancer:</p> <pre><code>deploykf_core:\ndeploykf_istio_gateway:\n\n## these values are used to configure the deployKF Gateway Service\n##\ngatewayService:\nname: \"deploykf-gateway\"\ntype: \"LoadBalancer\"\nannotations:\nnetworking.gke.io/load-balancer-type: \"Internal\"\n\n## for external-dns integration (if not `--source=istio-gateway` config)\n#external-dns.alpha.kubernetes.io/hostname: \"deploykf.example.com, *.deploykf.example.com\"\n\n## for static IP addresses\n#loadBalancerIP: \"192.168.XXX.XXX\"\n#loadBalancerSourceRanges: [\"192.168.XXX.XXX/32\"]\n</code></pre>"},{"location":"guides/platform/deploykf-gateway/#expose-with-ingress","title":"Expose with Ingress","text":"Steps to Expose with Ingress <p>Most Kubernetes platforms provide an Ingress class that can expose on a public/private IP address.</p> <p>To use this option, you will generally need to do the following:</p> <ol> <li>Set the <code>deploykf_core.deploykf_istio_gateway.gatewayService.type</code> value to <code>\"NodePort\"</code> or <code>\"ClusterIP\"</code></li> <li>Use the <code>deploykf_core.deploykf_istio_gateway.gatewayService.annotations</code> value to configure the Service</li> <li>Create an <code>Ingress</code> resource that points to the <code>deploykf-gateway</code> Service</li> </ol> Amazon Web Services (EKS) <p>The AWS Load Balancer Controller is commonly used to configure Ingress resources on EKS.</p> <p>TLS Certificates</p> <p>Because ALB does NOT support TLS-passthrough, you must manually create an AWS Certificate Manager (ACM) wildcard certificate for your domain. The <code>alb.ingress.kubernetes.io/certificate-arn</code> Ingress annotation will be used to select the certificate and allow the Ingress to terminate TLS before forwarding to the Gateway Service.</p> Hostname Certificate Field <code>*.deploykf.example.com</code> CN, SAN <code>deploykf.example.com</code> SAN <p>For example, you might set the following values to use an Application Load Balancer (ALB):</p> <pre><code>deploykf_core:\ndeploykf_istio_gateway:\n\n## this value is used to add arbitrary manifests to the generated output\n##\nextraManifests:\n- |\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\nname: deploykf-gateway\nannotations:\nalb.ingress.kubernetes.io/scheme: internal\nalb.ingress.kubernetes.io/target-type: ip\nalb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\nalb.ingress.kubernetes.io/ssl-redirect: '443'\nalb.ingress.kubernetes.io/certificate-arn: \"arn:aws:acm:REGION_NAME:ACCOUNT_ID:certificate/CERTIFICATE_ID\"\nalb.ingress.kubernetes.io/backend-protocol: HTTPS\nspec:\ningressClassName: alb                  \nrules:\n- host: \"deploykf.example.com\"\nhttp:\npaths:\n- path: \"/*\"\nbackend:\nservice:\nname: \"deploykf-gateway\"\nport:\nname: https\n- host: \"*.deploykf.example.com\"\nhttp:\npaths:\n- path: \"/*\"\nbackend:\nservice:\nname: \"deploykf-gateway\"\nport:\nname: https\n\n## these values are used to configure the deployKF Gateway Service\n##\ngatewayService:\nname: \"deploykf-gateway\"\ntype: \"NodePort\"\nannotations: {}\n</code></pre> Google Cloud (GKE) <p>GKE, has an Ingress class that can be used to configure Ingress resources for external or internal access. </p> <p>TLS Certificates</p> <p>In the following example, we are configuring the GKE Ingress to use the same TLS certificate as the deployKF Gateway Service (found in <code>Secret/deploykf-istio-gateway-cert</code>). Later in this guide you will learn how to make this certificate valid, and not self-signed.</p> <p>For example, you might set the following values to use an INTERNAL Application Load Balancer:</p> <pre><code>deploykf_core:\ndeploykf_istio_gateway:\n\n## this value is used to add arbitrary manifests to the generated output\n##\nextraManifests:\n- |\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\nname: deploykf-gateway\nannotations:\nkubernetes.io/ingress.class: \"gce-internal\"\nkubernetes.io/ingress.allow-http: \"false\"\nspec:\ntls:\n## NOTE: this secret is created as part of the deployKF installation\n- secretName: \"deploykf-istio-gateway-cert\"\nrules:\n- host: \"deploykf.example.com\"\nhttp:\npaths:\n- path: \"/*\"\npathType: ImplementationSpecific\nbackend:\nservice:\nname: \"deploykf-gateway\"\nport:\nname: https\n- host: \"*.deploykf.example.com\"\nhttp:\npaths:\n- path: \"/*\"\npathType: ImplementationSpecific\nbackend:\nservice:\nname: \"deploykf-gateway\"\nport:\nname: https\n\n## these values are used to configure the deployKF Gateway Service\n##\ngatewayService:\nname: \"deploykf-gateway\"\ntype: \"NodePort\"\nannotations:\ncloud.google.com/app-protocols: '{\"https\":\"HTTPS\",\"http\":\"HTTP\"}'\n\n## this annotation may be required if you are using a Shared VPC\n##  https://cloud.google.com/kubernetes-engine/docs/how-to/internal-load-balance-ingress#shared_vpc\n#cloud.google.com/neg: '{\"ingress\": true}'\n</code></pre> Ingress Considerations <p>In most cases, using a LoadBalancer Service is the preferred option for the following reasons:</p> <ol> <li>Faster: less hops between the client and the gateway</li> <li>Future-proof: deployKF might expose non-HTTP services in the future</li> <li>Simpler TLS: many Ingress controllers don't support TLS passthrough</li> </ol>"},{"location":"guides/platform/deploykf-gateway/#2-configure-dns","title":"2. Configure DNS","text":"<p>Now that the deployKF Gateway Service has an IP address, you must configure DNS records which point to it.</p> <p>There are two main options to configure DNS records:</p> <ol> <li>Automatically with External-DNS (recommended)</li> <li>Manually with your DNS provider</li> </ol> <p>Depending on which components of deployKF are used, the following hostnames may be served by the deployKF Gateway Service:</p> Hostname Description Required By <code>deploykf.example.com</code> the deployKF Gateway ALL <code>argo-server.deploykf.example.com</code> the Argo Server UI Argo Server (Kubeflow Pipelines) <code>minio-api.deploykf.example.com</code> the MinIO API MinIO <code>minio-console.deploykf.example.com</code> the MinIO UI MinIO <p>Base Domain</p> <p>The \"base domain\" is defined by <code>deploykf_core.deploykf_istio_gateway.gateway.hostname</code>, which has a default value of <code>\"deploykf.example.com\"</code>.</p> <p>Wildcard DNS Records</p> <p>If you plan to manually create the records, we recommend using a wildcard DNS record to account for any future subdomains that may be added to the deployKF Gateway Service.</p> <p>For example, you might set BOTH the following DNS records:</p> <ul> <li><code>*.deploykf.example.com</code></li> <li><code>deploykf.example.com</code></li> </ul>"},{"location":"guides/platform/deploykf-gateway/#configure-records-with-external-dns","title":"Configure records with External-DNS","text":"Steps to configure records with External-DNS <p>External-DNS is a Kubernetes controller that automatically configures DNS records for Kubernetes resources.</p> <p>To use this option, you will generally need to do the following:</p> <ol> <li>Install External-DNS and connect it to your DNS provider</li> <li>Configure External-DNS to set DNS records for the deployKF Gateway Service</li> </ol> <p>Step 1: Install External-DNS</p> <p>The External-DNS documentation provides instructions for installing External-DNS on various platforms.</p> <p>Here are some popular platforms:</p> Cloud Platform DNS Provider Amazon Web Services Route53 Google Cloud Cloud DNS Microsoft Azure Azure DNS, Azure Private DNS Any Cloudflare, Akamai Edge DNS <p>Step 2: Configure External-DNS</p> <p>There are a few ways to configure External-DNS so that it sets DNS records for the deployKF Gateway Service.</p> Option 1: Automatically Extract Hostnames from Istio Gateway <p>You may configure External-DNS to automatically extract the domain names from Istio <code>Gateway</code> resources.</p> <p>If you do this, a separate DNS record is created for each domain selected by our Istio <code>Gateway</code>.</p> <p>To connect External-DNS with Istio, you will need to:</p> <ol> <li>Update your <code>Deployment/external-dns</code> to set the <code>--source=istio-gateway</code> start argument</li> <li>Update your <code>ClusterRole/external-dns</code> to allow access to Istio <code>Gateway</code> and <code>VirtualService</code> resources</li> </ol> Option 2: Manually Annotate Service or Ingress <p>You can manually configure External-DNS by annotating the <code>Service</code> or <code>Ingress</code> resource with the <code>external-dns.alpha.kubernetes.io/hostname</code> annotation.</p> <p>If you do this, you need to add BOTH the base domain AND subdomains. You can avoid the need to specify each subdomain by using a wildcard DNS record, but you will still need to specify the base domain. Multiple hostnames can be specified in a single annotation using a comma-separated list.</p> <p>See the introduction of this section for a list of domains to configure.</p> <p>Depending on if you are using a Service or Ingress, you will set the <code>external-dns.alpha.kubernetes.io/hostname</code> annotation by:</p> <ul> <li>Service: setting the <code>deploykf_core.deploykf_istio_gateway.gatewayService.annotations</code> value</li> <li>Ingress: manually annotating your Ingress resource</li> </ul>"},{"location":"guides/platform/deploykf-gateway/#configure-records-manually","title":"Configure records manually","text":"Steps to configure records manually <p>You can manually configure DNS records with your DNS provider that target your deployKF Gateway Service.</p> <p>To use this option, you will generally need to do the following:</p> <ol> <li>Ensure the deployKF Gateway has a static IP address (or hostname, in some cases)</li> <li>Configure DNS records with your DNS provider</li> </ol> <p>Step 1: Static IP Addresses</p> <p>Each type of LoadBalancer Service (or Ingress controller) has different ways to configure static IP addresses or hostnames. Please refer to the documentation for your platform.</p> <p>Step 2: Configure DNS Records</p> <p>You need to create records for BOTH the base domain AND subdomains. You can avoid the need to specify each subdomain by using a wildcard DNS record, but you will still need to specify the base domain.</p> <p>See the introduction of this section for a list of domains to configure.</p>"},{"location":"guides/platform/deploykf-gateway/#3-configure-httpstls","title":"3. Configure HTTPS/TLS","text":"<p>Now that the deployKF Gateway Service has a DNS pointing to it, to prevent self-signed certificate errors, you must configure a way to make the TLS certificates valid.</p> <ul> <li>If you are exposing the deployKF Gateway with a LoadBalancer Service, then ONLY the Istio Gateway will need to be configured with valid TLS certificates.</li> <li>If you are exposing the deployKF Gateway with an Ingress, then BOTH the Istio Gateway and the Ingress will need to be configured with valid TLS certificates (unless your Ingress supports TLS passthrough, which most do not).</li> </ul>"},{"location":"guides/platform/deploykf-gateway/#configure-tls-for-istio-gateway","title":"Configure TLS for Istio Gateway","text":"<p>deployKF includes cert-manager to automatically generate TLS certificates for the Istio Gateway.</p> <p>By default, the Istio Gateway uses a self-signed certificate generated by this <code>ClusterIssuer</code>, which is fine for testing (especially if you don't own the domain you are using), but not recommended for production usage.</p> <p>To have cert-manager generate valid TLS certificates for the Istio Gateway, you will need to:</p> <ol> <li>Connect cert-manager to your DNS provider</li> <li>Create a <code>ClusterIssuer</code> resource that can generate certificates for your domain</li> <li>Configure the Istio Gateway to use your <code>ClusterIssuer</code> to generate certificates</li> </ol> <p>Custom Deployment</p> <p>deployKF includes an embedded version of cert-manager, if you wish to use your own, you may set the <code>deploykf_dependencies.cert_manager.enabled</code> value to <code>false</code>. If you do this, the <code>deploykf_dependencies.cert_manager.clusterIssuer</code> values will still control which <code>ClusterIssuer</code> is used to generate certificates for the Istio Gateway.</p>"},{"location":"guides/platform/deploykf-gateway/#step-1-connect-cert-manager-to-dns-provider","title":"STEP 1: Connect cert-manager to DNS Provider","text":"<p>For almost everyone, the best Certificate Authority (CA) is Let's Encrypt.</p> <p>Because deployKF uses a wildcard <code>Certificate</code>, you MUST use the <code>DNS-01</code> challenge to verify domain ownership rather than <code>HTTP-01</code>. This requires you to configure cert-manager so that it is able to create DNS records.</p> <p>The cert-manager documentation provides instructions for configuring <code>DNS-01</code> challenges for various DNS providers. The following table lists some popular DNS providers:</p> Cloud Platform DNS Provider Amazon Web Services Route53 Google Cloud Cloud DNS Microsoft Azure Azure DNS Any Cloudflare, Akamai Edge DNS <p>Pod ServiceAccount Annotations</p> <p>To use Pod-based authentication with your DNS Provider, you may need to annotate the cert-manager ServiceAccount. Custom ServiceAccount annotations can be applied with the <code>deploykf_dependencies.cert_manager.controller.serviceAccount.annotations</code> value.</p>"},{"location":"guides/platform/deploykf-gateway/#step-2-create-a-clusterissuer","title":"STEP 2: Create a ClusterIssuer","text":"<p>Once cert-manager is connected to your DNS provider, you must create a <code>ClusterIssuer</code> resource that can generate certificates for your domain from Let's Encrypt.</p> <p>For example, you may create a <code>ClusterIssuer</code> resource like this when using Google Cloud DNS:</p> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\nname: my-cluster-issuer\nspec:\nacme:\nserver: https://acme-staging-v02.api.letsencrypt.org/directory\nemail: user@example.com\nprivateKeySecretRef:\nname: letsencrypt-staging\nkey: tls.key\nsolvers:\n- dns01:\ncloudDNS:\nproject: my-project-id\nserviceAccountSecretRef:\nname: my-service-account-secret\nkey: service-account.json\nselector:\ndnsNames:\n- \"*.deploykf.example.com\"\n- \"deploykf.example.com\"\n</code></pre> <p>Issuer Kind</p> <p>Many cert-manager examples show an <code>Issuer</code> resource.  Note that any issuer may be converted to its equivalent cluster version by changing the <code>kind</code> field from <code>\"Issuer\"</code> to <code>\"ClusterIssuer\"</code> and removing the <code>metadata.namespace</code> field.</p>"},{"location":"guides/platform/deploykf-gateway/#step-3-configure-the-istio-gateway","title":"STEP 3: Configure the Istio Gateway","text":"<p>Once you have a <code>ClusterIssuer</code> resource that can generate certificates for your domain, you must configure the deployKF Istio Gateway to use it.</p> <p>This is done by using the <code>deploykf_dependencies.cert_manager.clusterIssuer</code> values. For example, if you created a <code>ClusterIssuer</code> named <code>my-cluster-issuer</code>, you would set the following values:</p> <pre><code>deploykf_dependencies:\ncert_manager:\nclusterIssuer:\n## this tells deployKF that you have created a ClusterIssuer\nenabled: false\n\n## this value should match the name of your ClusterIssuer\nissuerName: \"my-cluster-issuer\"\n</code></pre>"},{"location":"guides/platform/deploykf-gateway/#configure-tls-for-ingress","title":"Configure TLS for Ingress","text":"<p>How you configure TLS for your Ingress will depend on which Ingress controller you are using. Please refer to the documentation for your platform.</p> <p>Share Certificate with Istio Gateway</p> <p>In some cases, your Ingress can use the same TLS certificate as the Istio Gateway. By default, a Kubernetes <code>Secret</code> named <code>deploykf-istio-gateway-cert</code> which contains the certificate is found in the <code>deploykf-istio-gateway</code> namespace, managed by this <code>Certificate</code> resource.</p> <p>Both Istio Gateway and Ingress need valid TLS</p> <p>Pods which are in the Istio mesh use hairpinning (via this Istio <code>ServiceEntry</code>) to access the gateway without leaving the cluster. This means that even if your Ingress has a valid TLS certificate, if you do not Configure TLS for the Istio Gateway, you may see certificate errors when accessing services from within the cluster.</p>"},{"location":"guides/platform/deploykf-profiles/","title":"Manage Profiles and Assigning Users","text":"<p>This guide explains how to manage deployKF Profiles (Namespaces) and assign Users to them.</p>"},{"location":"guides/platform/deploykf-profiles/#overview","title":"Overview","text":"<p>A deployKF profile has a 1:1 relationship with a Kubernetes namespace. The profiles which a user is a member of determines their level of access to resources/tools in the cluster.</p> <p>No Profile = No Access</p> <p>If a user is not a member of any profiles, they will NOT have any access, even though they may be able to log in.</p> <p>Use Profile Generator Only</p> <p>You must ONLY use the <code>deploykf_core.deploykf_profiles_generator</code> values to manage profile definitions or user assignments. Any manual changes using the UI or other manifests will result in undefined behaviour.</p>"},{"location":"guides/platform/deploykf-profiles/#user-entities","title":"User Entities","text":"<p>The <code>deploykf_core.deploykf_profiles_generator.users</code> value defines \"user\" entities.</p> <p>For example, you might use the following values to define three users:</p> <pre><code>deploykf_core:\ndeploykf_profiles_generator:\nusers:\n- id: user-1\nemail: \"user1@example.com\"\n\n- id: user-2\nemail: \"user2@example.com\"\n\n- id: user-3\nemail: \"user3@example.com\"\n</code></pre> <p>User Identifiers</p> <p>Users are identified by email address, which is provided from the identity provider or static accounts, this means that each <code>email</code> must be unique.</p>"},{"location":"guides/platform/deploykf-profiles/#group-entities","title":"Group Entities","text":"<p>The <code>deploykf_core.deploykf_profiles_generator.groups</code> value defines \"group\" entities, which are logical collections of \"user\" entities.</p> <p>For example, you might use the following values to define two groups:</p> <pre><code>deploykf_core:\ndeploykf_profiles_generator:\ngroups:\n- id: team-1--admins\nusers:\n- user-1\n\n- id: team-1--users\nusers:\n- user-1\n- user-2\n- user-3\n</code></pre> <p>Syncing External Groups</p> <p>Currently, groups must be manually defined in the values, and can NOT be synced from an external identity provider.</p>"},{"location":"guides/platform/deploykf-profiles/#profile-definitions","title":"Profile Definitions","text":"<p>The <code>deploykf_core.deploykf_profiles_generator.profiles</code> value defines the profiles (namespaces) to create, and the groups/users to assign to them.</p> <p>For example, you might use the following values to define two profiles:</p> <pre><code>deploykf_core:\ndeploykf_profiles_generator:\nprofiles:\n- name: team-1\nmembers:\n- group: team-1--users\naccess:\nrole: edit\nnotebooksAccess: true\n\n- name: team-1-prod\nmembers:\n- group: team-1--admins\naccess:\nrole: edit\nnotebooksAccess: true\n\n- group: team-1--users\naccess:\nrole: view\nnotebooksAccess: false\n</code></pre> <p>Highest Level of Access</p> <p>If a user has multiple memberships in the same profile, the highest level of access will be used.</p> <p>Default Profile Owner</p> <p>By default, <code>\"admin@example.com\"</code> is the \"owner\" of all profiles, but is not a \"member\" of any. This means that it does not have access to the \"MinIO Console\" or \"Argo Workflows Server\" interfaces.</p> <p>Because it is NOT possible to change the owner of a profile (<code>kubeflow/kubeflow#6576</code>), we recommend that you leave the default owner as <code>admin@example.com</code>, and never log into that account.</p> <p>For additional security, remove the <code>staticPasswords</code> entry for that email, so it can never be used to log in.</p>"},{"location":"guides/tools/external-mysql/","title":"Connect an external MySQL Database","text":"<p>This guide explains how to use an external MySQL database for tools that require a MySQL database in deployKF.</p>"},{"location":"guides/tools/external-mysql/#overview","title":"Overview","text":"<p>deployKF includes an embedded MySQL instance, however, you may want to replace this with an external MySQL database.</p> <p>Production Usage</p> <p>The embedded MySQL instance is only intended for development and testing purposes. It is a single-instance MySQL server, with no backups, and no high-availability. For production usage, you should always use an external MySQL database.</p> Supported MySQL Services <p>deployKF should work with any MySQL service!</p> <p>Here are some MySQL services listed by platform:</p> Platform MySQL Service Amazon Web Services Amazon Relational Database Service (RDS) Microsoft Azure Azure Database for MySQL Google Cloud Cloud SQL Alibaba Cloud ApsaraDB RDS for MySQL IBM Cloud IBM Cloud Databases for MySQL"},{"location":"guides/tools/external-mysql/#1-disable-embedded-mysql","title":"1. Disable Embedded MySQL","text":"<p>The <code>deploykf_opt.deploykf_mysql.enabled</code> value controls if the embedded MySQL instance is deployed.</p> <p>For example, to disable MySQL, set the following value:</p> <pre><code>deploykf_opt:\ndeploykf_mysql:\nenabled: false\n</code></pre>"},{"location":"guides/tools/external-mysql/#2-create-databases-and-user","title":"2. Create Databases and User","text":"<p>You must manually create the databases (schemas) for Kubeflow Pipelines and Katib, and assign the correct permissions to the users they connect as.</p> <p>For example, you might run the following SQL commands to create the databases and users:</p> <pre><code>-- create the databases\nCREATE DATABASE IF NOT EXISTS `katib`;\nCREATE DATABASE IF NOT EXISTS `kfp_cache`;\nCREATE DATABASE IF NOT EXISTS `kfp_metadata`;\nCREATE DATABASE IF NOT EXISTS `kfp_pipelines`;\n\n-- create the 'kubeflow' user (allowing access from any host)\nCREATE USER 'kubeflow'@'%' IDENTIFIED WITH mysql_native_password BY 'MY_PASSWORD';\n\n-- grant access to the databases\nGRANT ALL PRIVILEGES ON `katib`.* TO 'kubeflow'@'%';\nGRANT ALL PRIVILEGES ON `kfp_cache`.* TO 'kubeflow'@'%';\nGRANT ALL PRIVILEGES ON `kfp_metadata`.* TO 'kubeflow'@'%';\nGRANT ALL PRIVILEGES ON `kfp_pipelines`.* TO 'kubeflow'@'%';\n</code></pre> <p>MySQL Authentication Plugin</p> <p>Kubeflow Pipelines is only capable of connecting to MySQL as a user authenticated by the <code>mysql_native_password</code> plugin (<code>kubeflow/pipelines#9549</code>).</p> <p>Note that in MySQL 8.0.4, the default authentication plugin was changed, so you may have to explicitly set the <code>mysql_native_password</code> plugin for the user you create.  Alternatively, you may set your MySQL server's <code>default-authentication-plugin</code> to <code>mysql_native_password</code>.</p>"},{"location":"guides/tools/external-mysql/#2-connect-katib","title":"2. Connect Katib","text":"<p>The following values configure Katib to use an external MySQL database:</p> <code>kubeflow_tools.katib.mysql</code> <p>These values configure which MySQL server is used by Katib.</p> <code>kubeflow_tools.katib.mysqlDatabase</code> <p>This value configures the name of the MySQL database (schema) which Katib will use.</p>"},{"location":"guides/tools/external-mysql/#3-connect-kubeflow-pipelines","title":"3. Connect Kubeflow Pipelines","text":"<p>The following values configure Kubeflow Pipelines to use an external MySQL database:</p> <code>kubeflow_tools.pipelines.mysql</code> <p>These values configure which MySQL server is used by Kubeflow Pipelines.</p> <code>kubeflow_tools.pipelines.mysqlDatabases</code> <p>These values configure the names of the MySQL databases (schemas) which Kubeflow Pipelines will use.</p>"},{"location":"guides/tools/external-object-store/","title":"Connect an external S3-like Object Store","text":"<p>This guide explains how to use an external S3-compatible object store for tools that require an object store in deployKF.</p>"},{"location":"guides/tools/external-object-store/#overview","title":"Overview","text":"<p>deployKF includes an embedded MinIO instance, however, you may want to replace this with an external S3-compatible object store.</p> <p>Production Usage</p> <p>Currently, the embedded MinIO is only intended for development and testing purposes as it only supports a single replica. In future, we are considering adding support for a high-availability MinIO cluster.</p> MinIO License <p>Ensure you are familiar with MinIO's licence, which at the time of writing is AGPLv3. However, rest assured that deployKF itself does NOT contain any code from MinIO, and is licensed under the Apache 2.0 License.</p> Supported Object Stores <p>deployKF should work with any S3-compatible object store!</p> <p>Here are some S3-compatible object stores listed by platform:</p> Platform Object Store Amazon Web Services Amazon Simple Storage Service (S3) Microsoft Azure Azure Blob Storage Google Cloud Google Cloud Storage Alibaba Cloud Alibaba Cloud Object Storage Service (OSS) IBM Cloud IBM Cloud Object Storage Other MinIO, Ceph, Wasabi"},{"location":"guides/tools/external-object-store/#1-disable-embedded-minio","title":"1. Disable Embedded MinIO","text":"<p>The <code>deploykf_opt.deploykf_minio.enabled</code> value controls if the embedded MinIO instance is deployed.</p> <p>For example, to disable MinIO, set the following value:</p> <pre><code>deploykf_opt:\ndeploykf_minio:\nenabled: false\n</code></pre>"},{"location":"guides/tools/external-object-store/#2-connect-kubeflow-pipelines","title":"2. Connect Kubeflow Pipelines","text":"<p>To connect Kubeflow Pipelines to your external object store, you will need to configure the <code>kubeflow_tools.pipelines.objectStore</code> values.</p> <p>For example, you may set values like this:</p> <pre><code>kubeflow_tools:\npipelines:\nobjectStore:\n## this must be true to enable external object store\nuseExternal: true\n\n## this specifies the REST endpoint for your object store\nhost: s3.amazonaws.com\nport: \"\"\nuseSSL: true\n</code></pre> <p>S3-Compatible Object Stores Only</p> <p>Currently, Kubeflow Pipelines only supports S3-compatible object store HTTP APIs. This means that while you can use services like Google Cloud Storage, you will need to use their S3-compatible XML API, and features like GKE Workload Identity will NOT work.</p> <p>If you would like Kubeflow Pipelines to implement support for the native APIs of your object store, please raise this with the upstream Kubeflow Pipelines community.</p>"},{"location":"guides/tools/external-object-store/#bucket","title":"Bucket","text":"<p>The following values configure which bucket is used by Kubeflow Pipelines:</p> <code>kubeflow_tools.pipelines.bucket</code> <p>These values configure the bucket used by Kubeflow Pipelines (v1)</p> <code>kubeflow_tools.pipelines.kfpV2.defaultPipelineRoot</code> <p>These values configure the bucket used by Kubeflow Pipelines (v2)</p>"},{"location":"guides/tools/external-object-store/#authentication","title":"Authentication","text":"<p>You will need to configure authentication for Kubeflow Pipelines to access your object store.</p> Bucket IAM Policies <p>When using the embedded MinIO, we automatically configure prefix-based IAM Policies for each profile.</p> <p>This is possible because of the \"key format\" structure we use for pipeline artifacts, which includes the name of the executing namespace/profile at the start of the key:</p> <ul> <li><code>kubeflow_dependencies.kubeflow_argo_workflows.artifactRepository.keyFormat</code></li> <li><code>kubeflow_tools.pipelines.kfpV2.defaultPipelineRoot</code></li> </ul> <p>To replicate this in your external object store, you may assign an IAM Policy for each profile that is similar to the ones generated by deployKF.</p> <p>The following IAM Policy is used by the Kubeflow Pipelines BACKEND:</p> <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:GetBucketLocation\",\n\"s3:ListBucket\"\n],\n\"Resource\": [\n\"arn:aws:s3:::&lt;BUCKET_NAME&gt;\"\n]\n},\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:GetObject\",\n\"s3:PutObject\",\n\"s3:DeleteObject\"\n],\n\"Resource\": [\n\"arn:aws:s3:::&lt;BUCKET_NAME&gt;/artifacts/*\",\n\"arn:aws:s3:::&lt;BUCKET_NAME&gt;/pipelines/*\",\n\"arn:aws:s3:::&lt;BUCKET_NAME&gt;/v2/artifacts/*\"\n]\n}\n]\n}\n</code></pre> <p>The following IAM Policy is used by the PROFILES:</p> <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:GetBucketLocation\",\n\"s3:ListBucket\"\n],\n\"Resource\": [\n\"arn:aws:s3:::&lt;BUCKET_NAME&gt;\"\n]\n},\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:GetObject\",\n\"s3:PutObject\",\n\"s3:DeleteObject\"\n],\n\"Resource\": [\n\"arn:aws:s3:::&lt;BUCKET_NAME&gt;/artifacts/&lt;PROFILE_NAME&gt;/*\",\n\"arn:aws:s3:::&lt;BUCKET_NAME&gt;/v2/artifacts/&lt;PROFILE_NAME&gt;/*\"\n]\n}\n]\n}\n</code></pre> Authenticate using Secret Keys (ALL Platforms) <p>The following values configure secret key-based auth for the Kubeflow Pipelines Backend, Argo Workflows Controller, and Argo Server UI.</p> <code>kubeflow_tools.pipelines.objectStore.auth</code> <p>These values configure object store auth, for the Kubeflow Pipelines Backend, Argo Workflows Controller, and Argo Server UI.</p> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth</code> <p>These values configure object store secret-based auth, for things running in profiles.</p> Authenticate using IRSA (AWS Only) <p>The following values configure IRSA-based auth for the Kubeflow Pipelines Backend, Argo Workflows Controller, and Argo Server UI.</p> <code>kubeflow_dependencies.kubeflow_argo_workflows.controller.serviceAccount</code> <p>These values configure the Kubernetes ServiceAccounts used by the Argo Workflows Controller, including their annotations.</p> <code>kubeflow_dependencies.kubeflow_argo_workflows.server.serviceAccount</code> <p>These values configure the Kubernetes ServiceAccounts used by the Argo Server UI, including their annotations.</p> <code>kubeflow_tools.pipelines.serviceAccounts</code> <p>These values configure the Kubernetes ServiceAccounts used by the Kubeflow Pipelines Backend, including their annotations.</p> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.plugins</code> <p>These values configure profile-plugins. </p> <p>The <code>AwsIamForServiceAccount</code> profile-plugin is used to configure AWS IRSA-based auth by annotating Kubernetes ServiceAccounts in the profile namespace.</p> <p>Note, these are the default plugins for profiles which do NOT have their own <code>plugins</code> defined in their <code>deploykf_core.deploykf_profiles_generator.profiles</code> list entry.</p>"},{"location":"guides/tools/kubeflow-notebooks/","title":"Configure Kubeflow Notebooks","text":"<p>This guide explains how to configure Kubeflow Notebooks in deployKF.</p>"},{"location":"guides/tools/kubeflow-notebooks/#overview","title":"Overview","text":"<p>Kubeflow Notebooks allows users to spawn Pods running instances of JupyterLab, Visual Studio Code (code-server), and RStudio in profile namespaces.</p> <p>As the cluster administrator, you may configure which options are available to users when spawning a Notebook Pod:</p> <ul> <li>Container Images</li> <li>Container Resources (CPU, Memory, GPU)</li> <li>Storage Volumes</li> <li>Advanced Pod Options (Affinity, Tolerations, PodDefaults)</li> <li>Idle Notebook Culling</li> </ul> <p>Kubeflow Notebooks Limitations</p> <p>The current version of Kubeflow Notebooks exposes many Kubernetes-specific concepts to users, which may be confusing for non-technical users. There is an upstream proposal to abstract away these concepts in a more user-friendly way, see <code>kubeflow/kubeflow#7156</code> for more information.</p> <p>When the <code>kubeflow_tools.notebooks.spawnerFormDefaults</code> values are updated, this has no effect on existing Notebook Pods, only new Pods will use the updated values.</p>"},{"location":"guides/tools/kubeflow-notebooks/#container-images","title":"Container Images","text":"<p>Container images are the \"environment\" which users will be working in when using a Notebook Pod, and can be configured to provide different tools and packages to users.</p> <p>The following values configure which container images are available to users when spawning a Notebook Pod:</p> <ul> <li>Jupyter-Like: <code>kubeflow_tools.notebooks.spawnerFormDefaults.image</code></li> <li>VSCode-like: <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupOne</code></li> <li>RStudio-like: <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupTwo</code></li> </ul>"},{"location":"guides/tools/kubeflow-notebooks/#container-resources","title":"Container Resources","text":"<p>Container resources directly correspond to Kubernetes Container Resources which are requested by the Notebook Pod.</p> <p>The following values configure the resource requests/limits for containers in Notebook Pods:</p> <ul> <li>CPU: <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu</code></li> <li>Memory: <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory</code></li> <li>GPU: <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpu</code></li> </ul> <p>Resource Requests</p> <p>Kubernetes uses resource requests when scheduling Pods, and does not strictly enforce them at runtime. User Notebooks are not well-behaved applications (from a resource perspective), so will likely impact other Pods running on the same node.</p> <p>However, setting resource limits will have unintended consequences for users, as the Notebook Pod will be terminated if it exceeds certain limits (like memory), which may result in lost work.</p> <p>A common alternative is to use a dedicated node for each Notebook Pod, see Advanced Pod Options for information on how to do this with Affinity and Tolerations.</p>"},{"location":"guides/tools/kubeflow-notebooks/#storage-volumes","title":"Storage Volumes","text":"<p>Storage volumes are used to provide persistent storage to Notebook Pods between restarts, and are implemented using Kubernetes Persistent Volumes.</p> <p>The following values configure the storage volumes for Notebook Pods:</p> <ul> <li>Home Volume: <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume</code></li> <li>Data Volume: <code>kubeflow_tools.notebooks.spawnerFormDefaults.dataVolumes</code></li> </ul> <p>StorageClass and Performance</p> <p>The <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.spec.storageClassName</code> value defines which Kubernetes StorageClass is used to provision the workspace volume. If a <code>storageClassName</code> is not specified, the cluster's default StorageClass is used.</p> <p>As ML workloads are often IO-intensive, it is recommended to use a StorageClass which provides high-performance, typically this is only possible with drives which are attached to the node, rather than network-attached storage.</p>"},{"location":"guides/tools/kubeflow-notebooks/#advanced-pod-options","title":"Advanced Pod Options","text":"<p>Advanced Pod Options are additional configurations for Notebook Pods which manage things like Pod Affinity, Node Tolerations, and Kubeflow's PodDefaults.</p> <p>The following values configure the advanced options for Notebook Pods:</p> <ul> <li>Pod Affinity: <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig</code></li> <li>Node Tolerations: <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup</code></li> <li>PodDefaults: <code>kubeflow_tools.notebooks.spawnerFormDefaults.configurations</code></li> </ul> Dedicated Node for each Notebook Pod <p>Because Notebook Pods are not well-behaved applications (from a resource perspective), it is common to want a dedicated node for each Notebook Pod. With a combination of Pod Affinity and Node Tolerations, this can be achieved.</p> <p>Note, this will require your cluster to have node-autoscaling configured (e.g. Cluster Autoscaler or Karpenter), as the cluster will need to provision a new node for each Notebook Pod.</p> <p>First, you will need to make one or more groups of nodes that are tainted to prevent other Pods from being scheduled on them. In the following example, we have four groups of nodes with different CPU/Memory configurations, that are each tainted with a different value of the <code>dedicated</code> key with effect <code>NoSchedule</code>:</p> <ul> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-c5.xlarge</code>, Effect: <code>NoSchedule</code></li> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-c5.2xlarge</code>, Effect: <code>NoSchedule</code></li> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-c5.4xlarge</code>, Effect: <code>NoSchedule</code></li> <li>Key: <code>dedicated</code>, Value: <code>kubeflow-r5.8xlarge</code>, Effect: <code>NoSchedule</code> </li> </ul> <p>Next, you will need to configure Pod Affinity configs that do not allow two Notebook Pods to be scheduled on the same node. In the following example, we do this by:</p> <ul> <li>Using <code>nodeAffinity</code> to require a Node with label <code>lifecycle=kubeflow-notebook</code></li> <li>Using <code>podAntiAffinity</code> to require a Node WITHOUT an existing Pod having <code>notebook-name</code> label</li> </ul> <p>Finally, you may use the following values to expose these options to users:</p> <pre><code>kubeflow_tools:\nnotebooks:\nspawnerFormDefaults:\n## Affinity\n##  - note, setting `readOnly` to `true` to ensures that this affinity is always applied\n##  - note, `namespaceSelector` was added in Kubernetes 1.22, \n##    so this will NOT work on older clusters\n##\naffinityConfig:\nreadOnly: true\nvalue: \"dedicated_node_per_notebook\"\noptions:\n- configKey: \"dedicated_node_per_notebook\"\ndisplayName: \"Dedicated Node Per Notebook\"\naffinity:\n## Require a Node with label `lifecycle=kubeflow-notebook`\nnodeAffinity:\nrequiredDuringSchedulingIgnoredDuringExecution:\nnodeSelectorTerms:\n- matchExpressions:\n- key: \"lifecycle\"\noperator: \"In\"\nvalues:\n- \"kubeflow-notebook\"\n\n## Require a Node WITHOUT an existing Pod having `notebook-name` label\npodAntiAffinity:\nrequiredDuringSchedulingIgnoredDuringExecution:\n- labelSelector:\nmatchExpressions:\n- key: \"notebook-name\"\noperator: \"Exists\"\ntopologyKey: \"kubernetes.io/hostname\"\nnamespaceSelector: {}\n\n## Tolerations\n##\ntolerationGroup:\nreadOnly: false\nvalue: \"group_1\"\noptions:\n- groupKey: \"group_1\"\ndisplayName: \"4 CPU 8Gb Mem at ~$X.XXX USD per day\"\ntolerations:\n- key: \"dedicated\"\noperator: \"Equal\"\nvalue: \"kubeflow-c5.xlarge\"\neffect: \"NoSchedule\"\n\n- groupKey: \"group_2\"\ndisplayName: \"8 CPU 16Gb Mem at ~$X.XXX USD per day\"\ntolerations:\n- key: \"dedicated\"\noperator: \"Equal\"\nvalue: \"kubeflow-c5.2xlarge\"\neffect: \"NoSchedule\"\n\n- groupKey: \"group_3\"\ndisplayName: \"16 CPU 32Gb Mem at ~$X.XXX USD per day\"\ntolerations:\n- key: \"dedicated\"\noperator: \"Equal\"\nvalue: \"kubeflow-c5.4xlarge\"\neffect: \"NoSchedule\"\n\n- groupKey: \"group_4\"\ndisplayName: \"32 CPU 256Gb Mem at ~$X.XXX USD per day\"\ntolerations:\n- key: \"dedicated\"\noperator: \"Equal\"\nvalue: \"kubeflow-r5.8xlarge\"\neffect: \"NoSchedule\"\n</code></pre> <p>Users will then be able to select which group of nodes they want to use by choosing the corresponding \"Toleration\" group when spawning their Notebook.</p> PodDefault for Kubeflow Pipelines Authentication <p>The <code>kubeflow_tools.pipelines.profileResourceGeneration.kfpApiTokenPodDefault</code> value  configures if a <code>PodDefault</code> named <code>\"kubeflow-pipelines-api-token\"</code> is automatically generated in each profile namespace.</p> <p>If the user selects this \"configuration\" when spawning their Notebook, they will be able to use the Kubeflow Pipelines Python SDK from the Notebook without needing to manually authenticate.</p> <p>To have this \"configuration\" selected by default in the spawner, you may use the following values:</p> <pre><code>kubeflow_tools:\nnotebooks:\nspawnerFormDefaults:\nconfigurations:\nvalue:\n- \"kubeflow-pipelines-api-token\"\n</code></pre> <p>For more information, see the Access Kubeflow Pipelines API user guide.</p>"},{"location":"guides/tools/kubeflow-notebooks/#idle-notebook-culling","title":"Idle Notebook Culling","text":"<p>Kubeflow Notebooks supports automatically culling idle Notebook Pods, which is configured by the <code>kubeflow_tools.notebooks.notebookCulling</code> values.</p> <p>For example, the following values will enable idle culling after 1 day of inactivity:</p> <pre><code>kubeflow_tools:\nnotebooks:\nnotebookCulling:\nenabled: true\nidleTime: 1440 # 1 day in minutes\n</code></pre> <p>Jupyter Notebooks Only</p> <p>Currently, only Jupyter Notebooks are supported for idle culling, see the upstream design proposal for more information.</p>"},{"location":"privacy-policy/website/","title":"Website Privacy Policy","text":""},{"location":"privacy-policy/website/#introduction","title":"Introduction","text":"<p>The deployKF project is committed to protecting the privacy of our users.  This Privacy Policy explains how we collect, use, disclose, and safeguard your information when you visit the deployKF website (the \"Website\"). Please read this Privacy Policy carefully.  If you do not agree with the terms of this Privacy Policy, please do not use our Website.</p> <p>We reserve the right to make changes to this Privacy Policy at any time and for any reason.  We will alert you about any changes by updating the \"Last Updated\" date of this Privacy Policy.  You are encouraged to periodically review this Privacy Policy to stay informed of updates.  You will be deemed to have been made aware of, will be subject to, and will be deemed to have accepted the changes in any revised Privacy Policy by your continued use of the Website after the date such revised Privacy Policy is posted.</p>"},{"location":"privacy-policy/website/#collection-of-your-information","title":"Collection of Your Information","text":"<p>We may collect information about you in a variety of ways. </p> <p>The information we may collect on the Website includes:</p>"},{"location":"privacy-policy/website/#anonymous-usage-data","title":"Anonymous Usage Data","text":"<p>When you visit the Website, we may automatically collect anonymous usage data to help improve the Website and understand how our users interact with it.  This information may include, but is not limited to, your IP address, browser type, device type, pages visited, and time spent on the Website.</p>"},{"location":"privacy-policy/website/#cookies","title":"Cookies","text":"<p>We may use cookies and similar tracking technologies on the Website to, among other things, analyze trends, administer the website, track user's movements around the website, and gather demographic information about our user base as a whole.  You can control the use of cookies at the individual browser level, but if you choose to disable cookies, it may limit your use of certain features or functions on our website.</p>"},{"location":"privacy-policy/website/#use-of-your-information","title":"Use of Your Information","text":"<p>We may use the information collected from the Website for various purposes, including:</p> <ul> <li>To monitor and analyze usage trends and preferences, and to improve the Website</li> <li>To identify areas of the Website that may need improvement, optimization, or additional features</li> <li>To diagnose and fix issues with the Website</li> </ul>"},{"location":"privacy-policy/website/#disclosure-of-your-information","title":"Disclosure of Your Information","text":"<p>We will not sell, trade, rent, or otherwise share your information for marketing purposes. </p> <p>We may, however, share your information in the following situations:</p>"},{"location":"privacy-policy/website/#third-party-service-providers","title":"Third-Party Service Providers","text":"<p>We may share your information with third-party service providers that perform services on our behalf, such as analytics providers.  These service providers are required to protect your information in a manner consistent with this Privacy Policy and may not use your information for any purpose other than to carry out the services they are performing for us.</p>"},{"location":"privacy-policy/website/#security-of-your-information","title":"Security of Your Information","text":"<p>We are committed to protecting the information we collect and maintain.  While no method of data transmission or storage is 100% secure, we implement administrative, technical, and physical security measures, such as encryption and access controls, to protect against unauthorized access, alteration, disclosure, or destruction of your information.</p>"},{"location":"privacy-policy/website/#changes-to-this-privacy-policy","title":"Changes to This Privacy Policy","text":"<p>We may update our Privacy Policy from time to time.  We will notify you of any changes by posting the new Privacy Policy on this page.  You are advised to review this Privacy Policy periodically for any changes.  Changes to this Privacy Policy are effective when they are posted on this page.</p>"},{"location":"privacy-policy/website/#contact-us","title":"Contact Us","text":"<p>If you have any questions or concerns about this Privacy Policy, please contact us at:</p> <p>privacy@deploykf.org</p> <p>Last Updated: 2023-04-03</p>"},{"location":"reference/deploykf-values/","title":"Generator Values (Configs)","text":"<p>The following is a summary of the generator values (configs) available in deployKF.</p> <p>Info</p> <p>The full list of values and their defaults can also be found in the <code>generator/default_values.yaml</code> file.</p> <p>Tip</p> <p>The generator values are how you configure all aspects of deployKF. While there are many values available, you only need to specify the ones you want to change from their defaults.</p> <p>For more information about creating your custom values files, see the getting started guide.</p>"},{"location":"reference/deploykf-values/#argo-cd","title":"Argo CD","text":"<p>Values for configuring Argo CD.</p>"},{"location":"reference/deploykf-values/#argocd","title":"<code>argocd</code>","text":"Value Default <code>argocd.appNamePrefix</code> <code>\"\"</code> <code>argocd.namespace</code> <code>\"argocd\"</code> <code>argocd.project</code> <code>\"default\"</code> <code>argocd.source.plugin.enabled</code> <code>false</code> <code>argocd.source.repo.url</code> <code>\"\"</code> <code>argocd.source.repo.revision</code> <code>\"\"</code> <code>argocd.source.repo.path</code> <code>\"\"</code> <code>argocd.destination.server</code> <code>\"https://kubernetes.default.svc\"</code> <code>argocd.destination.name</code> <code>\"\"</code>"},{"location":"reference/deploykf-values/#deploykf-dependencies","title":"deployKF Dependencies","text":"<p>Values for configuring the dependencies of deployKF.</p>"},{"location":"reference/deploykf-values/#deploykf_dependenciescert_manager","title":"<code>deploykf_dependencies.cert_manager</code>","text":"Value Default <code>deploykf_dependencies.cert_manager.enabled</code> <code>true</code> <code>deploykf_dependencies.cert_manager.namespace</code> <code>\"cert-manager\"</code> <code>deploykf_dependencies.cert_manager.extraManifests</code> <code>[]</code> <code>deploykf_dependencies.cert_manager.charts.certManager.name</code> <code>\"cert-manager\"</code> <code>deploykf_dependencies.cert_manager.charts.certManager.version</code> <code>\"1.12.2\"</code> <code>deploykf_dependencies.cert_manager.charts.certManager.repository</code> <code>\"https://charts.jetstack.io\"</code> <code>deploykf_dependencies.cert_manager.charts.trustManager.name</code> <code>\"trust-manager\"</code> <code>deploykf_dependencies.cert_manager.charts.trustManager.version</code> <code>\"0.5.0\"</code> <code>deploykf_dependencies.cert_manager.charts.trustManager.repository</code> <code>\"https://charts.jetstack.io\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerController.repository</code> <code>\"quay.io/jetstack/cert-manager-controller\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerController.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerWebhook.repository</code> <code>\"quay.io/jetstack/cert-manager-webhook\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerWebhook.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerWebhook.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerCainjector.repository</code> <code>\"quay.io/jetstack/cert-manager-cainjector\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerCainjector.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerCainjector.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerAcmesolver.repository</code> <code>\"quay.io/jetstack/cert-manager-acmesolver\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerAcmesolver.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerCtl.repository</code> <code>\"quay.io/jetstack/cert-manager-ctl\"</code> <code>deploykf_dependencies.cert_manager.images.certManagerCtl.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.certManagerCtl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.trustManager.repository</code> <code>\"quay.io/jetstack/trust-manager\"</code> <code>deploykf_dependencies.cert_manager.images.trustManager.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.trustManager.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.images.trustManagerDefaultPackage.repository</code> <code>\"quay.io/jetstack/cert-manager-package-debian\"</code> <code>deploykf_dependencies.cert_manager.images.trustManagerDefaultPackage.tag</code> <code>nil</code> <code>deploykf_dependencies.cert_manager.images.trustManagerDefaultPackage.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.cert_manager.controller.securityContext.fsGroup</code> <code>1001</code> <code>deploykf_dependencies.cert_manager.controller.serviceAccount.create</code> <code>true</code> <code>deploykf_dependencies.cert_manager.controller.serviceAccount.name</code> <code>\"cert-manager\"</code> <code>deploykf_dependencies.cert_manager.controller.extraArgs</code> <code>[\"--enable-certificate-owner-ref=true\"]</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.enabled</code> <code>true</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.issuerName</code> <code>\"deploykf-gateway-issuer\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.type</code> <code>\"SELF_SIGNED\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.selfSigned.caIssuerName</code> <code>\"selfsigned-ca-issuer\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.selfSigned.caSecretName</code> <code>\"selfsigned-ca-issuer-root-cert\"</code> <code>deploykf_dependencies.cert_manager.clusterIssuer.selfSigned.injectedConfigMapName</code> <code>\"deploykf-gateway-issuer-root-ca-cert\"</code>"},{"location":"reference/deploykf-values/#deploykf_dependencieskyverno","title":"<code>deploykf_dependencies.kyverno</code>","text":"Value Default <code>deploykf_dependencies.kyverno.enabled</code> <code>true</code> <code>deploykf_dependencies.kyverno.namespace</code> <code>\"kyverno\"</code> <code>deploykf_dependencies.kyverno.extraManifests</code> <code>[]</code> <code>deploykf_dependencies.kyverno.charts.kyverno.name</code> <code>\"kyverno\"</code> <code>deploykf_dependencies.kyverno.charts.kyverno.version</code> <code>\"3.0.1\"</code> <code>deploykf_dependencies.kyverno.charts.kyverno.repository</code> <code>\"https://kyverno.github.io/kyverno\"</code> <code>deploykf_dependencies.kyverno.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_dependencies.kyverno.images.kubectl.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyverno.repository</code> <code>\"ghcr.io/kyverno/kyverno\"</code> <code>deploykf_dependencies.kyverno.images.kyverno.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyverno.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoInit.repository</code> <code>\"ghcr.io/kyverno/kyvernopre\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoInit.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoInit.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoBackgroundController.repository</code> <code>\"ghcr.io/kyverno/background-controller\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoBackgroundController.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoBackgroundController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoCleanupController.repository</code> <code>\"ghcr.io/kyverno/cleanup-controller\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoCleanupController.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoCleanupController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoReportsController.repository</code> <code>\"ghcr.io/kyverno/reports-controller\"</code> <code>deploykf_dependencies.kyverno.images.kyvernoReportsController.tag</code> <code>nil</code> <code>deploykf_dependencies.kyverno.images.kyvernoReportsController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_dependencies.kyverno.extraResourceRules</code> <code>[{\"apiGroups\": [\"kubeflow.org\"], \"resources\": [\"poddefaults\"]}]</code>"},{"location":"reference/deploykf-values/#deploykf_dependenciesistio","title":"<code>deploykf_dependencies.istio</code>","text":"Value Default <code>deploykf_dependencies.istio.enabled</code> <code>true</code> <code>deploykf_dependencies.istio.namespace</code> <code>\"istio-system\"</code> <code>deploykf_dependencies.istio.extraManifests</code> <code>[]</code> <code>deploykf_dependencies.istio.charts.istioBase.name</code> <code>\"base\"</code> <code>deploykf_dependencies.istio.charts.istioBase.version</code> <code>\"1.17.3\"</code> <code>deploykf_dependencies.istio.charts.istioBase.repository</code> <code>\"https://istio-release.storage.googleapis.com/charts\"</code> <code>deploykf_dependencies.istio.charts.istioDaemon.name</code> <code>\"istiod\"</code> <code>deploykf_dependencies.istio.charts.istioDaemon.version</code> <code>\"1.17.3\"</code> <code>deploykf_dependencies.istio.charts.istioDaemon.repository</code> <code>\"https://istio-release.storage.googleapis.com/charts\"</code> <code>deploykf_dependencies.istio.images.istioProxy.repository</code> <code>\"docker.io/istio/proxyv2\"</code> <code>deploykf_dependencies.istio.images.istioProxy.tag</code> <code>nil</code> <code>deploykf_dependencies.istio.images.istioPilot.repository</code> <code>\"docker.io/istio/pilot\"</code> <code>deploykf_dependencies.istio.images.istioPilot.tag</code> <code>nil</code> <code>deploykf_dependencies.istio.defaultImageVariant</code> <code>\"distroless\"</code>"},{"location":"reference/deploykf-values/#deploykf-core","title":"deployKF Core","text":"<p>Values for configuring core deployKF components.</p>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_auth","title":"<code>deploykf_core.deploykf_auth</code>","text":"Value Default <code>deploykf_core.deploykf_auth.enabled</code> <code>true</code> <code>deploykf_core.deploykf_auth.namespace</code> <code>\"deploykf-auth\"</code> <code>deploykf_core.deploykf_auth.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_auth.images.dex.repository</code> <code>\"ghcr.io/dexidp/dex\"</code> <code>deploykf_core.deploykf_auth.images.dex.tag</code> <code>\"v2.37.0\"</code> <code>deploykf_core.deploykf_auth.images.dex.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_auth.images.oauth2Proxy.repository</code> <code>\"quay.io/oauth2-proxy/oauth2-proxy\"</code> <code>deploykf_core.deploykf_auth.images.oauth2Proxy.tag</code> <code>\"v7.4.0\"</code> <code>deploykf_core.deploykf_auth.images.oauth2Proxy.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_auth.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_core.deploykf_auth.images.kubectl.tag</code> <code>\"1.26.6-debian-11-r8\"</code> <code>deploykf_core.deploykf_auth.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_auth.dex.staticPasswords</code> <code>[{\"email\": \"admin@example.com\", \"password\": {\"value\": \"admin\"}}, {\"email\": \"user1@example.com\", \"password\": {\"value\": \"user1\"}}, {\"email\": \"user2@example.com\", \"password\": {\"value\": \"user2\"}}]</code> <code>deploykf_core.deploykf_auth.dex.connectors</code> <code>[]</code> <code>deploykf_core.deploykf_auth.dex.expiry.idToken</code> <code>\"60m\"</code> <code>deploykf_core.deploykf_auth.dex.expiry.refreshToken.idle</code> <code>\"168h\"</code> <code>deploykf_core.deploykf_auth.dex.expiry.refreshToken.total</code> <code>\"2160h\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientId</code> <code>\"oauth2-proxy\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.value</code> <code>\"bbbbbbbbbbbbbbbb\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.existingSecretKey</code> <code>\"client_secret\"</code> <code>deploykf_core.deploykf_auth.dex.clients.oauth2Proxy.clientSecret.generateSecret</code> <code>false</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientId</code> <code>\"minio-console\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.value</code> <code>\"bbbbbbbbbbbbbbbb\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.existingSecretKey</code> <code>\"client_secret\"</code> <code>deploykf_core.deploykf_auth.dex.clients.minioConsole.clientSecret.generateSecret</code> <code>false</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientId</code> <code>\"argo-server\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.value</code> <code>\"bbbbbbbbbbbbbbbb\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.existingSecretKey</code> <code>\"client_secret\"</code> <code>deploykf_core.deploykf_auth.dex.clients.argoServer.clientSecret.generateSecret</code> <code>false</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.name</code> <code>\"_deploykf_token\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.expire</code> <code>\"168h\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.refresh</code> <code>\"60m\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.value</code> <code>\"cccccccccccccccc\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.existingSecret</code> <code>\"\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.existingSecretKey</code> <code>\"cookie_secret\"</code> <code>deploykf_core.deploykf_auth.oauth2Proxy.cookie.secret.generateSecret</code> <code>false</code>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_profiles_generator","title":"<code>deploykf_core.deploykf_profiles_generator</code>","text":"Value Default <code>deploykf_core.deploykf_profiles_generator.enabled</code> <code>true</code> <code>deploykf_core.deploykf_profiles_generator.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.profileNamePrefix</code> <code>\"\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.ownerEmail</code> <code>\"admin@example.com\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.memberAccess.role</code> <code>\"view\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.memberAccess.notebooksAccess</code> <code>false</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.plugins</code> <code>[]</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecret</code> <code>\"kubeflow-pipelines--profile-object-store-auth--{profile_name}\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecretNamespace</code> <code>\"\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecretAccessKeyKey</code> <code>\"access_key\"</code> <code>deploykf_core.deploykf_profiles_generator.profileDefaults.tools.kubeflowPipelines.objectStoreAuth.existingSecretSecretKeyKey</code> <code>\"secret_key\"</code> <code>deploykf_core.deploykf_profiles_generator.users</code> <code>[{\"id\": \"user-1\", \"email\": \"user1@example.com\"}, {\"id\": \"user-2\", \"email\": \"user2@example.com\"}]</code> <code>deploykf_core.deploykf_profiles_generator.groups</code> <code>[{\"id\": \"team-1\", \"users\": [\"user-1\", \"user-2\"]}]</code> <code>deploykf_core.deploykf_profiles_generator.profiles</code> <code>[{\"name\": \"team-1\", \"members\": [{\"group\": \"team-1\", \"access\": {\"role\": \"edit\", \"notebooksAccess\": true}}]}, {\"name\": \"team-1-prod\", \"members\": [{\"group\": \"team-1\", \"access\": {\"role\": \"view\", \"notebooksAccess\": false}}]}]</code>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_dashboard","title":"<code>deploykf_core.deploykf_dashboard</code>","text":"Value Default <code>deploykf_core.deploykf_dashboard.enabled</code> <code>true</code> <code>deploykf_core.deploykf_dashboard.namespace</code> <code>\"deploykf-dashboard\"</code> <code>deploykf_core.deploykf_dashboard.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_dashboard.images.dashboard.repository</code> <code>\"ghcr.io/deploykf/dashboard\"</code> <code>deploykf_core.deploykf_dashboard.images.dashboard.tag</code> <code>\"0.1.0\"</code> <code>deploykf_core.deploykf_dashboard.images.dashboard.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_dashboard.images.profileController.repository</code> <code>\"kubeflownotebookswg/profile-controller\"</code> <code>deploykf_core.deploykf_dashboard.images.profileController.tag</code> <code>\"v1.7.0\"</code> <code>deploykf_core.deploykf_dashboard.images.profileController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_dashboard.images.kfamApi.repository</code> <code>\"kubeflownotebookswg/kfam\"</code> <code>deploykf_core.deploykf_dashboard.images.kfamApi.tag</code> <code>\"v1.7.0\"</code> <code>deploykf_core.deploykf_dashboard.images.kfamApi.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_core.deploykf_dashboard.navigation.externalLinks</code> <code>[]</code> <code>deploykf_core.deploykf_dashboard.navigation.documentationItems</code> <code>[{\"text\": \"deployKF Website\", \"desc\": \"The tool that deployed your ML platform!\", \"link\": \"https://github.com/deployKF/deployKF\"}]</code>"},{"location":"reference/deploykf-values/#deploykf_coredeploykf_istio_gateway","title":"<code>deploykf_core.deploykf_istio_gateway</code>","text":"Value Default <code>deploykf_core.deploykf_istio_gateway.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.namespace</code> <code>\"deploykf-istio-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.extraManifests</code> <code>[]</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.name</code> <code>\"gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.version</code> <code>\"1.17.3\"</code> <code>deploykf_core.deploykf_istio_gateway.charts.istioGateway.repository</code> <code>\"https://istio-release.storage.googleapis.com/charts\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.name</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.hostname</code> <code>\"deploykf.example.com\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.ports.http</code> <code>80</code> <code>deploykf_core.deploykf_istio_gateway.gateway.ports.https</code> <code>443</code> <code>deploykf_core.deploykf_istio_gateway.gateway.tls.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.gateway.selectorLabels.app</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.selectorLabels.istio</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gateway.enableProxyProtocol</code> <code>false</code> <code>deploykf_core.deploykf_istio_gateway.gateway.xffNumTrustedHops</code> <code>0</code> <code>deploykf_core.deploykf_istio_gateway.gateway.emailToLowercase</code> <code>false</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.replicaCount</code> <code>1</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.serviceAccount.name</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.enabled</code> <code>true</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.minReplicas</code> <code>1</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.maxReplicas</code> <code>5</code> <code>deploykf_core.deploykf_istio_gateway.gatewayDeployment.autoscaling.targetCPUUtilizationPercentage</code> <code>80</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.name</code> <code>\"deploykf-gateway\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.type</code> <code>\"LoadBalancer\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.loadBalancerIP</code> <code>\"\"</code> <code>deploykf_core.deploykf_istio_gateway.gatewayService.loadBalancerSourceRanges</code> <code>[]</code>"},{"location":"reference/deploykf-values/#deploykf-opt","title":"deployKF Opt","text":"<p>Values for configuring optional embedded applications that are used when external alternatives are not configured.</p>"},{"location":"reference/deploykf-values/#deploykf_optdeploykf_minio","title":"<code>deploykf_opt.deploykf_minio</code>","text":"Value Default <code>deploykf_opt.deploykf_minio.enabled</code> <code>false</code> <code>deploykf_opt.deploykf_minio.namespace</code> <code>\"deploykf-minio\"</code> <code>deploykf_opt.deploykf_minio.extraManifests</code> <code>[]</code> <code>deploykf_opt.deploykf_minio.images.minio.repository</code> <code>\"docker.io/minio/minio\"</code> <code>deploykf_opt.deploykf_minio.images.minio.tag</code> <code>\"RELEASE.2023-08-04T17-40-21Z\"</code> <code>deploykf_opt.deploykf_minio.images.minio.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_minio.images.minioMc.repository</code> <code>\"docker.io/minio/mc\"</code> <code>deploykf_opt.deploykf_minio.images.minioMc.tag</code> <code>\"RELEASE.2023-08-01T23-30-57Z\"</code> <code>deploykf_opt.deploykf_minio.images.minioMc.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_minio.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_opt.deploykf_minio.images.kubectl.tag</code> <code>\"1.26.6-debian-11-r8\"</code> <code>deploykf_opt.deploykf_minio.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_minio.persistence.enabled</code> <code>true</code> <code>deploykf_opt.deploykf_minio.persistence.existingClaim</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.persistence.subPath</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.persistence.storageClass</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.persistence.accessMode</code> <code>\"ReadWriteOnce\"</code> <code>deploykf_opt.deploykf_minio.persistence.size</code> <code>\"5Gi\"</code> <code>deploykf_opt.deploykf_minio.rootUser.username</code> <code>\"minioadmin\"</code> <code>deploykf_opt.deploykf_minio.rootUser.password</code> <code>\"minioadmin\"</code> <code>deploykf_opt.deploykf_minio.rootUser.existingSecret</code> <code>\"\"</code> <code>deploykf_opt.deploykf_minio.rootUser.existingSecretUsernameKey</code> <code>\"username\"</code> <code>deploykf_opt.deploykf_minio.rootUser.existingSecretPasswordKey</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_minio.rootUser.generateSecret</code> <code>false</code> <code>deploykf_opt.deploykf_minio.rootUser.serviceAccounts</code> <code>[]</code> <code>deploykf_opt.deploykf_minio.identity.openid.policyClaim</code> <code>\"email\"</code> <code>deploykf_opt.deploykf_minio.identity.openid.scopes</code> <code>\"openid,email,groups,profile,offline_access\"</code> <code>deploykf_opt.deploykf_minio.buckets</code> <code>[]</code> <code>deploykf_opt.deploykf_minio.policies</code> <code>[]</code>"},{"location":"reference/deploykf-values/#deploykf_optdeploykf_mysql","title":"<code>deploykf_opt.deploykf_mysql</code>","text":"Value Default <code>deploykf_opt.deploykf_mysql.enabled</code> <code>false</code> <code>deploykf_opt.deploykf_mysql.namespace</code> <code>\"deploykf-mysql\"</code> <code>deploykf_opt.deploykf_mysql.extraManifests</code> <code>[]</code> <code>deploykf_opt.deploykf_mysql.images.mysql.repository</code> <code>\"docker.io/mysql\"</code> <code>deploykf_opt.deploykf_mysql.images.mysql.tag</code> <code>\"8.0.33\"</code> <code>deploykf_opt.deploykf_mysql.images.mysql.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_mysql.images.kubectl.repository</code> <code>\"docker.io/bitnami/kubectl\"</code> <code>deploykf_opt.deploykf_mysql.images.kubectl.tag</code> <code>\"1.26.6-debian-11-r8\"</code> <code>deploykf_opt.deploykf_mysql.images.kubectl.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>deploykf_opt.deploykf_mysql.persistence.enabled</code> <code>true</code> <code>deploykf_opt.deploykf_mysql.persistence.existingClaim</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.persistence.subPath</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.persistence.storageClass</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.persistence.accessMode</code> <code>\"ReadWriteOnce\"</code> <code>deploykf_opt.deploykf_mysql.persistence.size</code> <code>\"5Gi\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.password</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.existingSecret</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.existingSecretPasswordKey</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.rootUser.generateSecret</code> <code>false</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.username</code> <code>\"kubeflow\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.password</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.existingSecret</code> <code>\"\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.existingSecretUsernameKey</code> <code>\"username\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.existingSecretPasswordKey</code> <code>\"password\"</code> <code>deploykf_opt.deploykf_mysql.kubeflowUser.generateSecret</code> <code>false</code> <code>deploykf_opt.deploykf_mysql.customUsers</code> <code>[]</code> <code>deploykf_opt.deploykf_mysql.customDatabases</code> <code>[]</code> <code>deploykf_opt.deploykf_mysql.configuration</code> `\"[mysqld] disable_log_bin default_authentication_plugin=mysql_native_password \"`"},{"location":"reference/deploykf-values/#deploykf-tools","title":"deployKF Tools","text":"<p>Values for configuring MLOps tools from the deployKF ecosystem.</p>"},{"location":"reference/deploykf-values/#kubeflow-dependencies","title":"Kubeflow Dependencies","text":"<p>Values for configuring dependencies of Kubeflow's MLOps tools.</p>"},{"location":"reference/deploykf-values/#kubeflow_dependencieskubeflow_argo_workflows","title":"<code>kubeflow_dependencies.kubeflow_argo_workflows</code>","text":"Value Default <code>kubeflow_dependencies.kubeflow_argo_workflows.enabled</code> <code>false</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.namespace</code> <code>\"kubeflow-argo-workflows\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.extraManifests</code> <code>[]</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoCli.repository</code> <code>\"quay.io/argoproj/argocli\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoCli.tag</code> <code>\"v3.4.8\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoCli.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoExecutor.repository</code> <code>\"quay.io/argoproj/argoexec\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoExecutor.tag</code> <code>\"v3.3.10\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoExecutor.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoWorkflowController.repository</code> <code>\"quay.io/argoproj/workflow-controller\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoWorkflowController.tag</code> <code>\"v3.3.10\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.images.argoWorkflowController.pullPolicy</code> <code>\"IfNotPresent\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.artifactRepository.keyFormat</code> <code>\"artifacts/{{ workflow.namespace }}/{{ workflow.name }}/{{ workflow.creationTimestamp.Y }}/{{ workflow.creationTimestamp.m }}/{{ workflow.creationTimestamp.d }}/{{ pod.name }}\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.controller.serviceAccount.create</code> <code>true</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.controller.serviceAccount.name</code> <code>\"argo-workflow-controller\"</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.server.serviceAccount.create</code> <code>true</code> <code>kubeflow_dependencies.kubeflow_argo_workflows.server.serviceAccount.name</code> <code>\"argo-server\"</code>"},{"location":"reference/deploykf-values/#kubeflow-tools","title":"Kubeflow Tools","text":"<p>Values for configuring MLOps tools from the Kubeflow ecosystem.</p>"},{"location":"reference/deploykf-values/#kubeflow_toolsnotebooks","title":"<code>kubeflow_tools.notebooks</code>","text":"Value Default <code>kubeflow_tools.notebooks.enabled</code> <code>false</code> <code>kubeflow_tools.notebooks.extraManifests</code> <code>[]</code> <code>kubeflow_tools.notebooks.images.jupyterWebApp.repository</code> <code>\"docker.io/kubeflownotebookswg/jupyter-web-app\"</code> <code>kubeflow_tools.notebooks.images.jupyterWebApp.tag</code> <code>nil</code> <code>kubeflow_tools.notebooks.images.notebookController.repository</code> <code>\"docker.io/kubeflownotebookswg/notebook-controller\"</code> <code>kubeflow_tools.notebooks.images.notebookController.tag</code> <code>nil</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.allowCustomImage</code> <code>true</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.hideRegistry</code> <code>true</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.hideTag</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imagePullPolicy.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imagePullPolicy.value</code> <code>\"IfNotPresent\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.image.value</code> <code>\"kubeflownotebookswg/jupyter-scipy:v1.7.0\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.image.options</code> <code>[\"kubeflownotebookswg/jupyter-scipy:v1.7.0\", \"kubeflownotebookswg/jupyter-pytorch-full:v1.7.0\", \"kubeflownotebookswg/jupyter-pytorch-cuda-full:v1.7.0\", \"kubeflownotebookswg/jupyter-tensorflow-full:v1.7.0\", \"kubeflownotebookswg/jupyter-tensorflow-cuda-full:v1.7.0\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupOne.value</code> <code>\"kubeflownotebookswg/codeserver-python:v1.7.0\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupOne.options</code> <code>[\"kubeflownotebookswg/codeserver-python:v1.7.0\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupTwo.value</code> <code>\"kubeflownotebookswg/rstudio-tidyverse:v1.7.0\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.imageGroupTwo.options</code> <code>[\"kubeflownotebookswg/rstudio-tidyverse:v1.7.0\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu.value</code> <code>\"0.5\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.cpu.limitFactor</code> <code>\"1.2\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory.value</code> <code>\"1.0Gi\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.memory.limitFactor</code> <code>\"1.2\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.value.vendor</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.value.vendors</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.gpus.value.num</code> <code>\"none\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.mount</code> <code>\"/home/jovyan\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.metadata.name</code> <code>\"{notebook-name}-workspace\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.spec.resources.requests.storage</code> <code>\"5Gi\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.workspaceVolume.value.newPvc.spec.accessModes</code> <code>[\"ReadWriteOnce\"]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.dataVolumes.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.dataVolumes.value</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig.value</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.affinityConfig.options</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup.value</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.tolerationGroup.options</code> <code>[]</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.shm.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.shm.value</code> <code>true</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.configurations.readOnly</code> <code>false</code> <code>kubeflow_tools.notebooks.spawnerFormDefaults.configurations.value</code> <code>[]</code> <code>kubeflow_tools.notebooks.notebookTemplate</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupOne.icon</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupOne.logo</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupTwo.icon</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.spawnerIcons.imageGroupTwo.logo</code> <code>\"\"</code> <code>kubeflow_tools.notebooks.notebookCulling.enabled</code> <code>false</code> <code>kubeflow_tools.notebooks.notebookCulling.idleTime</code> <code>1440</code> <code>kubeflow_tools.notebooks.notebookCulling.idlenessCheckPeriod</code> <code>1</code>"},{"location":"reference/deploykf-values/#kubeflow_toolspipelines","title":"<code>kubeflow_tools.pipelines</code>","text":"Value Default <code>kubeflow_tools.pipelines.enabled</code> <code>false</code> <code>kubeflow_tools.pipelines.extraManifests</code> <code>[]</code> <code>kubeflow_tools.pipelines.images.kfpCacheServer.repository</code> <code>\"gcr.io/ml-pipeline/cache-server\"</code> <code>kubeflow_tools.pipelines.images.kfpCacheServer.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpMetadataEnvoy.repository</code> <code>\"gcr.io/ml-pipeline/metadata-envoy\"</code> <code>kubeflow_tools.pipelines.images.kfpMetadataEnvoy.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpMetadataWriter.repository</code> <code>\"gcr.io/ml-pipeline/metadata-writer\"</code> <code>kubeflow_tools.pipelines.images.kfpMetadataWriter.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpApiServer.repository</code> <code>\"gcr.io/ml-pipeline/api-server\"</code> <code>kubeflow_tools.pipelines.images.kfpApiServer.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpPersistenceagent.repository</code> <code>\"gcr.io/ml-pipeline/persistenceagent\"</code> <code>kubeflow_tools.pipelines.images.kfpPersistenceagent.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpScheduledworkflow.repository</code> <code>\"gcr.io/ml-pipeline/scheduledworkflow\"</code> <code>kubeflow_tools.pipelines.images.kfpScheduledworkflow.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpFrontend.repository</code> <code>\"gcr.io/ml-pipeline/frontend\"</code> <code>kubeflow_tools.pipelines.images.kfpFrontend.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpViewerCrdController.repository</code> <code>\"gcr.io/ml-pipeline/viewer-crd-controller\"</code> <code>kubeflow_tools.pipelines.images.kfpViewerCrdController.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.kfpVisualizationServer.repository</code> <code>\"gcr.io/ml-pipeline/visualization-server\"</code> <code>kubeflow_tools.pipelines.images.kfpVisualizationServer.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.images.tfxMlMetadataStoreServer.repository</code> <code>\"gcr.io/tfx-oss-public/ml_metadata_store_server\"</code> <code>kubeflow_tools.pipelines.images.tfxMlMetadataStoreServer.tag</code> <code>nil</code> <code>kubeflow_tools.pipelines.bucket.name</code> <code>\"kubeflow-pipelines\"</code> <code>kubeflow_tools.pipelines.bucket.region</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.objectStore.useExternal</code> <code>false</code> <code>kubeflow_tools.pipelines.objectStore.host</code> <code>\"s3.amazonaws.com\"</code> <code>kubeflow_tools.pipelines.objectStore.port</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.objectStore.useSSL</code> <code>true</code> <code>kubeflow_tools.pipelines.objectStore.auth.fromEnv</code> <code>false</code> <code>kubeflow_tools.pipelines.objectStore.auth.accessKey</code> <code>\"my-access-key\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.secretKey</code> <code>\"my-secret-key\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.existingSecret</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.existingSecretAccessKeyKey</code> <code>\"AWS_ACCESS_KEY_ID\"</code> <code>kubeflow_tools.pipelines.objectStore.auth.existingSecretSecretKeyKey</code> <code>\"AWS_SECRET_ACCESS_KEY\"</code> <code>kubeflow_tools.pipelines.mysql.useExternal</code> <code>false</code> <code>kubeflow_tools.pipelines.mysql.host</code> <code>\"mysql.example.com\"</code> <code>kubeflow_tools.pipelines.mysql.port</code> <code>3306</code> <code>kubeflow_tools.pipelines.mysql.auth.username</code> <code>\"kubeflow\"</code> <code>kubeflow_tools.pipelines.mysql.auth.password</code> <code>\"password\"</code> <code>kubeflow_tools.pipelines.mysql.auth.existingSecret</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.mysql.auth.existingSecretUsernameKey</code> <code>\"username\"</code> <code>kubeflow_tools.pipelines.mysql.auth.existingSecretPasswordKey</code> <code>\"password\"</code> <code>kubeflow_tools.pipelines.mysqlDatabases.cacheDatabase</code> <code>\"kfp_cache\"</code> <code>kubeflow_tools.pipelines.mysqlDatabases.metadataDatabase</code> <code>\"kfp_metadata\"</code> <code>kubeflow_tools.pipelines.mysqlDatabases.pipelinesDatabase</code> <code>\"kfp_pipelines\"</code> <code>kubeflow_tools.pipelines.kfpV2.defaultPipelineRoot</code> <code>\"minio://{bucket_name}/v2/artifacts/{profile_name}\"</code> <code>kubeflow_tools.pipelines.kfpV2.minioFix</code> <code>false</code> <code>kubeflow_tools.pipelines.kfpV2.launcherImage</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.cache.image</code> <code>\"gcr.io/google-containers/busybox:1.27\"</code> <code>kubeflow_tools.pipelines.cache.maximumMaxCacheStaleness</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.cache.defaultMaxCacheStaleness</code> <code>\"\"</code> <code>kubeflow_tools.pipelines.cache.namespaceRedirect</code> <code>true</code> <code>kubeflow_tools.pipelines.profileResourceGeneration.kfpApiTokenPodDefault</code> <code>false</code>"},{"location":"reference/deploykf-values/#kubeflow_toolstraining_operator","title":"<code>kubeflow_tools.training_operator</code>","text":"Value Default <code>kubeflow_tools.training_operator.enabled</code> <code>false</code> <code>kubeflow_tools.training_operator.extraManifests</code> <code>[]</code> <code>kubeflow_tools.training_operator.images.trainingOperator.repository</code> <code>\"docker.io/kubeflow/training-operator\"</code> <code>kubeflow_tools.training_operator.images.trainingOperator.tag</code> <code>nil</code>"},{"location":"reference/deploykf-values/#kubeflow_toolskatib","title":"<code>kubeflow_tools.katib</code>","text":"Value Default <code>kubeflow_tools.katib.enabled</code> <code>false</code> <code>kubeflow_tools.katib.extraManifests</code> <code>[]</code> <code>kubeflow_tools.katib.images.katibController.repository</code> <code>\"docker.io/kubeflowkatib/katib-controller\"</code> <code>kubeflow_tools.katib.images.katibController.tag</code> <code>nil</code> <code>kubeflow_tools.katib.images.katibDbManager.repository</code> <code>\"docker.io/kubeflowkatib/katib-db-manager\"</code> <code>kubeflow_tools.katib.images.katibDbManager.tag</code> <code>nil</code> <code>kubeflow_tools.katib.images.katibUi.repository</code> <code>\"docker.io/kubeflowkatib/katib-ui\"</code> <code>kubeflow_tools.katib.images.katibUi.tag</code> <code>nil</code> <code>kubeflow_tools.katib.mysql.useExternal</code> <code>false</code> <code>kubeflow_tools.katib.mysql.host</code> <code>\"mysql.example.com\"</code> <code>kubeflow_tools.katib.mysql.port</code> <code>3306</code> <code>kubeflow_tools.katib.mysql.auth.username</code> <code>\"kubeflow\"</code> <code>kubeflow_tools.katib.mysql.auth.password</code> <code>\"password\"</code> <code>kubeflow_tools.katib.mysql.auth.existingSecret</code> <code>\"\"</code> <code>kubeflow_tools.katib.mysql.auth.existingSecretUsernameKey</code> <code>\"username\"</code> <code>kubeflow_tools.katib.mysql.auth.existingSecretPasswordKey</code> <code>\"password\"</code> <code>kubeflow_tools.katib.mysqlDatabase</code> <code>\"katib\"</code>"},{"location":"reference/deploykf-values/#kubeflow_toolsvolumes","title":"<code>kubeflow_tools.volumes</code>","text":"Value Default <code>kubeflow_tools.volumes.enabled</code> <code>false</code> <code>kubeflow_tools.volumes.extraManifests</code> <code>[]</code> <code>kubeflow_tools.volumes.images.volumesWebApp.repository</code> <code>\"docker.io/kubeflownotebookswg/volumes-web-app\"</code> <code>kubeflow_tools.volumes.images.volumesWebApp.tag</code> <code>nil</code>"},{"location":"reference/deploykf-values/#kubeflow_toolspoddefaults_webhook","title":"<code>kubeflow_tools.poddefaults_webhook</code>","text":"Value Default <code>kubeflow_tools.poddefaults_webhook.enabled</code> <code>false</code> <code>kubeflow_tools.poddefaults_webhook.extraManifests</code> <code>[]</code> <code>kubeflow_tools.poddefaults_webhook.images.poddefaultsWebhook.repository</code> <code>\"docker.io/kubeflownotebookswg/poddefaults-webhook\"</code> <code>kubeflow_tools.poddefaults_webhook.images.poddefaultsWebhook.tag</code> <code>nil</code>"},{"location":"reference/deploykf-values/#kubeflow_toolstensorboards","title":"<code>kubeflow_tools.tensorboards</code>","text":"Value Default <code>kubeflow_tools.tensorboards.enabled</code> <code>false</code> <code>kubeflow_tools.tensorboards.extraManifests</code> <code>[]</code> <code>kubeflow_tools.tensorboards.images.tensorboardController.repository</code> <code>\"docker.io/kubeflownotebookswg/tensorboard-controller\"</code> <code>kubeflow_tools.tensorboards.images.tensorboardController.tag</code> <code>nil</code> <code>kubeflow_tools.tensorboards.images.tensorboardsWebApp.repository</code> <code>\"docker.io/kubeflownotebookswg/tensorboards-web-app\"</code> <code>kubeflow_tools.tensorboards.images.tensorboardsWebApp.tag</code> <code>nil</code> <code>kubeflow_tools.tensorboards.images.kubeRbacProxy.repository</code> <code>\"gcr.io/kubebuilder/kube-rbac-proxy\"</code> <code>kubeflow_tools.tensorboards.images.kubeRbacProxy.tag</code> <code>nil</code> <code>kubeflow_tools.tensorboards.tensorboardImage</code> <code>\"docker.io/tensorflow/tensorflow:2.5.1\"</code>"},{"location":"reference/future-tools/","title":"Future Tools","text":"<p>This page lists the ML &amp; Data tools which are planned for future versions of deployKF.</p> <p>Request or Contribute</p> <p>If you would like to request or contribute support for a tool, please raise an issue on GitHub, or join the discussion on an existing issue.</p>"},{"location":"reference/future-tools/#index","title":"Index","text":"Tool Purpose deployKF Priority MLflow Model Registry Model Registry <code>P1</code> Apache Airflow Workflow Orchestration <code>P1</code> Feast Feature Store <code>P2</code> BentoML Yatai Model Registry &amp; Serving <code>P2</code> KServe Model Serving <code>P2</code> Seldon Core Model Serving <code>P2</code> DataHub Data Catalog <code>P3</code> Airbyte Data Integration Platform <code>P3</code> Label Studio Data Labeling <code>P3</code>"},{"location":"reference/future-tools/#mlflow-model-registry","title":"MLflow Model Registry","text":""},{"location":"reference/future-tools/#tool-description","title":"Tool Description:","text":"<p>MLflow Model Registry is an open source machine learning model registry.</p> <p>A model registry decouples model training from model deployment, allowing you to break the model lifecycle down into three separate concerns.</p> <ol> <li>Model Training: Training new versions of models and logging them into the registry.</li> <li>Model Evaluation: Evaluating versions of models and logging the results into the registry.</li> <li>Model Deployment: Making informed decisions about which models to deploy and then deploying them.</li> </ol> <p>This separation enables you to have well-scoped pipelines, rather than trying to go from training to deployment all at once.</p> <p>The key features of MLflow Model Registry are:</p> <ul> <li>Model Versioning: Version your model artifacts and attach metadata to each version.</li> <li>Model Stage Transitions: Transition models between stages (e.g. staging to production).</li> <li>Web UI: A graphical web interface for managing models.</li> <li>Python API: A Python API for managing models.</li> <li>REST API: A REST API for managing models.  </li> </ul>"},{"location":"reference/future-tools/#tool-details","title":"Tool Details:","text":"Name MLflow Model Registry Owner Databricks Purpose Model Registry deployKF Priority <code>P1</code> Upstream Repo <code>mlflow/mlflow</code> Upstream Docs Documentation"},{"location":"reference/future-tools/#apache-airflow","title":"Apache Airflow","text":""},{"location":"reference/future-tools/#tool-description_1","title":"Tool Description:","text":"<p>Apache Airflow is by far the most popular open-source workflow orchestration tool in the world.</p> <p>The versatility and extensibility of Apache Airflow make it a great fit for many different use cases, including machine learning.</p> <p>The key features of Apache Airflow are:      </p> <ul> <li>Python Centered: Airflow is written in Python and uses a Python DSL to define workflows.</li> <li>Dynamic Workflows: Airflow's code-driven workflow definitions enable powerful patterns like dynamically generating workflows.</li> <li>Extensive Plugins: Airflow has a rich ecosystem of plugins and integrations with other tools.</li> <li>User Interface: Airflow is known for its powerful user interface which allows users to monitor and manage workflows.</li> </ul>"},{"location":"reference/future-tools/#tool-details_1","title":"Tool Details:","text":"Name Apache Airflow Owner Apache Software Foundation Purpose Workflow Orchestration deployKF Priority <code>P1</code> Upstream Repo <code>apache/airflow</code> Upstream Docs Documentation"},{"location":"reference/future-tools/#feast","title":"Feast","text":""},{"location":"reference/future-tools/#tool-description_2","title":"Tool Description:","text":"<p>Feast is an open-source feature store for machine learning.</p> <p>A good way to understand the purpose of a feature store is to think about the data access patterns encountered during the model lifecycle.</p> <ul> <li>Feature Engineering: Accesses and transforms historical data to create features.</li> <li>Target Engineering: Accesses and transforms historical data to create targets.</li> <li>Model Training: Accesses features and targets to train and evaluate the model.</li> <li>Model Inference: Accesses features of new data to predict the target.</li> </ul> <p>A feature store should somehow make these data access patterns easier.</p> <p>The key features of Feast are:</p> <ul> <li>Feature Registry: Where Feast persists feature definitions (not data) that are registered with with it (e.g. Local-Files, S3, GCS).</li> <li>Python SDK: The primary interface for managing feature definitions, and retrieving feature values from Feast.</li> <li>Offline Data Stores: A store which Feast can read feature values from, for historical data retrieval (e.g. Snowflake, BigQuery, Redshift).</li> <li>Online Data Stores: A store which Feast can materialize (write) feature values into, for online model inference (e.g. Snowflake, Redis, DynamoDB, Bigtable).</li> <li>Batch Materialization Engine: A data processing engine which Feast can use to materialize feature values from an Offline Store into an Online Store (e.g. Snowflake, Spark, Bytewax).</li> </ul> <p>Tip</p> <p>A good feature store is NOT a database, but rather a data access layer between your data sources and your ML models. Be very wary of feature stores that require you to load your data into them.</p>"},{"location":"reference/future-tools/#tool-details_2","title":"Tool Details:","text":"Name Feast Owner Tecton Purpose Feature Store deployKF Priority <code>P2</code> Upstream Repo <code>feast-dev/feast</code> Upstream Docs Documentation"},{"location":"reference/future-tools/#bentoml-yatai","title":"BentoML Yatai","text":""},{"location":"reference/future-tools/#tool-description_3","title":"Tool Description:","text":"<p>BentoML Yatai is a platform for managing the lifecycle of BentoML models on Kubernetes.</p> <p>The core features of BentoML Yatai are:</p> <ul> <li>Model Registry: A central registry for packaged Bentos.</li> <li>Model Deployment: Managing the deployment of BentoML models to Kubernetes, including building model container images.</li> <li>Web UI: A graphical web interface for viewing, deploying, and monitoring models.</li> <li>REST APIs: A REST API for viewing, deploying, and monitoring models.</li> <li>Kubernetes CRDs: Manage the deployment of models in a DevOps-friendly way.</li> </ul>"},{"location":"reference/future-tools/#tool-details_3","title":"Tool Details:","text":"Name BentoML Yatai Owner BentoML Purpose Model Registry &amp; Serving deployKF Priority <code>P2</code> Upstream Repo <code>bentoml/Yatai</code> Upstream Docs Documentation"},{"location":"reference/future-tools/#kserve","title":"KServe","text":""},{"location":"reference/future-tools/#tool-description_4","title":"Tool Description:","text":"<p>KServe provides comprehensive interfaces for deploying, managing, and monitoring ML models on Kubernetes.</p> <p>The core features of KServe are:</p> <ul> <li>Support for Many Frameworks: KServe natively supports many ML frameworks (e.g. PyTorch, TensorFlow, scikit-learn, XGBoost).</li> <li>Autoscaling, Even to Zero: KServe can autoscale model replicas to meet demand, even scaling to zero when there are no requests.</li> <li>Model Monitoring: KServe integrates tools like Alibi Detect to provide model monitoring for drift and outlier detection.</li> <li>Model Explainability: KServe integrates tools like Alibi Explain to provide model explainability.</li> <li>Request Batching: KServe can batch requests to your model, improving throughput and reducing cost.</li> <li>Canary Deployments: KServe can deploy new versions of your model alongside old versions, and route requests to the new version based on a percentage.</li> <li>Feature Transformers: KServe can do feature pre/post processing alongside model inference (e.g. using Feast).</li> <li>Inference Graphs: KServe can chain multiple models together to form an inference graph.</li> </ul>"},{"location":"reference/future-tools/#tool-details_4","title":"Tool Details:","text":"Name KServe Owner LF AI &amp; Data Purpose Model Serving deployKF Priority <code>P2</code> Upstream Repo <code>kserve/kserve</code> Upstream Docs Documentation"},{"location":"reference/future-tools/#seldon-core","title":"Seldon Core","text":""},{"location":"reference/future-tools/#tool-description_5","title":"Tool Description:","text":"<p>Seldon Core provides interfaces for converting ML models into REST/gRPC microservices on Kubernetes.</p> <p>The core features of Seldon Core are:</p> <ul> <li>Support for Many Frameworks: Seldon Core natively supports many ML frameworks (e.g. TensorFlow, scikit-learn, XGBoost, HuggingFace, NVIDIA Triton).</li> <li>Reusable Model Servers: Seldon Core removes the need to build a container image for each model, by providing a system to download model artifacts at runtime.</li> <li>Model Deployment CRD Seldon Core provides a simple, yet powerful, Kubernetes CRD for deploying models.</li> </ul>"},{"location":"reference/future-tools/#tool-details_5","title":"Tool Details:","text":"Name Seldon Core Owner Seldon Purpose Model Serving deployKF Priority <code>P2</code> Upstream Repo <code>SeldonIO/seldon-core</code> Upstream Docs Documentation"},{"location":"reference/future-tools/#datahub","title":"DataHub","text":""},{"location":"reference/future-tools/#tool-description_6","title":"Tool Description:","text":"<p>DataHub is an open-source metadata platform for discovering, managing, and understanding data.</p> <p>The core features of DataHub are:</p> <ul> <li>Support for Many Data Sources: DataHub supports ingestion of metadata from many sources.</li> <li>Search &amp; Discovery: DataHub provides a search interface for discovering data.</li> <li>Data Lineage: DataHub can capture and visualize complex data lineage.</li> </ul>"},{"location":"reference/future-tools/#tool-details_6","title":"Tool Details:","text":"Name DataHub Owner Acryl Data Purpose Data Catalog deployKF Priority <code>P3</code> Upstream Repo <code>datahub-project/datahub</code> Upstream Docs Documentation"},{"location":"reference/future-tools/#airbyte","title":"Airbyte","text":""},{"location":"reference/future-tools/#tool-description_7","title":"Tool Description:","text":"<p>Airbyte is a data integration platform which aims to make it easy to move data from any source to any destination.</p> <p>The core features of Airbyte are:</p> <ul> <li>Comprehensive Connector Catalog: Airbyte has an extremely large catalog of connectors for data sources and destinations.</li> <li>Airbyte Web UI: Airbyte provides a graphical web interface for managing data connectors and orchestrating data syncs.</li> </ul>"},{"location":"reference/future-tools/#tool-details_7","title":"Tool Details:","text":"Name Airbyte Owner Airbyte Purpose Data Integration Platform deployKF Priority <code>P3</code> Upstream Repo <code>airbytehq/airbyte</code> Upstream Docs Documentation"},{"location":"reference/future-tools/#label-studio","title":"Label Studio","text":""},{"location":"reference/future-tools/#tool-description_8","title":"Tool Description:","text":"<p>Label Studio is an open-source data labeling platform which supports a variety of data types and labeling tasks.</p> <p>The core features of Label Studio are:</p> <ul> <li>Data Types: Label Studio supports a variety of data types, including text, images, audio, video, and time series.</li> <li>Task Templates: Label Studio provides many templates for common labeling tasks, including text classification, named entity recognition, and object detection.</li> <li>Label Studio Web UI: Label Studio provides a graphical web interface for labeling data and managing labeling projects.</li> </ul>"},{"location":"reference/future-tools/#tool-details_8","title":"Tool Details:","text":"Name Label Studio Owner Heartex Purpose Data Labeling deployKF Priority <code>P3</code> Upstream Repo <code>heartexlabs/label-studio</code> Upstream Docs Documentation"},{"location":"reference/tools/","title":"Supported Tools","text":"<p>This page lists the ML &amp; Data tools which are currently supported by deployKF.</p> <p>Build Your Platform</p> <p>You don't need to install all of the tools listed here, deployKF makes it easy to build your own platform by selecting only the tools you need, just toggle the tool's <code>enabled</code> value.</p> <p>Tool Versions</p> <p>For information about which versions of each tool are supported by deployKF, refer to the Version Matrix page.</p> <p>deployKF is always growing, for a list of tools that are coming soon, see the Future Tools page.</p>"},{"location":"reference/tools/#index","title":"Index","text":"Tool Purpose deployKF Version Kubeflow Pipelines Workflow Orchestration <code>&gt;= 0.1.0</code> Kubeflow Notebooks Development Environments <code>&gt;= 0.1.0</code> Katib Automated Machine Learning <code>&gt;= 0.1.0</code> Kubeflow Training Operator Training Models on Kubernetes <code>&gt;= 0.1.0</code> Kubeflow Volumes Managing Kubernetes Volumes <code>&gt;= 0.1.0</code> Kubeflow TensorBoards Managing TensorBoards <code>&gt;= 0.1.0</code>"},{"location":"reference/tools/#kubeflow-pipelines","title":"Kubeflow Pipelines","text":""},{"location":"reference/tools/#tool-description","title":"Tool Description:","text":"<p>Kubeflow Pipelines (KFP) is a platform for building and running machine learning workflows on Kubernetes.      </p> <p>KFP provides higher-level abstractions for Argo Workflows to reduce repetition when defining machine learning tasks.  KFP has abstractions for defining pipelines and reusable components which it can compile and execute as Argo <code>Workflows</code>.</p> <p>The primary interface of KFP is the Python SDK, which allows you to define pipelines and reusable components with Python. KFP also provides a Web UI for managing and tracking experiments, pipeline definitions, and pipeline runs. Finally, KFP provides a REST API that allows programmatic access to the platform.</p>"},{"location":"reference/tools/#tool-details","title":"Tool Details:","text":"Name Kubeflow Pipelines Owner Kubeflow Project Purpose Workflow Orchestration deployKF Version <code>&gt;= 0.1.0</code> deployKF Values <code>kubeflow_tools.pipelines</code> Upstream Repo <code>kubeflow/pipelines</code> Upstream Docs Documentation"},{"location":"reference/tools/#kubeflow-notebooks","title":"Kubeflow Notebooks","text":""},{"location":"reference/tools/#tool-description_1","title":"Tool Description:","text":"<p>Kubeflow Notebooks lets you run web-based development environments inside a Kubernetes cluster.</p> <p>Kubeflow Notebooks can run any web-based tool, but comes with pre-built images for JupyterLab, RStudio, and Visual Studio Code.</p> <p>Running development environments inside a Kubernetes cluster has several advantages:</p> <ul> <li>Remote Resources: Users can work directly on the cluster, rather than locally on their workstations.</li> <li>Standard Environments: Cluster admins can provide standard environment images for their organization, with required and approved packages pre-installed.</li> <li>Sharing &amp; Access control: Access is managed via role-based-access-control (RBAC), enabling easier notebook sharing and collaboration across the organization.</li> </ul>"},{"location":"reference/tools/#tool-details_1","title":"Tool Details:","text":"Name Kubeflow Notebooks Owner Kubeflow Project Purpose Development Environments deployKF Version <code>&gt;= 0.1.0</code> deployKF Values <code>kubeflow_tools.notebooks</code> Upstream Repo <code>kubeflow/kubeflow</code> Upstream Docs Documentation"},{"location":"reference/tools/#katib","title":"Katib","text":""},{"location":"reference/tools/#tool-description_2","title":"Tool Description:","text":"<p>Katib is an Automated Machine Learning (AutoML) platform for Kubernetes.</p> <p>The key features of Katib are:</p> <ul> <li>Support for Multiple Techniques: Katib supports techniques like Hyperparameter Tuning, Early Stopping, and Neural Architecture Search.</li> <li>Support for ML Frameworks: Katib natively supports many ML frameworks like TensorFlow, PyTorch, XGBoost, and more.</li> <li>Kubernetes Native: Katib can manage training jobs on any Kubernetes Resource, and has out-of-the-box support for Kubeflow Training Operator, Argo Workflows, Tekton Pipelines, and more.</li> </ul>"},{"location":"reference/tools/#tool-details_2","title":"Tool Details:","text":"Name Katib Owner Kubeflow Project Purpose Automated Machine Learning deployKF Version <code>&gt;= 0.1.0</code> deployKF Values <code>kubeflow_tools.katib</code> Upstream Repo <code>kubeflow/katib</code> Upstream Docs Documentation"},{"location":"reference/tools/#kubeflow-training-operator","title":"Kubeflow Training Operator","text":""},{"location":"reference/tools/#tool-description_3","title":"Tool Description:","text":"<p>Kubeflow Training Operator helps you run machine learning training jobs on Kubernetes.</p> <p>It provides Kubernetes Custom Resources (CRDs) to define and monitor training jobs on Kubernetes. Some popular ML frameworks that are supported include PyTorch, TensorFlow, XGBoost, and MPI.</p>"},{"location":"reference/tools/#tool-details_3","title":"Tool Details:","text":"Name Kubeflow Training Operator Owner Kubeflow Project Purpose Training Models on Kubernetes deployKF Version <code>&gt;= 0.1.0</code> deployKF Values <code>kubeflow_tools.training_operator</code> Upstream Repo <code>kubeflow/training-operator</code> Upstream Docs Documentation"},{"location":"reference/tools/#kubeflow-volumes","title":"Kubeflow Volumes","text":""},{"location":"reference/tools/#tool-description_4","title":"Tool Description:","text":"<p>Kubeflow Volumes is a web-based UI for creating and managing Kubernetes Persistent Volumes.</p>"},{"location":"reference/tools/#tool-details_4","title":"Tool Details:","text":"Name Kubeflow Volumes Owner Kubeflow Project Purpose Managing Kubernetes Volumes deployKF Version <code>&gt;= 0.1.0</code> deployKF Values <code>kubeflow_tools.volumes</code> Upstream Repo <code>kubeflow/kubeflow</code> Upstream Docs N/A"},{"location":"reference/tools/#kubeflow-tensorboards","title":"Kubeflow TensorBoards","text":""},{"location":"reference/tools/#tool-description_5","title":"Tool Description:","text":"<p>Kubeflow TensorBoards is a web-based UI for creating and managing TensorBoard instances on Kubernetes.</p>"},{"location":"reference/tools/#tool-details_5","title":"Tool Details:","text":"Name Kubeflow TensorBoards Owner Kubeflow Project Purpose Managing TensorBoards deployKF Version <code>&gt;= 0.1.0</code> deployKF Values <code>kubeflow_tools.tensorboards</code> Upstream Repo <code>kubeflow/kubeflow</code> Upstream Docs N/A"},{"location":"releases/changelog-deploykf-cli/","title":"Changelog for deployKF CLI","text":"<p>This changelog lists releases of the deployKF CLI that are found in the <code>deployKF/cli</code> repository.</p> <p>Pre-releases</p> <p>For a changelog that shows pre-releases, see the full-changelog page.</p>"},{"location":"releases/changelog-deploykf-cli/#012-2023-08-09","title":"0.1.2 - 2023-08-09","text":""},{"location":"releases/changelog-deploykf-cli/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>fix: nil pointer on download error by @thesuperzapper in #12</li> </ul>"},{"location":"releases/changelog-deploykf-cli/#011-2023-08-07","title":"0.1.1 - 2023-08-07","text":""},{"location":"releases/changelog-deploykf-cli/#new-features","title":"New Features","text":"<ul> <li>feat: publish container image for cli by @thesuperzapper in #11</li> </ul>"},{"location":"releases/changelog-deploykf-cli/#010-2023-07-09","title":"0.1.0 - 2023-07-09","text":""},{"location":"releases/changelog-deploykf-cli/#significant-changes","title":"Significant Changes","text":"<ul> <li>initial release \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 </li> </ul>"},{"location":"releases/changelog-deploykf/","title":"Changelog for deployKF","text":"<p>This changelog lists releases of deployKF that are found in the <code>deployKF/deployKF</code> repository.</p> <p>Pre-releases</p> <p>For a changelog that shows pre-releases, see the full-changelog page.</p>"},{"location":"releases/changelog-deploykf/#011-2023-08-08","title":"0.1.1 - 2023-08-08","text":""},{"location":"releases/changelog-deploykf/#significant-changes","title":"Significant Changes","text":"<ul> <li>feat: create argocd plugin by @thesuperzapper in #16</li> </ul>"},{"location":"releases/changelog-deploykf/#new-features","title":"New Features","text":"<ul> <li>feat: allow custom documentation links in dashboard by @yankcrime in #12</li> <li>feat: allow a single ArgoCD to manage deployKF across multiple clusters by @thesuperzapper in #17</li> </ul>"},{"location":"releases/changelog-deploykf/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>fix: set <code>securityContext.fsGroup</code> on minio pods by @thesuperzapper in #14</li> <li>fix: minio-console user permissions (update minio) by @thesuperzapper in #18</li> </ul>"},{"location":"releases/changelog-deploykf/#documentation","title":"Documentation","text":"<ul> <li>docs: improve getting started formatting by @thesuperzapper in #8</li> <li>docs: add links to important values in readme by @thesuperzapper in #9</li> <li>docs: improve getting started guide by @thesuperzapper in #11</li> <li>docs: add link to youtube demo by @thesuperzapper in #13</li> </ul>"},{"location":"releases/changelog-deploykf/#010-2023-07-10","title":"0.1.0 - 2023-07-10","text":""},{"location":"releases/changelog-deploykf/#significant-changes_1","title":"Significant Changes","text":"<ul> <li>initial release \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 </li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/","title":"FULL Changelog for deployKF CLI","text":"<p>This changelog lists ALL releases of the deployKF CLI (including pre-releases) that are found in the <code>deployKF/cli</code> repository.</p> <p>Main Changelog</p> <p>For a changelog that hides pre-releases, see the main changelog page.</p>"},{"location":"releases/full-changelog-deploykf-cli/#012-2023-08-09","title":"0.1.2 - 2023-08-09","text":""},{"location":"releases/full-changelog-deploykf-cli/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>fix: nil pointer on download error by @thesuperzapper in #12</li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#011-2023-08-07","title":"0.1.1 - 2023-08-07","text":""},{"location":"releases/full-changelog-deploykf-cli/#new-features","title":"New Features","text":"<ul> <li>feat: publish container image for cli by @thesuperzapper in #11</li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#010-2023-07-09","title":"0.1.0 - 2023-07-09","text":""},{"location":"releases/full-changelog-deploykf-cli/#significant-changes","title":"Significant Changes","text":"<ul> <li>initial release \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 </li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#010-alpha3-2023-05-23","title":"0.1.0-alpha.3 - 2023-05-23","text":""},{"location":"releases/full-changelog-deploykf-cli/#new-features_1","title":"New Features","text":"<ul> <li>feat: write runtime templates &amp; other fixes by @thesuperzapper in #7</li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#010-alpha2-2023-04-28","title":"0.1.0-alpha.2 - 2023-04-28","text":""},{"location":"releases/full-changelog-deploykf-cli/#new-features_2","title":"New Features","text":"<ul> <li>feat: dont use \"v\" prefix for --source-version by @thesuperzapper in #4</li> <li>feat: check generator schema version by @thesuperzapper in #6</li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>fix: precedence of --values by @thesuperzapper in #5</li> </ul>"},{"location":"releases/full-changelog-deploykf-cli/#010-alpha1-2023-04-09","title":"0.1.0-alpha.1 - 2023-04-09","text":""},{"location":"releases/full-changelog-deploykf-cli/#010-alpha0-2023-04-09","title":"0.1.0-alpha.0 - 2023-04-09","text":""},{"location":"releases/full-changelog-deploykf/","title":"FULL Changelog for deployKF","text":"<p>This changelog lists ALL releases of deployKF (including pre-releases) that are found in the <code>deployKF/deployKF</code> repository.</p> <p>Main Changelog</p> <p>For a changelog that hides pre-releases, see the main changelog page.</p>"},{"location":"releases/full-changelog-deploykf/#011-2023-08-08","title":"0.1.1 - 2023-08-08","text":""},{"location":"releases/full-changelog-deploykf/#significant-changes","title":"Significant Changes","text":"<ul> <li>feat: create argocd plugin by @thesuperzapper in #16</li> </ul>"},{"location":"releases/full-changelog-deploykf/#new-features","title":"New Features","text":"<ul> <li>feat: allow custom documentation links in dashboard by @yankcrime in #12</li> <li>feat: allow a single ArgoCD to manage deployKF across multiple clusters by @thesuperzapper in #17</li> </ul>"},{"location":"releases/full-changelog-deploykf/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>fix: set <code>securityContext.fsGroup</code> on minio pods by @thesuperzapper in #14</li> <li>fix: minio-console user permissions (update minio) by @thesuperzapper in #18</li> </ul>"},{"location":"releases/full-changelog-deploykf/#documentation","title":"Documentation","text":"<ul> <li>docs: improve getting started formatting by @thesuperzapper in #8</li> <li>docs: add links to important values in readme by @thesuperzapper in #9</li> <li>docs: improve getting started guide by @thesuperzapper in #11</li> <li>docs: add link to youtube demo by @thesuperzapper in #13</li> </ul>"},{"location":"releases/full-changelog-deploykf/#010-2023-07-10","title":"0.1.0 - 2023-07-10","text":""},{"location":"releases/full-changelog-deploykf/#significant-changes_1","title":"Significant Changes","text":"<ul> <li>initial release \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 </li> </ul>"},{"location":"releases/version-matrix/","title":"Version Matrix","text":"<p>The following tables summarize which tools and versions are supported by each version of deployKF.</p> <p>Tool Versions</p> <p>The version wrapped with <code>()</code> is the default version included with that version of deployKF.</p> <p>Versions that are <code>struck through</code> do not work with that version of deployKF.</p>"},{"location":"releases/version-matrix/#deploykf-dependencies","title":"deployKF Dependencies","text":"<p>Dependencies of deployKF.</p> deployKF <code>0.1</code> Kubernetes <code>1.22</code>, <code>1.23</code>, <code>1.24</code>, <code>1.25</code>, <code>1.26</code> Argo CD <code>2.3+</code> Istio <code>1.14</code>, <code>1.15</code>, <code>1.16</code>, (<code>1.17</code>) cert-manager (<code>1.12</code>) Kyverno <code>1.9</code>, (<code>1.10</code>)"},{"location":"releases/version-matrix/#deploykf-core","title":"deployKF Core","text":"<p>Core components of deployKF like <code>deploykf-auth</code> and <code>deploykf-dashboard</code>.</p> deployKF <code>0.1</code> Dex<sub><code>deploykf-auth</code></sub> (<code>2.37</code>) OAuth2 Proxy<sub><code>deploykf-auth</code></sub> (<code>7.4</code>) deployKF Dashboard<sub><code>deploykf-dashboard</code></sub> (<code>0.1</code>) KF: Access Management API<sub><code>deploykf-dashboard</code></sub> (<code>1.7</code>) KF: Profile Controller<sub><code>deploykf-dashboard</code></sub> (<code>1.7</code>)"},{"location":"releases/version-matrix/#deploykf-opt","title":"deployKF Opt","text":"<p>Optional embedded applications that are used when external alternatives are not configured.</p> deployKF <code>0.1</code> MinIO<sub><code>Argo Workflows</code><code>Kubeflow Pipelines</code></sub> (<code>2023-08-04T17-40-21Z</code>) MySQL<sub><code>Kubeflow Pipelines</code><code>Katib</code></sub> (<code>8.0</code>)"},{"location":"releases/version-matrix/#deploykf-tools","title":"deployKF Tools","text":"<p>MLOps tools from the deployKF ecosystem.</p> <p>Tip</p> <p>For detailed descriptions about the purpose of each tool, see the Supported Tools page.</p> deployKF <code>0.1</code> . ."},{"location":"releases/version-matrix/#kubeflow-dependencies","title":"Kubeflow Dependencies","text":"<p>Dependencies of Kubeflow's MLOps tools.</p> deployKF <code>0.1</code> Argo Workflows<sub><code>Kubeflow Pipelines</code></sub> (<code>3.3</code>), <code>3.4</code><sup>[1]</sup> <sup>[2]</sup>"},{"location":"releases/version-matrix/#kubeflow-tools","title":"Kubeflow Tools","text":"<p>MLOps tools from the Kubeflow ecosystem.</p> <p>Tip</p> <p>For detailed descriptions about the purpose of each tool, see the Supported Tools page.</p> deployKF <code>0.1</code> Kubeflow Pipelines (<code>2.0.0-alpha.7</code>) Kubeflow Notebooks: Web App (<code>1.7</code>) Kubeflow Notebooks: Controller (<code>1.7</code>) Volumes: Web App (<code>1.7</code>) Katib (<code>0.15.0</code>) Kubeflow Training Operator (<code>1.6.0</code>) PodDefaults Webhook (<code>1.7</code>) TensorBoards: Web App (<code>1.7</code>) TensorBoards: Controller (<code>1.7</code>)"},{"location":"user-guides/access-kubeflow-pipelines-api/","title":"Access Kubeflow Pipelines API","text":"<p>This guide explains how to access the Kubeflow Pipelines API using the Kubeflow Pipelines Python SDK and authenticate with deployKF.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#overview","title":"Overview","text":"<p>As described in the User Authentication Admin Guide, deployKF uses Dex and Oauth2 Proxy for user authentication.</p> <p>To use the Kubeflow Pipelines Python SDK, you will need to authenticate with Dex to obtain an Oauth2 Proxy session cookie, and then use that cookie to access the Kubeflow Pipelines API.</p> <p>Depending on where you are running the Kubeflow Pipelines Python SDK, different authentication methods are available.</p> Authentication Method In Cluster Outside Cluster Dex Credentials Kubernetes Service Account Token"},{"location":"user-guides/access-kubeflow-pipelines-api/#authenticate-with-dex-credentials","title":"Authenticate with Dex Credentials","text":"<p>To authenticate the Kubeflow Pipelines Python SDK with Dex credentials, you may use the following Python code.</p> <p>First, we define a <code>KFPClientManager()</code> class that creates authenticated <code>kfp.Client()</code> instances when <code>create_kfp_client()</code> is called:</p> <pre><code>import re\nfrom urllib.parse import urlsplit\n\nimport kfp\nimport requests\nimport urllib3\n\n\nclass KFPClientManager:\n\"\"\"\n    A class that creates `kfp.Client` instances with Dex authentication.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_url: str,\n        dex_username: str,\n        dex_password: str,\n        dex_auth_type: str = \"local\",\n        skip_tls_verify: bool = False,\n    ):\n\"\"\"\n        Initialize the KfpClient\n\n        :param api_url: the Kubeflow Pipelines API URL\n        :param skip_tls_verify: if True, skip TLS verification\n        :param dex_username: the Dex username\n        :param dex_password: the Dex password\n        :param dex_auth_type: the auth type to use if Dex has multiple enabled, one of: ['ldap', 'local']\n        \"\"\"\n        self._api_url = api_url\n        self._skip_tls_verify = skip_tls_verify\n        self._dex_username = dex_username\n        self._dex_password = dex_password\n        self._dex_auth_type = dex_auth_type\n        self._client = None\n\n        # ensure `dex_default_auth_type` is valid\n        if self._dex_auth_type not in [\"ldap\", \"local\"]:\n            raise ValueError(\n                f\"Invalid `dex_auth_type` '{self._dex_auth_type}', must be one of: ['ldap', 'local']\"\n            )\n\n    def _get_session_cookies(self) -&gt; str:\n\"\"\"\n        Get the session cookies by authenticating against Dex\n        :return: a string of session cookies in the form \"key1=value1; key2=value2\"\n        \"\"\"\n\n        # use a persistent session (for cookies)\n        s = requests.Session()\n\n        # disable SSL verification, if requested\n        if self._skip_tls_verify:\n            s.verify = False\n            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\n        # GET the api_url, which should redirect to Dex\n        resp = s.get(self._api_url, allow_redirects=True)\n        if resp.status_code != 200:\n            raise RuntimeError(\n                f\"HTTP status code '{resp.status_code}' for GET against: {self._api_url}\"\n            )\n\n        # if we were NOT redirected, then the endpoint is unsecured\n        if len(resp.history) == 0:\n            # no cookies are needed\n            return \"\"\n\n        # if we are at `/auth?=xxxx` path, we need to select an auth type\n        url_obj = urlsplit(resp.url)\n        if re.search(r\"/auth$\", url_obj.path):\n            url_obj = url_obj._replace(\n                path=re.sub(r\"/auth$\", f\"/auth/{self._dex_auth_type}\", url_obj.path)\n            )\n\n        # if we are at `/auth/xxxx/login` path, then we are at the login page\n        if re.search(r\"/auth/.*/login$\", url_obj.path):\n            dex_login_url = url_obj.geturl()\n        else:\n            # otherwise, we need to follow a redirect to the login page\n            resp = s.get(url_obj.geturl(), allow_redirects=True)\n            if resp.status_code != 200:\n                raise RuntimeError(\n                    f\"HTTP status code '{resp.status_code}' for GET against: {url_obj.geturl()}\"\n                )\n            dex_login_url = resp.url\n\n        # attempt Dex login\n        resp = s.post(\n            dex_login_url,\n            data={\"login\": self._dex_username, \"password\": self._dex_password},\n            allow_redirects=True,\n        )\n        if resp.status_code != 200:\n            raise RuntimeError(\n                f\"HTTP status code '{resp.status_code}' for POST against: {dex_login_url}\"\n            )\n\n        # if we were NOT redirected, then the login credentials were probably invalid\n        if len(resp.history) == 0:\n            raise RuntimeError(\n                f\"Login credentials are probably invalid - \"\n                f\"No redirect after POST to: {dex_login_url}\"\n            )\n\n        return \"; \".join([f\"{c.name}={c.value}\" for c in s.cookies])\n\n    def _create_kfp_client(self) -&gt; kfp.Client:\n        try:\n            session_cookies = self._get_session_cookies()\n        except Exception as ex:\n            raise RuntimeError(f\"Failed to get Dex session cookies\") from ex\n\n        # monkey patch the kfp.Client to support disabling SSL verification\n        # kfp only added support in v2: https://github.com/kubeflow/pipelines/pull/7174\n        original_load_config = kfp.Client._load_config\n\n        def patched_load_config(client_self, *args, **kwargs):\n            config = original_load_config(client_self, *args, **kwargs)\n            config.verify_ssl = not self._skip_tls_verify\n            return config\n\n        patched_kfp_client = kfp.Client\n        patched_kfp_client._load_config = patched_load_config\n\n        return patched_kfp_client(\n            host=self._api_url,\n            cookies=session_cookies,\n        )\n\n    def create_kfp_client(self) -&gt; kfp.Client:\n\"\"\"Get a newly authenticated Kubeflow Pipelines client.\"\"\"\n        return self._create_kfp_client()\n</code></pre> <p>Next, we use the <code>KFPClientManager()</code> class to create an authenticated <code>kfp.Client()</code>:</p> <pre><code># initialize a KFPClientManager\nkfp_client_manager = KFPClientManager(\n    api_url=\"https://deploykf.example.com/pipeline\",\n\n    dex_username=\"user-1@example.com\",\n    dex_password=\"user-1\",\n    dex_auth_type=\"local\",\n\n    skip_tls_verify=True,\n)\n\n# get a newly authenticated KFP client\n# TIP: long-lived sessions might need to get a new client when their session expires\nkfp_client = kfp_client_manager.create_kfp_client()\n\n# test the client by listing experiments\nkfp_client.list_experiments(namespace=\"my-profile-namespace\")\n</code></pre> <p>Static and LDAP Credentials Only</p> <p>The <code>KFPClientManager()</code> class ONLY supports authentication with Static or LDAP credentials. Due to the nature of other authentication methods, it is not likely that they could be supported by this class in the future.</p>"},{"location":"user-guides/access-kubeflow-pipelines-api/#authenticate-with-kubernetes-serviceaccount-token","title":"Authenticate with Kubernetes ServiceAccount Token","text":"<p>When running the Pipelines SDK inside a Pod on the cluster, a ServiceAccount token volume  can be mounted to the Pod, the Kubeflow Pipelines SDK can use this token to authenticate itself with the Kubeflow Pipelines API.</p> <p>The following Pod demonstrates mounting a ServiceAccount token volume:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: access-kfp-example\nspec:\ncontainers:\n- image: hello-world:latest\nname: hello-world\nenv:\n- name: KF_PIPELINES_SA_TOKEN_PATH\nvalue: /var/run/secrets/kubeflow/pipelines/token\nvolumeMounts:\n- mountPath: /var/run/secrets/kubeflow/pipelines\nname: volume-kf-pipeline-token\nreadOnly: true\nvolumes:\n- name: volume-kf-pipeline-token\nprojected:\nsources:\n- serviceAccountToken:\npath: token\nexpirationSeconds: 7200\naudience: pipelines.kubeflow.org      </code></pre> <p>The following Python code creates a <code>kfp.Client()</code> using a ServiceAccount token for authentication:</p> <pre><code>import kfp\n\n# the value of KF_PIPELINES_SA_TOKEN_PATH is used when no `path` is set\n# otherwise, \"/var/run/secrets/kubeflow/pipelines/token\" is the default\ncredentials = kfp.auth.ServiceAccountTokenVolumeCredentials(path=None)\n\n# note, we point at the internal `Service/ml-pipeline` service,\n# rather than the external deployKF gateway\nclient = kfp.Client(host=\"http://ml-pipeline-ui.kubeflow.svc.cluster.local\", credentials=credentials)\n\n# check that we can list experiments\nexperiments = client.list_experiments(namespace=\"my-profile\")\nprint(experiments)\n</code></pre> <p>RBAC Access</p> <p>By default, this token will only have access to Kubeflow Pipelines resources in the same namespace as the Pod.</p> <p>PodDefault for ServiceAccount Token Volume</p> <p>The <code>kubeflow_tools.pipelines.profileResourceGeneration.kfpApiTokenPodDefault</code> value  configures if a <code>PodDefault</code> named <code>\"kubeflow-pipelines-api-token\"</code> is automatically generated in each profile namespace.</p> <p>If this value is set to <code>true</code>, then any Pod in a profile namespace having a <code>kubeflow-pipelines-api-token</code> label with value <code>\"true\"</code> will automatically have a ServiceAccount token volume mounted to the Pod.</p>"},{"location":"user-guides/gitops-for-kubeflow-pipelines/","title":"GitOps for Kubeflow Pipelines","text":"<p>This guide explains how to use GitOps to manage Kubeflow Pipelines (pipeline definitions, schedules).</p>"},{"location":"user-guides/gitops-for-kubeflow-pipelines/#overview","title":"Overview","text":"<p>We provide a reference implementation for managing Kubeflow Pipelines (pipeline definitions, schedules) using GitOps in the <code>deployKF/kubeflow-pipelines-gitops</code> GitHub repo.</p> <p>This repository is logically grouped into four steps:</p> <ol> <li>Render Pipelines: demonstrates how to render pipelines</li> <li>Run Pipelines: demonstrates how run the rendered pipelines</li> <li>Schedule Pipelines: demonstrates how to schedule the rendered pipelines</li> <li>Automatic Reconciliation: demonstrates how to automatically reconcile the schedule configs</li> </ol>"}]}